{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we get +15% RAG hit_rate improvement for question answering on documentation?\n",
    "\n",
    "- On most scenarios OpenAI's Ada model paired with a naive similarity search can produce satisfactory results.\n",
    "- and the primary factors to consider when implementing RAGs in production settings are accuracy (recall), cost, and latency.\n",
    "- For higher accuracy or recall during searches, one might need to employ advanced retrieval techniques. These methods might involve varying data chunk sizes, rewriting queries multiple times, and more, potentially increasing latency and costs.\n",
    "- Activeloop's deep memory addresses the LLM's pipeline issues and introuduce a tiny neural network layer to trained to match user queries. This can increase accuracy upto 27% and remains cost effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def get_all_links(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the page: {url}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Finding all 'a' tags which typically contain href attribute for links\n",
    "    links = [\n",
    "        urljoin(url, a[\"href\"])\n",
    "        for a in soup.find_all(\"a\", href=True)\n",
    "        if a[\"href\"]\n",
    "    ]\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages:  94%|#########4| 116/123 [00:15<00:01,  6.69it/s]Failed to decode content from https://docs.deeplake.ai/_/downloads/en/latest/pdf/\n",
      "Failed to decode content from https://docs.deeplake.ai/_/downloads/en/latest/epub/\n",
      "Fetching pages: 100%|##########| 123/123 [00:19<00:00,  6.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import AsyncHtmlLoader\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from llama_index.core import Document\n",
    "\n",
    "\n",
    "def load_documents(url):\n",
    "    all_links = get_all_links(url)\n",
    "    loader = AsyncHtmlLoader(all_links)\n",
    "    docs = loader.load()\n",
    "\n",
    "    html2text = Html2TextTransformer()\n",
    "    docs_transformed = html2text.transform_documents(docs)\n",
    "    docs = [Document.from_langchain_format(doc) for doc in docs_transformed]\n",
    "    return docs\n",
    "\n",
    "docs = load_documents(\"https://docs.deeplake.ai/en/latest/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest\n",
      "\n",
      "Getting Started\n",
      "\n",
      "  * Installation\n",
      "\n",
      "Key Concepts\n",
      "\n",
      "  * Datasets\n",
      "  * Vector Store\n",
      "  * Tensors\n",
      "  * Htypes\n",
      "  * Compressions\n",
      "  * PyTorch and Tensorflow Support\n",
      "  * Utility Functions\n",
      "\n",
      "Integrations\n",
      "\n",
      "  * Weights and Biases\n",
      "  * MMDetection\n",
      "\n",
      "High-Performance Features\n",
      "\n",
      "  * Dataloader\n",
      "  * Sampler\n",
      "  * Tensor Query Language\n",
      "  * Random Split\n",
      "  * Deep Memory\n",
      "\n",
      "API Reference\n",
      "\n",
      "  * deeplake\n",
      "  * deeplake.VectorStore\n",
      "  * deeplake.core\n",
      "  * deeplake.core.dataset\n",
      "  * deeplake.core.tensor\n",
      "  * deeplake.api\n",
      "  * deeplake.auto\n",
      "  * deeplake.util\n",
      "  * deeplake.client.log\n",
      "  * deeplake.core.transform\n",
      "  * deeplake.core.vectorstore.deep_memory\n",
      "  * deeplake.random.seed\n",
      "\n",
      "__Deep Lake\n",
      "\n",
      "  * »\n",
      "  * Deep Lake API Reference\n",
      "  * Edit on GitHub\n",
      "\n",
      "* * *\n",
      "\n",
      "# Deep Lake API Reference\n",
      "\n",
      "Deep Lake is an open-source database for AI.\n",
      "\n",
      "Getting Started\n",
      "\n",
      "  * Installation\n",
      "\n",
      "Key Concepts\n",
      "\n",
      "  * Datasets\n",
      "    * Creating Datasets\n",
      "    * Loading Datasets\n",
      "    * Deleting and Renaming Datasets\n",
      "    * Copying Datasets\n",
      "    * Dataset Operations\n",
      "    * Dataset Visualization\n",
      "    * Dataset Credentials\n",
      "    * Dataset Properties\n",
      "    * Dataset Version Control\n",
      "    * Dataset Views\n",
      "  * Vector Store\n",
      "    * Creating a Deep Lake Vector Store\n",
      "    * Vector Store Operations\n",
      "    * Vector Store Properties\n",
      "  * Tensors\n",
      "    * Creating Tensors\n",
      "    * Deleting and Renaming Tensors\n",
      "    * Adding and deleting samples\n",
      "    * Retrieving samples\n",
      "    * Tensor Properties\n",
      "    * Info\n",
      "    * Video features\n",
      "  * Htypes\n",
      "    * Image Htype\n",
      "    * Video Htype\n",
      "    * Audio Htype\n",
      "    * Class Label Htype\n",
      "    * Tag Htype\n",
      "    * Bounding Box Htype\n",
      "    * 3D Bounding Box Htype\n",
      "    * Intrinsics Htype\n",
      "    * Segmentation Mask Htype\n",
      "    * Binary Mask Htype\n",
      "    * COCO Keypoints Htype\n",
      "    * Point Htype\n",
      "    * Polygon Htype\n",
      "    * Nifti Htype\n",
      "    * Point Cloud Htype\n",
      "    * Mesh Htype\n",
      "    * Embedding Htype\n",
      "    * Sequence htype\n",
      "    * Link htype\n",
      "  * Compressions\n",
      "    * Sample Compression\n",
      "    * Chunk Compression\n",
      "  * PyTorch and Tensorflow Support\n",
      "  * Utility Functions\n",
      "    * General Functions\n",
      "    * Making Deep Lake Samples\n",
      "    * Parallelism\n",
      "\n",
      "Integrations\n",
      "\n",
      "  * Weights and Biases\n",
      "    * Logging Dataset Creation\n",
      "    * Logging Dataset Read\n",
      "  * MMDetection\n",
      "\n",
      "High-Performance Features\n",
      "\n",
      "  * Dataloader\n",
      "  * Sampler\n",
      "  * Tensor Query Language\n",
      "  * Random Split\n",
      "  * Deep Memory\n",
      "\n",
      "API Reference\n",
      "\n",
      "  * deeplake\n",
      "  * deeplake.VectorStore\n",
      "  * deeplake.core\n",
      "  * deeplake.core.dataset\n",
      "  * deeplake.core.tensor\n",
      "  * deeplake.api\n",
      "  * deeplake.auto\n",
      "  * deeplake.util\n",
      "  * deeplake.client.log\n",
      "  * deeplake.core.transform\n",
      "  * deeplake.core.vectorstore.deep_memory\n",
      "  * deeplake.random.seed\n",
      "\n",
      "# Indices and tables\n",
      "\n",
      "  * Index\n",
      "\n",
      "  * Module Index\n",
      "\n",
      "  * Search Page\n",
      "\n",
      "Next\n",
      "\n",
      "* * *\n",
      "\n",
      "(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n",
      "\n",
      "Built with Sphinx using a theme provided by Read the Docs.\n",
      "\n",
      "Read the Docs v: latest\n",
      "\n",
      "Versions\n",
      "\n",
      "    latest\n",
      "    v3.1.5\n",
      "    v3.1.0\n",
      "    v3.0.16\n",
      "    v3.0.15\n",
      "    v2.8.5\n",
      "\n",
      "Downloads\n",
      "\n",
      "    pdf\n",
      "    epub\n",
      "\n",
      "On Read the Docs\n",
      "\n",
      "     Project Home\n",
      "     Builds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://akshatunsubscribe/deeplake_docs_deepmemory2 already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.evaluation import generate_question_context_pairs\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "username = \"akshatunsubscribe\"\n",
    "\n",
    "vector_store = DeepLakeVectorStore(\n",
    "    dataset_path= f\"hub://{username}/deeplake_docs_deepmemory2\",\n",
    "    overwrite=False,  # set to True to overwrite the existing dataset\n",
    "    runtime={\"tensor_db\": True},\n",
    "    token=token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modules(vector_store, docs=[], populate_vector_store=True):\n",
    "    if populate_vector_store:\n",
    "        node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
    "        nodes = node_parser.get_nodes_from_documents(docs)\n",
    "    else:\n",
    "        nodes = []\n",
    "\n",
    "    # by default, the node ids are set to random uuids. To ensure same id's per run, we manually set them.\n",
    "    for idx, node in enumerate(nodes):\n",
    "        node.id_ = f\"node_{idx}\"\n",
    "\n",
    "    llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    return storage_context, nodes, llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    storage_context,\n",
    "    nodes,\n",
    "    llm,\n",
    ") = create_modules(\n",
    "    vector_store=vector_store,\n",
    "    docs=docs,\n",
    "    # populate_vector_store=False, # uncomment this line to skip populating the vector store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex(nodes, storage_context= storage_context)\n",
    "deep_memory_retriever = vector_index.as_retriever(\n",
    "    similarity_top_k= 4,\n",
    "    deep_memory = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training deep memory\n",
    "\n",
    "To train the deep memory model we need to create the following things:\n",
    "\n",
    "- **question**: is a text of strings, where each string represents a query.\n",
    "- **relevance**: Contains links to the ground truth for each question. There might be several docs that contain an answer to the given question. Because of this, relevance is `List[List[tuple[str, float]]]`. All the list present in the first hierarchy contains their corresponding query data. The 2nd list (list of tuples) contains a str, float pair where the string represents the id of the source doc while the float contains how much the current document is related to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_SAMPLES = 600\n",
    "TRAIN_QA_DATASET_PATH = f\"./data/deeplake_docs_{NO_OF_SAMPLES}_train.json\"\n",
    "TEST_QA_DATASET_PATH = f\"./data/deeplake_docs_{NO_OF_SAMPLES}_train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset\n",
    ")\n",
    "import random\n",
    "\n",
    "def create_train_test_datasets(\n",
    "        num_of_samples= 600,\n",
    "        llm= None,\n",
    "        nodes= None,\n",
    "        save= False\n",
    "):\n",
    "    random_indices = random.sample(range(len(nodes)), num_of_samples)\n",
    "    \n",
    "    # ratio of train=80% and test=20%\n",
    "    ratio = int(len(random_indices) * 0.8)\n",
    "\n",
    "    # random indices for train/test\n",
    "    train_indices, test_indices = random_indices[:ratio], random_indices[ratio:]\n",
    "\n",
    "    # sample random nodes for train/test\n",
    "    train_nodes= [nodes[i] for i in train_indices]\n",
    "    test_nodes= [nodes[i] for i in test_indices]\n",
    "\n",
    "    # generate train question\n",
    "    train_qa_dataset = generate_question_context_pairs(\n",
    "        train_nodes,\n",
    "        llm= llm,\n",
    "        num_questions_per_chunk=1\n",
    "    )\n",
    "\n",
    "    # generate test question\n",
    "    test_qa_dataset = generate_question_context_pairs(\n",
    "        test_nodes,\n",
    "        llm= llm,\n",
    "        num_questions_per_chunk=1\n",
    "    )\n",
    "\n",
    "    if save:\n",
    "        train_qa_dataset.save_json(TRAIN_QA_DATASET_PATH)\n",
    "        test_qa_dataset.save_json(TEST_QA_DATASET_PATH)        \n",
    "\n",
    "    return train_qa_dataset, test_qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TRAIN_QA_DATASET_PATH) or not os.path.exists(TEST_QA_DATASET_PATH):\n",
    "    train_qa_dataset, test_qa_dataset = create_train_test_datasets(nodes= nodes, llm= llm, save=True)\n",
    "else:\n",
    "    train_qa_dataset = EmbeddingQAFinetuneDataset.from_json(TRAIN_QA_DATASET_PATH)\n",
    "    test_qa_dataset  = EmbeddingQAFinetuneDataset.from_json(TEST_QA_DATASET_PATH)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_relevance(qa_dataset: EmbeddingQAFinetuneDataset):\n",
    "    \"\"\"Function for converting llama-index dataset to correct format for deep memory training\"\"\"\n",
    "    \n",
    "    # extract the queries from the dataset\n",
    "    queries = [text for _, text in qa_dataset.queries.items()]\n",
    "\n",
    "    # extract the relevant docs from the dataset\n",
    "    relevance = [ [(qa_dataset.relevant_docs[doc][0], 1)] for doc in qa_dataset.relevant_docs]\n",
    "\n",
    "    return queries, relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries, train_relevance = create_query_relevance(train_qa_dataset)\n",
    "test_queries, test_relevance = create_query_relevance(test_qa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How does the `create_shape_tensor` parameter impact the reading of sample shapes in a dataset?', 'What are the exceptions to the rule that no data is loaded until a sample is read from a dataset?', 'How can credentials be added to a dataset for authentication purposes?']\n",
      "========================================\n",
      "[[('node_683', 1)], [('node_683', 1)], [('node_683', 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(train_queries[:3])\n",
    "print(\"=\" * 40)\n",
    "print(train_relevance[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "job_id= vector_store._vectorstore.deep_memory.train(\n",
    "    queries= train_queries,\n",
    "    relevance= train_relevance,\n",
    "    embedding_function= embeddings.embed_documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/akshatunsubscribe/deeplake_docs_deepmemory2\n",
      "--------------------------------------------------------------\n",
      "|                  66014b4db56bbac8b7a0161a                  |\n",
      "--------------------------------------------------------------\n",
      "| status                     | completed                     |\n",
      "--------------------------------------------------------------\n",
      "| progress                   | eta: 78.1 seconds             |\n",
      "|                            | recall@10: 64.5% (+30.6%)     |\n",
      "--------------------------------------------------------------\n",
      "| results                    | recall@10: 64.5% (+30.6%)     |\n",
      "--------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_id = \"66014b4db56bbac8b7a0161a\"\n",
    "vector_store._vectorstore.deep_memory.status(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshat/Documents/courses/ActiveloopProdRAG/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding queries took 33.28 seconds\n",
      "---- Evaluating without Deep Memory ---- \n",
      "Recall@1:\t  7.5%\n",
      "Recall@3:\t  17.7%\n",
      "Recall@5:\t  24.3%\n",
      "Recall@10:\t  34.1%\n",
      "Recall@50:\t  69.6%\n",
      "Recall@100:\t  83.2%\n",
      "---- Evaluating with Deep Memory ---- \n",
      "Recall@1:\t  44.8%\n",
      "Recall@3:\t  77.2%\n",
      "Recall@5:\t  83.7%\n",
      "Recall@10:\t  91.2%\n",
      "Recall@50:\t  98.9%\n",
      "Recall@100:\t  99.5%\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "recalls = vector_store._vectorstore.deep_memory.evaluate(\n",
    "    queries= test_queries,\n",
    "    relevance= test_relevance,\n",
    "    embedding_function= embeddings.embed_documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prv results with same details\n",
    "\n",
    "```Embedding queries took 5.03 seconds\n",
    "---- Evaluating without Deep Memory ---- \n",
    "Recall@1:\t  4.9%\n",
    "Recall@3:\t  14.5%\n",
    "Recall@5:\t  20.7%\n",
    "Recall@10:\t  32.2%\n",
    "Recall@50:\t  70.5%\n",
    "Recall@100:\t  83.7%\n",
    "---- Evaluating with Deep Memory ---- \n",
    "Recall@1:\t  6.4%\n",
    "Recall@3:\t  21.8%\n",
    "Recall@5:\t  28.7%\n",
    "Recall@10:\t  46.3%\n",
    "Recall@50:\t  90.7%\n",
    "Recall@100:\t  95.1%```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "\n",
    "- The above results show that how deep memory significantly increases the recall.\n",
    "- The resutls may be different for different LLM's. \n",
    "- Here we are using `gpt-3.5-turbo` and `gpt-4` can be used to increase the recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRR & Hit Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def display_results(eval_results):\n",
    "    \"\"\"Display results from evaluate\"\"\"\n",
    "\n",
    "    hit_rates = []\n",
    "    mrrs = []\n",
    "    names = []\n",
    "\n",
    "    for name, eval_result in eval_results.items():\n",
    "\n",
    "        metric_dicts = [er.metric_vals_dict for er in eval_result]\n",
    "\n",
    "        full_df = pd.DataFrame(metric_dicts)\n",
    "\n",
    "        hit_rate = full_df['hit_rate'].mean()\n",
    "        mrr = full_df['mrr'].mean()\n",
    "\n",
    "        hit_rates.append(hit_rate)\n",
    "        mrrs.append(mrr)\n",
    "        names.append(name)\n",
    "\n",
    "    metric_df = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"retrievers\": names[i],\n",
    "                \"hit_rate\": hit_rates[i],\n",
    "                \"mrr\": mrrs[i] \n",
    "            } for i in range(len(names))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep memory retriever eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VectorStoreIndex' object has no attribute 'as_retriver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetrieverEvaluator\n\u001b[0;32m----> 3\u001b[0m deep_memory_retriver \u001b[38;5;241m=\u001b[39m \u001b[43mvector_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_retriver\u001b[49m(\n\u001b[1;32m      4\u001b[0m     similarity_top_k\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      5\u001b[0m     vector_store_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeep_memory\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m dm_retriver_evaluator\u001b[38;5;241m=\u001b[39m RetrieverEvaluator\u001b[38;5;241m.\u001b[39mfrom_metric_names([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmrr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhit_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m], retriver\u001b[38;5;241m=\u001b[39m deep_memory_retriver)\n\u001b[1;32m      9\u001b[0m dm_eval_results\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m dm_retriver_evaluator\u001b[38;5;241m.\u001b[39maevaluate_dataset(test_qa_dataset, retriver\u001b[38;5;241m=\u001b[39m dm_retriver_evaluator, show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m) \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VectorStoreIndex' object has no attribute 'as_retriver'"
     ]
    }
   ],
   "source": [
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "\n",
    "deep_memory_retriver = vector_index.as_retriever(\n",
    "    similarity_top_k= 10,\n",
    "    vector_store_kwargs={\"deep_memory\" : True}\n",
    ")\n",
    "\n",
    "dm_retriver_evaluator= RetrieverEvaluator.from_metric_names([\"mrr\", \"hit_rate\"], retriver= deep_memory_retriver)\n",
    "dm_eval_results= await dm_retriver_evaluator.aevaluate_dataset(test_qa_dataset, retriver= dm_retriver_evaluator, show_progress=True, workers=8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive retriever eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2639 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 274/2639 [30:43<3:56:31,  6.00s/it]"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m naive_retriever\u001b[38;5;241m=\u001b[39m vector_index\u001b[38;5;241m.\u001b[39mas_retriever(similarity_top_k\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      4\u001b[0m naive_retriever_evaluator\u001b[38;5;241m=\u001b[39m RetrieverEvaluator\u001b[38;5;241m.\u001b[39mfrom_metric_names([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmrr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhit_rate\u001b[39m\u001b[38;5;124m'\u001b[39m], retriever\u001b[38;5;241m=\u001b[39m naive_retriever)\n\u001b[0;32m----> 6\u001b[0m naive_eval_results\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m naive_retriever_evaluator\u001b[38;5;241m.\u001b[39maevaluate_dataset(test_qa_dataset, retriever\u001b[38;5;241m=\u001b[39m naive_retriever, show_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m) \n",
      "File \u001b[0;32m~/Documents/courses/ActiveloopProdRAG/.venv/lib/python3.10/site-packages/llama_index/core/evaluation/retrieval/base.py:195\u001b[0m, in \u001b[0;36mBaseRetrievalEvaluator.aevaluate_dataset\u001b[0;34m(self, dataset, workers, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_progress:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masyncio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm_asyncio\n\u001b[0;32m--> 195\u001b[0m     eval_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m tqdm_asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mresponse_jobs)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     eval_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mresponse_jobs)\n",
      "File \u001b[0;32m~/Documents/courses/ActiveloopProdRAG/.venv/lib/python3.10/site-packages/tqdm/asyncio.py:79\u001b[0m, in \u001b[0;36mtqdm_asyncio.gather\u001b[0;34m(cls, loop, timeout, total, *fs, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m i, \u001b[38;5;28;01mawait\u001b[39;00m f\n\u001b[1;32m     78\u001b[0m ifs \u001b[38;5;241m=\u001b[39m [wrap_awaitable(i, f) \u001b[38;5;28;01mfor\u001b[39;00m i, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fs)]\n\u001b[0;32m---> 79\u001b[0m res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mawait\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mas_completed(ifs, loop\u001b[38;5;241m=\u001b[39mloop, timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m     80\u001b[0m                                          total\u001b[38;5;241m=\u001b[39mtotal, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtqdm_kwargs)]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [i \u001b[38;5;28;01mfor\u001b[39;00m _, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(res)]\n",
      "File \u001b[0;32m~/Documents/courses/ActiveloopProdRAG/.venv/lib/python3.10/site-packages/tqdm/asyncio.py:79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m i, \u001b[38;5;28;01mawait\u001b[39;00m f\n\u001b[1;32m     78\u001b[0m ifs \u001b[38;5;241m=\u001b[39m [wrap_awaitable(i, f) \u001b[38;5;28;01mfor\u001b[39;00m i, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fs)]\n\u001b[0;32m---> 79\u001b[0m res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mawait\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mas_completed(ifs, loop\u001b[38;5;241m=\u001b[39mloop, timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m     80\u001b[0m                                          total\u001b[38;5;241m=\u001b[39mtotal, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtqdm_kwargs)]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [i \u001b[38;5;28;01mfor\u001b[39;00m _, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(res)]\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py:567\u001b[0m, in \u001b[0;36mas_completed.<locals>._wait_for_one\u001b[0;34m()\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_for_one\u001b[39m():\n\u001b[0;32m--> 567\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m done\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         \u001b[38;5;66;03m# Dummy value from _on_timeout().\u001b[39;00m\n\u001b[1;32m    570\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTimeoutError\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/queues.py:159\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getters\u001b[38;5;241m.\u001b[39mappend(getter)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m getter\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     getter\u001b[38;5;241m.\u001b[39mcancel()  \u001b[38;5;66;03m# Just in case getter is not done yet.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/futures.py:285\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "\n",
    "naive_retriever= vector_index.as_retriever(similarity_top_k= 10)\n",
    "naive_retriever_evaluator= RetrieverEvaluator.from_metric_names(['mrr', 'hit_rate'], retriever= naive_retriever)\n",
    "\n",
    "naive_eval_results= await naive_retriever_evaluator.aevaluate_dataset(test_qa_dataset, retriever= naive_retriever, show_progress=True, workers=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = {\n",
    "    f\"{mode} with Deep Memory top-10 eval\": eval_result\n",
    "    for mode, eval_result in zip(\n",
    "        [\"with\", \"without\"], [dm_eval_results, naive_eval_results]\n",
    "    )\n",
    "}\n",
    "\n",
    "display_results(eval_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine= vector_index.as_query_engine(\n",
    "    vector_store_kwargs= {\"deep_memory\": True}, llm= llm\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"How can you connect your own storage to the deeplake?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine(\n",
    "    vector_store_kwargs={\"deep_memory\" : False}, llm= llm\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"How can you connect your own storage to the deeplake?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
