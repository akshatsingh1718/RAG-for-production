{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to choose ?\n",
    "\n",
    "- Finetuning\n",
    "- RAG\n",
    "- Open source LLM\n",
    "- Closed source LLM\n",
    "\n",
    "## Deadline is nearby ?\n",
    "\n",
    "If your deadline is nearby to include a LLM model for more accurate retrieval and generation it is recommended to use closded source LLM (like GPT-4 or Claude) as they are mostly trained with huge amount of quality data and may outform other open source LLM's.\n",
    "\n",
    "\n",
    "## Try Few shots prompting\n",
    "\n",
    "> Note: Use this when your use case is not necessarily knowledge specific and models like GPT-4 can answer from their parametric knowledge.\n",
    "\n",
    "Given some examples as what we expect from LLM to produce is a very popular technique while using LLM based application where you expect structured output without finetuning. This technique is not limited to just structured response but can also effect the following things:\n",
    "\n",
    "- Specific writing style.\n",
    "- Set specific formatting guidelines.\n",
    "- Provide additional context for answering question.\n",
    "\n",
    "## RAG\n",
    "\n",
    "> Note: When your model is dealing with a lot of hallucinations about user query and information.\n",
    "\n",
    "This is when the model's input is modified by adding new text data called context. This context has the data which is stored in vector db and is retrieved using the user query similarity to the documents in the vector database. \n",
    "\n",
    "The rag can be used to deal with the follwoing things:\n",
    "\n",
    "- Getting more accurate results for the user specific information.\n",
    "- To fix models hallucinations.\n",
    "- To fix biases from the initial training.\n",
    "\n",
    "\n",
    "## Fine-tuning\n",
    "\n",
    "> Note: Perform this only if you have enough time, resources and high quality data.\n",
    "\n",
    "- Finetuning is generally done to make the exisiting models strictly follow a very complex structure. \n",
    "- The model can better learn to perform specific actions like summarization & classification. \n",
    "- This method will update the models weights.\n",
    "- This can be done in the followings ways:\n",
    "    - Adjust the weights with a small learning rate to minimally affect the model's general abilities.\n",
    "    - or Freez the network weights and introducing new weights for fine tuning. (LoRA & QLoRA)\n",
    "\n",
    "\n",
    "\n",
    "## From scratch\n",
    "\n",
    "- This is the most intensive task which requries immense time, resources and data.\n",
    "- This is generally done by huge labs such as meta ai and google. The training of a good size model can take up to millions of dollars"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
