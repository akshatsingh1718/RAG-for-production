{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mastering Advanced RAG Techniques with LlamaIndex\n",
    "\n",
    "In this lesson you will learn the following:\n",
    "- Choere Re-ranker.\n",
    "- Streaming Query engines with top n retrievals.\n",
    "- `SubqueryTool` which can produce new sub question for effecient retrievals of each different part of question. \n",
    "\n",
    "# Intro\n",
    "The Retrieval-Augmented Generation (RAG) pipeline heavily relies on retrieval performance guided by the adoption of various techniques and advanced strategies. Methods like query expansion, query transformations, and query construction each play a distinct role in refining the search process. \n",
    "\n",
    "# Querying in LlamaIndex\n",
    "\n",
    "- Retrievers: These classes are designed to retrieve a set of nodes from an index based on a given query. Retrievers source the relevant data from the index.\n",
    "- Query Engine: It is the central class that processes a query and returns a response object. Query Engine leverages the retrievers and the response synthesizer modules to curate the final output.\n",
    "- Query Transform: It is a class that enhances a raw query string with various transformations to improve the retrieval efficiency. It can be used in conjunction with a Retriever and a Query Engine.\n",
    "\n",
    "# Query Construction\n",
    "The core idea is to answer user queries by leveraging the inherent structure of the data. For instance, a query like \"movies about aliens in the year 1980\" combines a semantic component like \"aliens\" (which will get better results if retrieved through vector storage) with a structured component like \"year == 1980\". The process involves translating a natural language query into the query language of a specific database, such as SQL for relational databases or Cypher for graph databases.\n",
    "\n",
    "# Query Expansion\n",
    "\n",
    "- Query expansion works by extending the original query with additional terms or phrases that are related or synonymous.\n",
    "\n",
    "- if the original query is too narrow or uses specific terminology, query expansion can include broader or more commonly used terms relevant to the topic. Eg. \"climate change effects.\" -> involve adding related terms or synonyms to this query, such as \"global warming impact,\" \"environmental consequences,\" or \"temperature rise implications.\"\n",
    "\n",
    "- One approach to do it is utilizing the `synonym_expand_policy` from the `KnowledgeGraphRAGRetriever` class. In the context of LlamaIndex, the effectiveness of query expansion is usually enhanced when combined with the Query Transform class.\n",
    "\n",
    "# Query Transformation\n",
    "\n",
    "- modifies query to retrieve relevant more information.\n",
    "- It can include changes in query structure, the use of synonyms, or the inclusion of contextual information.\n",
    "- create query more optimized for search engines and vector db. Eg \"What were Microsoft's revenues in 2021?\" -> “Microsoft revenues 2021”.\n",
    "\n",
    "# Query Engine\n",
    "\n",
    "- Interact with data using nlq.\n",
    "- Multiple query engines can be combined for enhance functionlaity, catering to complex data interrogation needs.\n",
    "- Use Chat Engines to proivde more dynamic and engaging interaction with data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-09 12:30:16--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘./data/paul_graham_essay.txt’\n",
      "\n",
      "./data/paul_graham_ 100%[===================>]  73.28K  --.-KB/s    in 0.07s   \n",
      "\n",
      "2024-03-09 12:30:17 (1.05 MB/s) - ‘./data/paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p './data/'\n",
    "! wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O './data/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.readers import SimpleDirectoryReader\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(input_files=[\"./data/paul_graham_essay.txt\"]).load_data()\n",
    "\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_376507/1600606042.py:3: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(chunk_size= 512, chunk_overlap= 64)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import ServiceContext\n",
    "\n",
    "service_context = ServiceContext.from_defaults(chunk_size= 512, chunk_overlap= 64)\n",
    "node_parser= service_context.node_parser\n",
    "# default splitter is : SentenceSplitter\n",
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshat/Documents/courses/ActiveloopProdRAG/.venv/lib/python3.10/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.23) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "# Instantiate vector db\n",
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
    "\n",
    "my_activeloop_org_id = \"akshatsingh1718\"\n",
    "my_activeloop_dataset_name = \"LlamaIndex_paulgraham_essays\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "\n",
    "# Create an index over the documnts\n",
    "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading data to deeplake dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:04<00:00,  9.34it/s]\n",
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://akshatsingh1718/LlamaIndex_paulgraham_essays', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      "   text       text      (40, 1)      str     None   \n",
      " metadata     json      (40, 1)      str     None   \n",
      " embedding  embedding  (40, 1536)  float32   None   \n",
      "    id        text      (40, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "storage_context.docstore.add_documents(nodes)\n",
    "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create query engine \n",
    "query_engine = vector_index.as_query_engine(streaming=True, similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is involved in various activities such as founding and running companies, writing essays, working on programming projects like creating a new Lisp dialect called Arc, and starting initiatives like Y Combinator to fund and support startups."
     ]
    }
   ],
   "source": [
    "streaming_response = query_engine.query(\n",
    "    \"What does Paul Graham do?\",\n",
    ")\n",
    "streaming_response.print_response_stream()\n",
    "# Streaming will provide a sense to the user that our chatbot is typing in real time and reduce idle time for end users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine(similarity_top_k=10)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"pg_essay\",\n",
    "            description=\"Paul Graham essay on What I Worked On\",\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "query_engine = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools=query_engine_tools,\n",
    "    service_context=service_context,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[pg_essay] Q: What did Paul Graham work on before Y Combinator?\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[pg_essay] Q: What did Paul Graham work on during Y Combinator?\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[pg_essay] Q: What did Paul Graham work on after Y Combinator?\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[pg_essay] A: Paul Graham worked on a new version of Arc before Y Combinator.\n",
      "\u001b[0m\u001b[1;3;38;2;90;149;237m[pg_essay] A: Paul Graham worked on writing essays, working on Y Combinator (YC), and developing a new version of Arc during his time at Y Combinator.\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203m[pg_essay] A: After Y Combinator, Paul Graham worked on a new dialect of Lisp called Arc in a house he bought in Cambridge.\n",
      "\u001b[0m>>> The final response:\n",
      " Paul Graham's life involved working on a new version of Arc before Y Combinator, during Y Combinator he focused on writing essays, working on Y Combinator (YC), and developing a new version of Arc, and after Y Combinator, he worked on a new dialect of Lisp called Arc in a house he bought in Cambridge.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"How was Paul Grahams life different before, during, and after YC?\"\n",
    ")\n",
    "print( \">>> The final response:\\n\", response )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1 sub questions.\n",
      "\u001b[1;3;38;2;237;90;200m[pg_essay] Q: What is Python programming language?\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200m[pg_essay] A: Python is a high-level programming language known for its simplicity and readability. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is widely used for web development, data analysis, artificial intelligence, scientific computing, and more. It emphasizes code readability and has a large standard library that makes it suitable for various applications.\n",
      "\u001b[0m>>> The final response:\n",
      " Python is a high-level programming language that is recognized for its simplicity, readability, and versatility. It supports various programming paradigms such as procedural, object-oriented, and functional programming. Python finds extensive use in web development, data analysis, artificial intelligence, scientific computing, and other fields due to its emphasis on code readability and its comprehensive standard library.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is python programming language ?\"\n",
    ")\n",
    "print( \">>> The final response:\\n\", response )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Retriever Engine\n",
    "\n",
    "- `QueryEngine` depends heavily on retriever and its parameters (# of docs returned).\n",
    "- `LlamaIndex` supports custom retrievers which consist of combination of different retriever styles, creating more nuanced retrieval strategies that adapt to distinct individual queries. \n",
    "- `RetrieverQueryEngine` operates with a designated retriever and are of two types:\n",
    "    - `VectorIndexRetriever`: The retreiver used till now is this one. It fetches top-k nodes that are most similar to the query and ensure the result closley align with the query. It is ideal where precision and relevance to the specific query are dominant.\n",
    "    - `SummaryIndexRetriever`: This approach is less concerned with aligining closely to the specific context of the question and more about providing a broad overview. Useful where a comprehensive sweep of information is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking\n",
    "\n",
    "- Reranking is re-evaluating and re-ordering search results to present the most relevant options.\n",
    "- One can removes the lower scores chunks and boost's LLM performance.\n",
    "- It sorts the search results according to their relevance to the query.\n",
    "- Retrieval can fetch multiple docs which may be irrevalant to the users query.\n",
    "- `Cohere` reranker is uded for complex and domain-specific queries. \n",
    "- It is not a replacement to the search engine but a supplementary tool for sorting search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cohere\n",
      "  Downloading cohere-4.53-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in ./.venv/lib/python3.10/site-packages (from cohere) (3.9.3)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in ./.venv/lib/python3.10/site-packages (from cohere) (2.2.1)\n",
      "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
      "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in ./.venv/lib/python3.10/site-packages (from cohere) (6.11.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in ./.venv/lib/python3.10/site-packages (from cohere) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in ./.venv/lib/python3.10/site-packages (from cohere) (2.0.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.10/site-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.25.0->cohere) (2024.2.2)\n",
      "Downloading cohere-4.53-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fastavro, cohere\n",
      "Successfully installed cohere-4.53 fastavro-1.9.4\n"
     ]
    }
   ],
   "source": [
    "! pip3 install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import os\n",
    "\n",
    "# os.environ['COHERE_API_KEY'] = \"<YOUR_COHERE_API_KEY>\"\n",
    "\n",
    "# Get your cohere API key on: www.cohere.com\n",
    "co = cohere.Client(os.environ['COHERE_API_KEY'])\n",
    "\n",
    "# Example query and passages\n",
    "query = \"What is the capital of the United States?\"\n",
    "documents = [\n",
    "   \"Carson City is the capital city of the American state of Nevada. At the  2010 United States Census, Carson City had a population of 55,274.\",\n",
    "\n",
    "   \"The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean that are a political division controlled by the United States. Its capital is Saipan.\",\n",
    "   \n",
    "   \"Charlotte Amalie is the capital and largest city of the United States Virgin Islands. It has about 20,000 people. The city is on the island of Saint Thomas.\",\n",
    "   \n",
    "   \"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. \",\n",
    "   \n",
    "   \"Capital punishment (the death penalty) has existed in the United States since before the United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states.\",\n",
    "   \n",
    "   \"North Dakota is a state in the United States. 672,591 people lived in North Dakota in the year 2010. The capital and seat of government is Bismarck.\"\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Rank: 1, Document Index: 3\n",
      "Document: Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. \n",
      "Relevance Score: 0.98\n",
      "\n",
      "\n",
      "Document Rank: 2, Document Index: 1\n",
      "Document: The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean that are a political division controlled by the United States. Its capital is Saipan.\n",
      "Relevance Score: 0.30\n",
      "\n",
      "\n",
      "Document Rank: 3, Document Index: 4\n",
      "Document: Capital punishment (the death penalty) has existed in the United States since before the United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states.\n",
      "Relevance Score: 0.28\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = co.rerank(query=query, documents=documents, top_n=3, model='rerank-english-v2.0') # Change top_n to change the number of results returned. If top_n is not passed, all results will be returned.\n",
    "for idx, r in enumerate(results):\n",
    "  print(f\"Document Rank: {idx + 1}, Document Index: {r.index}\")\n",
    "  print(f\"Document: {r.document['text']}\")\n",
    "  print(f\"Relevance Score: {r.relevance_score:.2f}\")\n",
    "  print(\"\\n\")\n",
    "\n",
    "# results can also filter out on the basis of the relevancy score by providing a threshold. \n",
    "# if r.relevance_score < threshold: exclude document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-postprocessor-cohere-rerank\n",
      "  Downloading llama_index_postprocessor_cohere_rerank-0.1.2-py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: cohere<5.0,>=4.45 in ./.venv/lib/python3.10/site-packages (from llama-index-postprocessor-cohere-rerank) (4.53)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in ./.venv/lib/python3.10/site-packages (from llama-index-postprocessor-cohere-rerank) (0.10.16.post1)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in ./.venv/lib/python3.10/site-packages (from cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (3.9.3)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in ./.venv/lib/python3.10/site-packages (from cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2.0,>=1.8 in ./.venv/lib/python3.10/site-packages (from cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (1.9.4)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in ./.venv/lib/python3.10/site-packages (from cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (6.11.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in ./.venv/lib/python3.10/site-packages (from cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in ./.venv/lib/python3.10/site-packages (from cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (2.0.7)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (2.0.28)\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (2024.2.0)\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (3.8.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.13.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (10.2.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (0.9.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0,>=3.0->cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (4.0.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.10/site-packages (from importlib_metadata<7.0,>=6.0->cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (3.17.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in ./.venv/lib/python3.10/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (2.6.3)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (4.3.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.0.4)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (3.6)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (0.14.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.25.0->cohere<5.0,>=4.45->llama-index-postprocessor-cohere-rerank) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.2.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-postprocessor-cohere-rerank) (1.16.0)\n",
      "Downloading llama_index_postprocessor_cohere_rerank-0.1.2-py3-none-any.whl (2.7 kB)\n",
      "Installing collected packages: llama-index-postprocessor-cohere-rerank\n",
      "Successfully installed llama-index-postprocessor-cohere-rerank-0.1.2\n"
     ]
    }
   ],
   "source": [
    "! pip install llama-index-postprocessor-cohere-rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sam Altman initially declined the offer to become the president of Y Combinator as he wanted to start a startup focused on making nuclear reactors. However, after persistent persuasion, he eventually agreed to take over as the president starting with the winter 2014 batch.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "\n",
    "# reranker will rank the retrievals based on the query and the select the top 2 ranked retrievals\n",
    "cohere_rerank = CohereRerank(api_key=os.environ['COHERE_API_KEY'], top_n=2)\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    node_postprocessors=[cohere_rerank],\n",
    ")\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"What did Sam Altman do in this essay?\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Retrievals\n",
    "\n",
    "- Alternative method for retrieving relevant documents involves using document summaries instead of extracting fragmented snippets or brief text chunks to respond to queries. This will ensure that the ans reflect the entire context or topic being examined.\n",
    "\n",
    "- **Recursive retrieval**: This works well with hierarchical structure where there are relationships between nodes. This is found in the cases of PDF's which may contain sub-data such as tables and diagrams, alongside refrences to other documents.\n",
    "\n",
    "- **Small-to-Big retrieval**: Starting with concise and focused sentences to get the most relevant section of content using differnet rag techniques like `SentenceWindowNodeParser` and `HierarchicalNodeParser`. This technique is particularly useful in situations where the initial query may not encompass the entirety of relevant information or where the data's relationships are intricate and multi-layered."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
