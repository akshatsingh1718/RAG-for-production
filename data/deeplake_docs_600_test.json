{
    "queries": {
        "01c96154-a749-44d4-9630-b1932f4dfc44": "What is the purpose of the `deep_memory` parameter in the Vector Store initialization and how does it affect search results?",
        "6d65adf8-5381-4d9b-953d-876f72bbd92e": "Under what conditions will a `ValueError` be raised in the context of the provided information?",
        "3c0b28f1-a7de-4fea-8679-4db913c7e480": "Explain the significance of the `return_tql` parameter and when it is set to True or False.",
        "a008ac26-09a9-4980-963f-8c5c1ce0d2ad": "What is the restriction placed on using the Deep Memory model in the context of paid accounts and why is it important?",
        "8dc8ad4c-ead5-48dc-a729-ed9d416122aa": "Describe the functionality of the `summary()` method in the context of the dataset.",
        "4fbd6437-0792-4d13-be69-9e376a3a9d4f": "How can the `tensors()` method be utilized in the context of the dataset?",
        "95152146-215e-449a-bf34-09734a78db66": "Explain the purpose of the `update_embedding()` method and how it can be used to recompute existing embeddings in the Vector Store.",
        "c1740a44-623d-4010-93fb-bb4ed149f45c": "What are some of the errors that can occur related to datasets in the context provided?",
        "8e5d0988-5af1-42c5-b502-fd11ba331b6c": "Can you provide examples of errors related to chunk management in the context provided?",
        "4d545411-3904-45b5-9793-69e058dc8a56": "What are some of the errors related to version control mentioned in the context provided?",
        "ffa74c6a-887e-4955-bfa1-8ee398af1371": "How are errors related to dataset handling categorized in the context provided?",
        "4f3d732b-9672-4ca7-b075-43a312b248cc": "Can you explain the significance of the `InvalidTokenException` error in the context provided?",
        "4ff6f25c-8ca0-4022-bdcb-ef0ce05518e9": "What is the purpose of the `delete` method in the provided context? Explain the parameters and potential exceptions that can be raised when using this method.",
        "64498eac-32ac-4636-85c3-01adcd0f75d7": "How can audio samples be appended to tensors in Deep Lake?",
        "e61527ac-50c1-4a3d-97e6-06e0322c0bc9": "What are the supported compressions for audio samples in Deep Lake?",
        "16ff7c2d-7300-469e-8421-327131c24d40": "How can a class label tensor be created in Deep Lake?",
        "185f8322-0fb9-4f38-b772-06e92a9b1560": "What are the optional arguments that can be specified when creating a class label tensor?",
        "b3bfb7d3-ec37-41dd-81e0-82818c6efe2d": "How can the class names be set for a class label tensor after tensor creation in Deep Lake?",
        "0240efbb-1078-429a-a4a4-bf63489dc9b1": "What are some of the exceptions that can be raised when using the `tensorflow()` method in the `Dataset` class of the `deeplake` package?",
        "3b824761-935f-4935-906e-2bd0c0bd5dc1": "What is the purpose of the `tensors` property in the `Dataset` class of the `deeplake` package?",
        "b17fbc8a-9a27-4433-82eb-d4ac65bf4cf1": "How can you convert a tensor object to bytes using the `tobytes()` method in the `Tensor` class of the `deeplake` package?",
        "34cc7d27-3492-40e2-b660-020a78273823": "What is the significance of the `timestamps` property in the `Tensor` class of the `deeplake` package?",
        "547e3c80-7cd8-41d0-a1e7-b23cedef43d0": "How can you handle a `TokenPermissionError` when working with the `token` property in the `Dataset` class of the `deeplake` package?",
        "f01786d7-d709-4730-9741-6ea0e21f43bd": "What is the purpose of the `embedding_data` parameter in the query?",
        "533fbcc7-635a-4c06-a79b-398830aaaa02": "Can the `embedding_data` and `embedding` be specified at the same time? Why or why not?",
        "97aee20d-5559-4ed0-957c-4ea8da431c87": "How does the `embedding_function` parameter contribute to the query process?",
        "ed610337-60fe-4df9-954d-16349f83ac18": "What is the significance of the `k` parameter in the query?",
        "2e6acc4d-6968-4b00-9276-b31bedda3f05": "Explain the role of the `distance_metric` parameter in sorting the data during the search process.",
        "04f1dcfe-8b5d-4c4e-b9bb-4e1754463cb7": "How does the `filter` parameter help in refining the search results before the embedding search?",
        "2d343190-721c-45de-895a-27ae36419095": "What are the available options for the `exec_option` parameter, and how do they affect the search execution?",
        "fe34b451-27c0-41ab-8288-0947bd494305": "Compare and contrast the architectural differences between Deep Lake and Pinecone in terms of data storage, computation, and visualization capabilities.",
        "c8bfa54c-55df-49db-b4de-f2da0f454bcc": "How does Deep Lake differentiate itself from Weaviate in terms of deployment options, data storage capabilities, and support for lightweight production applications?",
        "1de89e01-0391-42fd-915d-6e2588918785": "Explain the significance of Deep Lake's performant dataloader for fine-tuning Large Language Models and how it enhances the user experience compared to other platforms mentioned in the context.",
        "138e76ac-a9e0-4253-8635-badf990431f2": "Explain the purpose of the `link` and `link_tiled` utilities in the context provided. How do they differ in their functionality?",
        "cb771657-5a21-40c6-ad95-1caea76c0d3f": "How does the `compute` decorator work in the context of the document? Provide an example to illustrate its usage.",
        "bbf6de2a-e60d-4879-97d0-f35306be45cd": "Describe the process of creating a pipeline using the `compose` function with functions decorated using `deeplake.compute()`. How does this pipeline get evaluated using `.eval`?",
        "89efe705-6083-4c0d-b561-15d29b63ebb7": "What is the role of the `eval` function in the context of transform pipelines created with `compute()` and `compose()`? How does it contribute to the processing of data?",
        "8150d622-bdc0-45e0-96a7-e5fa6db1ecba": "How can the concept of parallelism be applied in the context of the document? Provide a scenario where parallelism can be beneficial in the evaluation of pipelines.",
        "20ec9e52-2da8-454c-a4b9-723b6fbcea3a": "How can a polygon tensor be created in the given context?",
        "5c2e3734-25ee-469f-91b2-f1908ae35ec8": "What are the requirements for the points in a sample of a polygon tensor?",
        "261066cf-d0dc-4e5c-9669-5c75d0981b2d": "Can different samples in a polygon tensor have a different number of polygons? Explain.",
        "96608d83-53a9-4621-ad08-d5d952184c2c": "What are the supported compressions for creating a polygon tensor?",
        "1e0bef1d-efc7-4b10-b53a-2c118d065a0d": "How can polygons be appended to a polygon tensor in the given context?",
        "770465b0-842e-4c35-849f-6926d45b0448": "What are the two types of units specified for bounding box coordinates in the given context information?",
        "1dd221e7-759f-47e6-9ce4-90fcd2b1a0c9": "Explain the difference between the \"LTRB\" and \"LTWH\" modes for specifying bounding box coordinates.",
        "96fa15a0-4bdc-4847-90a3-bf161a174718": "How can bounding boxes be appended in the dataset using np.ndarrays or lists?",
        "4364b408-0d66-4114-a3a8-76ad2c9308ec": "When will the visualizer assume a YOLO format for bounding box coordinates?",
        "23100f8b-408f-4f99-a75c-8f022397611c": "Why is it important to specify the format of the bounding box for 3D bounding boxes in the given context information?",
        "371171b6-564a-4c51-9322-2aecdf83af14": "What is the purpose of the `get_model()` function in the DeepMemory vectorstore?",
        "f0a12fa6-9caa-4041-97c0-109f5ae1c525": "How can the `list_jobs()` function be used to manage training jobs on the DeepMemory managed service?",
        "aaba5b86-4d19-462c-b795-2d95cc1ef66e": "Explain the significance of the `set_model()` function in the context of DeepMemory vectorstore.",
        "49b656c8-f181-49a7-8e0e-96d2eb1cbc7a": "How can the `status()` function help in monitoring the progress of a training job on DeepMemory managed service?",
        "48a0b235-6996-425a-94c1-9d416263a7b2": "Describe the process of training a model using the `train()` function in the DeepMemory vectorstore.",
        "b0b08076-24c7-4dfc-97e9-0ddcfae795bd": "What is the significance of setting `ENV` when fetching credentials for cloud datasets in the context provided?",
        "685041bc-9530-44f4-96d9-d076cd634d01": "How can a Vector Store be created in Deep Lake\u2019s Managed Tensor Database according to the information given?",
        "63b6cd2e-610b-4a8d-bd68-92355169ebff": "What caution should be exercised when setting the `overwrite` parameter to `True` while working with a Vector Store?",
        "c8f2994b-30f5-4138-9538-32ae28f71ced": "Explain the purpose of the `add` function in the context of the deeplake vector store.",
        "7c24ffc2-aed5-44ad-a82e-8a4222e1cc28": "Provide an example scenario where the `add` function is used to upload embeddings directly into the deeplake vector store.",
        "dfc77299-7a58-455e-8192-5e7d5a6e6281": "What is the difference between `deeplake.copy` and `deeplake.deepcopy` in terms of copying datasets?",
        "7f5468b1-bb5c-4071-9717-69e8418cb52a": "How can you append samples to multiple tensors at once using the `Dataset` class?",
        "90d1bb35-720b-44cd-9ed7-c48b03e11555": "Explain the purpose of the `Dataset.delete` method and what it does to the dataset.",
        "e3a66ea4-2f34-4053-9c53-3f79ab6fc480": "How can you estimate the size of a dataset in bytes using the `Dataset` class?",
        "6a258251-5634-43bd-a784-97c3aa010b9e": "Describe the process of splitting a dataset into non-overlapping `Dataset` objects using the `Dataset.random_split` method.",
        "5c9b48af-bd6f-4e21-8d04-bd6f39665cd2": "What is the revision number of the document?",
        "6e6770dd-3635-41d1-82a8-34d980c60661": "What tool was used to build the document?",
        "e76df81a-3219-4264-b566-12244e218e0d": "What theme was provided by Read the Docs?",
        "874e184f-516e-4975-8fd7-0ec05ea84b65": "What is the version of the document currently being viewed?",
        "07f99f86-3fc5-47e8-b777-cf43200b70d0": "Where can the project home and builds be found on Read the Docs?",
        "58727107-0a2c-4f46-a6b7-c966073c9e2e": "What is the default value for the 'allow_no_annotation' flag?",
        "b351b99f-f7e0-4e11-abf9-353b3b0a8dae": "How can credentials be provided to access the source data?",
        "83c68153-3d02-427d-9b0e-3802077953e6": "What is the purpose of the 'inspect_limit' parameter in the context of this document?",
        "f2bfc92c-33e2-4543-9b5f-59a79f88c998": "How can the ingestion progress bar be enabled or disabled?",
        "4251ad9d-9cfe-41a3-ba11-de49c4647014": "What is the significance of the 'shuffle' parameter in data ingestion?",
        "60ef5301-f407-4cc9-bccb-9c142aea1b02": "How is the number of workers for ingestion specified in the document?",
        "d1226390-4041-4db6-b1b7-ae612b68b18a": "When would the 'image_creds_key' parameter be applicable?",
        "3589454c-ef64-4419-a0bc-b7fda66fd220": "What is the role of the 'token' parameter in accessing the dataset or connecting it to Deep Lake?",
        "3cfd73db-531a-46a3-82c1-71a05b96b3be": "What are the three options available for the `exec_option` parameter in the search execution method?",
        "f171b258-0a9a-4b15-b53b-f7fcd7638cea": "How does the `python` method differ from the `compute_engine` method in terms of implementation and usage?",
        "d7672a9c-983b-451d-af6d-9b6daf0e777b": "When creating a Deep Lake dataset, how can you specify to store the dataset in the Managed Tensor Database using the `runtime` parameter?",
        "648aa6e3-3e92-413d-83ea-3add2c076dde": "What is the default name of the tensor that contains embeddings in the search query?",
        "d94a9c32-c93f-412c-938d-45afd0398126": "How does setting `return_view` to `True` affect the `return_tensors` parameter in the search query?",
        "8e2f0da4-8d7f-40f6-a010-750f87c5bf41": "Question: How can a polygon tensor be created using the provided context information? What are the optional arguments that can be specified when creating a polygon tensor?",
        "2196a9c9-5c0b-4ddc-a3f4-daff87e0e6b6": "Explain the process of creating an image tensor and appending image samples in the context of the Image Htype.",
        "15199179-2da6-46d2-8d12-476054984c2b": "How can you store your credentials on the Activeloop Platform for datasets?",
        "c39586bd-13e9-4487-9c76-909855fc5ffb": "What is the purpose of using managed credentials in the context of adding keys to a dataset?",
        "b0b13251-4394-4ab7-b9fb-e1111be56c95": "How can you create a link tensor for images in the dataset?",
        "f5be46a2-840c-42e4-998b-f1da4ad668a0": "Provide examples of different ways to populate the image tensor with links, including when credentials are required and when they are not.",
        "ee5d67cb-3f1c-4135-9bba-f7dccd462270": "How can you access the data stored in the image tensor using a loop?",
        "d0cabbca-041e-4af4-8c26-79c4721147de": "How can you update a sample in the dataset with a new link to an image?",
        "6d423df4-3c2a-4c81-bb6a-1ceb9f101569": "Explain the process of creating a point cloud tensor using the `create_tensor` method in the given context. What are the optional arguments that can be used during the creation of a point cloud tensor?",
        "3f25c521-f6a2-4fa7-a150-b4b8a8330a20": "How can point clouds be appended to a dataset using numpy arrays? Provide an example of appending two point clouds with different numbers of points and explain the resulting shape of the dataset.",
        "1a628e72-eb41-4022-84cb-345708466394": "Describe how point clouds can be added to a dataset using the `deeplake.read()` method. Provide an example of adding a sample point cloud with 100 points and explain the resulting shape of the dataset.",
        "5175de8a-d116-47d1-9eb2-00e48550b8c5": "What are the key characteristics of the `mesh` htype in the given context? How is the sample dimension defined for mesh samples?",
        "1120383b-2aa3-4100-ba52-9c1a940b7f8b": "Compare and contrast the structure of point clouds and meshes in the context provided. How do they differ in terms of data representation and dimensions?",
        "ab964d7f-69cc-4bd7-b3de-539b1a84cd0b": "Explain the process of creating an image tensor and appending image samples in the context of the Image Htype.",
        "c9a30d2e-f00e-4a19-a33d-b21dc9776b25": "What are the two types of units specified for bounding box coordinates in the context information?",
        "bc3fd50d-fc52-4a7a-92ec-5f3c67a81072": "How can you specify the convention for the 4 coordinates of a bounding box in the context information?",
        "a9eb22ce-a248-4c74-9175-56161b8fea86": "When appending bounding boxes, what types of data structures can be used, according to the examples provided?",
        "462b2fc3-2723-4575-bf5c-771c07c4242a": "How does the visualizer determine the bounding box format if it is not specified in the context information?",
        "97534b65-4cbd-48ab-8a86-25cd3ce9b4fe": "Why is it important to specify the format of the bounding box for 3D bounding boxes in the context information?",
        "a31b5d46-fbf6-41e2-bc0b-5f777576c625": "What are the supported compressions for creating a video tensor in Deep Lake?",
        "cc9773c2-4682-41d6-822a-79d6c7d39d2d": "Can the Deep Lake Performant Dataloader support videos? Explain.",
        "e2017bb1-61f3-40a5-9009-ea6e2c7cf20e": "How can you create an audio tensor in Deep Lake?",
        "81adfcff-aeb3-4edc-b72b-cd51a1902744": "What is the default dtype when creating an audio tensor in Deep Lake?",
        "b775b3ff-7056-4f5d-afb8-1e7ed53feb55": "Is recompression of audio samples supported in Deep Lake? Explain.",
        "9cc8725f-079c-4fc4-8c07-2b18265dbb01": "Explain the process of creating a point cloud tensor using the provided code snippet. What are the optional arguments that can be used during the creation of a point cloud tensor?",
        "5289908c-6181-4f9b-932c-4ff47b68a2a8": "How can point clouds be appended to a dataset using numpy arrays? Provide an example of appending two point clouds with different numbers of points.",
        "bce2c371-0c0f-4198-a3d7-a36fb76e2781": "Describe the structure of a mesh sample in a tensor of 'mesh' htype. How does it differ from a point cloud sample?",
        "1ef39167-391c-4f0c-a492-ceaad8aa1c4e": "What is the significance of the 'sample_compression' argument when creating a point cloud tensor? How does it impact the storage and retrieval of point cloud data?",
        "a5cfea53-19a6-48ef-8d41-6130474602ba": "How can samples be added to a dataset using the 'deeplake.read()' method? Provide an example of adding a sample of a point cloud with 100 points to a dataset.",
        "b0ab4f0d-baff-49c1-bfcd-e2f03b592d24": "What are the two supported compressions for the `tensor.info.class_names` list?",
        "0ce5bde5-343d-4724-9211-d7bb2267dd55": "How can you update the class names after creating a tensor?",
        "2f862c95-825a-4c15-8420-479d261020d9": "Why is `chunk_compression` recommended when specifying compression for class labels?",
        "b0ac81d3-a051-4058-91d3-27e65d23d046": "How can you append class labels to a dataset in different formats?",
        "d9a911e8-43e7-4c66-b3c9-267b401660f7": "What is the purpose of the `tag` htype in creating a tag tensor?",
        "6ce191f8-120d-40a8-a91f-b45d531e9a23": "How can you create a tag tensor with compression using the provided context information?",
        "fca60769-4332-4141-abb5-a08045e63ebc": "Can you provide an example of appending tag samples to a dataset using the `tag` htype?",
        "9e00c26f-2bd6-4de7-88ba-ddaf42097ff4": "What are the different types of data formats that can be used to append class labels to a dataset?",
        "6f0ab823-764b-422f-bcfe-c499555a1bcf": "Why is it important to consider the number of labels in one sample when choosing compression for class labels?",
        "279873ed-659b-444e-935b-cce6c78daa94": "How can you extend a dataset with a list of indices for class labels?",
        "f35a8962-b585-4507-a5e4-b2510e6f59ee": "What are the possible errors that can be raised when using a scheduler other than \"threaded\" with a deeplake dataset having memory as the base storage for `data_in`?",
        "4cd42985-3eae-4ee3-975a-2d573f9370cb": "Explain the purpose of the `deeplake.compose()` function and provide an example of how it can be used with a list of functions decorated using `deeplake.compute()`.",
        "348aaa81-eec4-408b-996b-b6ff40161a24": "What are the requirements for the `ds_out` dataset object when using the `eval` method in the deeplake pipeline?",
        "48ecc33f-6030-4bae-a9cc-8df0267d92ac": "Can you list the supported values for the scheduler parameter in the `eval` method of the deeplake pipeline?",
        "7791468f-94c7-415e-aad0-ab993c35b5aa": "How should the initial state of the `ds_out` dataset object be when using the `eval` method in the deeplake pipeline?",
        "e1bd2adc-232e-40cf-bd46-6e2040bf71f6": "What is the purpose of the `transform` parameter in the DataLoader setup?",
        "f95f6d96-660a-4549-b508-218a3b750eca": "How does the `tensors` parameter help in organizing the data for the training script?",
        "903e50dc-c3ac-4e9d-955b-b8199f52c16f": "Explain the significance of the `num_workers` parameter in the DataLoader configuration.",
        "7d52a3a3-4b6c-416d-81c7-4a3ea682fdf5": "When would you set the `drop_last` parameter to True in the DataLoader setup?",
        "1863d793-9441-4aef-9001-a2938abfac0b": "How does the `collate_fn` function contribute to the DataLoader process?",
        "57203a1c-ddc5-44a1-b6f1-7a515257d145": "What is the role of the `pin_memory` parameter in the DataLoader configuration?",
        "150b78db-2f1b-4858-9528-d677751c8e6c": "How does the `shuffle` parameter impact the data loading process in the DataLoader?",
        "9acc3bbc-8947-49c6-aea8-0b243c31a0fa": "Explain the importance of the `buffer_size` parameter in shuffling the data during training.",
        "43cea70f-3ad7-4a80-ac70-49094f960608": "What are the key concepts covered in Deep Lake v3.0.16?",
        "abdf8f7d-7508-42db-99b6-6331ce8f6402": "How does Deep Lake support PyTorch and Tensorflow?",
        "fd36598e-e1fd-4f60-90d4-ceb4b0120c11": "What integrations are available with Deep Lake, and how do they enhance its functionality?",
        "ccd8ef20-8609-4126-8bab-490f5712f71f": "What experimental APIs are mentioned in the context, and how can they be utilized?",
        "1feeafd9-c3a0-40e3-9a2c-c34133a7a49e": "Can you explain the purpose of the deeplake.core.dataset module in the Deep Lake API Reference?",
        "d9decec0-3234-4622-ae96-1ec06f5696f0": "What is the purpose of the `verbose` parameter in the `deeplake.connect` function? How does it affect the behavior of the function?",
        "42fe56b8-a38c-4221-8358-3b5424c16c82": "What are the possible exceptions that can be raised when using the `deeplake.connect` function? Provide a brief explanation of each.",
        "cc87e6f1-2f5e-4f0e-9fda-8f0b8f0e935f": "Can you provide an example of how to connect an S3 dataset using the `deeplake.connect` function? Include the necessary parameters and values in your answer.",
        "c30fb4c5-ed6d-428f-bb8e-d3ea0779162e": "What is the significance of the `creds_key` parameter in the `deeplake.connect` function? Why is it required?",
        "086980cb-eefd-45f9-83f1-27fe150277af": "Explain the difference between the `src_path` and `dest_path` parameters in the `deeplake.connect` function. How do they impact the connection of a dataset to Deep Lake?",
        "8bd4434e-c94f-4c41-a69c-0f2919f0f7e6": "Explain the purpose of the `populate_creds` function in the context of the provided information. How is it used and why is it necessary for datasets containing links to external data?",
        "9b2ce10f-bee4-4ec5-a60f-75866316deba": "What are the parameters that can be passed to the `pytorch` function in order to convert a dataset into a PyTorch DataLoader? Provide a brief explanation of each parameter and its significance.",
        "c0bca41e-8eed-487d-9725-e716116a6e25": "How does the `index` parameter work in the context of removing a sample from a tensor? What exceptions are raised if the index is out of range or if duplicate indices are provided?",
        "8a2d17eb-5174-4e2f-8aaa-c6a59e3936ae": "Describe the process of adding and populating a new creds key in a dataset using the `add_creds_key` and `populate_creds` functions. Why is it important to populate the creds key when reloading datasets with links to external data?",
        "dec9b971-4f19-48cd-8bb7-3dc988e8b5dd": "What is the significance of the `return_index` parameter in the `pytorch` function? How does setting this parameter affect the behavior of the PyTorch DataLoader?",
        "bd5cf616-23ce-4c84-b963-7e991a0a2985": "How can you create an image tensor in the context of the Vector Store key concept?",
        "dffea10b-2e3e-4154-af3a-e23b37142043": "What are the steps involved in appending image samples according to the Image Htype in the context of the document?",
        "be5aab51-8edc-4f21-8e07-3355fdaccf59": "Explain the difference between image.rgb and image. in the context of the Htypes key concept.",
        "ca32243f-6eb8-4b1d-b0cd-f605f7723218": "How can you specify the htype of a tensor at its creation in Deep Lake?",
        "7bb96241-4535-4a74-8e6c-2148f038885d": "Why is specifying an htype important for increasing the performance of Deep Lake datasets containing rich data like images and videos?",
        "c7caee8b-fbfb-4396-8ca1-14e9ac245079": "What is the default htype of a tensor in Deep Lake if not specified during creation?",
        "7b09a6e7-1e91-4ae7-af64-11351fd26d05": "How can strict settings and error handling be achieved by specifying an htype for a tensor in Deep Lake?",
        "9acb6ca1-49f4-40a0-8998-b9153b430c68": "Can you provide an example of creating a tensor named \"my_tensor\" with a specified htype in Deep Lake?",
        "f1e8f6c4-1c7f-4008-afae-602f64b57d43": "What are the supported compressions for creating a video tensor in Deep Lake Performant Dataloader?",
        "e0e50afc-bd1c-4179-b808-84b1f801f10a": "Can raw video frames be compressed when appending video samples in Deep Lake?",
        "6bdde5c7-edcf-452d-b4d7-fedc8b83fa2c": "How can you create an audio tensor in Deep Lake Performant Dataloader?",
        "d8b3592e-937c-495a-bdef-c12a137fa833": "What is the default dtype when creating an audio tensor in Deep Lake?",
        "1f231fbc-f781-4384-8c5f-71741d795a9c": "Is recompression of audio samples supported in Deep Lake Performant Dataloader?",
        "b6c5c495-829f-4e3c-aa57-2d77398f0570": "What method is used to clear the cache in the LRUCache class in the deeplake.core.storage module?",
        "c2449ffe-c842-4b6c-beb0-760dd9596afe": "What property is associated with the client in the deeplake.core.dataset.Dataset class?",
        "11cebef9-a4d5-4946-b2e5-a5eb725a7415": "In which class is the CommitError defined in the deeplake.util.exceptions module?",
        "af75589e-12ac-4e19-908e-bb34c4ecab2c": "What method is used to connect to a dataset in the deeplake.api.dataset module?",
        "ab7d1a28-73ad-434b-abd1-fc54c6ceb890": "What method is used to compress bytes in the deeplake.core.sample.Sample class?",
        "ec7a1fa7-f8f5-4094-9c88-ba36ad9fcfcc": "How are binary masks different from segmentation masks in terms of representation of objects in an image?",
        "bc0c1999-34ca-42f5-86a6-ba0ea23d804d": "What is the recommended compression method for storing segmentation masks and why?",
        "9cacb6bf-8f5e-4d0a-b22e-0730ae908436": "How can a binary_mask tensor be created in a dataset using Python code?",
        "d32bc1ae-24d4-48ea-b663-e51de87c9e6d": "Explain the structure of a binary mask tensor in terms of dimensions and object representation.",
        "bd444b90-a188-4d48-b398-fe97cc0f9b5a": "Describe the COCO keypoints convention for storing points of interest in an image.",
        "05cdd79b-afb1-4fcd-a695-3b62e626da14": "How can you specify the htype of a tensor at its creation in Deep Lake?",
        "e9cf3b54-0568-4732-b23e-eaf5229ae543": "Why is specifying an htype important for increasing the performance of Deep Lake datasets containing rich data like images and videos?",
        "225b85a5-6350-4e05-8dd9-480964bda3e4": "What is the default htype of a tensor in Deep Lake if not specified during creation?",
        "7389d28d-679d-4617-afe6-f3e489bec41e": "How can audio samples be appended to tensors in Deep Lake? What are the supported compressions for audio samples?",
        "7d80bc91-6195-4d28-8fbd-3af34a509245": "How can class label tensors be created in Deep Lake? What are the optional arguments that can be specified when creating a class label tensor?",
        "1e03b5bb-8a0e-4fdc-bf1a-8c3b50e5ce0a": "What is the purpose of the `class_names` parameter when creating a class label tensor in Deep Lake? How can it be set after tensor creation?",
        "b8ba3a37-9e8a-4ff5-ac46-4d50a70b3054": "Why is `chunk_compression` recommended over `sample_compression` when specifying compression for class label tensors in Deep Lake?",
        "0ab6df2c-1a7a-4b3c-8309-d496a7d1396a": "Can you provide an example of extending a dataset with Deep Lake audio samples?",
        "5e697ff6-156e-427d-8bd1-9ab790b62760": "Explain the key concepts of Datasets, Vector Store, Tensors, Htypes, Compressions, PyTorch and Tensorflow Support, and Utility Functions in the context of Deep Lake.",
        "242270d4-c251-4547-9abf-03359da363ca": "How does the Dataloader in Deep Lake contribute to high-performance features?",
        "e0c28297-187d-4500-94e6-5657c24ed72b": "Describe the API Reference sections available in Deep Lake and their respective functionalities.",
        "ad3e0048-d588-4cbd-9d39-025d333aae3e": "What are the different modules under deeplake.auto and what are their specific purposes?",
        "3b39a5f0-19bd-4fc5-8afe-b1f85919bda9": "How does Deep Lake integrate with Weights and Biases and MMDetection?",
        "4a1708fd-7b21-467d-a521-6d2867bbe2a1": "What method raises an error if the tensor is not compatible with a certain operation?",
        "53a00bb1-ea30-4415-86af-bcd9ffe73bad": "How can you retrieve a summary of the configuration of a tensor?",
        "50da1cd0-2ed4-4bed-a6c3-1fc06ae10453": "When can the _linked_sample() method be used and what does it return?",
        "30fdc795-ad78-476a-bcb5-92c0074e71f1": "How can elements be removed from a tensor using the _pop() method?",
        "cafa1c33-a531-4553-8229-a8a325569dde": "Explain how a single sample can be appended to the end of a tensor, providing examples for both Numpy input and file input.",
        "ee64714c-fc95-4388-8404-012ccf3b3524": "What does the _base_htype property of a tensor represent?",
        "ebc87a71-d9f2-47e7-8cc5-bcf511e1f8af": "How can you delete all samples from a tensor using a specific method?",
        "515b8f10-8edd-4683-a6b2-2240c089fbbc": "When is the creds_key() method applicable and what does it return?",
        "58a96ea9-5f0c-407c-8dbf-1c26a9793e82": "What does the data() method return and how is the format determined based on the tensor's base htype?",
        "da2fe6ef-df1a-4645-b6f4-6bb422a80695": "How can a mesh tensor be created in Deep Lake using the `create_tensor` function? What are the optional arguments that can be specified?",
        "3c1e512e-ff6d-4522-b655-b7e311e981c9": "Explain the process of appending a ply file containing mesh data to a tensor in Deep Lake. Provide an example scenario.",
        "b7aaee36-360f-4c6d-8da2-ff28d04b898e": "What is the purpose of the `embedding` htype in Deep Lake? How can an embedding tensor be created and extended with samples?",
        "0bbf5169-a831-425f-8fe1-f47a601e7fce": "Describe the `sequence` htype in Deep Lake. How does it differ from other htypes like `sequence[image]` or `sequence[text]`?",
        "5797c2a8-cdec-4575-8dda-fa5aa831b67b": "Can different meshes in a tensor of `mesh` htype have a different number of points? Explain with an example.",
        "0578cb7b-da87-49de-a1b9-3dbb49cafa1c": "Explain the process of creating a dataset in Deep Lake, including any necessary steps and considerations.",
        "bf78da55-df07-4158-a231-04cef6cd5e0b": "How can you visualize a dataset in Deep Lake, and why is this visualization important for data analysis?",
        "e01bf854-76f3-43cb-b56c-4f5c5452f7ed": "What are some key properties of tensors in Deep Lake, and how are they used in the platform?",
        "7549e0ee-3a89-4896-a9b3-17f98f678512": "Describe the different Htypes available in Deep Lake and provide an example use case for each type.",
        "3f364873-1114-4114-b328-f076a3c83425": "How does Deep Lake support PyTorch and Tensorflow, and why is this support important for users of these frameworks?",
        "fbf08bdf-3cd4-4c21-8a8e-539016d2cd62": "What are some utility functions available in Deep Lake, and how can they assist users in their data processing tasks?",
        "3b576621-57f8-407d-80e8-51d2f89e8b67": "Explain the integration with Weights and Biases in Deep Lake, and how it can be used to enhance the logging of dataset creation and read operations.",
        "362259ff-b3b5-4e26-bc5f-fd8f11ed555d": "Discuss the high-performance features of Deep Lake, such as the Dataloader, Sampler, and Tensor Query Language, and how they contribute to efficient data processing.",
        "34941080-833b-4a65-a246-bfa6abf01be1": "How does Deep Lake utilize deep memory to optimize performance, and what benefits does this feature provide to users?",
        "e5f742c5-fc35-43cd-8f3f-263390464eeb": "Provide an overview of the API references available in Deep Lake and explain how they can be used to access different functionalities of the platform.",
        "767390ea-d2e9-4081-b847-9aceed8192d0": "What is the purpose of the `creds_key` parameter in the function `ingest_huggingface`?",
        "831f42ea-8d88-4002-b9d6-c71c2083d6eb": "How can you enable or disable the ingestion progress bar in the `ingest_huggingface` function?",
        "433cc6e1-97dc-4664-9565-992a35d53292": "What is the significance of the `token` parameter in the `ingest_huggingface` function?",
        "8cda3e06-549f-40d1-8d73-f03f06bece63": "Explain the role of the `connect_kwargs` parameter in the `ingest_huggingface` function.",
        "087e6618-d0df-4ed2-bc0c-bd2056c0a97f": "How can you create a new dataset from a dataframe using the `ingest_huggingface` function?",
        "93c581fe-409c-4636-be46-87e5bd4220b6": "What type of exception will be raised if the `src` parameter is not a valid pandas dataframe object in the `ingest_huggingface` function?",
        "98eb6c9f-0ed0-436f-8f14-755eb4dc4df0": "Describe the purpose of the `use_progressbar` parameter in the `ingest_huggingface` function.",
        "9a6aa142-09e3-4d73-b78d-777106d5728a": "How can you convert Hugging Face datasets to Deep Lake format using the `ingest_huggingface` function?",
        "123504ad-f0e0-4ae4-832a-38c96f4eb2c9": "What is the role of the `dest` parameter in the `ingest_huggingface` function?",
        "2d5fbc73-9b8d-4170-8a85-d28cce008d35": "How can you specify additional arguments to be passed to the dataset creator function in the `ingest_huggingface` function?",
        "65aaafe2-266c-42dd-b50d-436904e04b20": "What are the two types of units for bounding box coordinates specified in the context information?",
        "a853a220-7c7f-427a-9a21-45ea12546f7b": "Explain the difference between the \"LTRB\" and \"LTWH\" modes for specifying bounding box coordinates.",
        "e2d704a3-9636-45d2-885d-06c91371e9e9": "How can bounding boxes be appended to a dataset in the provided examples?",
        "bc7d534d-41b8-48e5-995b-bc232ddc0c72": "When will the visualizer assume a YOLO format for bounding box coordinates?",
        "700c1de4-3728-4181-a562-253b94101a1a": "Why is it important to specify the format of 3D bounding boxes for correct display in the visualizer?",
        "c45d2115-96a4-4eed-b061-f1fb0880e101": "What are the supported compressions for creating a video tensor in Deep Lake Performant Dataloader?",
        "352a3e5c-56bf-4d17-8c54-908c74684816": "Can Deep Lake support videos in its Performant Dataloader?",
        "ec31ae51-173d-4caf-b84b-f154500b03f3": "How can a video tensor be created in Deep Lake Performant Dataloader?",
        "191d78f1-cf20-4aa6-8487-427121daa7a8": "What are the optional arguments that can be specified when creating a video tensor?",
        "a8d5df62-791e-4a6a-8110-e449899ad5c5": "How can video samples be appended to a tensor in Deep Lake Performant Dataloader?",
        "a9782352-437f-4279-a920-5da92d8f16ca": "Is recompression of samples read with `deeplake.read` supported for video samples?",
        "daf6f106-24a7-41d9-8751-5d719be53c5e": "What is the sample dimensions for the audio tensor in Deep Lake Performant Dataloader?",
        "57db705b-9899-40b8-8b5b-84fb02d2dc5c": "How can an audio tensor be created in Deep Lake Performant Dataloader?",
        "5a5c5c2c-8697-44d5-813f-f6d9e61f9ba0": "What are the supported compressions for creating an audio tensor in Deep Lake Performant Dataloader?",
        "519828c0-1843-4da4-bc60-07ecd271d7a8": "Can audio samples of type `np.ndarray` be appended to tensors with compression in Deep Lake Performant Dataloader?",
        "2a650c78-0841-480e-9a94-d455a8901cd4": "Explain the key concepts of Datasets, Tensors, Htypes, Compressions, PyTorch and Tensorflow Support, and Utility Functions in the Deep Lake API. Provide examples for each concept.",
        "fe0d331d-e44c-4bdb-9768-321de1d67977": "How can dataset views be created in Deeplake? Provide examples of methods that can be used to create dataset views.",
        "e39d86f2-2cd6-4bfa-88a2-6f143fa9bb72": "What conditions must be met in order to save a dataset view in Deeplake?",
        "3b0a1a6a-d055-4306-a8a8-1219e7a94413": "Explain the difference between filtering a dataset and querying a dataset in Deeplake. How are these operations performed?",
        "3bec0ab6-726b-478d-8864-639f190cb6c8": "How can a dataset view be loaded and accessed in Deeplake? Provide an example of loading a dataset view.",
        "db80300a-5396-45e5-8601-9f89e13cf59b": "What is the purpose of saving a dataset view as a virtual dataset (VDS) in Deeplake? How does it help in preserving data lineage?",
        "f4926999-e260-412a-8938-d230ec2ac479": "Can you explain the significance of the `Dataset.get_views` method in Deeplake? How does it assist in managing dataset views?",
        "5658a916-d52e-43e1-a9f0-5227ac15753d": "How can a dataset view be deleted in Deeplake? Explain the process of deleting a view with a specific view ID.",
        "b6bba8b7-7d4c-4780-b764-61f9816205ed": "In what scenarios would it be beneficial to use the `Dataset.is_view` method in Deeplake? How does it help in dataset management?",
        "df0b2f78-ca45-47a0-959a-70dbb9874312": "Discuss the importance of dataset commits and branches in the context of managing dataset views in Deeplake.",
        "cd5912af-1d69-4838-b93f-0f992db1a220": "How does Deeplake handle dataset sampling and slicing when creating dataset views? Provide examples of methods used for sampling and slicing datasets.",
        "b9e317be-6ae1-4827-88b4-7d4ba5540b0d": "Explain the difference between binary masks and segmentation masks in the context of object representation in an image.",
        "a4c5cde2-c042-46f2-8c9b-456fe72916de": "How are labels corresponding to channels stored in a binary mask tensor with htype \"binary_mask\"?",
        "c1b003a9-921c-4c65-9cd4-a20ae6fc26f9": "Why is it recommended to compress segmentation masks using \"lz4\" compression?",
        "2d67ecfe-e48d-4fd6-83e8-3210c3611ac5": "How can a binary mask tensor be created using the provided code snippet?",
        "77c756ca-a847-46dc-94b5-b302334993e4": "Describe the format of COCO keypoints and the information they store in an image.",
        "17c05f3f-91ae-4fe6-bc82-b2278fbd3768": "What are the supported htypes in Deep Lake and their respective defaults?",
        "b61154de-8ace-4ea9-b2db-78703b4cd2a9": "How can you specify the htype of a tensor at its creation in Deep Lake?",
        "b692fbc9-5f74-4e31-a923-bb0640b08304": "Why is specifying an htype important in Deep Lake datasets containing rich data like images and videos?",
        "95ac17c7-92f4-464e-8d96-ae019cfe2021": "What are the sample dimensions for the Image Htype in Deep Lake?",
        "5a54e9cc-e27a-459c-a282-a61e1132a69d": "Can images be stored in Deep Lake as compressed bytes or raw arrays?",
        "983f6367-e007-459f-94f2-d40a7d963c8c": "What are the key concepts in Deep Lake, as mentioned in the context information?",
        "567a01ab-1375-45b4-a068-e8e56cb6cc97": "How does Deep Lake support PyTorch and Tensorflow?",
        "4a935613-71a4-41fc-8fe4-2525ec6bd7cc": "What are the different types of compressions supported by Deep Lake for various data formats?",
        "d3ba380d-7a13-489a-a4f9-03e889b1611b": "Explain the concept of sample compression in Deep Lake and how it is utilized when creating tensors.",
        "78448f98-fa4e-4c8c-8aba-890edacbfdf1": "How does Deep Lake handle different types of data such as images, videos, audio, dicom, point clouds, meshes, and other data formats?",
        "8aeb84dc-a168-425c-a094-8fe9836df108": "What are the different types of paths that can be used as the destination for the dataset in the provided function?",
        "65610fe6-fa2b-4250-a3ac-ed98ab1c5922": "How can credentials be provided for accessing an s3 path in the function?",
        "55d3f3f3-05f3-4469-af70-4f2c3c0da3aa": "What is the purpose of the `images_compression` parameter in the function, and how is it determined if set to \"auto\"?",
        "3d9c9ee7-3cd1-4d46-a108-a1962af3d3ba": "When should the `mem://` path be used as the destination for the dataset, according to the context information?",
        "10f168e3-2c3c-4938-b33c-c53ec21a29c6": "Why is shuffling the input data prior to ingestion important, especially when dealing with data arranged in folders by class?",
        "47ef46fe-adc9-457f-83ed-b0617e01f695": "What are the parameters required for the `update_creds_key` method?",
        "fac306f1-ed4a-40ea-b6dc-d5b318a324aa": "What exceptions can be raised when using the `update_creds_key` method?",
        "8b4a3c92-01d3-47cb-971a-39e1c5559833": "Provide an example of how to use the `update_creds_key` method with the `deeplake.dataset` object.",
        "6d8e9970-c77e-4a17-9324-1d510a8a2da8": "What is the purpose of the `visualize` method in the context of the document?",
        "d3c526c4-046c-495a-912a-1044846283b1": "How can you customize the width and height of the visualizer canvas when using the `visualize` method?",
        "8fb2f1b6-1858-4adb-8321-5d4ce38d22bb": "What is the recommended compression method for segmentation masks due to their large amounts of data?",
        "e449f90a-abe5-4c76-ba16-19fa9253cae7": "How can a segment_mask tensor be created in the dataset using the provided code snippet?",
        "f6f8064a-7cb6-4d10-9004-18f8c84a76b3": "Explain the difference between segmentation masks and binary masks in terms of representing objects in an image.",
        "7b952ccd-3a94-40b3-aa13-766b6f86a1d7": "Why are segmentation masks not suitable for datasets where objects might overlap or where multiple objects within the same class need to be distinguished?",
        "5be076fa-2176-4a0b-ac6a-8c4cd50bac80": "How can class names be set for a segment_mask tensor after its creation in the dataset?",
        "28aa7163-50ae-4c58-9c7b-86784bba69f6": "How can a tag tensor be created in a dataset using Python code?",
        "a6021b20-9e7e-4326-8cc0-86ad79bcd1b6": "What are the supported compressions for chunk compression when creating a tag tensor?",
        "f1968d3a-8092-47b5-954a-c0459f337730": "Provide an example of how to append a tag sample to a dataset.",
        "a3ad548a-8c02-4dfc-b962-e23da8fce804": "Explain the format of bounding boxes in the context of the Bounding Box Htype.",
        "224d42ac-4828-4a84-a893-7787cf7d534b": "How can a bbox tensor be created in a dataset, and what are the optional arguments that can be specified?",
        "55be591a-8ddc-4cbf-9f43-c65ec2bfcdd1": "Describe the different conventions for bounding box coordinates specified by the \"mode\" key in the coords dictionary.",
        "0d7b1d39-4f17-4374-9f61-caff12a43168": "What is the default data type for bounding box coordinates when creating a bbox tensor?",
        "0d537cb3-e9c7-4bfc-8412-a83fb3cfccc4": "How can class names be set after creating a tensor in a dataset?",
        "7be20263-4f9c-4d7d-9acf-2321179fd0e9": "Explain the process of creating a point cloud tensor using the `create_tensor` method in the given context. What are the optional arguments that can be used during this process?",
        "1f4fd3ac-001d-4683-80fb-9743bf978d65": "How can point clouds be appended to a dataset using numpy arrays? Provide an example of appending two point clouds with different numbers of points.",
        "5fa0a178-a41f-4cf7-b074-8c844bbd1b32": "Describe how samples can be added to a dataset using the `deeplake.read()` method for point clouds. Provide an example scenario where a sample with 100 points is added to the dataset.",
        "2e3fb5f6-b1f5-4757-a98a-1d46cf7cebf9": "What are the sample dimensions for the `mesh` htype in the given context? How are mesh samples represented in a tensor of `mesh` htype?",
        "387b6c20-20ab-4284-b407-893355f305a0": "Compare and contrast the characteristics of point cloud and mesh samples in the context provided. How do they differ in terms of data representation and structure?",
        "0d9d0ff2-3239-4aa4-8cc0-e23cb953b3e6": "Explain the key concepts of Datasets, Vector Store, Tensors, and Htypes as mentioned in the document.",
        "e6824357-81a4-4c97-86b3-f48c35203b5d": "How can an image tensor be created according to the document?",
        "147e6f37-f01f-4dd9-9757-15b341875f8d": "Describe the process of appending image samples as outlined in the document.",
        "547ede31-efe7-49a8-89ea-2797dacff1e0": "What are the differences between image.rgb and image. as mentioned in the document?",
        "1e19b2b8-b759-4090-8b1a-d0dc32e9c62e": "What are the possible keys in the dictionary returned for `class_label` tensors?",
        "4a47b054-651e-4462-ac1a-fcc4b423d1c9": "How is the value of the key \"text\" in the dictionary for `class_label` tensors defined?",
        "20c0d965-5a34-453f-906b-633a8aefa233": "What are the keys present in the dictionary returned for `image` or `dicom` tensors?",
        "cf9e5c3f-6fd3-4a0a-89ff-2df332fadb36": "How is the value of the key \"value\" in the dictionary for `image` or `dicom` tensors determined?",
        "f47f6057-35c6-4751-b7dc-8875140d4015": "What type of data does the `dict(_fetch_chunks : bool = False_)` function return?",
        "1a6481e0-bf89-491e-8383-f14106a363f5": "What is the purpose of the `extend()` function in the context of the document?",
        "dfc37271-649b-4382-9c54-a0e2e5692a8c": "How can the `extend()` function be used to add elements to the end of a tensor?",
        "bd1366ef-cc7d-4a88-8447-d46f83224108": "What is the significance of the `_property _dtype_: Optional[dtype]` in the document?",
        "3e4f19cf-b26f-496f-bd02-a464d0a4114b": "How can the `extend()` function be utilized to append elements from a sequence to a tensor?",
        "f7a8e374-9780-4895-9c85-9f3a9b64da0e": "What is the condition under which the `extend()` function may ignore errors during execution?",
        "5fd62f15-25e8-43f8-89b3-dd13a3e3c390": "Explain the process of creating an image tensor and appending image samples in the context of the Image Htype.",
        "9296e1fa-fd54-4c70-bc6e-d0101d86724a": "How can the cloud-volume tool developed by William Silversmith be utilized in the context of storing and visualizing AI data?",
        "74a94624-53d0-4a8a-8218-833639bc8568": "Explain the importance of specifying the format of the bounding box in the coords key for correct display by the visualizer.",
        "54f27326-93f0-4073-b9c3-99cfd34a5431": "How can a 3D bbox tensor be created using the provided code snippet?",
        "b709e5e7-49c5-427f-84cd-258490bdc006": "Describe the two different conventions for specifying the coordinates of a 3D bounding box using the \"mode\" key in the coords dictionary.",
        "41314583-cbc9-4df0-bdc5-8c17f4e2344b": "What are the dimensions of the sample data when using the \"center\" mode to specify the coordinates of a 3D bounding box?",
        "0fb52993-2230-4c8b-8542-2395203cd1c9": "Can you explain the vertex order for the 3D bounding box when using the \"vertex\" mode to specify the coordinates?",
        "afcc3da5-43b4-41cc-ab44-df3ba6768ae1": "Explain the process of creating a dataset using Deep Lake, including the different methods available such as `deeplake.empty` and `deeplake.like`.",
        "a84f5584-b634-4131-8645-b2915f97bed2": "How can you ingest a dataset of images from a local folder to a Deep Lake Dataset using the `deeplake.ingest_classification` function?",
        "7416045b-0ce9-4cb6-a552-ae9560cfdcb2": "What is the purpose of the `deeplake.VectorStore` in Deep Lake and how does it relate to datasets?",
        "23b2058c-71f3-4e15-9bf8-0023f4c0b2f5": "Describe the functionality of the `deeplake.random.seed` API reference in Deep Lake and its importance in data processing.",
        "509d4fad-6c51-474e-bb29-f70fafa353ed": "How does Deep Lake support PyTorch and Tensorflow, and what are the implications for users working with these frameworks?",
        "2a944896-d639-4097-817a-3136976d0d9f": "Explain the purpose of the `__len__()` method in the Tensor class and provide an example of how it can be used with a tensor object.",
        "7a407144-548d-476e-bb82-899804de4341": "How does the `__setitem__()` method in the Tensor class allow for updating samples with new values? Provide an example to illustrate this functionality.",
        "2d883164-ed6a-48c6-bb8b-b1dd47def258": "What does the `_check_compatibility_with_htype()` method in the Tensor class do, and what happens if the tensor is not compatible with the given htype?",
        "0ab79e5c-07de-4f81-babc-8ab6e40d3339": "Describe what information is returned by the `__config` property in the Tensor class.",
        "526aa1a7-b3e3-468e-83f4-3638f6b9c5de": "How does the `append()` method in the Tensor class work, and what is its purpose in relation to adding samples to the tensor object?",
        "b69569e8-2623-4aae-99d5-95530380e68f": "What is the default value for the `ingestion_batch_size` parameter?",
        "ef95749d-cbe1-430d-bd4c-adfd4f8d18b2": "Explain the purpose of the `index_params` dictionary and its key-value pairs.",
        "d22c0008-862d-4772-af93-ab8619853208": "How can the `distance_metric` key in the `index_params` dictionary be specified, and what are the default options for this parameter?",
        "863b180b-8073-4b24-8b29-a3c6a67a0ebc": "What is the significance of the `exec_option` parameter, and what are the available options for this parameter?",
        "b479e75c-30cb-45a5-8721-026b7db4fdf3": "Explain the process of creating a Deep Lake Vector Store and list some of the operations that can be performed on it.",
        "ec3fc888-29cb-41e5-ae60-1eed499f1e8c": "How can datasets be visualized in Deep Lake and what are some of the properties associated with datasets?",
        "84d61010-1f48-42ad-a093-065787593493": "Describe the different Htypes available in Deep Lake and provide an example use case for each type.",
        "e1cbd1a3-5090-4d30-93bf-4cf8f7606963": "What are some of the high-performance features offered by Deep Lake, such as Dataloader and Tensor Query Language?",
        "4a45c3af-7caa-40e1-ba71-51b340c1609a": "How can Weights and Biases be integrated with Deep Lake for logging dataset creation and read operations?",
        "3cdbf2a9-b480-4c04-b1dd-714afd3c294d": "How can the deeplake database be utilized for AI applications?",
        "2b3cfa0b-e14f-42a9-9346-16f257d81ad3": "What types of data can be stored in the deeplake database?",
        "0e738cb8-0cad-4580-b79e-22f2b6e26438": "How can the deeplake database be integrated with LLMs/LangChain?",
        "d266b30e-8aac-49ae-9be2-609e9c311cf7": "What are some of the key features of the deeplake database?",
        "74e2f9b4-2827-4119-b273-29408fb8ef87": "How can data be streamed in real-time to PyTorch/TensorFlow using the deeplake database?",
        "077ffe8a-438c-4dbd-b231-41a605f1da94": "What is the purpose of the `load_view` function in the dataset class?",
        "3efde0e6-5e74-4393-8c8c-9c699c893f43": "How does the `optimize` parameter in the `load_view` function affect the loading process of a dataset view?",
        "8305918c-cd8a-4fdd-ac51-22954dae4cb7": "Explain the significance of the `num_workers` parameter in the `load_view` function when optimizing a dataset view.",
        "556355d8-ed81-4ba4-8a2c-6cf7ffa840cf": "What is the role of the `scheduler` parameter in the `load_view` function, and what are the supported values for this parameter?",
        "ca96a693-e982-404b-a540-0da86c0d8d12": "How does the `progressbar` parameter in the `load_view` function impact the optimization process of a dataset view?",
        "c1b0d51d-6886-4cfd-ab1f-9c0e5201d3ca": "What does the `log` function in the dataset class do, and when would it be useful to use it?",
        "a6fdf80e-7375-49b9-ae8f-588f140bb246": "How does the `_max_len` property in the dataset class contribute to the dataset's functionality?",
        "dc8dcdb8-c2b3-4f4c-887a-eb87b4e996ed": "Explain the purpose of the `_max_view` property in the dataset class and how it handles tensors of different lengths.",
        "86f19aea-0b3b-46bb-b8f0-229a516e848d": "Explain the purpose of the `exists` utility function in Deep Lake and provide an example of how it can be used.",
        "3a712eec-93a8-4f65-a840-c5c59f332709": "How does the `read` utility function in Deep Lake work, and what is its significance in the context of handling raw data?",
        "d4bfba90-7d2d-4e6b-b3d3-581c51d851b5": "Describe the functionality of the `compute` decorator in Deep Lake and how it can be utilized in parallel processing tasks.",
        "132d8191-e197-4f15-9ecc-00b38ac9675d": "What is the role of the `eval` function in Deep Lake, and how is it used to evaluate transform pipelines created with `compute()` and `compose()`?",
        "0420895f-942a-4838-aac3-550fc0fd8970": "Discuss the importance of the `link_tiled` utility function in Deep Lake and provide a scenario where it would be beneficial to use.",
        "75c7e2bf-cd90-4dfe-b41d-73cad482b3d3": "What are the possible values for the conflict_resolution parameter when merging datasets, and what do they signify?",
        "998cc0ee-8b31-4c96-998b-cec9a256c44b": "How does the delete_removed_tensors parameter affect the dataset when set to True?",
        "89774a05-f5b8-4b61-90b2-8e5300664158": "Explain the effects of setting the force parameter to True during a merge operation with conflicting tensors.",
        "67abc9fc-71b6-474c-8efa-839dbc267493": "What exceptions may be raised when attempting to merge datasets, and under what circumstances?",
        "110532d1-767e-423f-a4c4-443872eff731": "How can you access the metadata of a dataset using the _meta property?",
        "e88ec81f-eadd-4cc7-9573-ba2a4da69b78": "What does the _min_len property return for a dataset?",
        "7c745d67-3e32-46aa-9f40-2ed996adff68": "Describe the functionality of the _min_view property in a dataset.",
        "9f4a2b86-d7bd-4544-81a1-bf43f5cb0d7f": "What is the purpose of creating a keypoints_coco tensor in the given context?",
        "0e9ca4e9-94b1-48db-bc0e-665c455eab93": "How can a keypoints_coco tensor be created using the provided code snippet?",
        "abc875f5-85a2-40d1-9909-649526c2cb49": "What are the optional arguments that can be used when creating a keypoints_coco tensor?",
        "fc15b6cb-66b5-4a12-8c11-a2c9e5039b1d": "How can you set the keypoints and connections after creating a keypoints_coco tensor?",
        "dae030d9-66e6-40e2-8806-b9728b4a3db5": "How can keypoints be appended to a keypoints_coco tensor in the given context?",
        "caab943a-60a3-418c-8f86-4016138999d3": "Explain the process of creating a Deep Lake Vector Store using the `VectorStore.__init__` method. What does this method do and what are the parameters involved in its usage?",
        "3a625ab6-571d-46f0-8ccd-3afb642a6eb0": "What are the two supported compressions for the `tensor.info.class_names` list?",
        "9439c80e-2c2f-459f-af3b-13a48c11bd3c": "How can you update the class names after tensor creation?",
        "2e4e2549-434c-4a6b-b406-63445b8355d3": "Why is `chunk_compression` recommended when specifying compression for class labels?",
        "4a658dca-5891-4e2d-a9cd-16e637ae3ef4": "How can class labels be appended to a dataset?",
        "9babc842-8188-43fe-98b4-c27b894128ad": "What is the purpose of the `tag` htype in creating a tag tensor?",
        "e3028d65-9ac3-4498-baa1-b0787b74448d": "What are the supported compressions for creating a tag tensor?",
        "f3afb755-64d9-46f6-9ff8-1f9196e451f7": "How can tag samples be appended to a dataset using the `tag` htype?",
        "e130b591-c048-4287-b8de-99caa7da8152": "How can Deep Lake datasets be converted into PyTorch and Tensorflow formats for training?",
        "7eb46567-6afc-4bc4-a905-45b72eabfbfc": "What are some of the key concepts covered in the documentation of Deep Lake?",
        "30d88cb8-3696-4359-a2fc-54f3e6706293": "How does the `Dataset.pytorch` function in Deep Lake help in converting datasets?",
        "6bfb1c7b-59d3-4ce2-a483-6a3c6d79d051": "What integrations are mentioned in the document related to Deep Lake?",
        "18231210-1ec4-4714-80f4-669566480303": "Explain the purpose of the `deeplake.VectorStore` API reference in the Deep Lake documentation.",
        "40206303-bab7-4499-9376-9d1d0edb7c48": "Explain the difference between sample_compression and chunk_compression in the context of the provided information. How are they used in the dataset?",
        "38eeed5c-48b1-49cd-a4f8-0a42cfe3f758": "How can 3D bounding boxes be appended in the dataset? Provide an example of appending one bounding box and another example of appending a sample with three bounding boxes.",
        "7937d10a-0330-43bf-8c2d-e044b98059c2": "What is the purpose of the intrinsic matrix in the context of camera parameters? Explain the components of the intrinsic matrix and their significance in a projective transformation.",
        "805e70e1-c759-4ab3-b0d4-6a2933a5b1b5": "How can you specify the htype of a tensor at its creation in Deep Lake? What is the default htype if not specified? Why is specifying an htype important for datasets containing rich data like images and videos?",
        "ef97aa30-4dab-41e4-a98f-56440da59f8c": "What are the keys supported by the `deeplake.rename` function for credentials when working with s3 paths?",
        "d1782401-509a-4d52-b25d-c3913841e03a": "What is the purpose of the `token` parameter in the `deeplake.rename` function?",
        "2dad2bfa-cd8a-47df-9f3c-3d19e67875a0": "What exception is raised if a Dataset does not exist at the given path and `force = False` in the `deeplake.rename` function?",
        "f280e3ab-38de-4f76-9f77-b20230b9674f": "What warning is provided regarding the `deeplake.rename` function?",
        "39fd97ab-8669-472a-af24-7467faef3c6f": "Can you provide an example of how to use the `deeplake.rename` function to rename a dataset located in an s3 bucket?",
        "e57e287f-d5ab-449b-92c4-e600a5f22ec3": "What is the difference between `deeplake.copy` and `deeplake.deepcopy` in terms of copying datasets?",
        "efccd79b-04f8-4e1b-88bf-29af11cc2142": "How can you append samples to multiple tensors at once in a dataset?",
        "8124fe2d-0b45-4a8e-ad27-34aa27bce68e": "Explain the purpose of the `Dataset.delete` operation.",
        "2ccc1112-660e-4c1d-859a-98db6f510ef2": "How can you estimate the size of a dataset in bytes using Deep Lake?",
        "ba232f53-fb28-4117-a9f1-8985bf4f5284": "Describe the process of splitting a dataset into non-overlapping `Dataset` objects of given lengths using Deep Lake.",
        "d9f0e00c-fbdb-47c6-9869-4ce0038be9bf": "What is the purpose of the `extend()` method in the tensor class?",
        "4be2b2c2-2eb2-47cd-9459-154cec17bfb2": "How can you add multiple elements to the end of a tensor using the `extend()` method?",
        "88798b25-f479-4987-b585-baba43f19220": "What is the significance of the `ignore_errors` parameter in the `extend()` method?",
        "ad5bc050-69ae-43ee-a6bd-09b051d0902d": "How can you add data to a tensor using numpy input?",
        "97a78467-c08c-486c-951f-6e8fe9dee116": "What error may be raised if the dtype of the input array is not compatible with the tensor's dtype?",
        "a89d06ba-0139-46c8-9c4d-b50ecf432345": "What is the purpose of the `delete()` function in the context of the provided information?",
        "a4676534-dcd6-411e-917d-22d711378373": "How can you retrieve the id of a view using the `_property _id _: str_` attribute?",
        "199e7cb1-f0d1-48a1-9052-ca6028ae171e": "Explain the significance of the `optimize()` function in the context of dataset views.",
        "9ae8ad5a-aea4-4315-bc56-17e2bf49bfaa": "What parameters can be specified when optimizing a dataset view?",
        "4fdf08c6-8187-4a1b-9440-bd8ae5562161": "How can you load an optimized view after it has been optimized using the `optimize()` function?",
        "03a4d293-9dba-495f-9d33-75616d412fb1": "What is the difference between `deeplake.copy` and `deeplake.deepcopy` in terms of copying datasets?",
        "0c1e4861-f028-496c-b88e-3e5610b3c62c": "How can you append samples to multiple tensors at once using the `Dataset` class?",
        "e33ce6cb-590a-4e55-a617-a4f277ec4ca0": "Explain the purpose of the `Dataset.delete` method.",
        "aad45d92-3d2d-45b2-b6a4-6be294447b9c": "How can you estimate the size of a dataset in bytes using the `Dataset` class?",
        "ce9af080-c289-4f5d-b4d9-447789f9b82a": "Describe the process of splitting a dataset into non-overlapping `Dataset` objects using the `Dataset.random_split` method.",
        "ce8c0b45-b8ba-42fe-9ed6-ddad0fc9029d": "How can you set the `connections` attribute in `tensor.info.keypoints`?",
        "30403bde-aae0-48ab-afc3-2b53366e7882": "What is the default data type for `dtype` in `tensor.info.keypoints`?",
        "d5b33747-a576-46e6-bb19-182e54ea1ebb": "How can you append keypoints to a sample in the dataset?",
        "594761fe-fdb0-41c1-8705-8aef5ebd685e": "Why is it important for all objects in every sample to have the same number of keypoints in the same order?",
        "7534f57d-4c16-4aee-a664-19cb0ee2af6b": "How can you prevent keypoints that are not present in an image from being drawn in the visualizer?",
        "a50e9457-155e-4179-a459-9380757bd38c": "How can audio samples be appended to tensors in Deep Lake?",
        "530c452c-de23-4590-a46d-3a8b0739373c": "What are the supported compressions for audio samples in Deep Lake?",
        "e3d946b1-8e1f-4447-a001-bc8c0c6fa211": "How can a class label tensor be created in Deep Lake?",
        "4165e9df-2bf3-42ad-a5f4-551bcc6d7b8f": "What are the optional arguments that can be specified when creating a class label tensor?",
        "bcca55a5-d76c-49ed-9d2b-66355fe4d54a": "Why is `chunk_compression` recommended when specifying compression for class label tensors with a low number of labels in one sample?",
        "997d5b43-3e99-4ac2-8548-e6409d7083eb": "How can you append 2 2-D points to a dataset using the provided code snippet?",
        "c7805749-2af6-40dd-921d-7396a53ad05d": "What are the requirements for the points in a sample of the 'polygon' htype tensor?",
        "168e5abb-519a-4962-aa66-90c197dce52d": "How can you create a polygon tensor named \"polygons\" with the htype \"polygon\" using the provided code snippet?",
        "22a5e366-751a-4ef3-b2e7-b571ad6ea60e": "What are the supported compressions for creating a polygon tensor?",
        "3b00a6de-fd2f-4f7b-9429-c368e766bcf5": "How can polygons be appended to a dataset according to the context information provided?",
        "1792e223-002c-48ca-b971-bba1b7caf458": "Explain the purpose of storing keypoints with dummy coordinates in an image. How does visibility prevent them from being drawn in the visualizer?",
        "6257d370-0bec-4025-8e35-4029d8e5c584": "What are the sample dimensions for points in the context of 2-D and 3-D coordinates? Provide an example for each case.",
        "903e20d2-0e4e-4701-99ce-dacf199905b3": "How can a point tensor be created using the provided code snippet? What are the optional arguments that can be included?",
        "2ee14c57-98f2-45e0-b818-a6d73c37ed13": "Describe the process of appending points as numpy arrays or lists. Provide examples for appending 2 2-D points and 2 3-D points.",
        "b7069f95-c6c1-4331-bcf7-f4786c6aa0ea": "What are the sample dimensions for polygons in the context of the polygon htype? Explain the structure of each sample in a tensor of polygon htype.",
        "3f5ee512-f47e-4602-989e-516144c03acc": "Can different samples have a different number of polygons in the polygon htype? Explain.",
        "db79a72f-13e3-4925-ae2c-714bbdadd0da": "What are the two options for storing images in Deep Lake, and why is it recommended to store compressed images?",
        "edd364cf-68cf-49ba-9db8-af4961e0f873": "How can an image tensor be created in Deep Lake, and what are the supported compressions for sample compression?",
        "911202d5-f475-4d4e-a2d0-aa80eebb7807": "How can image samples be appended to a Deep Lake dataset, and what is the benefit of using the `extend()` method?",
        "2e61f509-a8eb-44f3-822e-bf9539198fb1": "What happens if the compression format of an input sample does not match the sample compression of the tensor in Deep Lake?",
        "b7956c1c-bec6-4519-94e4-6be885eefbdf": "How can the `image.rgb` and `image.gray` htypes be used in Deep Lake to specify the type of samples being stored?",
        "c32ac534-65d0-4284-9c4a-a686155c8ffc": "How can audio samples be appended to tensors in Deep Lake? What type of compressions are supported for audio samples?",
        "5d4a90e3-0368-4d68-a974-3e706dd28c00": "How can class label tensors be created in Deep Lake? What are the optional arguments that can be specified when creating a class label tensor?",
        "1e022415-b39b-4d4f-9ca7-f0ec89f9dc63": "What is the purpose of the `class_names` argument when creating a class label tensor in Deep Lake? How can it be updated after tensor creation?",
        "46ba9f6d-0da4-4179-9a41-f3ff313440f5": "Why is `chunk_compression` recommended over `sample_compression` when specifying compression for class label tensors in Deep Lake?",
        "b3b835a5-2d78-4816-9908-4100766e6e6b": "Can samples of type `np.ndarray` be appended to tensors with compression in Deep Lake? If so, under what conditions can they be appended?",
        "bf71a512-a10b-4eef-9132-106ca50567ad": "What are some key concepts related to Deep Lake, as mentioned in the context information provided?",
        "86ff216f-2a47-4695-8cf0-d6525b9af625": "How does Deep Lake support PyTorch and Tensorflow?",
        "c48647eb-d263-447c-a2bf-58c5b7fef2e8": "What integrations does Deep Lake have with other tools or platforms?",
        "30b63ab4-985a-488f-9f1f-d3c201f7c71a": "Can you explain the purpose and functionality of the Dataloader and Sampler in Deep Lake?",
        "d81b51b9-55b0-477f-973c-5fc6064a639d": "What is the main focus or purpose of the Deep Lake API Reference mentioned in the context information?",
        "414ec1a1-738e-4fd4-a091-c991de588f66": "What are some of the topics covered in the User Guides section of the Sphinx documentation?",
        "9f50b978-4718-44db-835b-0a952b8e9bde": "How can one contribute to the Sphinx project according to the Community guide?",
        "ee8572b5-7d26-40c2-8b36-d10f5f68dbfa": "What is the purpose of the Reference guide in the Sphinx documentation?",
        "6f5f72f5-16ef-4822-b1cf-371040a009d4": "What are some of the key elements discussed in the LaTeX customization section of the Sphinx documentation?",
        "6aeb7d37-0bb5-4aeb-bcdb-c9df50b8cd76": "How can one get support for Sphinx according to the Community guide?",
        "8dd681c1-d30f-4739-99d3-fea55a1ff067": "How does Deep Lake integrate with MMDetection for model training, and what benefits does this integration provide for users?",
        "f764c7b8-7a5a-43eb-8498-72016e56fad6": "What is the purpose of the integration between Deep Lake and Weights & Biases for experiment tracking, and how does it contribute to achieving full model reproducibility?",
        "d61d75cf-79c7-4365-9e4c-7894ad631b7a": "How can Deep Lake be used as a vector store for LLM apps, and what is the advantage of combining it with the Langchain VectorStores API?",
        "b2fcae9d-28ab-41aa-b19e-682152828e8c": "What resources and benefits are available to students and educators through Deep Lake's integration with popular datasets and the Tensor Database?",
        "d1eedb8b-6170-428f-8128-3caafd1739fe": "Compare and contrast the architectural differences between Deep Lake and ChromaDB in terms of storing and searching vectors.",
        "3ae1a3d8-b5e3-4984-8e19-1040905fc354": "What are the parameters that can be provided when connecting a Deep Lake dataset, and what is the purpose of each parameter?",
        "c0cff382-c8ec-4399-af3f-778c3f5e031b": "What are the potential errors that can be raised when deleting a dataset, and under what circumstances would each error occur?",
        "3f27876f-0943-49bd-b7ac-aedcd07b0a27": "How can you retrieve the set of managed credentials keys added to a dataset in Activeloop platform?",
        "27d60f6e-f62b-459c-9cae-7d311e8d1bf3": "What is the significance of the property \"_is_actually_cloud_\" in the context of datasets connected to Deep Lake cloud?",
        "12f3db99-634d-49c8-bea2-2ef1c3beecfa": "Explain the functionality of the \"rename\" method in the context of managing datasets.",
        "7df11f30-990b-450a-bd9c-29c292e82bb5": "How can a tag tensor be created in a dataset using the provided code snippet? What optional argument can be specified while creating a tag tensor?",
        "f697fb42-e020-45de-8125-1b5c1ea8c5e3": "Explain the process of appending tag samples to a dataset using the examples provided in the context.",
        "3f38a7c2-5640-4957-b016-809a767706ef": "What is the required format for bounding boxes to be correctly displayed by the visualizer? How can a bbox tensor be created in a dataset according to the provided information?",
        "5e0c4ebe-ee82-49ad-9084-89ac51c0491b": "Describe the keys required in the \"coords\" dictionary when creating a bbox tensor. What are the supported conventions for bounding box coordinates mentioned in the context?",
        "d411dbd6-3147-4104-acbe-873cc9a918da": "What are the supported compressions for chunk compression when creating a tag or bbox tensor in a dataset?",
        "4ca7f734-6821-45ea-820a-c7a22b467c7a": "What are the possible values that `tensor.info.keypoints` can be set to?",
        "6b7a4978-b898-47a8-acf7-4fde7c7e7067": "How can you append keypoints to a dataset in the given context?",
        "c6ca36a8-147d-4895-a75c-5410a2f1fe37": "Why is it important for all objects in every sample to have the same number of keypoints in the same order?",
        "67abaca3-dd43-41b4-b66c-16c8f0888842": "How can you update the `keypoints` and `connections` after tensor creation?",
        "9c668c60-23e2-4f35-b30f-e74dcbf1b3f8": "What is the purpose of setting `dtype` to `int32` by default?",
        "a90f548d-7f80-4b3f-966b-69078c13fbc4": "How can you choose to set `keypoints` and/or `connections` after tensor creation?",
        "5e5c3c64-9f6b-42ff-95d2-30b9d26433cc": "What are the supported compressions for `sample_compression` or `chunk_compression`?",
        "5b4e5742-d169-425f-85d3-e046bae15a07": "How can you store keypoints that are not present in an image according to the given information?",
        "e8ccd8a3-4166-4812-b589-c2a07cd07dd0": "What is the significance of visibility in preventing keypoints from being drawn in the visualizer?",
        "415327e0-7f4c-4a8e-aa73-1233e0c8d376": "How can you append keypoints sample with 3 keypoints and 4 objects as shown in the examples provided?",
        "469033ca-37e0-4ccf-badd-293cbedd244a": "Compare and contrast the compression capabilities of Deep Lake with MDS, highlighting the advantages of Deep Lake's flexible compression scheme.",
        "70d98a75-a7b4-4aac-9faf-ecd04aa4d70a": "Explain the significance of Deep Lake's native version control and in-browser data visualization features in managing and tracking different versions of data, especially in comparison to MosaicML data format.",
        "3c57812f-6dc8-4483-9da1-5947997715b7": "Discuss the differences between Deep Lake and TensorFlow Datasets (TFDS) in terms of compatibility with ML frameworks, dataset streaming capabilities, and focus on custom dataset management.",
        "64233a57-0490-44af-88bf-8af997c0ac30": "How does Deep Lake differentiate itself from TFDS in terms of dataset accessibility, storage options, and collaboration tools for creating and sharing custom datasets?",
        "4d2655dd-ce70-496b-bf79-f1a82f5416f9": "Evaluate the benefits of using Deep Lake for importing datasets directly from TensorFlow Datasets and streaming them to PyTorch or TensorFlow, compared to the process of downloading datasets locally with TFDS.",
        "740eb0b6-bfb7-44bb-9851-93d7c1011755": "Explain the difference between `deeplake.ingest_classification`, `deeplake.ingest_coco`, and `deeplake.ingest_yolo` in terms of the input data format they accept and the output they generate.",
        "ee2ca479-ad4c-43c4-a90a-b4caedccf86f": "How can you create a new dataset by copying the structure of an existing dataset using the `deeplake.like` function?",
        "2ae309a5-cab6-4e91-af20-ab70137dece1": "Describe the process of loading an existing dataset using the `deeplake.load` function.",
        "ec6e85c4-9a48-4a12-b235-6c7e43088d03": "What are the differences between `deeplake.copy` and `deeplake.deepcopy` when it comes to copying datasets?",
        "49ede9fc-ba68-470a-823c-ef76ed324ea3": "How can you delete a dataset using the `deeplake.delete` function, and what are the implications of deleting a dataset?",
        "ec3339eb-390a-49fd-af84-68444b1e6fd3": "What is the difference between `deeplake.copy` and `deeplake.deepcopy` in terms of copying datasets?",
        "898f9052-c54e-4172-bcf0-05e6cb462145": "How can you append samples to multiple tensors at once in a dataset?",
        "a6460989-014c-46dd-b28e-1a751eeb4637": "Explain the purpose of the `Dataset.delete` operation.",
        "6efd1c6d-7159-477b-ba7a-4e7a4f613b01": "How can you estimate the size of a dataset in bytes using Deep Lake?",
        "8fa26f3e-7fc4-4a07-80da-a2442f8cde47": "Describe the process of visualizing a dataset in the Jupyter notebook using Deep Lake.",
        "40f15df4-5a30-4807-8d45-8de99fd53038": "How can you store your credentials on the Activeloop Platform as Managed Credentials and use them for your dataset?",
        "0296f0b8-5508-4df1-9107-cc37b4491c06": "How can you add managed credentials to your dataset using `Dataset.add_creds_key`?",
        "b5ef6378-e216-43b4-9c4b-10fb910be91f": "What is the purpose of creating a link tensor in the context of the Activeloop Platform?",
        "3a8bffb6-7d36-49d0-8f67-3b976f50bc1c": "Provide examples of how you can populate the tensor with links in the dataset.",
        "4f38752b-f702-47c4-8c51-38dee4bf9117": "Why does a cloud path always require a `creds_key` when appending a link to the tensor?",
        "7d782c0d-e3d5-49db-97d3-5b56379b6f93": "How can you access the data stored in the `img` tensor in the dataset?",
        "e4de4beb-6496-4347-90ed-aa099897e672": "How can you update a sample in the dataset with a new link using `ds.img[0] = deeplake.link(\"./data/cat.jpeg\")`?",
        "e099f0af-a489-4306-a324-56262691cf13": "What method in the `Dataset` class is used to create a new tensor with the same shape and data type as another tensor?",
        "3cf1f285-048c-4566-a13d-d1ecfe0dc6d2": "How can you retrieve the details of a specific commit in a dataset?",
        "9d3672f7-832b-4585-9c8b-750541b35adc": "Explain the difference between the `delete()` and `delete_tensor()` methods in the `Dataset` class.",
        "3b408c6e-3685-4fab-ba1e-04c07966152a": "How can you determine if a dataset has pending changes that have not been committed yet?",
        "3b2fee3a-bba1-4e95-864e-a3440b0b9e37": "What is the purpose of the `random_split()` method in the `Dataset` class?",
        "d87f5688-2e5f-4bb9-9d14-91ffb17795a2": "How can you access the metadata associated with a dataset?",
        "431c626d-4b40-4325-bcab-8f4ed3fde29d": "Describe the functionality of the `pytorch()` and `tensorflow()` methods in the `Dataset` class.",
        "a3e0c4bf-908b-4433-899f-ca7f419840c3": "How can you rename a specific group within a dataset?",
        "16680c7b-ca86-4987-aa42-8855232a0a1e": "What does the `summary()` method in the `Dataset` class provide information about?",
        "3f8eab1e-ab46-426b-a48f-8c59349d6604": "How can you check if a specific node in a dataset is the head node?",
        "14fd8bcb-afe3-4895-96d5-cd8feff636d7": "Explain the process of creating a new tensor in a dataset using the `Dataset.create_tensor` function. What are the key steps involved in this process?",
        "ec70060f-c880-4102-ac51-122b343787fe": "How can you delete a tensor from a dataset using the `Dataset.delete_tensor` function? Provide a step-by-step explanation of how this operation is carried out.",
        "3931932d-5ad3-40eb-a0dc-d249130a849e": "Discuss the significance of the `Tensor.append` function in adding samples to a tensor. How does this function differ from the `Tensor.extend` function in terms of functionality and usage?",
        "b19fef29-c395-4198-be17-5a2cd5158ab3": "What is the purpose of the `Dataset.rename_tensor` function in the context of managing tensors? How does this function contribute to organizing and maintaining datasets effectively?",
        "e58b7e76-a787-4313-92b4-30a4e39504d6": "How does the `Dataset.create_tensor_like` function facilitate the creation of a new tensor based on the meta information of a source tensor? Explain the advantages of using this function in data manipulation tasks.",
        "38105eec-6e2f-4973-8883-061142cd7a11": "Explain the difference between binary masks and segmentation masks in the context of object representation in an image.",
        "7524632c-a524-4908-902f-be7c0c51e092": "How are objects represented in a binary mask tensor? Provide an example to illustrate your answer.",
        "3fb66621-ca4a-498b-8542-043e600a81cd": "Why is it recommended to compress segmentation masks using `lz4` compression?",
        "b1c9ca2d-9159-4e85-815d-7a0da76b5e43": "Describe the structure of a COCO keypoints tensor and explain the significance of the three values associated with each keypoint.",
        "3c01c36e-79d8-4058-8328-882fc8b80412": "How can binary masks be appended to a dataset? Provide a step-by-step explanation with an example.",
        "c4fcc6bf-fbba-4d4f-9ebd-8a6cdb13f6f9": "How can you specify the htype of a tensor when creating it in Deep Lake?",
        "344650f7-a7bb-46d8-8815-ac126335ef02": "Why is specifying an htype important for increasing the performance of Deep Lake datasets containing rich data like images and videos?",
        "2f98a488-d7a2-44af-b573-365860698b38": "What is the default htype of a tensor in Deep Lake if not specified during creation?",
        "9aaae3e4-2a44-4df7-973b-5c2adf3f8bc1": "Can you provide an example of creating a tensor named \"my_tensor\" with a specified htype in Deep Lake?",
        "89ba1aaf-e5ea-42fc-aca8-f1a0bd7cbf29": "How does specifying an htype allow for strict settings and error handling in Deep Lake?",
        "37cee623-ea0d-4610-8ea7-d712f80b7d62": "Explain the importance of specifying the format of the bounding box in the coords key in tensor meta information for correct display by the visualizer.",
        "e7a321c9-25e1-44f6-8c91-dc178c43226f": "How can a 3D bbox tensor be created using the provided code snippet? Explain the optional arguments that can be included.",
        "9fdb0864-7a4a-4710-878b-5e8f2f916a63": "Describe the different modes available for specifying the convention for the bbox coordinates when creating a 3D bbox tensor.",
        "66a58f26-11ac-4f30-8a84-593d090a3643": "What are the sample dimensions for the \"center\" mode of bbox coordinates? Explain the meaning of each component in the coordinate format.",
        "456a3844-ed3f-4bd0-abf7-a51628ec3c3a": "Provide the sample dimensions for the \"vertex\" mode of bbox coordinates. Explain the order of the vertices in this mode.",
        "758aff53-2f3f-4e48-8dc1-7b3059ed45dc": "What are the supported keys for credentials when working with s3 paths in the provided context?",
        "0d33eb02-c545-4dc9-b144-20c6e780e2d1": "What is the purpose of the 'token' parameter in the deeplake.rename function?",
        "576625a8-d832-4288-aa7b-e2546afd2e7e": "What exception is raised when a user is not authenticated while using the deeplake.rename function?",
        "b1c99930-d5d6-4bf4-ac67-d143c3335463": "What warning is given regarding the operation of renaming a dataset using the deeplake.rename function?",
        "6fd45363-b920-4775-8981-12efb7f5a491": "Can you provide an example of how to rename a dataset using the deeplake.rename function?",
        "f49d71f3-6d6d-4406-8ca6-ebabe3076b27": "Explain the purpose of the `deeplake.tiled` function and provide an example of how it can be used with the specified parameters.",
        "eb2aeefc-7b39-4bab-a640-f19498070db3": "What is the significance of the `tile_shape` parameter in the `deeplake.tiled` function? How does it affect the storage of the sample data?",
        "aaebd32d-4336-47a4-9db8-38b0818f93c8": "How does the `dtype` parameter in the `deeplake.tiled` function impact the data type of the sample array? Provide an example scenario where specifying a different data type would be beneficial.",
        "145cd08b-ac7d-48c8-9230-9fcc027b3cbe": "Describe the role of the `deeplake.compute` decorator in the context of the provided information. How does it modify the behavior of functions it decorates?",
        "98e337bc-4508-4ce8-a904-7bd7069dbe67": "Can you explain the requirements for functions that are decorated with `deeplake.compute`? What are the expected arguments and output for such functions?",
        "0e7f3ec8-27f3-4c6f-888e-0b39fc12d8f8": "How can you store your credentials on the Activeloop Platform for datasets?",
        "8583e9a8-269a-4918-a448-1ae66a3a26de": "What is the purpose of using managed credentials in the context of the Activeloop Platform?",
        "990a35fc-19b0-46a9-84e7-c400416e729d": "How can you add managed credentials to a dataset using `Dataset.add_creds_key`?",
        "88fef03e-8a99-40cd-8e86-8b894532893d": "What is the function of `ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")` in the context of the document?",
        "229fc4bf-3a23-4f7b-a7f9-08b77c7a5559": "Explain the different ways in which you can populate the `img` tensor with links in the dataset.",
        "bfe17b41-8828-42e3-8517-772319660e64": "Why does the statement `ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))` throw an exception?",
        "dece367c-b482-44de-9ab2-4579a2a0e718": "How can you access the data stored in the `img` tensor in the dataset?",
        "f8625081-09ac-4045-ad98-5d0d0bf2b147": "What is the purpose of the statement `ds.img[0] = deeplake.link(\"./data/cat.jpeg\")` in the context of updating a sample in the dataset?",
        "1a528447-af3b-493e-972e-9d8dd434abb9": "How can you create an image tensor in Deep Lake using compressed images? What are the recommended compression formats for storing images?",
        "b19c3f10-8efc-40b5-91bf-b7ad520341a6": "What are the optional arguments that can be specified when creating an image tensor in Deep Lake?",
        "895329aa-1ccb-4279-b451-61044c4cd7d5": "How can image samples be appended to the image tensor in Deep Lake? Provide examples of appending pixel data with an array and a Deep Lake image sample.",
        "5ccb1380-d231-425f-a496-93f1a4b05829": "What happens if the compression format of the input sample does not match the sample compression of the tensor in Deep Lake? How does it affect the upload process?",
        "f95c6e81-a22a-4e98-bb18-3377f640a1ed": "How can the `image.rgb` and `image.gray` htypes be used in Deep Lake to specify the color type of the image samples?",
        "9969eb15-a328-4779-8400-1fb515ddb8e8": "How can you log the creation of a Deep Lake dataset using Weights and Biases? Provide a code example to demonstrate the process.",
        "5b2556e8-a0d1-48d2-835b-b5b7516b03c3": "Explain the process of creating a class label tensor and appending class labels in the context of the provided information.",
        "9723cdc4-6439-4ee4-becf-711c0a64950e": "What is the purpose of the token parameter in the function described in the context information?",
        "38c9be58-7992-46e0-8a08-f6b62f01a9bd": "What type of error will be raised if a version is specified in the path when using the deeplake.read function?",
        "d9dcb763-2588-4c0e-aa68-0fe4af778865": "How does the deeplake.read function handle data from supported files?",
        "7c79f1a2-e44b-4566-8bd7-dab549c98496": "What are the optional parameters that can be passed to the deeplake.read function?",
        "31e1dc1d-22ae-4266-bd77-4efd2f5a5b27": "How does the deeplake.read function maximize upload speeds when the file format matches the sample_compression of the tensor?",
        "a9c57f25-1bd1-4c84-9e5c-38df62d3ccc3": "Explain the difference between binary masks and segmentation masks in the context of object representation in an image.",
        "4829596d-f255-4a12-9070-0dbd4caed540": "How are objects represented in a binary mask tensor? Provide an example to illustrate your answer.",
        "6057c3d2-62c1-438f-8e62-71c873e1178c": "Why is it recommended to compress segmentation masks using `lz4` compression?",
        "9354b484-3004-46ce-ba18-68e20b75821b": "Describe the structure of a COCO keypoints tensor and explain the significance of the three values associated with each keypoint.",
        "4aeb0dd2-812e-47ad-b0a5-90184fa0ccc1": "How can binary masks be appended to a dataset? Provide a step-by-step explanation with an example.",
        "a8328514-08bc-4cd8-89fb-8d7171470e9f": "How can you specify the htype of a tensor at its creation in Deep Lake? What is the default htype if not specified? Why is specifying an htype important for datasets containing rich data like images and videos in Deep Lake?",
        "27f2923b-ffe5-43d3-bab8-c8a0ca78c3ec": "How can you track the training progress of a job in the deep memory database?",
        "e9a34c58-6f39-4c6e-ac1d-ce255b987a40": "What information does the `job_id` contain and how is it used in the training process?",
        "2fc9ca04-e6cf-480b-b1dc-103405fd0a17": "What does the status \"pending\" indicate when checking the status of a job using `db.deep_memory.status(job_id)`?",
        "140074d1-ab6c-460d-80da-6fe8767fdec5": "How can you check the progress of a training job in the deep memory database?",
        "5e1e95a3-48e7-40c7-8911-b4299a799065": "What does the progress information \"eta: 2.5 seconds\" signify in the context of training a model?",
        "5246a65e-d0c9-4c7a-9046-8fd4aaba6f44": "How can you retrieve all training jobs that have occurred on a specific dataset using `db.deep_memory.list_jobs()`?",
        "5c3fa3d4-f4c2-4e60-a895-4f8e8b65604f": "Explain the importance of specifying the format of the bounding box in the coords key in tensor meta information for correct display by the visualizer.",
        "d28cc908-4cb0-4326-8533-4134b7f8afaa": "How can a 3D bbox tensor be created using the provided code snippet? Explain the optional arguments that can be included.",
        "f3d6f59c-19f5-4999-8566-87eaec1b147e": "Describe the two different conventions for specifying bbox coordinates in the coords dictionary, namely \"center\" and \"vertex\". Provide details on the format of coordinates for each convention.",
        "32d652ef-3b92-4a6c-8103-1fdc7ea5f834": "What is the significance of the intrinsics tensor or matrix when projecting 3D bounding boxes onto 2D data? How can the intrinsics matrix be specified in the dataset?",
        "8641ae2c-9ecf-47c8-9ac4-1c2f62654dba": "Can you explain the dimensions of the sample data for the \"center\" convention of bbox coordinates? Include details on the size and rotation angles along different axes.",
        "c87b78b1-f05a-4e5c-a6ec-fca75ea9ba4c": "What is the purpose of the `deeplake.like` function in the provided context?",
        "2781ff55-ff25-48b8-a0d9-feb312e827a7": "What parameters are required when using the `deeplake.like` function to create a new dataset?",
        "3b0c6947-6432-4b74-9c13-c3b7a7d2db45": "How does the `overwrite` parameter in the `deeplake.like` function affect the creation of a new dataset?",
        "62bf01dc-d268-41ba-8f36-7cd17fba0625": "When using the `deeplake.like` function, what does the `tensors` parameter allow you to specify?",
        "330f601d-8a22-492b-887f-cfc41af9c177": "How can credentials be provided when using the `deeplake.like` function for cloud datasets?",
        "a665911d-f9f4-4dcf-82e9-c693caa145fc": "What are the different types of destinations that can be specified when ingesting data from a DataFrame using the `deeplake.ingest_dataframe` function?",
        "6d135796-0e28-4caa-8e5d-5682004ee788": "How can you authenticate to Deep Lake when writing to Deep Lake cloud datasets?",
        "42a41365-65b6-4364-80a6-c267899cf577": "What is the purpose of the `column_params` parameter in the `deeplake.ingest_dataframe` function?",
        "31d5cb92-164c-4ada-b4ce-9685ef419b28": "When should the `mem://` path be used as a destination in the `deeplake.ingest_dataframe` function?",
        "e8a1be23-e806-4609-bad5-55ad056ffae3": "How can you specify the filenames for linked data in the dataset when ingesting data from a DataFrame using `deeplake.ingest_dataframe`?",
        "2a092559-c32d-4269-bf82-71ce646cd2d6": "What is the purpose of the deepcopy function in the deeplake library?",
        "53b3cbbe-b192-48c3-9264-5663f0277463": "What are the possible exceptions that can be raised when using the deepcopy function?",
        "7f9a6a94-45b6-45c2-b166-4a388379662b": "Explain the parameters required for the deepcopy function and their significance.",
        "2e8f3b4c-964c-40b3-84cb-011765ee5976": "How does the overwrite parameter in the deepcopy function work?",
        "382bd4b4-8a16-4bcb-8bdf-5e763f971557": "Can you provide an example of how to use the deepcopy function with the src_creds parameter?",
        "a9a095c9-4511-4a6b-8826-c8ffa560927c": "How can audio samples be appended to tensors in Deep Lake?",
        "24be9541-512b-438b-bafa-b2b8c6297246": "What are the supported compressions for audio samples in Deep Lake?",
        "69f30c5e-ccc2-41a4-b480-c7e62d3a9e9f": "How can a class label tensor be created in Deep Lake?",
        "855518f2-c8ea-4a5d-b61f-dfbd62cddf98": "What are the optional arguments that can be specified when creating a class label tensor in Deep Lake?",
        "fc43b367-6061-47eb-be58-81f76ffccc5f": "Why is `chunk_compression` recommended when specifying compression for class label tensors in Deep Lake?",
        "a31562ca-cceb-4c00-ba0b-9e768e4c2955": "What is the purpose of the `cancel()` method in the `DeepMemory` class of the `deeplake.core.vectorstore.deep_memory.deep_memory` module?",
        "78b7b293-ad00-4695-8264-e5f30dd8ab15": "Explain the difference between the `BadGatewayException` and `BadRequestException` classes in the `deeplake.util.exceptions` module.",
        "b9dd440b-98f2-42ec-9597-afe2ad813cb0": "How does the `clear_cache()` method in the `deeplake.core.dataset.Dataset` class interact with the `LRUCache` class in the `deeplake.core.storage` module?",
        "ca0d3691-15ac-4821-be85-99c3f5b457c2": "What is the significance of the `ChunkSizeTooSmallError` class in the `deeplake.util.exceptions` module?",
        "984be6ce-653c-480d-b12b-5035f65d4fe8": "Describe the functionality of the `checkout()` method in the `deeplake.core.dataset.Dataset` class and how it differs from the `checkout()` method in the `deeplake.core.vectorstore.deeplake_vectorstore.VectorStore` class.",
        "18b11651-f068-4078-b70a-c0193133e2ca": "How can dataset reads be logged in Weights and Biases when using a Torch dataloader?",
        "cc6e6ea8-64d5-40da-baab-7315e0102347": "What is the recommended method to log dataset reads when iterating over a dataset in Weights and Biases?",
        "7b81cc66-a64d-475a-8b34-01b7b69d9e91": "What is the importance of committing changes to an existing dataset with an active Weights and Biases run?",
        "bb7619ae-cb9e-42d0-86a1-8e5ad26471a3": "How can you log dataset reads when using `Dataset.pytorch()` or `Tensor.numpy()` on its tensors in Weights and Biases?",
        "ea330fde-3cb0-4b15-b913-67ec1b53c0ef": "Explain the significance of logging dataset reads in the context of machine learning projects.",
        "0f05a8a2-173b-4990-a65a-22146684068b": "What are the key concepts in Deep Lake, as mentioned in the context information?",
        "34e7c81c-b878-4322-9579-2c2714fb9b00": "How does Deep Lake support PyTorch and Tensorflow?",
        "3d55948f-0f64-4e31-aa86-14255fd43c0a": "What are the different types of compressions supported by Deep Lake for various sample types?",
        "093f57e8-4016-483a-9b5f-584e6c9f1eeb": "Explain the concept of sample compression in Deep Lake and how it is utilized when creating tensors.",
        "a8ea3f3f-a3b6-4e70-8091-eb8afaab7a83": "Can you list some of the API references provided by Deep Lake as mentioned in the context information?",
        "4315a054-5360-447c-9b8d-7c87e534e35f": "What is the recommended compression method for segmentation masks and why?",
        "255b9795-7f20-4515-948e-9086ca4c571e": "How can a segment_mask tensor be created in the dataset?",
        "a34371f3-39e6-433c-bd3d-a387841eb78e": "What is the difference between segmentation masks and binary masks in terms of representing objects in an image?",
        "4063708a-7e86-413a-a667-2cc548d785a5": "How can class names be set for a segment_mask tensor after creation?",
        "494186ea-565b-4860-af95-15d53811d065": "Why are segmentation masks not suitable for datasets where objects might overlap or where multiple objects within the same class need to be distinguished?",
        "2cafebba-653d-4058-a647-4f8e9c5230cf": "How can bounding boxes be appended in the dataset for object detection tasks?",
        "40f5b225-6e2e-4b9c-a107-41d9b4ce3dd1": "What is the required format for 3D bounding boxes to be correctly displayed by the visualizer?",
        "87a8d382-a9a3-4f20-8d7e-6af9b82d9e56": "What key must be specified in the coords dictionary when creating a 3D bbox tensor?",
        "7e77cb5f-0f3a-4ce9-924e-9c543fef2211": "What information must be present in the dataset for projecting 3D bounding boxes onto 2D data?",
        "04bbb04b-30a3-4712-bbd6-cadb6696ec0f": "Can bounding boxes be appended as both np.ndarrays and lists of arrays in the dataset?",
        "94e34702-5a40-44d5-be8e-4d8a3aaba390": "Explain the process of creating a polygon tensor using the provided code snippet. What are the optional arguments that can be used during the creation of a polygon tensor?",
        "247e5a6d-38c0-452e-b269-78b232ada1bd": "How can polygons be appended to a dataset using a list of tuples or numpy arrays? Provide examples for both 2-D and 3-D points.",
        "42980ec9-72f0-4495-8120-d92a4167df75": "Describe the Nifti Htype mentioned in the context. What are the possible sample dimensions for Nifti data?",
        "048e8e94-1cfc-40a2-8cdc-684df1fe4398": "Can you explain the significance of using compressions like \"lz4\" when creating a polygon tensor? How does it impact the data storage and retrieval process?",
        "6d8c7070-c0fa-4c37-a41c-0d09b882ac0e": "Compare and contrast the methods of appending polygons using lists of tuples and numpy arrays. What are the advantages of using numpy arrays for storing polygon data?"
    },
    "corpus": {
        "node_1140": "* **deep_memory** (_bool_) \u2013 Whether to use the Deep Memory model for improving search results. Defaults to False if deep_memory is not specified in the Vector Store initialization. If True, the distance metric is set to \u201cdeepmemory_distance\u201d, which represents the metric with which the model was trained. The search is performed using the Deep Memory model. If False, the distance metric is set to \u201cCOS\u201d or whatever distance metric user specifies.\n\n  * **return_tql** (_bool_) \u2013 Whether to return the TQL query string used for the search. Defaults to False.\n\nRaises\n\n    \n\n  * **ValueError** \u2013 When invalid parameters are specified.\n\n  * **ValueError** \u2013 when deep_memory is True. Deep Memory is only available for datasets stored in the Deep Lake Managed Database for paid accounts.\n\n  * **DeepMemoryAccessError** \u2013 if user does not have access to deep_memory.\n\nReturns\n\n    \n\nDictionary where keys are tensor names and values are the results of the\nsearch\n\nReturn type\n\n    \n\nDict\n\nsummary()\uf0c1\n\n    \n\nPrints a summary of the dataset\n\ntensors()\uf0c1\n\n    \n\nReturns the list of tensors present in the dataset\n\nupdate_embedding(_row_ids : Optional[List[str]] = None_, _ids :\nOptional[List[str]] = None_, _filter : Optional[Union[Dict, Callable]] =\nNone_, _query : Optional[str] = None_, _exec_option : Optional[str] = None_,\n_embedding_function : Optional[Union[Callable, List[Callable]]] = None_,\n_embedding_source_tensor : Union[str, List[str]] = 'text'_, _embedding_tensor\n: Optional[Union[str, List[str]]] = None_)\uf0c1\n\n    \n\nRecompute existing embeddings of the VectorStore, that match either query,\nfilter, ids or row_ids.",
        "node_1228": "* `InvalidOutputDatasetError`\n    * `InvalidTransformDataset`\n    * `HubComposeEmptyListError`\n    * `HubComposeIncompatibleFunction`\n    * `DatasetUnsupportedPytorch`\n    * `CorruptedMetaError`\n    * `ChunkEngineError`\n    * `FullChunkError`\n    * `ChunkIdEncoderError`\n    * `ChunkSizeTooSmallError`\n    * `DatasetHandlerError`\n    * `MemoryDatasetCanNotBePickledError`\n    * `CorruptedSampleError`\n    * `VersionControlError`\n    * `MergeError`\n    * `MergeNotSupportedError`\n    * `MergeMismatchError`\n    * `MergeConflictError`\n    * `CheckoutError`\n    * `CommitError`\n    * `EmptyCommitError`\n    * `TensorModifiedError`\n    * `GCSDefaultCredsNotFoundError`\n    * `InvalidOperationError`\n    * `AgreementError`\n    * `AgreementNotAcceptedError`\n    * `RenameError`\n    * `BufferError`\n    * `InfoError`\n    * `OutOfChunkCountError`\n    * `OutOfSampleCountError`\n    * `SampleHtypeMismatchError`\n    * `EmptyTensorError`\n    * `DatasetViewSavingError`\n    * `ManagedCredentialsNotFoundError`\n    * `UnableToReadFromUrlError`\n    * `InvalidTokenException`\n    * `TokenPermissionError`\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.",
        "node_190": "load('hub://activeloop/coco-train')\n    >>> train_loader = ds_train.dataloader()\\\n    .     .query(\"(select * where contains(categories, 'car') limit 1000) union (select * where contains(categories, 'motorcycle') limit 1000)\")\\\n    .     .pytorch()\n    .\n    >>> # loop over the elements\n    >>> for i, data in enumerate(train_loader):\n    .     # custom logic on data\n    .     pass\n    \n\ndelete(_large_ok =False_)\uf0c1\n\n    \n\nDeletes the entire dataset from the cache layers (if any) and the underlying\nstorage. This is an **IRREVERSIBLE** operation. Data once deleted can not be\nrecovered.\n\nParameters\n\n    \n\n**large_ok** (_bool_) \u2013 Delete datasets larger than 1 GB. Defaults to `False`.\n\nRaises\n\n    \n\n  * **DatasetTooLargeToDelete** \u2013 If the dataset is larger than 1 GB and `large_ok` is `False`.\n\n  * **DatasetHandlerError** \u2013 If the dataset is marked as allow_delete=False.\n\ndelete_branch(_name : str_) -> None\uf0c1\n\n    \n\nDeletes the branch and cleans up any unneeded data. Branches can only be\ndeleted if there are no sub-branches and if it has never been merged into\nanother branch.\n\nParameters\n\n    \n\n**name** (_str_) \u2013 The branch to delete.\n\nRaises\n\n    \n\n  * **CommitError** \u2013 If `branch` could not be found.\n\n  * **ReadOnlyModeError** \u2013 If branch deletion is attempted in read-only mode.\n\n  * **Exception** \u2013 If you have the given branch currently checked out.",
        "node_517": "* Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.\n\nExamples\n\nAppending Deep Lake audio sample\n\n    \n    \n    >>> ds.audios.append(deeplake.read(\"audios/001.mp3\"))\n    \n\nExtending with Deep Lake audio samples\n\n    \n    \n    >>> ds.audios.extend([deeplake.read(f\"videos/00{i}.mp3\") for i in range(10)])\n    \n\n## Class Label Htype\uf0c1\n\n  * Sample dimensions: `(# labels,)`\n\nClass labels are stored as numerical values in tensors, which are indices of\nthe list `tensor.info.class_names`.\n\n### Creating a class label tensor\uf0c1\n\nA class label tensor can be created using\n\n    \n    \n    >>> classes = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"]\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\", class_names=classes, chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.",
        "node_1278": "exceptions)\n  * tensorflow() (deeplake.core.dataset.Dataset method)\n    * (deeplake.enterprise.DeepLakeDataLoader method)\n  * TensorGroupAlreadyExistsError (class in deeplake.util.exceptions)\n  * TensorGroupDoesNotExistError (class in deeplake.util.exceptions)\n  * TensorInvalidSampleShapeError (class in deeplake.util.exceptions)\n  * TensorMetaInvalidHtype (class in deeplake.util.exceptions)\n  * TensorMetaInvalidHtypeOverwriteKey (class in deeplake.util.exceptions)\n  * TensorMetaInvalidHtypeOverwriteValue (class in deeplake.util.exceptions)\n  * TensorMetaMissingKey (class in deeplake.util.exceptions)\n  * TensorMetaMissingRequiredValue (class in deeplake.util.exceptions)\n  * TensorMetaMutuallyExclusiveKeysError (class in deeplake.util.exceptions)\n\n|\n\n  * TensorMismatchError (class in deeplake.util.exceptions)\n  * TensorModifiedError (class in deeplake.util.exceptions)\n  * tensors (deeplake.core.dataset.Dataset property)\n  * tensors() (deeplake.core.vectorstore.deeplake_vectorstore.VectorStore method)\n  * TensorUnsupportedSampleType (class in deeplake.util.exceptions)\n  * text() (deeplake.core.tensor.Tensor method)\n  * tiled() (in module deeplake)\n    * (in module deeplake.api.tiled)\n  * timestamps (deeplake.core.tensor.Tensor property)\n  * tobytes() (deeplake.core.tensor.Tensor method)\n  * token (deeplake.core.dataset.Dataset property)\n    * (deeplake.core.dataset.DeepLakeCloudDataset property)\n  * TokenPermissionError (class in deeplake.util.exceptions)\n  * train() (deeplake.core.vectorstore.deep_memory.deep_memory.DeepMemory method)\n  * transform() (deeplake.enterprise.DeepLakeDataLoader method)\n  * TransformError (class in deeplake.util.",
        "node_163": "Defaults to None. The `embedding_data` and `embedding` cannot both be specified.\n\n  * **embedding_data** (_List_ _[__str_ _]_) \u2013 Data against which the search will be performed by embedding it using the embedding_function. Defaults to None. The embedding_data and embedding cannot both be specified.\n\n  * **embedding_function** (_Optional_ _[__Callable_ _]__,__optional_) \u2013 function for converting embedding_data into embedding. Only valid if embedding_data is specified. Input to embedding_function is a list of data and output is a list of embeddings.\n\n  * **k** (_int_) \u2013 Number of elements to return after running query. Defaults to 4.\n\n  * **distance_metric** (_str_) \u2013 Distance metric to use for sorting the data. Avaliable options are: `\"L1\", \"L2\", \"COS\", \"MAX\"`. Defaults to None, which uses same distance metric specified in `index_params`. If there is no index, it performs linear search using `DEFAULT_VECTORSTORE_DISTANCE_METRIC`.\n\n  * **query** (_Optional_ _[__str_ _]_) \u2013 TQL Query string for direct evaluation, without application of additional filters or vector search.\n\n  * **filter** (_Union_ _[__Dict_ _,__Callable_ _]__,__optional_) \u2013 \n\nAdditional filter evaluated prior to the embedding search.\n\n    * `Dict` \\- Key-value search on tensors of htype json, evaluated on an AND basis (a sample must satisfy all key-value filters to be True) Dict = {\u201ctensor_name_1\u201d: {\u201ckey\u201d: value}, \u201ctensor_name_2\u201d: {\u201ckey\u201d: value}}\n\n    * `Function` \\- Any function that is compatible with `Dataset.filter`.\n\n  * **exec_option** (_Optional_ _[__str_ _]_) \u2013 \n\nMethod for search execution. It could be either `\"python\"`, `\"compute_engine\"`\nor `\"tensor_db\"`. Defaults to `None`, which inherits the option from the\nVector Store initialization.\n\n    * `python` \\- Pure-python implementation that runs on the client and can be used for data stored anywhere. WARNING: using this option with big datasets is discouraged because it can lead to memory issues.",
        "node_295": "Deep Lake also has a performant dataloader\nfor fine-tuning your Large Language Models.\n\n**Deep Lake vs Pinecone**\n\nBoth Deep Lake and Pinecone enable users to store and search vectors\n(embeddings) and offer integrations with LangChain and LlamaIndex. However,\nthey are architecturally very different. Pinecone is a fully-managed Vector\nDatabase that is optimized for highly demanding applications requiring a\nsearch for billions of vectors. Deep Lake is serverless. All computations run\nclient-side, which enables users to get started in seconds. Unlike Pinecone,\nDeep Lake\u2019s data format can store raw data such as images, videos, and text,\nin addition to embeddings. Deep Lake datasets can be visualized and version\ncontrolled. Pinecone is limited to light metadata on top of the embeddings and\nhas no visualization. Deep Lake also has a performant dataloader for fine-\ntuning your Large Language Models.\n\n**Deep Lake vs Weaviate**\n\nBoth Deep Lake and Weaviate enable users to store and search vectors\n(embeddings) and offer integrations with LangChain and LlamaIndex. However,\nthey are architecturally very different. Weaviate is a Vector Database that\ncan be deployed in a managed service or by the user via Kubernetes or Docker.\nDeep Lake is serverless. All computations run client-side, which enables users\nto support lightweight production apps in seconds. Unlike Weaviate, Deep\nLake\u2019s data format can store raw data such as images, videos, and text, in\naddition to embeddings. Deep Lake datasets can be visualized and version\ncontrolled.",
        "node_1012": "---|---  \n`link` | Utility that stores a link to raw data.  \n`link_tiled` | Utility that stores links to multiple images that act as tiles and together form a big image.  \n  \n## Parallelism\uf0c1\n\n`compute` | Compute is a decorator for functions.  \n---|---  \n`compose` | Takes a list of functions decorated using `deeplake.compute()` and creates a pipeline that can be evaluated using .eval  \n  \nTransform pipelines returned by `compute()` and `compose()` are evaluated\nusing `eval`:\n\n`eval` | Evaluates the pipeline on `data_in` to produce an output dataset `ds_out`.  \n---|---  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_618": "Examples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.",
        "node_898": "* **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.boxes.info.update(coords = {\"type\": \"pixel\", \"mode\": \"LTRB\"})\n    \n\nNote\n\nIf the bounding box format is not specified, the visualizer will assume a YOLO\nformat (`fractional` \\+ `CCWH`) if the box coordinates are < 1 on average.\nOtherwise, it will assume the COCO format (`pixel` \\+ `LTWH`).\n\n### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.",
        "node_268": "When specified, creates a new vectorstore to track evaluation queries, the Deep Memory response, and the naive vector search results. Defaults to None.\n\nReturns\n\n    \n\nRecalls for each rank.\n\nReturn type\n\n    \n\nDict[str, Dict[str, float]]\n\nRaises\n\n    \n\n  * **ImportError** \u2013 If indra is not installed.\n\n  * **ValueError** \u2013 If no embedding_function is provided either during initialization or evaluation.\n\nget_model()\uf0c1\n\n    \n\nGet the name of the model currently being used by DeepMemory managed service.\n\nlist_jobs(_debug =False_)\uf0c1\n\n    \n\nList all training jobs on DeepMemory managed service.\n\nset_model(_model_name : str_)\uf0c1\n\n    \n\nSet model.npy to use model_name instead of default model :param model_name:\nname of the model to use :type model_name: str\n\nstatus(_job_id : str_)\uf0c1\n\n    \n\nGet the status of a training job on DeepMemory managed service.\n\nExamples\n\n    \n    \n    >>> vectorstore.deep_memory.status(job_id)\n    --------------------------------------------------------------\n    |                  6508464cd80cab681bfcfff3                  |\n    --------------------------------------------------------------\n    | status                     | pending                       |\n    --------------------------------------------------------------\n    | progress                   | None                          |\n    --------------------------------------------------------------\n    | results                    | not available yet             |\n    --------------------------------------------------------------\n    \n\nParameters\n\n    \n\n**job_id** (_str_) \u2013 job_id of the training job.\n\ntrain(_queries : List[str]_, _relevance : List[List[Tuple[str, int]]]_,\n_embedding_function : Optional[Callable[[str], ndarray]] = None_, _token :\nOptional[str] = None_) -> str\uf0c1\n\n    \n\nTrain a model on DeepMemory managed service.\n\nExamples\n\n    \n    \n    >>> queries: List[str] = [\"What is the capital of India?\", \"What is the capital of France?\"]\n    >>> relevance: List[List[Tuple[str, int]]] = [[(\"doc_id_1\", 1), (\"doc_id_2\", 1)], [(\"doc_id_3\", 1)]]\n    >>> # doc_id_1, doc_id_2, doc_id_3 are the ids of the documents in the corpus dataset that is relevant to the queries.",
        "node_1127": "\\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **runtime** (_Dict_ _,__optional_) \u2013 Parameters for creating the Vector Store in Deep Lake\u2019s Managed Tensor Database. Not applicable when loading an existing Vector Store. To create a Vector Store in the Managed Tensor Database, set runtime = {\u201ctensor_db\u201d: True}.\n\n  * **branch** (_str_) \u2013 Branch name to use for the Vector Store. Defaults to \u201cmain\u201d.\n\n  * ****kwargs** (_dict_) \u2013 Additional keyword arguments.\n\nDanger\n\nSetting `overwrite` to `True` will delete all of your data if the Vector Store\nexists! Be very careful when setting this parameter.\n\nadd(_embedding_function : Optional[Union[Callable, List[Callable]]] = None_,\n_embedding_data : Optional[Union[List, List[List]]] = None_, _embedding_tensor\n: Optional[Union[str, List[str]]] = None_, _return_ids : bool = False_,\n_rate_limiter : Dict = {'batch_byte_size': 10000, 'bytes_per_minute':\n1800000.0, 'enabled': False}_, _** tensors_) -> Optional[List[str]]\uf0c1\n\n    \n\nAdding elements to deeplake vector store.\n\nTensor names are specified as parameters, and data for each tensor is\nspecified as parameter values. All data must of equal length.\n\nExamples\n\n    \n    \n    >>> # Dummy data\n    >>> texts = [\"Hello\", \"World\"]\n    >>> embeddings = [[1, 2, 3], [4, 5, 6]]\n    >>> metadatas = [{\"timestamp\": \"01:20\"}, {\"timestamp\": \"01:22\"}]\n    >>> emebdding_fn = lambda x: [[1, 2, 3]] * len(x)\n    >>> embedding_fn_2 = lambda x: [[4, 5]] * len(x)\n    >>> # Directly upload embeddings\n    >>> deeplake_vector_store.add(\n    .     text = texts,\n    .     embedding = embeddings,\n    .",
        "node_365": "## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.  \n`Dataset.rename` | Renames the dataset to path.  \n`Dataset.connect` | Connect a Deep Lake cloud dataset through a deeplake path.  \n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n`Dataset.pop` | Removes a sample from all the tensors of the dataset.  \n`Dataset.rechunk` | Rewrites the underlying chunks to make their sizes optimal.  \n`Dataset.flush` | Necessary operation after writes if caches are being used.  \n`Dataset.clear_cache` | \n\n  * Flushes (see `Dataset.flush()`) the contents of the cache layers (if any) and then deletes contents of all the layers of it.\n\n  \n`Dataset.size_approx` | Estimates the size in bytes of the dataset.  \n`Dataset.random_split` | Splits the dataset into non-overlapping `Dataset` objects of given lengths.  \n  \n## Dataset Visualization\uf0c1\n\n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n---|---  \n  \n## Dataset Credentials\uf0c1\n\n`Dataset.add_creds_key` | Adds a new creds key to the dataset.  \n---|---  \n`Dataset.populate_creds` | Populates the creds key added in add_creds_key with the given creds.  \n`Dataset.update_creds_key` | Updates the name and/or management status of a creds key.",
        "node_1315": "Revision `e8ef6585`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: v2.8.5\n\nVersions\n\n    latest\n    v2.8.5\n\nDownloads\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_1079": "If specified, the \u2018data_directory\u2019 will not be examined for annotations.\n\n  * **allow_no_annotation** (_bool_) \u2013 Flag to determine whether missing annotations files corresponding to an image should be treated as empty annoations. Set to `False` by default.\n\n  * **image_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the images tensor.\n\n  * **label_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the labels tensor.\n\n  * **coordinates_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the ccoordinates tensor. This tensor either contains bounding boxes or polygons.\n\n  * **src_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 Credentials to access the source data. If not provided, will be inferred from the environment.\n\n  * **dest_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 The string `ENV` or a dictionary containing credentials used to access the destination path of the dataset.\n\n  * **image_creds_key** (_Optional_ _[__str_ _]_) \u2013 creds_key for linked tensors, applicable if the htype for the images tensor is specified as \u2018link[image]\u2019 in the \u2018image_params\u2019 input.\n\n  * **inspect_limit** (_int_) \u2013 The maximum number of annotations to inspect, in order to infer whether they are bounding boxes of polygons. This in put is ignored if the htype is specfied in the \u2018coordinates_params\u2019.\n\n  * **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Set to `True` by default.\n\n  * **shuffle** (_bool_) \u2013 Shuffles the input data prior to ingestion. Set to `False` by default.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for ingestion. Set to `0` by default.\n\n  * **token** (_Optional_ _[__str_ _]_) \u2013 The token to use for accessing the dataset and/or connecting it to Deep Lake.",
        "node_1138": "* `Dict` \\- Key-value search on tensors of htype json, evaluated on an AND basis (a sample must satisfy all key-value filters to be True) Dict = {\u201ctensor_name_1\u201d: {\u201ckey\u201d: value}, \u201ctensor_name_2\u201d: {\u201ckey\u201d: value}}\n\n    * `Function` \\- Any function that is compatible with `Dataset.filter`.\n\n  * **exec_option** (_Optional_ _[__str_ _]_) \u2013 \n\nMethod for search execution. It could be either `\"python\"`, `\"compute_engine\"`\nor `\"tensor_db\"`. Defaults to `None`, which inherits the option from the\nVector Store initialization.\n\n    * `python` \\- Pure-python implementation that runs on the client and can be used for data stored anywhere. WARNING: using this option with big datasets is discouraged because it can lead to memory issues.\n\n    * `compute_engine` \\- Performant C++ implementation of the Deep Lake Compute Engine that runs on the client and can be used for any data stored in or connected to Deep Lake. It cannot be used with in-memory or local datasets.\n\n    * `tensor_db` \\- Performant and fully-hosted Managed Tensor Database that is responsible for storage and query execution. Only available for data stored in the Deep Lake Managed Database. Store datasets in this database by specifying runtime = {\u201ctensor_db\u201d: True} during dataset creation.\n\n  * **embedding_tensor** (_str_) \u2013 Name of tensor with embeddings. Defaults to \u201cembedding\u201d.\n\n  * **return_tensors** (_Optional_ _[__List_ _[__str_ _]__]_) \u2013 List of tensors to return data for. Defaults to None, which returns data for all tensors except the embedding tensor (in order to minimize payload). To return data for all tensors, specify return_tensors = \u201c*\u201d.\n\n  * **return_view** (_bool_) \u2013 Return a Deep Lake dataset view that satisfied the search parameters, instead of a dictionary with data. Defaults to False. If `True` return_tensors is set to \u201c*\u201d beucase data is lazy-loaded and there is no cost to including all tensors in the view.\n\n  * **deep_memory** (_bool_) \u2013 Whether to use the Deep Memory model for improving search results.",
        "node_619": "* Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.\n\nExamples\n\nAppending polygons with 2-D points\n\n    \n    \n    >>> poly1 = [(1, 2), (2, 3), (3, 4)]\n    >>> poly2 = [(10, 12), (14, 19)]\n    >>> poly3 = [(33, 32), (54, 67), (67, 43), (56, 98)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with 3-D points\n\n    \n    \n    >>> poly1 = [(10, 2, 9), (12, 3, 8), (12, 10, 4)]\n    >>> poly2 = [(10, 1, 8), (5, 17, 11)]\n    >>> poly3 = [(33, 33, 31), (45, 76, 13), (60, 24, 17), (67, 87, 83)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> sample = np.random.randint(0, 10, (5, 7, 2))  # 5 polygons with 7 points\n    >>> ds.polygons.append(sample)\n    \n    \n    \n    >>> import numpy as np\n    >>> poly1 = np.random.randint(0, 10, (5, 2))\n    >>> poly2 = np.random.randint(0, 10, (8, 2))\n    >>> poly3 = np.random.randint(0, 10, (3, 2))\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\n## Nifti Htype\uf0c1\n\n  * Sample dimensions: `(# height, # width, # slices)` or `(# height, # width, # slices, # time unit)` in case of time-series data.",
        "node_889": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.gray htypes\n    * Video Htype\n      * Limitations\n      * Creating a video tensor\n      * Appending video samples\n    * Audio Htype\n      * Creating an audio tensor\n      * Appending audio samples\n    * Class Label Htype\n      * Creating a class label tensor\n      * Appending class labels\n    * Tag Htype\n      * Creating a tag tensor\n      * Appending tag samples\n    * Bounding Box Htype\n      * Creating a bbox tensor\n      * Appending bounding boxes\n    * 3D Bounding Box Htype\n      * Creating a 3d bbox tensor\n      * Appending 3d bounding boxes\n    * Intrinsics Htype\n      * Creating an intrinsics tensor\n      * Appending intrinsics matrices\n    * Segmentation Mask Htype\n      * Creating a segment_mask tensor\n      * Appending segmentation masks\n    * Binary Mask Htype\n      * Creating a binary_mask tensor\n      * Appending binary masks\n    * COCO Keypoints Htype\n      * Creating a keypoints_coco tensor\n      * Appending keypoints\n    * Point Htype\n      * Creating a point tensor\n      * Appending point samples\n    * Polygon Htype\n      * Creating a polygon tensor\n      * Appending polygons\n    * Nifti Htype\n      * Limitations\n      * Creating a nifti tensor\n      * Appending nifti data\n    * Point Cloud Htype\n      * Creating a point cloud tensor\n      * Appending point clouds\n    * Mesh Htype\n      * Creating a mesh tensor\n      * Appending meshes\n    * Embedding Htype\n      * Creating an embedding tensor\n      * Appending embedding samples\n    * Sequence htype\n    * Link htype\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.",
        "node_655": "For datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.\n\n    \n    \n    >>> ds.add_creds_key(\"my_s3_creds\", managed=True)\n    >>> ds.add_creds_key(\"my_gcs_creds\", managed=True)\n    \n\nCreate a link tensor\n\n    \n    \n    >>> ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")\n    \n\nPopulate the tensor with links\n\n    \n    \n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\", creds_key=\"my_s3_key\"))\n    >>> ds.img.append(deeplake.link(\"gcs://ghi/jkl.png\", creds_key=\"GCS_KEY\"))\n    >>> ds.img.append(deeplake.link(\"https://picsum.photos/200/300\")) # http path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"./path/to/cat.jpeg\")) # local path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))  # this will throw an exception as cloud paths always need creds_key\n    :bluebold:`Accessing the data`\n    \n    \n    \n    >>> for i in range(5):\n    ...     ds.img[i].numpy()\n    ...\n    \n\nUpdating a sample\n\n    \n    \n    >>> ds.img[0] = deeplake.link(\"./data/cat.jpeg\")\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_883": "* Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.\n\nExamples\n\nAppending point clouds with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> point_cloud1 = np.random.randint(0, 10, (5, 3))\n    >>> ds.point_clouds.append(point_cloud1)\n    >>> point_cloud2 = np.random.randint(0, 10, (15, 3))\n    >>> ds.point_clouds.append(point_cloud2)\n    >>> ds.point_clouds.shape\n    >>> (2, None, 3)\n    \n\nOr we can use `deeplake.read()` method to add samples\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.las\") # point cloud with 100 points\n    >>> ds.point_cloud.append(sample)\n    >>> ds.point_cloud.shape\n    >>> (1, 100, 3)\n    \n\n## Mesh Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Mesh samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.",
        "node_773": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.gray htypes\n    * Video Htype\n      * Limitations\n      * Creating a video tensor\n      * Appending video samples\n    * Audio Htype\n      * Creating an audio tensor\n      * Appending audio samples\n    * Class Label Htype\n      * Creating a class label tensor\n      * Appending class labels\n    * Tag Htype\n      * Creating a tag tensor\n      * Appending tag samples\n    * Bounding Box Htype\n      * Creating a bbox tensor\n      * Appending bounding boxes\n    * 3D Bounding Box Htype\n      * Creating a 3d bbox tensor\n      * Appending 3d bounding boxes\n    * Intrinsics Htype\n      * Creating an intrinsics tensor\n      * Appending intrinsics matrices\n    * Segmentation Mask Htype\n      * Creating a segment_mask tensor\n      * Appending segmentation masks\n    * Binary Mask Htype\n      * Creating a binary_mask tensor\n      * Appending binary masks\n    * COCO Keypoints Htype\n      * Creating a keypoints_coco tensor\n      * Appending keypoints\n    * Point Htype\n      * Creating a point tensor\n      * Appending point samples\n    * Polygon Htype\n      * Creating a polygon tensor\n      * Appending polygons\n    * Nifti Htype\n      * Limitations\n      * Creating a nifti tensor\n      * Appending nifti data\n    * Point Cloud Htype\n      * Creating a point cloud tensor\n      * Appending point clouds\n    * Mesh Htype\n      * Creating a mesh tensor\n      * Appending meshes\n    * Embedding Htype\n      * Creating an embedding tensor\n      * Appending embedding samples\n    * Sequence htype\n    * Link htype\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.",
        "node_753": "* **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.boxes.info.update(coords = {\"type\": \"pixel\", \"mode\": \"LTRB\"})\n    \n\nNote\n\nIf the bounding box format is not specified, the visualizer will assume a YOLO\nformat (`fractional` \\+ `CCWH`) if the box coordinates are < 1 on average.\nOtherwise, it will assume the COCO format (`pixel` \\+ `LTWH`).\n\n### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.",
        "node_23": "* Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\n  * Recompression of samples read with `deeplake.read` is also not supported.\n\nExamples\n\nAppending Deep Lake video sample\n\n    \n    \n    >>> ds.videos.append(deeplake.read(\"videos/0012.mp4\"))\n    \n\nExtending with multiple videos\n\n    \n    \n    >>> ds.videos.extend([deeplake.read(f\"videos/00{i}.mp4\") for i in range(10)])\n    \n\n## Audio Htype\uf0c1\n\n  * Sample dimensions: `(# samples in audio, # channels)` or `(# samples in audio,)`\n\n### Creating an audio tensor\uf0c1\n\nAn audio tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"audios\", htype=\"audio\", sample_compression=\"mp3\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `float64`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.",
        "node_563": "* Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.\n\nExamples\n\nAppending point clouds with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> point_cloud1 = np.random.randint(0, 10, (5, 3))\n    >>> ds.point_clouds.append(point_cloud1)\n    >>> point_cloud2 = np.random.randint(0, 10, (15, 3))\n    >>> ds.point_clouds.append(point_cloud2)\n    >>> ds.point_clouds.shape\n    >>> (2, None, 3)\n    \n\nOr we can use `deeplake.read()` method to add samples\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.las\") # point cloud with 100 points\n    >>> ds.point_cloud.append(sample)\n    >>> ds.point_cloud.shape\n    >>> (1, 100, 3)\n    \n\n## Mesh Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Mesh samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.",
        "node_518": "`tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.\n\n### Appending class labels\uf0c1\n\n  * Class labels can be appended as `int`, `str`, `np.ndarray` or `list` of `int` or `str`.\n\n  * In case of strings, `tensor.info.class_names` is updated automatically.\n\nExamples\n\nAppending index\n\n    \n    \n    >>> ds.labels.append(0)\n    >>> ds.labels.append(np.zeros((5,), dtype=np.uint32))\n    \n\nExtending with list of indices\n\n    \n    \n    >>> ds.labels.extend([[0, 1, 2], [1, 3]])\n    \n\nAppending text labels\n\n    \n    \n    >>> ds.labels.append([\"cars\", \"airplanes\"])\n    \n\n## Tag Htype\uf0c1\n\n  * Sample dimensions: `(# tags,)`\n\nThis htype can be used to tag samples with one or more string values.\n\n### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.",
        "node_1116": "It should support `__getitem__` and `__len__` operations. Using scheduler other than \u201cthreaded\u201d with deeplake dataset having base storage as memory as `data_in` will also raise this.\n\n  * `InvalidOutputDatasetError`: If all the tensors of `ds_out` passed to transform don\u2019t have the same length. Using scheduler other than \u201cthreaded\u201d with deeplake dataset having base storage as memory as `ds_out` will also raise this.\n\n  * `TensorMismatchError`: If one or more of the outputs generated during transform contain different tensors than the ones present in `ds_out` provided to transform.\n\n  * `UnsupportedSchedulerError`: If the scheduler passed is not recognized. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019.\n\n  * `TransformError`: All other exceptions raised if there are problems while running the pipeline.\n\ndeeplake.compose(_functions : List[ComputeFunction]_)\uf0c1\n\n    \n\nTakes a list of functions decorated using `deeplake.compute()` and creates a\npipeline that can be evaluated using .eval\n\nExample:\n\n    \n    \n    pipeline = deeplake.compose([my_fn(a=3), another_function(b=2)])\n    pipeline.eval(data_in, ds_out, scheduler=\"processed\", num_workers=2)\n    \n\nThe `eval` method evaluates the pipeline/transform function.\n\nIt has the following arguments:\n\n  * `data_in`: Input passed to the transform to generate output dataset.\n\n>     * It should support `__getitem__` and `__len__`. This can be a Deep Lake\n> dataset.\n\n  * `ds_out (Dataset, optional)`: The dataset object to which the transform will get written.\n\n>     * If this is not provided, data_in will be overwritten if it is a Deep\n> Lake dataset, otherwise error will be raised.\n>\n>     * It should have all keys being generated in output already present as\n> tensors.\n>\n>     * It\u2019s initial state should be either:\n>\n\n>>       * Empty i.e. all tensors have no samples. In this case all samples\nare added to the dataset.\n\n>>\n\n>>       * All tensors are populated and have same length. In this case new\nsamples are appended to the dataset.",
        "node_207": "Parameters\n\n    \n\n  * ***args** \u2013 Additional args to be passed to torch_dataset\n\n  * ****kwargs** \u2013 Additional kwargs to be passed to torch_dataset\n\n  * **transform** (_Callable_ _,__Optional_) \u2013 Transformation function to be applied to each sample.\n\n  * **tensors** (_List_ _,__Optional_) \u2013 Optionally provide a list of tensor names in the ordering that your training script expects. For example, if you have a dataset that has \u201cimage\u201d and \u201clabel\u201d tensors, if `tensors=[\"image\", \"label\"]`, your training script should expect each batch will be provided as a tuple of (image, label).\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for fetching data in parallel.\n\n  * **batch_size** (_int_) \u2013 Number of samples per batch to load. Default value is 1.\n\n  * **drop_last** (_bool_) \u2013 Set to True to drop the last incomplete batch, if the dataset size is not divisible by the batch size. if `False` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default value is `False`. Read torch.utils.data.DataLoader docs for more details.\n\n  * **collate_fn** (_Callable_ _,__Optional_) \u2013 merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset. Read torch.utils.data.DataLoader docs for more details.\n\n  * **pin_memory** (_bool_) \u2013 If `True`, the data loader will copy Tensors into CUDA pinned memory before returning them. Default value is `False`. Read torch.utils.data.DataLoader docs for more details.\n\n  * **shuffle** (_bool_) \u2013 If `True`, the data loader will shuffle the data indices. Default value is False. Details about how Deep Lake shuffles data can be found at Shuffling in ds.pytorch()\n\n  * **buffer_size** (_int_) \u2013 The size of the buffer used to shuffle the data in MBs. Defaults to 2048 MB. Increasing the buffer_size will increase the extent of shuffling.",
        "node_1308": "Deep Lake\n\nv3.0.16\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n\nExperimental API\n\n  * Dataloader\n  * Tensor Query Language\n\nAPI Reference\n\n  * deeplake\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n\n__Deep Lake\n\n  * \u00bb\n  * Deep Lake API Reference\n  * Edit on GitHub\n\n* * *\n\n# Deep Lake API Reference\u00b6\n\nDeep Lake is an open-source database for AI.",
        "node_1104": "* **verbose** (_bool_) \u2013 If True, logs will be printed. Defaults to `True`.\n\n  * ****kwargs** \u2013 Additional keyword arguments\n\nReturns\n\n    \n\nNew dataset object.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **DatasetHandlerError** \u2013 If a dataset already exists at destination path and overwrite is False.\n\n  * **TypeError** \u2013 If source is not a dataset.\n\n  * **UnsupportedParameterException** \u2013 If parameter that is no longer supported is beeing called.\n\n  * **DatasetCorruptError** \u2013 If loading source dataset fails with DatasetCorruptedError\n\ndeeplake.connect(_src_path : str_, _creds_key : str_, _dest_path :\nOptional[str] = None_, _org_id : Optional[str] = None_, _ds_name :\nOptional[str] = None_, _token : Optional[str] = None_) -> Dataset\uf0c1\n\n    \n\nConnects dataset at `src_path` to Deep Lake via the provided path.\n\nExamples\n\n    \n    \n    >>> # Connect an s3 dataset\n    >>> ds = deeplake.connect(src_path=\"s3://bucket/dataset\", dest_path=\"hub://my_org/dataset\", creds_key=\"my_managed_credentials_key\", token=\"my_activeloop_token\")\n    >>> # or\n    >>> ds = deeplake.connect(src_path=\"s3://bucket/dataset\", org_id=\"my_org\", creds_key=\"my_managed_credentials_key\", token=\"my_activeloop_token\")\n    \n\nParameters\n\n    \n\n  * **src_path** (_str_) \u2013 Cloud path to the source dataset. Can be: an s3 path like `s3://bucket/path/to/dataset`. a gcs path like `gcs://bucket/path/to/dataset`. an azure path like `az://account_name/container/path/to/dataset`.\n\n  * **creds_key** (_str_) \u2013 The managed credentials to be used for accessing the source path.\n\n  * **dest_path** (_str_ _,__optional_) \u2013 The full path to where the connected Deep Lake dataset will reside. Can be: a Deep Lake path like `hub://organization/dataset`\n\n  * **org_id** (_str_ _,__optional_) \u2013 The organization to where the connected Deep Lake dataset will be added.",
        "node_206": "For any tensor if the\nindex >= len(tensor), the sample won\u2019t be popped from it.\n\nParameters\n\n    \n\n**index** (_int_ _,__Optional_) \u2013 The index of the sample to be removed. If it\nis `None`, the index becomes the `length of the longest tensor - 1`.\n\nRaises\n\n    \n\n  * **ValueError** \u2013 If duplicate indices are provided.\n\n  * **IndexError** \u2013 If the index is out of range.\n\npopulate_creds(_creds_key : str_, _creds : Optional[dict] = None_,\n_from_environment : bool = False_)\uf0c1\n\n    \n\nPopulates the creds key added in add_creds_key with the given creds. These\ncreds are used to fetch the external data. This needs to be done everytime the\ndataset is reloaded for datasets that contain links to external data.\n\nExamples\n\n    \n    \n    >>> # create/load a dataset\n    >>> ds = deeplake.dataset(\"path/to/dataset\")\n    >>> # add a new creds key\n    >>> ds.add_creds_key(\"my_s3_key\")\n    >>> # populate the creds\n    >>> ds.populate_creds(\"my_s3_key\", {\"aws_access_key_id\": \"my_access_key\", \"aws_secret_access_key\": \"my_secret_key\"})\n    >>> # or\n    >>> ds.populate_creds(\"my_s3_key\", from_environment=True)\n    \n\npytorch(_transform : Optional[Callable] = None_, _tensors :\nOptional[Sequence[str]] = None_, _num_workers : int = 1_, _batch_size : int =\n1_, _drop_last : bool = False_, _collate_fn : Optional[Callable] = None_,\n_pin_memory : bool = False_, _shuffle : bool = False_, _buffer_size : int =\n2048_, _use_local_cache : bool = False_, _progressbar : bool = False_,\n_return_index : bool = True_, _pad_tensors : bool = False_, _transform_kwargs\n: Optional[Dict[str, Any]] = None_, _decode_method : Optional[Dict[str, str]]\n= None_, _cache_size : int = 32000000_, _* args_, _** kwargs_)\uf0c1\n\n    \n\nConverts the dataset into a pytorch Dataloader.",
        "node_510": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.",
        "node_658": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_720": "* Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\n  * Recompression of samples read with `deeplake.read` is also not supported.\n\nExamples\n\nAppending Deep Lake video sample\n\n    \n    \n    >>> ds.videos.append(deeplake.read(\"videos/0012.mp4\"))\n    \n\nExtending with multiple videos\n\n    \n    \n    >>> ds.videos.extend([deeplake.read(f\"videos/00{i}.mp4\") for i in range(10)])\n    \n\n## Audio Htype\uf0c1\n\n  * Sample dimensions: `(# samples in audio, # channels)` or `(# samples in audio,)`\n\n### Creating an audio tensor\uf0c1\n\nAn audio tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"audios\", htype=\"audio\", sample_compression=\"mp3\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `float64`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.",
        "node_1258": "util.exceptions)\n  * clear() (deeplake.api.info.Info method)\n    * (deeplake.core.storage.GCSProvider method)\n    * (deeplake.core.storage.GDriveProvider method)\n    * (deeplake.core.storage.LocalProvider method)\n    * (deeplake.core.storage.LRUCache method)\n    * (deeplake.core.storage.MemoryProvider method)\n    * (deeplake.core.storage.S3Provider method)\n    * (deeplake.core.storage.StorageProvider method)\n    * (deeplake.core.tensor.Tensor method)\n  * clear_cache() (deeplake.core.dataset.Dataset method)\n    * (deeplake.core.storage.LRUCache method)\n  * clear_deeplake_objects() (deeplake.core.storage.LRUCache method)\n  * client (deeplake.core.dataset.Dataset property)\n    * (deeplake.core.dataset.DeepLakeCloudDataset property)\n  * close() (deeplake.enterprise.DeepLakeDataLoader method)\n  * commit() (deeplake.core.dataset.Dataset method)\n    * (deeplake.core.vectorstore.deeplake_vectorstore.VectorStore method)\n\n|\n\n  * commit_id (deeplake.core.dataset.Dataset property)\n  * CommitError (class in deeplake.util.exceptions)\n  * commits (deeplake.core.dataset.Dataset property)\n  * compose() (in module deeplake)\n  * compose_at() (deeplake.core.index.Index method)\n  * compressed_bytes() (deeplake.core.sample.Sample method)\n  * compute() (in module deeplake)\n  * connect() (deeplake.api.dataset.dataset static method)\n    * (deeplake.core.dataset.Dataset method)\n    * (deeplake.core.dataset.DeepLakeCloudDataset method)\n    * (in module deeplake)\n  * copy() (deeplake.api.dataset.dataset static method)\n    * (deeplake.core.dataset.",
        "node_701": "For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.\n\n### Creating a binary_mask tensor\uf0c1\n\nA binary_mask tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"masks\", htype=\"binary_mask\", sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * ref:sample_compression <sample_compression> or chunk_compression\n\n    * dtype: Defaults to `bool`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`.",
        "node_948": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_430": "* Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.\n\nExamples\n\nAppending Deep Lake audio sample\n\n    \n    \n    >>> ds.audios.append(deeplake.read(\"audios/001.mp3\"))\n    \n\nExtending with Deep Lake audio samples\n\n    \n    \n    >>> ds.audios.extend([deeplake.read(f\"videos/00{i}.mp3\") for i in range(10)])\n    \n\n## Class Label Htype\uf0c1\n\n  * Sample dimensions: `(# labels,)`\n\nClass labels are stored as numerical values in tensors, which are indices of\nthe list `tensor.info.class_names`.\n\n### Creating a class label tensor\uf0c1\n\nA class label tensor can be created using\n\n    \n    \n    >>> classes = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"]\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\", class_names=classes, chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.",
        "node_249": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n    * deeplake.auto.structured\n    * deeplake.auto.unstructured\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * deeplake.auto\n  * Edit on GitHub\n\n* * *\n\n# deeplake.auto\uf0c1\n\n  * deeplake.auto.structured\n    * deeplake.auto.structured.base\n    * deeplake.auto.structured.dataframe\n  * deeplake.auto.unstructured\n    * deeplake.auto.unstructured.base\n    * deeplake.auto.unstructured.image_classification\n    * deeplake.auto.unstructured.kaggle\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_1209": "Raises an error if\nnot compatible.\n\n_property __config\uf0c1\n\n    \n\nReturns a summary of the configuration of the tensor.\n\n_linked_sample()\uf0c1\n\n    \n\nReturns the linked sample at the given index. This is only applicable for\ntensors of `link[]` htype and can only be used for exactly one sample.\n\n    \n    \n    >>> linked_sample = ds.abc[0]._linked_sample().path\n    'https://picsum.photos/200/300'\n    \n\n_pop(_index : List[int]_)\uf0c1\n\n    \n\nRemoves elements at the given indices. `index` must be sorted in descending\norder.\n\nappend(_sample : Union[Sample, ndarray, int, float, bool, dict, list, str,\ninteger, floating, bool_]_)\uf0c1\n\n    \n\nAppends a single sample to the end of the tensor. Can be an array, scalar\nvalue, or the return value from `deeplake.read()`, which can be used to load\nfiles. See examples down below.\n\nExamples\n\nNumpy input:\n\n    \n    \n    >>> len(tensor)\n    0\n    >>> tensor.append(np.zeros((28, 28, 1)))\n    >>> len(tensor)\n    1\n    \n\nFile input:\n\n    \n    \n    >>> len(tensor)\n    0\n    >>> tensor.append(deeplake.read(\"path/to/file\"))\n    >>> len(tensor)\n    1\n    \n\nParameters\n\n    \n\n**sample** (_InputSample_) \u2013 The data to append to the tensor. `Sample` is\ngenerated by `deeplake.read()`. See the above examples.\n\n_property _base_htype\uf0c1\n\n    \n\nBase htype of the tensor.\n\nExample\n\n    \n    \n    >>> ds.create_tensor(\"video_seq\", htype=\"sequence[video]\", sample_compression=\"mp4\")\n    >>> ds.video_seq.htype\n    sequence[video]\n    >>> ds.video_seq.base_htype\n    video\n    \n\nclear()\uf0c1\n\n    \n\nDeletes all samples from the tensor\n\ncreds_key()\uf0c1\n\n    \n\nReturn path data. Only applicable for linked tensors\n\ndata(_aslist : bool = False_, _fetch_chunks : bool = False_) -> Any\uf0c1\n\n    \n\nReturns data in the tensor in a format based on the tensor\u2019s base htype.",
        "node_971": "* Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.\n\n### Creating a mesh tensor\uf0c1\n\nA mesh tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"mesh\", htype=\"mesh\", sample_compression=\"ply\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"ply\"]\n    \n\n### Appending meshes\uf0c1\n\nExamples\n\nAppending a ply file containing a mesh data to tensor\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.ply\")  # mesh with 100 points and 200 faces\n    >>> ds.mesh.append(sample)\n    \n    \n    \n    >>> ds.mesh.shape\n    >>> (1, 100, 3)\n    \n\n## Embedding Htype\uf0c1\n\n  * Sample dimensions: `(# elements in the embedding,)`\n\n### Creating an embedding tensor\uf0c1\n\nAn embedding tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"embedding\", htype=\"embedding\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\", None]\n    \n\n### Appending embedding samples\uf0c1\n\n  * Embedding samples can be of type `np.ndarray`.\n\nExamples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.",
        "node_1300": "Getting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n    * Creating Datasets\n    * Loading Datasets\n    * Deleting and Renaming Datasets\n    * Copying Datasets\n    * Dataset Operations\n    * Dataset Visualization\n    * Dataset Credentials\n    * Dataset Properties\n    * Dataset Version Control\n    * Dataset Views\n  * Vector Store\n    * Creating a Deep Lake Vector Store\n    * Vector Store Operations\n    * Vector Store Properties\n  * Tensors\n    * Creating Tensors\n    * Deleting and Renaming Tensors\n    * Adding and deleting samples\n    * Retrieving samples\n    * Tensor Properties\n    * Info\n    * Video features\n  * Htypes\n    * Image Htype\n    * Video Htype\n    * Audio Htype\n    * Class Label Htype\n    * Tag Htype\n    * Bounding Box Htype\n    * 3D Bounding Box Htype\n    * Intrinsics Htype\n    * Segmentation Mask Htype\n    * Binary Mask Htype\n    * COCO Keypoints Htype\n    * Point Htype\n    * Polygon Htype\n    * Nifti Htype\n    * Point Cloud Htype\n    * Mesh Htype\n    * Embedding Htype\n    * Sequence htype\n    * Link htype\n  * Compressions\n    * Sample Compression\n    * Chunk Compression\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n    * General Functions\n    * Making Deep Lake Samples\n    * Parallelism\n\nIntegrations\n\n  * Weights and Biases\n    * Logging Dataset Creation\n    * Logging Dataset Read\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.",
        "node_113": "* **creds_key** (_Optional_ _[__str_ _]_) \u2013 creds_key for linked tensors, applicable if the htype any tensor is specified as \u2018link[\u2026]\u2019 in the \u2018column_params\u2019 input.\n\n  * **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Set to `True` by default.\n\n  * **token** (_Optional_ _[__str_ _]_) \u2013 The token to use for accessing the dataset.\n\n  * **connect_kwargs** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing arguments to be passed to the dataset connect method. See `Dataset.connect()`.\n\n  * ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function. See `deeplake.empty()`.\n\nReturns\n\n    \n\nNew dataset created from the dataframe.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**Exception** \u2013 If `src` is not a valid pandas dataframe object.\n\ndeeplake.ingest_huggingface(_src_ , _dest_ , _use_progressbar =True_, _token :\nOptional[str] = None_, _connect_kwargs : Optional[Dict] = None_, _**\ndataset_kwargs_) -> Dataset\uf0c1\n\n    \n\nConverts Hugging Face datasets to Deep Lake format.\n\nParameters\n\n    \n\n  * **src** (_hfDataset_ _,__DatasetDict_) \u2013 Hugging Face Dataset or DatasetDict to be converted. Data in different splits of a DatasetDict will be stored under respective tensor groups.\n\n  * **dest** (_Dataset_ _,__str_ _,__pathlib.Path_) \u2013 Destination dataset or path to it.\n\n  * **use_progressbar** (_bool_) \u2013 Defines if progress bar should be used to show conversion progress.\n\n  * **token** (_Optional_ _[__str_ _]_) \u2013 The token to use for accessing the dataset and/or connecting it to Deep Lake.\n\n  * **connect_kwargs** (_Optional_ _[__Dict_ _]_) \u2013 If specified, the dataset will be connected to Deep Lake, and connect_kwargs will be passed to `Dataset.connect`.\n\n  * ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function. See `deeplake.empty()`.\n\nReturns\n\n    \n\nThe destination Deep Lake dataset.",
        "node_636": "* **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.boxes.info.update(coords = {\"type\": \"pixel\", \"mode\": \"LTRB\"})\n    \n\nNote\n\nIf the bounding box format is not specified, the visualizer will assume a YOLO\nformat (`fractional` \\+ `CCWH`) if the box coordinates are < 1 on average.\nOtherwise, it will assume the COCO format (`pixel` \\+ `LTWH`).\n\n### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.",
        "node_545": "* Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\n  * Recompression of samples read with `deeplake.read` is also not supported.\n\nExamples\n\nAppending Deep Lake video sample\n\n    \n    \n    >>> ds.videos.append(deeplake.read(\"videos/0012.mp4\"))\n    \n\nExtending with multiple videos\n\n    \n    \n    >>> ds.videos.extend([deeplake.read(f\"videos/00{i}.mp4\") for i in range(10)])\n    \n\n## Audio Htype\uf0c1\n\n  * Sample dimensions: `(# samples in audio, # channels)` or `(# samples in audio,)`\n\n### Creating an audio tensor\uf0c1\n\nAn audio tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"audios\", htype=\"audio\", sample_compression=\"mp3\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `float64`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.",
        "node_1309": "Deep Lake\n\nv3.0.16\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n\nExperimental API\n\n  * Dataloader\n  * Tensor Query Language\n\nAPI Reference\n\n  * deeplake\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n\n__Deep Lake\n\n  * \u00bb\n  * Deep Lake API Reference\n  * Edit on GitHub\n\n* * *\n\n# Deep Lake API Reference\u00b6\n\nDeep Lake is an open-source database for AI.\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n    * Creating Datasets\n    * Loading Datasets\n    * Deleting and Renaming Datasets\n    * Copying Datasets\n    * Dataset Operations\n    * Dataset Visualization\n    * Dataset Credentials\n    * Dataset Properties\n    * Dataset Version Control\n    * Dataset Views\n  * Tensors\n    * Creating Tensors\n    * Deleting and Renaming Tensors\n    * Adding and deleting samples\n    * Retrieving samples\n    * Tensor Properties\n    * Info\n    * Video features\n  * Htypes\n    * Image Htype\n    * Video Htype\n    * Audio Htype\n    * Class Label Htype\n    * Bounding Box Htype\n    * Segmentation Mask Htype\n    * Binary Mask Htype\n    * COCO Keypoints Htype\n    * Point Htype\n    * Polygon Htype\n    * Point Cloud Htype\n    * Mesh Htype\n    * Sequence htype\n    * Link htype\n  * Compressions\n    * Sample Compression\n    * Chunk Compression\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n    * General Functions\n    * Making Deep Lake Samples\n    * Parallelism\n\nIntegrations\n\n  * Weights and Biases\n    * Logging Dataset Creation\n    * Logging Dataset Read\n\nExperimental API\n\n  * Dataloader\n  * Tensor Query Language\n\nAPI Reference\n\n  * deeplake\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n\n# Indices and tables\u00b6\n\n  * Index\n\n  * Module Index\n\n  * Search Page\n\nNext\n\n* * *\n\n(C) Copyright 2022, Activeloop.",
        "node_354": "`Dataset.commits` | Lists all the commits leading to the current dataset state.  \n`Dataset.branches` | Lists all the branches of the dataset.  \n  \n## Dataset Views\uf0c1\n\nA dataset view is a subset of a dataset that points to specific samples\n(indices) in an existing dataset. Dataset views can be created by indexing a\ndataset, filtering a dataset with `Dataset.filter()`, querying a dataset with\n`Dataset.query()` or by sampling a dataset with `Dataset.sample_by()`.\nFiltering is done with user-defined functions or simplified expressions\nwhereas query can perform SQL-like queries with our Tensor Query Language. See\nthe full TQL spec here.\n\nDataset views can only be saved when a dataset has been committed and has no\nchanges on the HEAD node, in order to preserve data lineage and prevent the\nunderlying data from changing after the query or filter conditions have been\nevaluated.\n\n**Example**\n\n    \n    \n    >>> import deeplake\n    >>> # load dataset\n    >>> ds = deeplake.load(\"hub://activeloop/mnist-train\")\n    >>> # filter dataset\n    >>> zeros = ds.filter(\"labels == 0\")\n    >>> # save view\n    >>> zeros.save_view(id=\"zeros\")\n    >>> # load_view\n    >>> zeros = ds.load_view(id=\"zeros\")\n    >>> len(zeros)\n    5923\n    \n\n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n---|---  \n`Dataset.sample_by` | Returns a sliced `Dataset` with given weighted sampler applied.  \n`Dataset.filter` | Filters the dataset in accordance of filter function `f(x: sample) -> bool`  \n`Dataset.save_view` | Saves a dataset view as a virtual dataset (VDS)  \n`Dataset.get_view` | Returns the dataset view corresponding to `id`.  \n`Dataset.load_view` | Loads the view and returns the `Dataset` by id.  \n`Dataset.delete_view` | Deletes the view with given view id.  \n`Dataset.get_views` | Returns list of views stored in this Dataset.  \n`Dataset.is_view` | Returns `True` if this dataset is a view and `False` otherwise.",
        "node_642": "For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.\n\n### Creating a binary_mask tensor\uf0c1\n\nA binary_mask tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"masks\", htype=\"binary_mask\", sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * ref:sample_compression <sample_compression> or chunk_compression\n\n    * dtype: Defaults to `bool`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`.",
        "node_833": "core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.\n\nSupported htypes and their respective defaults are:\n\nHtype configs\uf0c1 HTYPE | DTYPE | COMPRESSION  \n---|---|---  \ngeneric | None | None  \nimage | uint8 | Required arg  \nimage.rgb | uint8 | Required arg  \nimage.gray | uint8 | Required arg  \nvideo | uint8 | Required arg  \naudio | float64 | Required arg  \nclass_label | uint32 | None  \ntag | str | None  \nbbox | float32 | None  \nbbox.3d | float32 | None  \nintrinsics | float32 | None  \nsegment_mask | uint32 | None  \nbinary_mask | bool | None  \nkeypoints_coco | int32 | None  \npoint | int32 | None  \npolygon | float32 | None  \ntext | str | None  \njson | Any | None  \nlist | List | None  \ndicom | None | dcm  \nnifti | None | Required arg  \npoint_cloud | None | las  \nmesh | None | ply  \ninstance_label | uint32 | None  \nembedding | None | None  \nlink | str | None  \nsequence | None | None  \n  \n## Image Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # channels)` or `(height, width)`.\n\nImages can be stored in Deep Lake as compressed bytes or as raw arrays.",
        "node_1008": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n    * Sample Compression\n    * Chunk Compression\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Compressions\n  * Edit on GitHub\n\n* * *\n\n# Compressions\uf0c1\n\nDeep Lake can read, compress, decompress and recompress data to different\nformats. The supported htype-compression configurations are given below.\n\nSample Type | Htype | Compressions  \n---|---|---  \nImage | image |  `bmp`, `dib`, `gif`, `ico`, `jpeg`, `jpeg2000`, `pcx`, `png`, `ppm`, `sgi`, `tga`, `tiff`, `webp`, `wmf`, `xbm`, `eps`, `fli`, `im`, `msp`, `mpo`, `apng`  \nVideo | video | `mp4`, `mkv`, `avi`  \nAudio | audio | `flac`, `mp3`, `wav`  \nDicom | dicom | `dcm`  \nPoint Cloud | point_cloud | `las`  \nMesh | mesh | `ply`  \nOther | bbox, text, list, json, generic, etc. | `lz4`  \n  \n## Sample Compression\uf0c1\n\nIf sample compression is specified when `creating tensors`, samples will be\ncompressed to the given format if possible.",
        "node_1082": "* **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://username/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.\n\n  * **exist_ok** (_bool_) \u2013 If the kaggle dataset was already downloaded and `exist_ok` is `True`, ingestion will proceed without error.\n\n  * **images_compression** (_str_) \u2013 For image classification datasets, this compression will be used for the `images` tensor. If `images_compression` is \u201cauto\u201d, compression will be automatically determined by the most common extension in the directory.\n\n  * **dest_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 The string `ENV` or a dictionary containing credentials used to access the destination path of the dataset.\n\n  * **kaggle_credentials** (_dict_) \u2013 A dictionary containing kaggle credentials {\u201cusername\u201d:\u201dYOUR_USERNAME\u201d, \u201ckey\u201d: \u201cYOUR_KEY\u201d}. If `None`, environment variables/the kaggle.json file will be used if available.\n\n  * **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Set to `True` by default.\n\n  * **summary** (_bool_) \u2013 Generates ingestion summary. Set to `True` by default.\n\n  * **shuffle** (_bool_) \u2013 Shuffles the input data prior to ingestion. Since data arranged in folders by class is highly non-random, shuffling is important in order to produce optimal results when training. Defaults to `True`.",
        "node_1202": "Parameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The key whose management status is to be changed.\n\n  * **new_creds_key** (_str_ _,__optional_) \u2013 The new key to replace the old key. If not provided, the old key will be used.\n\n  * **managed** (_bool_) \u2013 The target management status. If `True`, the creds corresponding to the key will be fetched from activeloop platform.\n\nRaises\n\n    \n\n  * **ValueError** \u2013 If the dataset is not connected to activeloop platform.\n\n  * **ValueError** \u2013 If both `new_creds_key` and `managed` are `None`.\n\n  * **KeyError** \u2013 If the creds key is not present in the dataset.\n\n  * **Exception** \u2013 All other errors such as during population of managed creds.\n\nExamples\n\n    \n    \n    >>> # create/load a dataset\n    >>> ds = deeplake.dataset(\"path/to/dataset\")\n    >>> # add a new creds key\n    >>> ds.add_creds_key(\"my_s3_key\")\n    >>> # Populate the name added with creds dictionary\n    >>> # These creds are only present temporarily and will have to be repopulated on every reload\n    >>> ds.populate_creds(\"my_s3_key\", {})\n    >>> # Rename the key and change the management status of the key to True. Before doing this, ensure that the creds have been created on activeloop platform\n    >>> # Now, this key will no longer use the credentials populated in the previous step but will instead fetch them from activeloop platform\n    >>> # These creds don't have to be populated again on every reload and will be fetched every time the dataset is loaded\n    >>> ds.update_creds_key(\"my_s3_key\", \"my_managed_key\", True)\n    \n\nvisualize(_width : Optional[Union[int, str]] = None_, _height :\nOptional[Union[int, str]] = None_)\uf0c1\n\n    \n\nVisualizes the dataset in the Jupyter notebook.\n\nParameters\n\n    \n\n  * **width** \u2013 Union[int, str, None] Optional width of the visualizer canvas.\n\n  * **height** \u2013 Union[int, str, None] Optional height of the visualizer canvas.",
        "node_961": "The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"])\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending segmentation masks\uf0c1\n\n  * Segmentation masks can be appended as `np.ndarray`.\n\nExamples\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512)))\n    \n\nNote\n\nSince each pixel can only be labeled once, segmentation masks are not\nappropriate for datasets where objects might overlap, or where multiple\nobjects within the same class must be distinguished. For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.",
        "node_810": "### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.\n\nExamples\n\nAppending a tag\n\n    \n    \n    >>> ds.tags.append(\"verified\")\n    \n\nExtending with list of tags\n\n    \n    \n    >>> ds.tags.extend([\"verified\", \"unverified\"])\n    \n\n## Bounding Box Htype\uf0c1\n\n  * Sample dimensions: `(# bounding boxes, 4)`\n\nBounding boxes have a variety of conventions such as those used in YOLO, COCO,\nPascal-VOC and others. In order for bounding boxes to be correctly displayed\nby the visualizer, the format of the bounding box must be specified in the\ncoords key in tensor meta information mentioned below.\n\n### Creating a bbox tensor\uf0c1\n\nA bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"boxes\", htype=\"bbox\", coords={\"type\": \"fractional\", \"mode\": \"CCWH\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with keys \u201ctype\u201d and \u201cmode\u201d.\n    \n      * **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.",
        "node_680": "* Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.\n\nExamples\n\nAppending point clouds with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> point_cloud1 = np.random.randint(0, 10, (5, 3))\n    >>> ds.point_clouds.append(point_cloud1)\n    >>> point_cloud2 = np.random.randint(0, 10, (15, 3))\n    >>> ds.point_clouds.append(point_cloud2)\n    >>> ds.point_clouds.shape\n    >>> (2, None, 3)\n    \n\nOr we can use `deeplake.read()` method to add samples\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.las\") # point cloud with 100 points\n    >>> ds.point_cloud.append(sample)\n    >>> ds.point_cloud.shape\n    >>> (1, 100, 3)\n    \n\n## Mesh Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Mesh samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.",
        "node_801": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.",
        "node_1211": ">\n>     * Value of dict[\u201ctimestamps\u201d] will be same as `timestamps` corresponding\n> to the frames.\n>\n>     * Value of dict[\u201csample_info\u201d] will be same as `sample_info`.\n\n  * For `class_label` tensors, returns a dict with keys \u201cvalue\u201d and \u201ctext\u201d.\n\n>     * Value of dict[\u201cvalue\u201d] will be same as `numpy()`.\n>\n>     * Value of dict[\u201ctext\u201d] will be list of class labels as strings.\n\n  * For `image` or `dicom` tensors, returns dict with keys \u201cvalue\u201d and \u201csample_info\u201d.\n\n>     * Value of dict[\u201cvalue\u201d] will be same as `numpy()`.\n>\n>     * Value of dict[\u201csample_info\u201d] will be same as `sample_info`.\n\n  * For all else, returns dict with key \u201cvalue\u201d with value same as `numpy()`.\n\ndict(_fetch_chunks : bool = False_)\uf0c1\n\n    \n\nReturn json data. Only applicable for tensors with \u2018json\u2019 base htype.\n\n_property _dtype _: Optional[dtype]_\uf0c1\n\n    \n\nDtype of the tensor.\n\nextend(_samples : Union[ndarray, Sequence[Union[Sample, ndarray, int, float,\nbool, dict, list, str, integer, floating, bool_]], Tensor]_, _progressbar :\nbool = False_, _ignore_errors : bool = False_)\uf0c1\n\n    \n\nExtends the end of the tensor by appending multiple elements from a sequence.\nAccepts a sequence, a single batched numpy array, or a sequence of\n`deeplake.read()` outputs, which can be used to load files. See examples down\nbelow.",
        "node_598": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.gray htypes\n    * Video Htype\n      * Limitations\n      * Creating a video tensor\n      * Appending video samples\n    * Audio Htype\n      * Creating an audio tensor\n      * Appending audio samples\n    * Class Label Htype\n      * Creating a class label tensor\n      * Appending class labels\n    * Tag Htype\n      * Creating a tag tensor\n      * Appending tag samples\n    * Bounding Box Htype\n      * Creating a bbox tensor\n      * Appending bounding boxes\n    * 3D Bounding Box Htype\n      * Creating a 3d bbox tensor\n      * Appending 3d bounding boxes\n    * Intrinsics Htype\n      * Creating an intrinsics tensor\n      * Appending intrinsics matrices\n    * Segmentation Mask Htype\n      * Creating a segment_mask tensor\n      * Appending segmentation masks\n    * Binary Mask Htype\n      * Creating a binary_mask tensor\n      * Appending binary masks\n    * COCO Keypoints Htype\n      * Creating a keypoints_coco tensor\n      * Appending keypoints\n    * Point Htype\n      * Creating a point tensor\n      * Appending point samples\n    * Polygon Htype\n      * Creating a polygon tensor\n      * Appending polygons\n    * Nifti Htype\n      * Limitations\n      * Creating a nifti tensor\n      * Appending nifti data\n    * Point Cloud Htype\n      * Creating a point cloud tensor\n      * Appending point clouds\n    * Mesh Htype\n      * Creating a mesh tensor\n      * Appending meshes\n    * Embedding Htype\n      * Creating an embedding tensor\n      * Appending embedding samples\n    * Sequence htype\n    * Link htype\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.",
        "node_306": "We\nwould like to thank William Silversmith @SeungLab for his awesome cloud-volume\ntool.\n\n## About\n\nDatabase for AI. Store Vectors, Images, Texts, Videos, etc. Use with\nLLMs/LangChain. Store, query, version, & visualize any AI data. Stream data in\nreal-time to PyTorch/TensorFlow.",
        "node_726": "### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.\n    \n        * \u201ccenter\u201d: [center_x, center_y, center_z, size_x, size_y, size_z, rot_x, rot_y, rot_z]\n    \n          * Sample dimensions: `(# bounding boxes, 9)`\n\n          * `size_x` \\- is the length of the bounding box along x direction\n\n          * `size_y` \\- is the width of the bounding box along y direction\n\n          * `size_z` \\- is the height of the bounding box along z direction\n\n          * `rot_x` \\- rotation angle along x axis, given in degrees\n\n          * `rot_y` \\- rotation angle along y axis, given in degrees\n\n          * `rot_z` \\- rotation angle along z axis, given in degrees\n\n        * \u201cvertex\u201d: 8 3D vertices - [[x0, y0, z0], [x1, y1, z1], [x2, y2, z2], \u2026.., [x7, y7, z7]]\n    \n          * Sample dimensions: `(# bounding boxes, 8, 3)`\n\nThe vertex order is of the following form:\n\n                \n                                      4_____________________ 5\n                     /|                    /|\n                    / |                   / |\n                   /  |                  /  |\n                  /___|_________________/   |\n                0|    |                 | 1 |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |_________________|___|\n                 |   /  7               |   / 6\n                 |  /                   |  /\n                 | /                    | /\n                 |/_____________________|/\n                  3                      2\n                \n\n    * **dtype** : Defaults to `float32`.",
        "node_363": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n    * Creating Datasets\n    * Loading Datasets\n    * Deleting and Renaming Datasets\n    * Copying Datasets\n    * Dataset Operations\n    * Dataset Visualization\n    * Dataset Credentials\n    * Dataset Properties\n    * Dataset Version Control\n    * Dataset Views\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Datasets\n  * Edit on GitHub\n\n* * *\n\n# Datasets\uf0c1\n\n## Creating Datasets\uf0c1\n\n`deeplake.dataset` | Returns a `Dataset` object referencing either a new or existing dataset.  \n---|---  \n`deeplake.empty` | Creates an empty dataset  \n`deeplake.like` | Creates a new dataset by copying the `source` dataset's structure to a new location.  \n`deeplake.ingest_classification` | Ingest a dataset of images from a local folder to a Deep Lake Dataset.  \n`deeplake.ingest_coco` | Ingest images and annotations in COCO format to a Deep Lake Dataset.  \n`deeplake.ingest_yolo` | Ingest images and annotations (bounding boxes or polygons) in YOLO format to a Deep Lake Dataset.  \n`deeplake.ingest_kaggle` | Download and ingest a kaggle dataset and store it as a structured dataset to destination.",
        "node_234": "core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * deeplake.core.tensor\n  * Edit on GitHub\n\n* * *\n\n# deeplake.core.tensor\uf0c1\n\n## Tensor\uf0c1\n\n_class _deeplake.core.tensor.Tensor\uf0c1\n\n    \n\n__len__()\uf0c1\n\n    \n\nReturns the length of the primary axis of the tensor. Accounts for indexing\ninto the tensor object.\n\nExamples\n\n    \n    \n    >>> len(tensor)\n    0\n    >>> tensor.extend(np.zeros((100, 10, 10)))\n    >>> len(tensor)\n    100\n    >>> len(tensor[5:10])\n    5\n    \n\nReturns\n\n    \n\nThe current length of this tensor.\n\nReturn type\n\n    \n\nint\n\n__setitem__(_item : Union[int, slice]_, _value : Any_)\uf0c1\n\n    \n\nUpdate samples with new values.\n\nExample\n\n    \n    \n    >>> tensor.append(np.zeros((10, 10)))\n    >>> tensor.shape\n    (1, 10, 10)\n    >>> tensor[0] = np.zeros((3, 3))\n    >>> tensor.shape\n    (1, 3, 3)\n    \n\n_check_compatibility_with_htype(_htype_)\uf0c1\n\n    \n\nChecks if the tensor is compatible with the given htype. Raises an error if\nnot compatible.\n\n_property __config\uf0c1\n\n    \n\nReturns a summary of the configuration of the tensor.\n\n_linked_sample()\uf0c1\n\n    \n\nReturns the linked sample at the given index. This is only applicable for\ntensors of `link[]` htype and can only be used for exactly one sample.\n\n    \n    \n    >>> linked_sample = ds.abc[0]._linked_sample().path\n    'https://picsum.photos/200/300'\n    \n\n_pop(_index : List[int]_)\uf0c1\n\n    \n\nRemoves elements at the given indices. `index` must be sorted in descending\norder.\n\nappend(_sample : Union[Sample, ndarray, int, float, bool, dict, list, str,\ninteger, floating, bool_]_)\uf0c1\n\n    \n\nAppends a single sample to the end of the tensor.",
        "node_150": "Defaults to False.\n\n  * **ingestion_batch_size** (_int_) \u2013 Batch size to use for parallel ingestion.\n\n  * **index_params** (_Dict_ _[__str_ _,__Union_ _[__int_ _,__str_ _]__]_) \u2013 \n\nDictionary containing information about vector index that will be created.\nDefaults to `None`, which will utilize `DEFAULT_VECTORSTORE_INDEX_PARAMS` from\n`deeplake.constants`. The specified key-values override the default ones:\n\n    * \u2019threshold\u2019: The threshold for the dataset size above which an index will be created for the embedding tensor. When the threshold value is set to -1, index creation is turned off. Defaults to -1, which turns off the index.\n\n    * \u2019distance_metric\u2019: This key specifies the method of calculating the distance between vectors when creating the vector database (VDB) index. It can either be a string that corresponds to a member of the DistanceType enumeration, or the string value itself.\n\n>       * If no value is provided, it defaults to \u201cL2\u201d.\n>\n>       * \u201dL2\u201d corresponds to DistanceType.L2_NORM.\n>\n>       * \u201dCOS\u201d corresponds to DistanceType.COSINE_SIMILARITY.\n\n    * \u2019additional_params\u2019: Additional parameters for fine-tuning the index.\n\n  * **exec_option** (_str_) \u2013 Default method for search execution. It could be either `\"auto\"`, `\"python\"`, `\"compute_engine\"` or `\"tensor_db\"`. Defaults to `\"auto\"`. If None, it\u2019s set to \u201cauto\u201d. \\- `auto`\\- Selects the best execution method based on the storage location of the Vector Store. It is the default option. \\- `python` \\- Pure-python implementation that runs on the client and can be used for data stored anywhere. WARNING: using this option with big datasets is discouraged because it can lead to memory issues. \\- `compute_engine` \\- Performant C++ implementation of the Deep Lake Compute Engine that runs on the client and can be used for any data stored in or connected to Deep Lake. It cannot be used with in-memory or local datasets.",
        "node_277": "Getting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n    * Creating Datasets\n    * Loading Datasets\n    * Deleting and Renaming Datasets\n    * Copying Datasets\n    * Dataset Operations\n    * Dataset Visualization\n    * Dataset Credentials\n    * Dataset Properties\n    * Dataset Version Control\n    * Dataset Views\n  * Vector Store\n    * Creating a Deep Lake Vector Store\n    * Vector Store Operations\n    * Vector Store Properties\n  * Tensors\n    * Creating Tensors\n    * Deleting and Renaming Tensors\n    * Adding and deleting samples\n    * Retrieving samples\n    * Tensor Properties\n    * Info\n    * Video features\n  * Htypes\n    * Image Htype\n    * Video Htype\n    * Audio Htype\n    * Class Label Htype\n    * Tag Htype\n    * Bounding Box Htype\n    * 3D Bounding Box Htype\n    * Intrinsics Htype\n    * Segmentation Mask Htype\n    * Binary Mask Htype\n    * COCO Keypoints Htype\n    * Point Htype\n    * Polygon Htype\n    * Nifti Htype\n    * Point Cloud Htype\n    * Mesh Htype\n    * Embedding Htype\n    * Sequence htype\n    * Link htype\n  * Compressions\n    * Sample Compression\n    * Chunk Compression\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n    * General Functions\n    * Making Deep Lake Samples\n    * Parallelism\n\nIntegrations\n\n  * Weights and Biases\n    * Logging Dataset Creation\n    * Logging Dataset Read\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.",
        "node_280": "Include my email address so I can be contacted\n\nCancel  Submit feedback\n\n#  Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName\n\nQuery\n\nTo see all available qualifiers, see our documentation.\n\nCancel  Create saved search\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\n{{ message }}\n\nactiveloopai  / **deeplake ** Public\n\n  * Notifications \n  * Fork 581\n  * Star  7.6k\n\n  * \n\nDatabase for AI. Store Vectors, Images, Texts, Videos, etc. Use with\nLLMs/LangChain. Store, query, version, & visualize any AI data. Stream data in\nreal-time to PyTorch/TensorFlow.",
        "node_1174": "_property _is_view _: bool_\uf0c1\n\n    \n\nReturns `True` if this dataset is a view and `False` otherwise.\n\nload_view(_id : str_, _optimize : Optional[bool] = False_, _tensors :\nOptional[List[str]] = None_, _num_workers : int = 0_, _scheduler : str =\n'threaded'_, _progressbar : Optional[bool] = True_)\uf0c1\n\n    \n\nLoads the view and returns the `Dataset` by id. Equivalent to\nds.get_view(id).load().\n\nParameters\n\n    \n\n  * **id** (_str_) \u2013 id of the view to be loaded.\n\n  * **optimize** (_bool_) \u2013 If `True`, the dataset view is optimized by copying and rechunking the required data before loading. This is necessary to achieve fast streaming speeds when training models using the dataset view. The optimization process will take some time, depending on the size of the data.\n\n  * **tensors** (_Optional_ _,__List_ _[__str_ _]_) \u2013 Tensors to be copied if optimize is True. By default all tensors are copied.\n\n  * **num_workers** (_int_) \u2013 Number of workers to be used for the optimization process. Only applicable if optimize=True. Defaults to 0.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for optimization. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Only applicable if optimize=True. Defaults to \u2018threaded\u2019.\n\n  * **progressbar** (_bool_) \u2013 Whether to use progressbar for optimization. Only applicable if optimize=True. Defaults to True.\n\nReturns\n\n    \n\nThe loaded view.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**KeyError** \u2013 if view with given id does not exist.\n\nlog()\uf0c1\n\n    \n\nDisplays the details of all the past commits.\n\n_property _max_len\uf0c1\n\n    \n\nReturn the maximum length of the tensor.\n\n_property _max_view\uf0c1\n\n    \n\nReturns a view of the dataset in which shorter tensors are padded with `None`\ns to have the same length as the longest tensor.\n\nExample\n\nCreating a dataset with 5 images and 4 labels.",
        "node_1011": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n    * General Functions\n    * Making Deep Lake Samples\n    * Parallelism\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Utility Functions\n  * Edit on GitHub\n\n* * *\n\n# Utility Functions\uf0c1\n\n## General Functions\uf0c1\n\n`exists` | Checks if a dataset exists at the given `path`.  \n---|---  \n  \n## Making Deep Lake Samples\uf0c1\n\n`read` | Utility that reads raw data from supported files into Deep Lake format.  \n---|---  \n`link` | Utility that stores a link to raw data.  \n`link_tiled` | Utility that stores links to multiple images that act as tiles and together form a big image.  \n  \n## Parallelism\uf0c1\n\n`compute` | Compute is a decorator for functions.  \n---|---  \n`compose` | Takes a list of functions decorated using `deeplake.compute()` and creates a pipeline that can be evaluated using .eval  \n  \nTransform pipelines returned by `compute()` and `compose()` are evaluated\nusing `eval`:\n\n`eval` | Evaluates the pipeline on `data_in` to produce an output dataset `ds_out`.  \n---|---  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.",
        "node_203": "Parameters\n\n    \n\n  * **target_id** (_str_) \u2013 The commit_id or branch to merge.\n\n  * **conflict_resolution** (_str_ _,__Optional_) \u2013 \n    * The strategy to use to resolve merge conflicts.\n\n    * Conflicts are scenarios where both the current dataset and the target id have made changes to the same sample/s since their common ancestor.\n\n    * Must be one of the following\n    \n      * None - this is the default value, will raise an exception if there are conflicts.\n\n      * \u201dours\u201d - during conflicts, values from the current dataset will be used.\n\n      * \u201dtheirs\u201d - during conflicts, values from target id will be used.\n\n  * **delete_removed_tensors** (_bool_) \u2013 If `True`, deleted tensors will be deleted from the dataset.\n\n  * **force** (_bool_) \u2013 \n    * Forces merge.\n\n    * `force=True` will have these effects in the following cases of merge conflicts:\n    \n      * If tensor is renamed on target but is missing from HEAD, renamed tensor will be registered as a new tensor on current branch.\n\n      * If tensor is renamed on both target and current branch, tensor on target will be registered as a new tensor on current branch.\n\n      * If tensor is renamed on target and a new tensor of the new name was created on the current branch, they will be merged.\n\nRaises\n\n    \n\n  * **Exception** \u2013 if dataset is a filtered view.\n\n  * **ValueError** \u2013 if the conflict resolution strategy is not one of the None, \u201cours\u201d, or \u201ctheirs\u201d.\n\n_property _meta _: DatasetMeta_\uf0c1\n\n    \n\nReturns the metadata of the dataset.\n\n_property _min_len\uf0c1\n\n    \n\nReturn the minimum length of the tensor.\n\n_property _min_view\uf0c1\n\n    \n\nReturns a view of the dataset in which all tensors are sliced to have the same\nlength as the shortest tensor.\n\nExample\n\nCreating a dataset with 5 images and 4 labels. `ds.min_view` will return a\nview in which tensors are sliced to have 4 samples.",
        "node_557": "1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.",
        "node_391": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n    * Creating a Deep Lake Vector Store\n    * Vector Store Operations\n    * Vector Store Properties\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Vector Store\n  * Edit on GitHub\n\n* * *\n\n# Vector Store\uf0c1\n\n## Creating a Deep Lake Vector Store\uf0c1\n\n`VectorStore.__init__` | Creates an empty VectorStore or loads an existing one if it exists at the specified `path`.  \n---|---  \n  \n## Vector Store Operations\uf0c1\n\n`VectorStore.add` | Adding elements to deeplake vector store.  \n---|---  \n`VectorStore.search` | VectorStore search method that combines embedding search, metadata search, and custom TQL search.  \n`VectorStore.delete` | Delete the data in the Vector Store.  \n`VectorStore.delete_by_path` | Deleted the Vector Store at the specified path.  \n`VectorStore.update_embedding` | Recompute existing embeddings of the VectorStore, that match either query, filter, ids or row_ids.  \n  \n## Vector Store Properties\uf0c1\n\n`VectorStore.summary` | Prints a summary of the dataset  \n---|---  \n`VectorStore.tensors` | Returns the list of tensors present in the dataset  \n`VectorStore.__len__` | Length of the dataset  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop.",
        "node_547": "`tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.\n\n### Appending class labels\uf0c1\n\n  * Class labels can be appended as `int`, `str`, `np.ndarray` or `list` of `int` or `str`.\n\n  * In case of strings, `tensor.info.class_names` is updated automatically.\n\nExamples\n\nAppending index\n\n    \n    \n    >>> ds.labels.append(0)\n    >>> ds.labels.append(np.zeros((5,), dtype=np.uint32))\n    \n\nExtending with list of indices\n\n    \n    \n    >>> ds.labels.extend([[0, 1, 2], [1, 3]])\n    \n\nAppending text labels\n\n    \n    \n    >>> ds.labels.append([\"cars\", \"airplanes\"])\n    \n\n## Tag Htype\uf0c1\n\n  * Sample dimensions: `(# tags,)`\n\nThis htype can be used to tag samples with one or more string values.\n\n### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.",
        "node_1010": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * PyTorch and Tensorflow Support\n  * Edit on GitHub\n\n* * *\n\n# PyTorch and Tensorflow Support\uf0c1\n\nDeep Lake datasets can be easily converted to Torch dataloaders or Tensorflow\ndatasets for training.\n\n`Dataset.pytorch` | Converts the dataset into a pytorch Dataloader.  \n---|---  \n`Dataset.tensorflow` | Converts the dataset into a tensorflow compatible format.  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_494": "* sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nrotation angles are specified in degrees, not radians\n\n### Appending 3d bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98, 22, 36, 44, 18, 0, 36, 0]])\n    >>> ds.3d_boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77, 22, 36, 44, 18, 0, 28, 0],\n           [462, 123, 238,  98, 26, 34, 24, 19, 0, -50, 0],\n           [688, 108, 279, 116, 12, 32, 14, 38, 0, 30, 0]])\n    >>> boxes.shape\n    (9, 4)\n    >>> ds.3d_boxes.append(boxes)\n    \n\n## Intrinsics Htype\uf0c1\n\n  * Sample dimensions: `(# intrinsics matrices, 3, 3)`\n\nThe intrinsic matrix represents a projective transformation from the 3-D\ncamera\u2019s coordinates into the 2-D image coordinates. The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.",
        "node_716": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_122": "Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\n  * **verbose** (_bool_) \u2013 If True, logs will be printed. Defaults to True.\n\nRaises\n\n    \n\n  * **DatasetHandlerError** \u2013 If a Dataset does not exist at the given path and `force = False`.\n\n  * **UserNotLoggedInException** \u2013 When user is not authenticated.\n\n  * **NotImplementedError** \u2013 When attempting to delete a managed view.\n\n  * **ValueError** \u2013 If version is specified in the path\n\nWarning\n\nThis is an irreversible operation. Data once deleted cannot be recovered.\n\ndeeplake.rename(_old_path : Union[str, Path]_, _new_path : Union[str, Path]_,\n_creds : Optional[Union[dict, str]] = None_, _token : Optional[str] = None_)\n-> Dataset\uf0c1\n\n    \n\nRenames dataset at `old_path` to `new_path`.\n\nExamples\n\n    \n    \n    >>> deeplake.rename(\"hub://username/image_ds\", \"hub://username/new_ds\")\n    >>> deeplake.rename(\"s3://mybucket/my_ds\", \"s3://mybucket/renamed_ds\")\n    \n\nParameters\n\n    \n\n  * **old_path** (_str_ _,__pathlib.Path_) \u2013 The path to the dataset to be renamed.\n\n  * **new_path** (_str_ _,__pathlib.Path_) \u2013 Path to the dataset after renaming.\n\n  * **creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path.",
        "node_7": "## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.  \n`Dataset.rename` | Renames the dataset to path.  \n`Dataset.connect` | Connect a Deep Lake cloud dataset through a deeplake path.  \n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n`Dataset.pop` | Removes a sample from all the tensors of the dataset.  \n`Dataset.rechunk` | Rewrites the underlying chunks to make their sizes optimal.  \n`Dataset.flush` | Necessary operation after writes if caches are being used.  \n`Dataset.clear_cache` | \n\n  * Flushes (see `Dataset.flush()`) the contents of the cache layers (if any) and then deletes contents of all the layers of it.\n\n  \n`Dataset.size_approx` | Estimates the size in bytes of the dataset.  \n`Dataset.random_split` | Splits the dataset into non-overlapping `Dataset` objects of given lengths.  \n  \n## Dataset Visualization\uf0c1\n\n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n---|---  \n  \n## Dataset Credentials\uf0c1\n\n`Dataset.add_creds_key` | Adds a new creds key to the dataset.  \n---|---  \n`Dataset.populate_creds` | Populates the creds key added in add_creds_key with the given creds.  \n`Dataset.update_creds_key` | Updates the name and/or management status of a creds key.",
        "node_238": "* For all else, returns dict with key \u201cvalue\u201d with value same as `numpy()`.\n\ndict(_fetch_chunks : bool = False_)\uf0c1\n\n    \n\nReturn json data. Only applicable for tensors with \u2018json\u2019 base htype.\n\n_property _dtype _: Optional[dtype]_\uf0c1\n\n    \n\nDtype of the tensor.\n\nextend(_samples : Union[ndarray, Sequence[Union[Sample, ndarray, int, float,\nbool, dict, list, str, integer, floating, bool_]], Tensor]_, _progressbar :\nbool = False_, _ignore_errors : bool = False_)\uf0c1\n\n    \n\nExtends the end of the tensor by appending multiple elements from a sequence.\nAccepts a sequence, a single batched numpy array, or a sequence of\n`deeplake.read()` outputs, which can be used to load files. See examples down\nbelow.\n\nExample\n\nNumpy input:\n\n    \n    \n    >>> len(tensor)\n    0\n    >>> tensor.extend(np.zeros((100, 28, 28, 1)))\n    >>> len(tensor)\n    100\n    \n\nFile input:\n\n    \n    \n    >>> len(tensor)\n    0\n    >>> tensor.extend([\n            deeplake.read(\"path/to/image1\"),\n            deeplake.read(\"path/to/image2\"),\n        ])\n    >>> len(tensor)\n    2\n    \n\nParameters\n\n    \n\n  * **samples** (_np.ndarray_ _,__Sequence_ _,__Sequence_ _[__Sample_ _]_) \u2013 The data to add to the tensor. The length should be equal to the number of samples to add.\n\n  * **progressbar** (_bool_) \u2013 Specifies whether a progressbar should be displayed while extending.\n\n  * **ignore_errors** (_bool_) \u2013 Skip samples that cause errors while extending, if set to `True`.\n\nRaises\n\n    \n\n**TensorDtypeMismatchError** \u2013 Dtype for array must be equal to or castable to\nthis tensor\u2019s dtype.\n\n_property _hidden _: bool_\uf0c1\n\n    \n\nWhether this tensor is a hidden tensor.\n\n_property _htype\uf0c1\n\n    \n\nHtype of the tensor.\n\n_property _info _: Info_\uf0c1\n\n    \n\nReturns the information about the tensor. User can set info of tensor.\n\nReturns\n\n    \n\nInformation about the tensor.",
        "node_1204": "delete()\uf0c1\n\n    \n\nDeletes the view.\n\n_property _id _: str_\uf0c1\n\n    \n\nReturns id of the view.\n\nload(_verbose =True_)\uf0c1\n\n    \n\nLoads the view and returns the `Dataset`.\n\nParameters\n\n    \n\n**verbose** (_bool_) \u2013 If `True`, logs will be printed. Defaults to `True`.\n\nReturns\n\n    \n\nLoaded dataset view.\n\nReturn type\n\n    \n\nDataset\n\n_property _message _: str_\uf0c1\n\n    \n\nReturns the message with which the view was saved.\n\noptimize(_tensors : Optional[List[str]] = None_, _unlink =True_, _num_workers\n=0_, _scheduler ='threaded'_, _progressbar =True_)\uf0c1\n\n    \n\nOptimizes the dataset view by copying and rechunking the required data. This\nis necessary to achieve fast streaming speeds when training models using the\ndataset view. The optimization process will take some time, depending on the\nsize of the data.\n\nExample\n\n    \n    \n    >>> # save view\n    >>> ds[:10].save_view(id=\"first_10\")\n    >>> # optimize view\n    >>> ds.get_view(\"first_10\").optimize()\n    >>> # load optimized view\n    >>> ds.load_view(\"first_10\")\n    \n\nParameters\n\n    \n\n  * **tensors** (_List_ _[__str_ _]_) \u2013 Tensors required in the optimized view. By default all tensors are copied.\n\n  * **unlink** (_bool_) \u2013 \n    * If `True`, this unlinks linked tensors (if any) by copying data from the links to the view.\n\n    * This does not apply to linked videos. Set `deeplake.constants._UNLINK_VIDEOS` to `True` to change this behavior.\n\n  * **num_workers** (_int_) \u2013 Number of workers to be used for the optimization process. Defaults to 0.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for optimization. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Only applicable if `optimize=True`. Defaults to \u2018threaded\u2019.\n\n  * **progressbar** (_bool_) \u2013 Whether to display a progressbar.",
        "node_330": "## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.  \n`Dataset.rename` | Renames the dataset to path.  \n`Dataset.connect` | Connect a Deep Lake cloud dataset through a deeplake path.  \n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n`Dataset.pop` | Removes a sample from all the tensors of the dataset.  \n`Dataset.rechunk` | Rewrites the underlying chunks to make their sizes optimal.  \n`Dataset.flush` | Necessary operation after writes if caches are being used.  \n`Dataset.clear_cache` | \n\n  * Flushes (see `Dataset.flush()`) the contents of the cache layers (if any) and then deletes contents of all the layers of it.\n\n  \n`Dataset.size_approx` | Estimates the size in bytes of the dataset.  \n`Dataset.random_split` | Splits the dataset into non-overlapping `Dataset` objects of given lengths.  \n  \n## Dataset Visualization\uf0c1\n\n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n---|---  \n  \n## Dataset Credentials\uf0c1\n\n`Dataset.add_creds_key` | Adds a new creds key to the dataset.  \n---|---  \n`Dataset.populate_creds` | Populates the creds key added in add_creds_key with the given creds.  \n`Dataset.update_creds_key` | Updates the name and/or management status of a creds key.",
        "node_820": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_24": "* Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.\n\nExamples\n\nAppending Deep Lake audio sample\n\n    \n    \n    >>> ds.audios.append(deeplake.read(\"audios/001.mp3\"))\n    \n\nExtending with Deep Lake audio samples\n\n    \n    \n    >>> ds.audios.extend([deeplake.read(f\"videos/00{i}.mp3\") for i in range(10)])\n    \n\n## Class Label Htype\uf0c1\n\n  * Sample dimensions: `(# labels,)`\n\nClass labels are stored as numerical values in tensors, which are indices of\nthe list `tensor.info.class_names`.\n\n### Creating a class label tensor\uf0c1\n\nA class label tensor can be created using\n\n    \n    \n    >>> classes = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"]\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\", class_names=classes, chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.",
        "node_531": "Examples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.",
        "node_501": "For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.\n\n## Point Htype\uf0c1\n\n  * Sample dimensions: `(# points, 2)` in case of 2-D (X, Y) co-ordinates or `(# points, 3)` in case of 3-D (X, Y, Z) co-ordinates of the point.\n\nPoints does not contain a fixed mapping across samples between the point order\nand real-world objects (i.e., point 0 is an elbow, point 1 is a knee, etc.).\nIf you require such a mapping, use COCO Keypoints Htype.\n\n### Creating a point tensor\uf0c1\n\nA point tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"points\", htype=\"point\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending point samples\uf0c1\n\n  * Points can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.",
        "node_776": "Images can be stored in Deep Lake as compressed bytes or as raw arrays. Due to\nthe high compression ratio for most image formats, it is highly recommended to\nstore compressed images using the `sample_compression` input to the\ncreate_tensor method.\n\n### Creating an image tensor\uf0c1\n\nAn image tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\")\n    \n\nOR\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", chunk_compression=\"jpg\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"bmp\", \"dib\", \"gif\", \"ico\", \"jpeg\", \"jpeg2000\", \"pcx\", \"png\", \"ppm\", \"sgi\", \"tga\", \"tiff\",\n    ... \"webp\", \"wmf\", \"xbm\", \"eps\", \"fli\", \"im\", \"msp\", \"mpo\"]\n    \n\n### Appending image samples\uf0c1\n\n  * Image samples can be of type `np.ndarray` or Deep Lake `Sample` which can be created using `deeplake.read()`.\n\nExamples\n\nAppending pixel data with array\n\n    \n    \n    >>> ds.images.append(np.zeros((5, 5, 3), dtype=np.uint8))\n    \n\nAppening Deep Lake image sample\n\n    \n    \n    >>> ds.images.append(deeplake.read(\"images/0001.jpg\"))\n    \n\nYou can append multiple samples at the same time using `extend()`.\n\n    \n    \n    >>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type.",
        "node_459": "* Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.\n\nExamples\n\nAppending Deep Lake audio sample\n\n    \n    \n    >>> ds.audios.append(deeplake.read(\"audios/001.mp3\"))\n    \n\nExtending with Deep Lake audio samples\n\n    \n    \n    >>> ds.audios.extend([deeplake.read(f\"videos/00{i}.mp3\") for i in range(10)])\n    \n\n## Class Label Htype\uf0c1\n\n  * Sample dimensions: `(# labels,)`\n\nClass labels are stored as numerical values in tensors, which are indices of\nthe list `tensor.info.class_names`.\n\n### Creating a class label tensor\uf0c1\n\nA class label tensor can be created using\n\n    \n    \n    >>> classes = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"]\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\", class_names=classes, chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.",
        "node_0": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Deep Lake API Reference\n  * Edit on GitHub\n\n* * *\n\n# Deep Lake API Reference\uf0c1\n\nDeep Lake is an open-source database for AI.",
        "node_1287": "They are a comprehensive guide to using Sphinx in many contexts and\nassume more knowledge of Sphinx. If you are new to Sphinx, we recommend\nstarting with Get started.\n\nUser Guides\n\n  * Using Sphinx\n    * reStructuredText\n    * Markdown\n    * Cross-referencing syntax\n    * Configuration\n    * Builders\n    * Domains\n    * Extensions\n    * HTML Theming\n    * Internationalization\n    * Sphinx Web Support\n  * Writing Sphinx Extensions\n    * Developing extensions overview\n    * Extension tutorials\n    * Configuring builders\n    * Templating\n    * HTML theme development\n  * LaTeX customization\n    * The `latex_elements` configuration setting\n    * The `sphinxsetup` configuration setting\n    * Additional CSS-like `'sphinxsetup'` keys\n    * LaTeX macros and environments\n  * Sphinx Extensions API\n    * Important objects\n    * Build Phases\n    * Extension metadata\n    * APIs used for writing extensions\n\n## Community guide\u00b6\n\nSphinx is community supported and welcomes contributions from anybody. The\nsections below should help you get started joining the Sphinx community as\nwell as contributing.\n\nSee the Sphinx contributors\u2019 guide if you would like to contribute to the\nproject.\n\nCommunity\n\n  * Get support\n  * Contribute to Sphinx\n    * Contributing to Sphinx\n    * Sphinx\u2019s release process\n    * Organization of the Sphinx project\n    * Sphinx Code of Conduct\n  * Sphinx FAQ\n    * How do I\u2026\n    * Using Sphinx with\u2026\n    * Sphinx vs. Docutils\n    * Epub info\n    * Texinfo info\n  * Sphinx authors\n    * Maintainers\n    * Contributors\n    * Former maintainers\n\n## Reference guide\u00b6\n\nReference documentation is more complete and programmatic in nature, it is a\ncollection of information that can be quickly referenced. If you would like\nusecase-driven documentation, see Get started or User Guides.",
        "node_292": "Current integrations include:\n\n  * **Model Training**\n\n    * Stream data while training thousands of pre-built models using MMDetection, a popular open-source object detection toolbox based on PyTorch. Learn more in this tutorial.\n  * **Experiment Tracking**\n\n    * Track experiments and achieve full model reproducibility using Deep Lake and Weights & Biases. Our integration automatically pushes dataset-related information (uri, commit hash, view id) to your W&B runs. Further details are available in our model-reproducibility playbook.\n  * **LLM Apps**\n\n    * Use Deep Lake as a vector store for LLM apps. Our integration combines the Langchain VectorStores API with Deep Lake datasets as the underlying data storage. The integration is a serverless vector store that can be deployed locally or in a cloud of your choice.\n\n## \ud83d\udcda Documentation\n\nGetting started guides, examples, tutorials, API reference, and other useful\ninformation can be found on our documentation page.\n\n## \ud83c\udf93 For Students and Educators\n\nDeep Lake users can access and visualize a variety of popular datasets through\na free integration with Deep Lake's App. Universities can get up to 1TB of\ndata storage and 100,000 monthly queries on the Tensor Database for free per\nmonth. Chat in on our website: to claim the access!\n\n## \ud83d\udc69\u200d\ud83d\udcbb Comparisons to Familiar Tools\n\n**Deep Lake vs Chroma**\n\nBoth Deep Lake & ChromaDB enable users to store and search vectors\n(embeddings) and offer integrations with LangChain and LlamaIndex. However,\nthey are architecturally very different.",
        "node_1200": "* **dest_path** (_str_ _,__optional_) \u2013 The full path to where the connected Deep Lake dataset will reside. Can be: a Deep Lake path like `hub://organization/dataset`\n\n  * **org_id** (_str_ _,__optional_) \u2013 The organization to where the connected Deep Lake dataset will be added.\n\n  * **ds_name** (_str_ _,__optional_) \u2013 The name of the connected Deep Lake dataset. Will be infered from `dest_path` or `src_path` if not provided.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token used to fetch the managed credentials.\n\nRaises\n\n    \n\n  * **InvalidSourcePathError** \u2013 If the dataset\u2019s path is not a valid s3, gcs or azure path.\n\n  * **InvalidDestinationPathError** \u2013 If `dest_path`, or `org_id` and `ds_name` do not form a valid Deep Lake path.\n\n  * **TokenPermissionError** \u2013 If the user does not have permission to create a dataset in the specified organization.\n\ndelete(_large_ok =False_)\uf0c1\n\n    \n\nDeletes the entire dataset from the cache layers (if any) and the underlying\nstorage. This is an **IRREVERSIBLE** operation. Data once deleted can not be\nrecovered.\n\nParameters\n\n    \n\n**large_ok** (_bool_) \u2013 Delete datasets larger than 1 GB. Defaults to `False`.\n\nRaises\n\n    \n\n  * **DatasetTooLargeToDelete** \u2013 If the dataset is larger than 1 GB and `large_ok` is `False`.\n\n  * **DatasetHandlerError** \u2013 If the dataset is marked as allow_delete=False.\n\nget_managed_creds_keys() -> Set[str]\uf0c1\n\n    \n\nReturns the set of creds keys added to the dataset that are managed by\nActiveloop platform. These are used to fetch external data in linked tensors.\n\n_property _is_actually_cloud _: bool_\uf0c1\n\n    \n\nDatasets that are connected to Deep Lake cloud can still technically be stored\nanywhere. If a dataset is in Deep Lake cloud but stored without `hub://`\nprefix, it should only be used for testing.\n\nrename(_path_)\uf0c1\n\n    \n\nRenames the dataset to path.",
        "node_868": "### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.\n\nExamples\n\nAppending a tag\n\n    \n    \n    >>> ds.tags.append(\"verified\")\n    \n\nExtending with list of tags\n\n    \n    \n    >>> ds.tags.extend([\"verified\", \"unverified\"])\n    \n\n## Bounding Box Htype\uf0c1\n\n  * Sample dimensions: `(# bounding boxes, 4)`\n\nBounding boxes have a variety of conventions such as those used in YOLO, COCO,\nPascal-VOC and others. In order for bounding boxes to be correctly displayed\nby the visualizer, the format of the bounding box must be specified in the\ncoords key in tensor meta information mentioned below.\n\n### Creating a bbox tensor\uf0c1\n\nA bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"boxes\", htype=\"bbox\", coords={\"type\": \"fractional\", \"mode\": \"CCWH\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with keys \u201ctype\u201d and \u201cmode\u201d.\n    \n      * **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.",
        "node_878": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_299": "* **Compression:** Deep Lake offers a more flexible compression scheme, allowing control over both chunk-level and sample-level compression for each column or tensor. This feature eliminates the need for additional compressions like zstd, which would otherwise demand more CPU cycles for decompressing on top of formats like jpeg.\n  * **Shuffling:** MDS currently offers more advanced shuffling strategies.\n  * **Version Control & Visualization Support:** A notable feature of Deep Lake is its native version control and in-browser data visualization, a feature not present for MosaicML data format. This can provide significant advantages in managing, understanding, and tracking different versions of the data.\n\n**Deep Lake vs TensorFlow Datasets (TFDS)**\n\nDeep Lake and TFDS seamlessly connect popular datasets to ML frameworks. Deep\nLake datasets are compatible with both PyTorch and TensorFlow, whereas TFDS\nare only compatible with TensorFlow. A key difference between Deep Lake and\nTFDS is that Deep Lake datasets are designed for streaming from the cloud,\nwhereas TFDS must be downloaded locally prior to use. As a result, with Deep\nLake, one can import datasets directly from TensorFlow Datasets and stream\nthem either to PyTorch or TensorFlow. In addition to providing access to\npopular publicly available datasets, Deep Lake also offers powerful tools for\ncreating custom datasets, storing them on a variety of cloud storage\nproviders, and collaborating with others via simple API. TFDS is primarily\nfocused on giving the public easy access to commonly available datasets, and\nmanagement of custom datasets is not the primary focus. A full comparison\narticle can be found here.",
        "node_343": "---|---  \n`deeplake.empty` | Creates an empty dataset  \n`deeplake.like` | Creates a new dataset by copying the `source` dataset's structure to a new location.  \n`deeplake.ingest_classification` | Ingest a dataset of images from a local folder to a Deep Lake Dataset.  \n`deeplake.ingest_coco` | Ingest images and annotations in COCO format to a Deep Lake Dataset.  \n`deeplake.ingest_yolo` | Ingest images and annotations (bounding boxes or polygons) in YOLO format to a Deep Lake Dataset.  \n`deeplake.ingest_kaggle` | Download and ingest a kaggle dataset and store it as a structured dataset to destination.  \n`deeplake.ingest_dataframe` | Convert pandas dataframe to a Deep Lake Dataset.  \n`deeplake.ingest_huggingface` | Converts Hugging Face datasets to Deep Lake format.  \n  \n## Loading Datasets\uf0c1\n\n`deeplake.load` | Loads an existing dataset  \n---|---  \n  \n## Deleting and Renaming Datasets\uf0c1\n\n`deeplake.delete` | Deletes a dataset at a given path.  \n---|---  \n`deeplake.rename` | Renames dataset at `old_path` to `new_path`.  \n  \n## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.",
        "node_386": "## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.  \n`Dataset.rename` | Renames the dataset to path.  \n`Dataset.connect` | Connect a Deep Lake cloud dataset through a deeplake path.  \n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n`Dataset.pop` | Removes a sample from all the tensors of the dataset.  \n`Dataset.rechunk` | Rewrites the underlying chunks to make their sizes optimal.  \n`Dataset.flush` | Necessary operation after writes if caches are being used.  \n`Dataset.clear_cache` | \n\n  * Flushes (see `Dataset.flush()`) the contents of the cache layers (if any) and then deletes contents of all the layers of it.\n\n  \n`Dataset.size_approx` | Estimates the size in bytes of the dataset.  \n`Dataset.random_split` | Splits the dataset into non-overlapping `Dataset` objects of given lengths.  \n  \n## Dataset Visualization\uf0c1\n\n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n---|---  \n  \n## Dataset Credentials\uf0c1\n\n`Dataset.add_creds_key` | Adds a new creds key to the dataset.  \n---|---  \n`Dataset.populate_creds` | Populates the creds key added in add_creds_key with the given creds.  \n`Dataset.update_creds_key` | Updates the name and/or management status of a creds key.",
        "node_974": "For datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.\n\n    \n    \n    >>> ds.add_creds_key(\"my_s3_creds\", managed=True)\n    >>> ds.add_creds_key(\"my_gcs_creds\", managed=True)\n    \n\nCreate a link tensor\n\n    \n    \n    >>> ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")\n    \n\nPopulate the tensor with links\n\n    \n    \n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\", creds_key=\"my_s3_key\"))\n    >>> ds.img.append(deeplake.link(\"gcs://ghi/jkl.png\", creds_key=\"GCS_KEY\"))\n    >>> ds.img.append(deeplake.link(\"https://picsum.photos/200/300\")) # http path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"./path/to/cat.jpeg\")) # local path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))  # this will throw an exception as cloud paths always need creds_key\n    :bluebold:`Accessing the data`\n    \n    \n    \n    >>> for i in range(5):\n    ...     ds.img[i].numpy()\n    ...\n    \n\nUpdating a sample\n\n    \n    \n    >>> ds.img[0] = deeplake.link(\"./data/cat.jpeg\")\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_173": "create_tensor_like()`\n        * `Dataset.dataloader()`\n        * `Dataset.delete()`\n        * `Dataset.delete_branch()`\n        * `Dataset.delete_group()`\n        * `Dataset.delete_tensor()`\n        * `Dataset.delete_view()`\n        * `Dataset.diff()`\n        * `Dataset.extend()`\n        * `Dataset.filter()`\n        * `Dataset.fix_vc()`\n        * `Dataset.flush()`\n        * `Dataset.get_commit_details()`\n        * `Dataset.get_creds_keys()`\n        * `Dataset.get_managed_creds_keys()`\n        * `Dataset.get_view()`\n        * `Dataset.get_views()`\n        * `Dataset.groups`\n        * `Dataset.has_head_changes`\n        * `Dataset.info`\n        * `Dataset.is_head_node`\n        * `Dataset.is_view`\n        * `Dataset.load_view()`\n        * `Dataset.log()`\n        * `Dataset.max_len`\n        * `Dataset.max_view`\n        * `Dataset.merge()`\n        * `Dataset.meta`\n        * `Dataset.min_len`\n        * `Dataset.min_view`\n        * `Dataset.no_view_dataset`\n        * `Dataset.num_samples`\n        * `Dataset.parent`\n        * `Dataset.pending_commit_id`\n        * `Dataset.pop()`\n        * `Dataset.populate_creds()`\n        * `Dataset.pytorch()`\n        * `Dataset.query()`\n        * `Dataset.random_split()`\n        * `Dataset.read_only`\n        * `Dataset.rechunk()`\n        * `Dataset.rename()`\n        * `Dataset.rename_group()`\n        * `Dataset.rename_tensor()`\n        * `Dataset.reset()`\n        * `Dataset.root`\n        * `Dataset.sample_by()`\n        * `Dataset.sample_indices`\n        * `Dataset.save_view()`\n        * `Dataset.set_token()`\n        * `Dataset.size_approx()`\n        * `Dataset.summary()`\n        * `Dataset.tensorflow()`\n        * `Dataset.tensors`\n        * `Dataset.token`\n        * `Dataset.",
        "node_420": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n    * Creating Tensors\n    * Deleting and Renaming Tensors\n    * Adding and deleting samples\n    * Retrieving samples\n    * Tensor Properties\n    * Info\n    * Video features\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Tensors\n  * Edit on GitHub\n\n* * *\n\n# Tensors\uf0c1\n\n## Creating Tensors\uf0c1\n\n`Dataset.create_tensor` | Creates a new tensor in the dataset.  \n---|---  \n`Dataset.create_group` | Creates a tensor group.  \n`Dataset.create_tensor_like` | Copies the `source` tensor's meta information and creates a new tensor with it.  \n  \n## Deleting and Renaming Tensors\uf0c1\n\n`Dataset.delete_tensor` | Delete a tensor from the dataset.  \n---|---  \n`Dataset.delete_group` | Delete a tensor group from the dataset.  \n`Dataset.rename_tensor` | Renames tensor with name `name` to `new_name`  \n`Dataset.rename_group` | Renames group with name `name` to `new_name`  \n  \n## Adding and deleting samples\uf0c1\n\n`Tensor.append` | Appends a single sample to the end of the tensor.  \n---|---  \n`Tensor.extend` | Extends the end of the tensor by appending multiple elements from a sequence.",
        "node_555": "For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.\n\n### Creating a binary_mask tensor\uf0c1\n\nA binary_mask tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"masks\", htype=\"binary_mask\", sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * ref:sample_compression <sample_compression> or chunk_compression\n\n    * dtype: Defaults to `bool`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`.",
        "node_628": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_871": "### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.\n    \n        * \u201ccenter\u201d: [center_x, center_y, center_z, size_x, size_y, size_z, rot_x, rot_y, rot_z]\n    \n          * Sample dimensions: `(# bounding boxes, 9)`\n\n          * `size_x` \\- is the length of the bounding box along x direction\n\n          * `size_y` \\- is the width of the bounding box along y direction\n\n          * `size_z` \\- is the height of the bounding box along z direction\n\n          * `rot_x` \\- rotation angle along x axis, given in degrees\n\n          * `rot_y` \\- rotation angle along y axis, given in degrees\n\n          * `rot_z` \\- rotation angle along z axis, given in degrees\n\n        * \u201cvertex\u201d: 8 3D vertices - [[x0, y0, z0], [x1, y1, z1], [x2, y2, z2], \u2026.., [x7, y7, z7]]\n    \n          * Sample dimensions: `(# bounding boxes, 8, 3)`\n\nThe vertex order is of the following form:\n\n                \n                                      4_____________________ 5\n                     /|                    /|\n                    / |                   / |\n                   /  |                  /  |\n                  /___|_________________/   |\n                0|    |                 | 1 |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |_________________|___|\n                 |   /  7               |   / 6\n                 |  /                   |  /\n                 | /                    | /\n                 |/_____________________|/\n                  3                      2\n                \n\n    * **dtype** : Defaults to `float32`.",
        "node_1096": "Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\n  * **verbose** (_bool_) \u2013 If True, logs will be printed. Defaults to True.\n\nRaises\n\n    \n\n  * **DatasetHandlerError** \u2013 If a Dataset does not exist at the given path and `force = False`.\n\n  * **UserNotLoggedInException** \u2013 When user is not authenticated.\n\n  * **NotImplementedError** \u2013 When attempting to delete a managed view.\n\n  * **ValueError** \u2013 If version is specified in the path\n\nWarning\n\nThis is an irreversible operation. Data once deleted cannot be recovered.\n\ndeeplake.rename(_old_path : Union[str, Path]_, _new_path : Union[str, Path]_,\n_creds : Optional[Union[dict, str]] = None_, _token : Optional[str] = None_)\n-> Dataset\uf0c1\n\n    \n\nRenames dataset at `old_path` to `new_path`.\n\nExamples\n\n    \n    \n    >>> deeplake.rename(\"hub://username/image_ds\", \"hub://username/new_ds\")\n    >>> deeplake.rename(\"s3://mybucket/my_ds\", \"s3://mybucket/renamed_ds\")\n    \n\nParameters\n\n    \n\n  * **old_path** (_str_ _,__pathlib.Path_) \u2013 The path to the dataset to be renamed.\n\n  * **new_path** (_str_ _,__pathlib.Path_) \u2013 Path to the dataset after renaming.\n\n  * **creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path.",
        "node_138": "deeplake.tiled(_sample_shape : Tuple[int, ...]_, _tile_shape :\nOptional[Tuple[int, ...]] = None_, _dtype : Union[str, dtype] =\ndtype('uint8')_)\uf0c1\n\n    \n\nAllocates an empty sample of shape `sample_shape`, broken into tiles of shape\n`tile_shape` (except for edge tiles).\n\nExample\n\n    \n    \n    >>> with ds:\n    ...    ds.create_tensor(\"image\", htype=\"image\", sample_compression=\"png\")\n    ...    ds.image.append(deeplake.tiled(sample_shape=(1003, 1103, 3), tile_shape=(10, 10, 3)))\n    ...    ds.image[0][-217:, :212, 1:] = np.random.randint(0, 256, (217, 212, 2), dtype=np.uint8)\n    \n\nParameters\n\n    \n\n  * **sample_shape** (_Tuple_ _[__int_ _,__...__]_) \u2013 Full shape of the sample.\n\n  * **tile_shape** (_Optional_ _,__Tuple_ _[__int_ _,__...__]_) \u2013 The sample will be will stored as tiles where each tile will have this shape (except edge tiles). If not specified, it will be computed such that each tile is close to half of the tensor\u2019s max_chunk_size (after compression).\n\n  * **dtype** (_Union_ _[__str_ _,__np.dtype_ _]_) \u2013 Dtype for the sample array. Default uint8.\n\nReturns\n\n    \n\nA PartialSample instance which can be appended to a Tensor.\n\nReturn type\n\n    \n\nPartialSample\n\ndeeplake.compute(_fn_ , _name : Optional[str] = None_) -> Callable[[...],\nComputeFunction]\uf0c1\n\n    \n\nCompute is a decorator for functions.\n\nThe functions should have atleast 2 argument, the first two will correspond to\n`sample_in` and `samples_out`.\n\nThere can be as many other arguments as required.\n\nThe output should be appended/extended to the second argument in a deeplake\nlike syntax.\n\nAny value returned by the fn will be ignored.",
        "node_887": "For datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.\n\n    \n    \n    >>> ds.add_creds_key(\"my_s3_creds\", managed=True)\n    >>> ds.add_creds_key(\"my_gcs_creds\", managed=True)\n    \n\nCreate a link tensor\n\n    \n    \n    >>> ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")\n    \n\nPopulate the tensor with links\n\n    \n    \n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\", creds_key=\"my_s3_key\"))\n    >>> ds.img.append(deeplake.link(\"gcs://ghi/jkl.png\", creds_key=\"GCS_KEY\"))\n    >>> ds.img.append(deeplake.link(\"https://picsum.photos/200/300\")) # http path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"./path/to/cat.jpeg\")) # local path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))  # this will throw an exception as cloud paths always need creds_key\n    :bluebold:`Accessing the data`\n    \n    \n    \n    >>> for i in range(5):\n    ...     ds.img[i].numpy()\n    ...\n    \n\nUpdating a sample\n\n    \n    \n    >>> ds.img[0] = deeplake.link(\"./data/cat.jpeg\")\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_950": "Images can be stored in Deep Lake as compressed bytes or as raw arrays. Due to\nthe high compression ratio for most image formats, it is highly recommended to\nstore compressed images using the `sample_compression` input to the\ncreate_tensor method.\n\n### Creating an image tensor\uf0c1\n\nAn image tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\")\n    \n\nOR\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", chunk_compression=\"jpg\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"bmp\", \"dib\", \"gif\", \"ico\", \"jpeg\", \"jpeg2000\", \"pcx\", \"png\", \"ppm\", \"sgi\", \"tga\", \"tiff\",\n    ... \"webp\", \"wmf\", \"xbm\", \"eps\", \"fli\", \"im\", \"msp\", \"mpo\"]\n    \n\n### Appending image samples\uf0c1\n\n  * Image samples can be of type `np.ndarray` or Deep Lake `Sample` which can be created using `deeplake.read()`.\n\nExamples\n\nAppending pixel data with array\n\n    \n    \n    >>> ds.images.append(np.zeros((5, 5, 3), dtype=np.uint8))\n    \n\nAppening Deep Lake image sample\n\n    \n    \n    >>> ds.images.append(deeplake.read(\"images/0001.jpg\"))\n    \n\nYou can append multiple samples at the same time using `extend()`.\n\n    \n    \n    >>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type.",
        "node_1026": "Deep Lake will\nautomatically push all information required to reproduce the snapshot of the\ndata like your dataset\u2019s URI, commit ID, and view IDs of any views that you\nhave used in your training workflow.\n\nLearn more about Weights and Biases here.\n\n## Logging Dataset Creation\uf0c1\n\nIf you create a Deep Lake dataset using any of the functions mentioned in\nCreating Datasets, just perform a commit on the dataset to log its creation on\nW&B.\n\n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"dataset_upload\")\n    >>> ds = deeplake.empty(\"hub://fayazrahman4u/my_dataset\") # create dataset\n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\") # create a tensor\n    >>> ds.images.append(deeplake.read(\"files/images/dog.jpg\")) # add a sample\n    >>> ds.commit(\"creation\") # commit -> trigger logging\n    >>> run.finish()\n    \n\nNote\n\nIf you created your dataset using `deeplake.deepcopy()`, perform the commit\nonly if you have head changes.\n\nNote\n\nIf you make changes to an existing dataset, commit the changes with an active\nWeights and Biases run to log it\u2019s state.\n\n## Logging Dataset Read\uf0c1\n\nA dataset read will be logged if you iterate over a dataset or call\n`Dataset.pytorch()` or `Tensor.numpy()` on its tensors.\n\n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"torch dataloader\")\n    >>> train_loader = ds.pytorch()\n    >>> run.finish()\n    \n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"iteration\")\n    >>> for sample in ds:\n    >>>     print(sample[\"images\"].shape)\n    >>> run.finish()\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.",
        "node_918": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.gray htypes\n    * Video Htype\n      * Limitations\n      * Creating a video tensor\n      * Appending video samples\n    * Audio Htype\n      * Creating an audio tensor\n      * Appending audio samples\n    * Class Label Htype\n      * Creating a class label tensor\n      * Appending class labels\n    * Tag Htype\n      * Creating a tag tensor\n      * Appending tag samples\n    * Bounding Box Htype\n      * Creating a bbox tensor\n      * Appending bounding boxes\n    * 3D Bounding Box Htype\n      * Creating a 3d bbox tensor\n      * Appending 3d bounding boxes\n    * Intrinsics Htype\n      * Creating an intrinsics tensor\n      * Appending intrinsics matrices\n    * Segmentation Mask Htype\n      * Creating a segment_mask tensor\n      * Appending segmentation masks\n    * Binary Mask Htype\n      * Creating a binary_mask tensor\n      * Appending binary masks\n    * COCO Keypoints Htype\n      * Creating a keypoints_coco tensor\n      * Appending keypoints\n    * Point Htype\n      * Creating a point tensor\n      * Appending point samples\n    * Polygon Htype\n      * Creating a polygon tensor\n      * Appending polygons\n    * Nifti Htype\n      * Limitations\n      * Creating a nifti tensor\n      * Appending nifti data\n    * Point Cloud Htype\n      * Creating a point cloud tensor\n      * Appending point clouds\n    * Mesh Htype\n      * Creating a mesh tensor\n      * Appending meshes\n    * Embedding Htype\n      * Creating an embedding tensor\n      * Appending embedding samples\n    * Sequence htype\n    * Link htype\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.",
        "node_1107": "* **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\nReturns\n\n    \n\nA boolean confirming whether the dataset exists or not at the given path.\n\nRaises\n\n    \n\n**ValueError** \u2013 If version is specified in the path\n\ndeeplake.read(_path : Union[str, Path]_, _verify : bool = False_, _creds :\nOptional[Dict] = None_, _compression : Optional[str] = None_, _storage :\nOptional[StorageProvider] = None_, _timeout : Optional[float] = None_) ->\nSample\uf0c1\n\n    \n\nUtility that reads raw data from supported files into Deep Lake format.\n\n  * Recompresses data into format required by the tensor if permitted by the tensor htype.\n\n  * Simply copies the data in the file if file format matches sample_compression of the tensor, thus maximizing upload speeds.",
        "node_497": "For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.\n\n### Creating a binary_mask tensor\uf0c1\n\nA binary_mask tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"masks\", htype=\"binary_mask\", sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * ref:sample_compression <sample_compression> or chunk_compression\n\n    * dtype: Defaults to `bool`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`.",
        "node_803": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_77": "Each tuple should\ncontain the document id (`id` tensor from the corpus dataset) and the\nrelevance score (range is 0-1, where 0 represents unrelated document and 1\nrelated). `queries` should be a list of strings.\n\n    \n    \n    >>> job_id = db.deep_memory.train(\n    ...     corpus: List[List[Tuple[str, float]]] = corpus,\n    ...     queries: List[str] = queries,\n    ...     embedding_function = embedding_function, # function that takes converts texts into embeddings, it is optional and can be skipped if provided during initialization\n    ... )\n    \n\n### Tracking the training progress\uf0c1\n\n`job_id` is string, which can be used to track the training progress. You can\nuse `db.deep_memory.status(job_id)` to get the status of the job.\n\nwhen the model is still in pending state (not started yet) you will see the following: >>> db.deep_memory.status(job_id) \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2013 | 6508464cd80cab681bfcfff3 | \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2013 | status | pending | \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2013 | progress | None | \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2013 | results | not available yet | \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2013\n\nAfter some time the model will start training and you will see the following:\n\n    \n    \n    >>> db.deep_memory.status(job_id)\n    --------------------------------------------------------------\n    |                  6508464cd80cab681bfcfff3                  |\n    --------------------------------------------------------------\n    | status                     | training                      |\n    --------------------------------------------------------------\n    | progress                   | eta: 2.5 seconds              |\n    |                            | recall@10: 0.62% (+0.62%)     |\n    --------------------------------------------------------------\n    | results                    | not available yet             |\n    --------------------------------------------------------------\n    \n\nIf you want to get all training jobs you can use `db.deep_memory.list_jobs()`\nwhich will show all jobs that happened on this dataset.",
        "node_580": "### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.\n    \n        * \u201ccenter\u201d: [center_x, center_y, center_z, size_x, size_y, size_z, rot_x, rot_y, rot_z]\n    \n          * Sample dimensions: `(# bounding boxes, 9)`\n\n          * `size_x` \\- is the length of the bounding box along x direction\n\n          * `size_y` \\- is the width of the bounding box along y direction\n\n          * `size_z` \\- is the height of the bounding box along z direction\n\n          * `rot_x` \\- rotation angle along x axis, given in degrees\n\n          * `rot_y` \\- rotation angle along y axis, given in degrees\n\n          * `rot_z` \\- rotation angle along z axis, given in degrees\n\n        * \u201cvertex\u201d: 8 3D vertices - [[x0, y0, z0], [x1, y1, z1], [x2, y2, z2], \u2026.., [x7, y7, z7]]\n    \n          * Sample dimensions: `(# bounding boxes, 8, 3)`\n\nThe vertex order is of the following form:\n\n                \n                                      4_____________________ 5\n                     /|                    /|\n                    / |                   / |\n                   /  |                  /  |\n                  /___|_________________/   |\n                0|    |                 | 1 |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |_________________|___|\n                 |   /  7               |   / 6\n                 |  /                   |  /\n                 | /                    | /\n                 |/_____________________|/\n                  3                      2\n                \n\n    * **dtype** : Defaults to `float32`.",
        "node_92": "Be\nvery careful when setting this parameter.\n\ndeeplake.like(_dest : Union[str, Path]_, _src : Union[str, Dataset, Path]_,\n_runtime : Optional[Dict] = None_, _tensors : Optional[List[str]] = None_,\n_overwrite : bool = False_, _creds : Optional[Union[dict, str]] = None_,\n_token : Optional[str] = None_, _org_id : Optional[str] = None_, _public :\nbool = False_, _verbose : bool = True_) -> Dataset\uf0c1\n\n    \n\nCreates a new dataset by copying the `source` dataset\u2019s structure to a new\nlocation. No samples are copied, only the meta/info for the dataset and it\u2019s\ntensors.\n\nParameters\n\n    \n\n  * **dest** \u2013 Empty Dataset or Path where the new dataset will be created.\n\n  * **src** (_Union_ _[__str_ _,__Dataset_ _]_) \u2013 Path or dataset object that will be used as the template for the new dataset.\n\n  * **runtime** (_dict_) \u2013 Parameters for Activeloop DB Engine. Only applicable for hub:// paths.\n\n  * **tensors** (_List_ _[__str_ _]__,__optional_) \u2013 Names of tensors (and groups) to be replicated. If not specified all tensors in source dataset are considered.\n\n  * **overwrite** (_bool_) \u2013 If True and a dataset exists at destination, it will be overwritten. Defaults to False.\n\n  * **creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets.",
        "node_1085": "The filenames in `df_column_with_cloud_paths` will be used as the filenames for linked data in the dataset.\n    >>> ds = deeplake.ingest_dataframe(\n    >>>     df,\n    >>>     dest=\"hub://org_id/dataset\",\n    >>>     column_params={\"df_column_with_cloud_paths\": {\"name\": \"image_links\", \"htype\": \"link[image]\"}},\n    >>>     creds_key=\"my_s3_managed_credentials\"\n    >>> )\n    >>> # Ingest data from a DataFrame into a Deep Lake dataset stored in your cloud, and connect that dataset to the Deep Lake backend. The filenames in `df_column_with_cloud_paths` will be used as the filenames for linked data in the dataset.\n    >>> ds = deeplake.ingest_dataframe(\n    >>>     df,\n    >>>     dest=\"s3://bucket/dataset_name\",\n    >>>     column_params={\"df_column_with_cloud_paths\": {\"name\": \"image_links\", \"htype\": \"link[image]\"}},\n    >>>     creds_key=\"my_s3_managed_credentials\"\n    >>>     connect_kwargs={\"creds_key\": \"my_s3_managed_credentials\", \"org_id\": \"org_id\"},\n    >>> )\n    \n\nParameters\n\n    \n\n  * **src** (_pd.DataFrame_) \u2013 The pandas dataframe to be converted.\n\n  * **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * A Dataset or The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://username/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.",
        "node_1101": "Return type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **DatasetHandlerError** \u2013 If a dataset already exists at destination path and overwrite is False.\n\n  * **UnsupportedParameterException** \u2013 If a parameter that is no longer supported is specified.\n\n  * **DatasetCorruptError** \u2013 If loading source dataset fails with DatasetCorruptedError.\n\ndeeplake.deepcopy(_src : Union[str, Path, Dataset]_, _dest : Union[str,\nPath]_, _runtime : Optional[Dict] = None_, _tensors : Optional[List[str]] =\nNone_, _overwrite : bool = False_, _src_creds =None_, _dest_creds =None_,\n_token =None_, _num_workers : int = 0_, _scheduler ='threaded'_, _progressbar\n=True_, _public : bool = False_, _verbose : bool = True_, _** kwargs_)\uf0c1\n\n    \n\nCopies dataset at `src` to `dest` including version control history.\n\nParameters\n\n    \n\n  * **src** (_str_ _,__pathlib.Path_ _,__Dataset_) \u2013 The Dataset or the path to the dataset to be copied.\n\n  * **dest** (_str_ _,__pathlib.Path_) \u2013 Destination path to copy to.\n\n  * **runtime** (_dict_) \u2013 Parameters for Activeloop DB Engine. Only applicable for hub:// paths.\n\n  * **tensors** (_List_ _[__str_ _]__,__optional_) \u2013 Names of tensors (and groups) to be copied. If not specified all tensors are copied.\n\n  * **overwrite** (_bool_) \u2013 If True and a dataset exists at destination, it will be overwritten. Defaults to False.\n\n  * **src_creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys.",
        "node_575": "* Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.\n\nExamples\n\nAppending Deep Lake audio sample\n\n    \n    \n    >>> ds.audios.append(deeplake.read(\"audios/001.mp3\"))\n    \n\nExtending with Deep Lake audio samples\n\n    \n    \n    >>> ds.audios.extend([deeplake.read(f\"videos/00{i}.mp3\") for i in range(10)])\n    \n\n## Class Label Htype\uf0c1\n\n  * Sample dimensions: `(# labels,)`\n\nClass labels are stored as numerical values in tensors, which are indices of\nthe list `tensor.info.class_names`.\n\n### Creating a class label tensor\uf0c1\n\nA class label tensor can be created using\n\n    \n    \n    >>> classes = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"]\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\", class_names=classes, chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.",
        "node_1257": "util.exceptions)\n\n  \n---|---  \n  \n## B\n\n  * BadGatewayException (class in deeplake.util.exceptions)\n  * BadRequestException (class in deeplake.util.exceptions)\n  * base_htype (deeplake.core.tensor.Tensor property)\n\n|\n\n  * batch() (deeplake.enterprise.DeepLakeDataLoader method)\n  * branch (deeplake.core.dataset.Dataset property)\n  * branches (deeplake.core.dataset.Dataset property)\n  * BufferError (class in deeplake.util.exceptions)\n\n  \n---|---  \n  \n## C\n\n  * cancel() (deeplake.core.vectorstore.deep_memory.deep_memory.DeepMemory method)\n  * check_readonly() (deeplake.core.storage.StorageProvider method)\n  * checkout() (deeplake.core.dataset.Dataset method)\n    * (deeplake.core.vectorstore.deeplake_vectorstore.VectorStore method)\n  * CheckoutError (class in deeplake.util.exceptions)\n  * ChunkEngineError (class in deeplake.util.exceptions)\n  * ChunkIdEncoderError (class in deeplake.util.exceptions)\n  * ChunkSizeTooSmallError (class in deeplake.util.exceptions)\n  * clear() (deeplake.api.info.Info method)\n    * (deeplake.core.storage.GCSProvider method)\n    * (deeplake.core.storage.GDriveProvider method)\n    * (deeplake.core.storage.LocalProvider method)\n    * (deeplake.core.storage.LRUCache method)\n    * (deeplake.core.storage.MemoryProvider method)\n    * (deeplake.core.storage.S3Provider method)\n    * (deeplake.core.storage.StorageProvider method)\n    * (deeplake.core.tensor.Tensor method)\n  * clear_cache() (deeplake.core.dataset.Dataset method)\n    * (deeplake.core.storage.LRUCache method)\n  * clear_deeplake_objects() (deeplake.core.storage.",
        "node_1024": "Note\n\nIf you make changes to an existing dataset, commit the changes with an active\nWeights and Biases run to log it\u2019s state.\n\n## Logging Dataset Read\uf0c1\n\nA dataset read will be logged if you iterate over a dataset or call\n`Dataset.pytorch()` or `Tensor.numpy()` on its tensors.\n\n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"torch dataloader\")\n    >>> train_loader = ds.pytorch()\n    >>> run.finish()\n    \n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"iteration\")\n    >>> for sample in ds:\n    >>>     print(sample[\"images\"].shape)\n    >>> run.finish()\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_1006": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n    * Sample Compression\n    * Chunk Compression\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Compressions\n  * Edit on GitHub\n\n* * *\n\n# Compressions\uf0c1\n\nDeep Lake can read, compress, decompress and recompress data to different\nformats. The supported htype-compression configurations are given below.\n\nSample Type | Htype | Compressions  \n---|---|---  \nImage | image |  `bmp`, `dib`, `gif`, `ico`, `jpeg`, `jpeg2000`, `pcx`, `png`, `ppm`, `sgi`, `tga`, `tiff`, `webp`, `wmf`, `xbm`, `eps`, `fli`, `im`, `msp`, `mpo`, `apng`  \nVideo | video | `mp4`, `mkv`, `avi`  \nAudio | audio | `flac`, `mp3`, `wav`  \nDicom | dicom | `dcm`  \nPoint Cloud | point_cloud | `las`  \nMesh | mesh | `ply`  \nOther | bbox, text, list, json, generic, etc. | `lz4`  \n  \n## Sample Compression\uf0c1\n\nIf sample compression is specified when `creating tensors`, samples will be\ncompressed to the given format if possible.",
        "node_32": "The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"])\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending segmentation masks\uf0c1\n\n  * Segmentation masks can be appended as `np.ndarray`.\n\nExamples\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512)))\n    \n\nNote\n\nSince each pixel can only be labeled once, segmentation masks are not\nappropriate for datasets where objects might overlap, or where multiple\nobjects within the same class must be distinguished. For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.",
        "node_725": "### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.\n\n### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.",
        "node_39": "* Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.\n\nExamples\n\nAppending polygons with 2-D points\n\n    \n    \n    >>> poly1 = [(1, 2), (2, 3), (3, 4)]\n    >>> poly2 = [(10, 12), (14, 19)]\n    >>> poly3 = [(33, 32), (54, 67), (67, 43), (56, 98)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with 3-D points\n\n    \n    \n    >>> poly1 = [(10, 2, 9), (12, 3, 8), (12, 10, 4)]\n    >>> poly2 = [(10, 1, 8), (5, 17, 11)]\n    >>> poly3 = [(33, 33, 31), (45, 76, 13), (60, 24, 17), (67, 87, 83)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> sample = np.random.randint(0, 10, (5, 7, 2))  # 5 polygons with 7 points\n    >>> ds.polygons.append(sample)\n    \n    \n    \n    >>> import numpy as np\n    >>> poly1 = np.random.randint(0, 10, (5, 2))\n    >>> poly2 = np.random.randint(0, 10, (8, 2))\n    >>> poly3 = np.random.randint(0, 10, (3, 2))\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\n## Nifti Htype\uf0c1\n\n  * Sample dimensions: `(# height, # width, # slices)` or `(# height, # width, # slices, # time unit)` in case of time-series data."
    },
    "relevant_docs": {
        "01c96154-a749-44d4-9630-b1932f4dfc44": [
            "node_1140"
        ],
        "6d65adf8-5381-4d9b-953d-876f72bbd92e": [
            "node_1140"
        ],
        "3c0b28f1-a7de-4fea-8679-4db913c7e480": [
            "node_1140"
        ],
        "a008ac26-09a9-4980-963f-8c5c1ce0d2ad": [
            "node_1140"
        ],
        "8dc8ad4c-ead5-48dc-a729-ed9d416122aa": [
            "node_1140"
        ],
        "4fbd6437-0792-4d13-be69-9e376a3a9d4f": [
            "node_1140"
        ],
        "95152146-215e-449a-bf34-09734a78db66": [
            "node_1140"
        ],
        "c1740a44-623d-4010-93fb-bb4ed149f45c": [
            "node_1228"
        ],
        "8e5d0988-5af1-42c5-b502-fd11ba331b6c": [
            "node_1228"
        ],
        "4d545411-3904-45b5-9793-69e058dc8a56": [
            "node_1228"
        ],
        "ffa74c6a-887e-4955-bfa1-8ee398af1371": [
            "node_1228"
        ],
        "4f3d732b-9672-4ca7-b075-43a312b248cc": [
            "node_1228"
        ],
        "4ff6f25c-8ca0-4022-bdcb-ef0ce05518e9": [
            "node_190"
        ],
        "64498eac-32ac-4636-85c3-01adcd0f75d7": [
            "node_517"
        ],
        "e61527ac-50c1-4a3d-97e6-06e0322c0bc9": [
            "node_517"
        ],
        "16ff7c2d-7300-469e-8421-327131c24d40": [
            "node_517"
        ],
        "185f8322-0fb9-4f38-b772-06e92a9b1560": [
            "node_517"
        ],
        "b3bfb7d3-ec37-41dd-81e0-82818c6efe2d": [
            "node_517"
        ],
        "0240efbb-1078-429a-a4a4-bf63489dc9b1": [
            "node_1278"
        ],
        "3b824761-935f-4935-906e-2bd0c0bd5dc1": [
            "node_1278"
        ],
        "b17fbc8a-9a27-4433-82eb-d4ac65bf4cf1": [
            "node_1278"
        ],
        "34cc7d27-3492-40e2-b660-020a78273823": [
            "node_1278"
        ],
        "547e3c80-7cd8-41d0-a1e7-b23cedef43d0": [
            "node_1278"
        ],
        "f01786d7-d709-4730-9741-6ea0e21f43bd": [
            "node_163"
        ],
        "533fbcc7-635a-4c06-a79b-398830aaaa02": [
            "node_163"
        ],
        "97aee20d-5559-4ed0-957c-4ea8da431c87": [
            "node_163"
        ],
        "ed610337-60fe-4df9-954d-16349f83ac18": [
            "node_163"
        ],
        "2e6acc4d-6968-4b00-9276-b31bedda3f05": [
            "node_163"
        ],
        "04f1dcfe-8b5d-4c4e-b9bb-4e1754463cb7": [
            "node_163"
        ],
        "2d343190-721c-45de-895a-27ae36419095": [
            "node_163"
        ],
        "fe34b451-27c0-41ab-8288-0947bd494305": [
            "node_295"
        ],
        "c8bfa54c-55df-49db-b4de-f2da0f454bcc": [
            "node_295"
        ],
        "1de89e01-0391-42fd-915d-6e2588918785": [
            "node_295"
        ],
        "138e76ac-a9e0-4253-8635-badf990431f2": [
            "node_1012"
        ],
        "cb771657-5a21-40c6-ad95-1caea76c0d3f": [
            "node_1012"
        ],
        "bbf6de2a-e60d-4879-97d0-f35306be45cd": [
            "node_1012"
        ],
        "89efe705-6083-4c0d-b561-15d29b63ebb7": [
            "node_1012"
        ],
        "8150d622-bdc0-45e0-96a7-e5fa6db1ecba": [
            "node_1012"
        ],
        "20ec9e52-2da8-454c-a4b9-723b6fbcea3a": [
            "node_618"
        ],
        "5c2e3734-25ee-469f-91b2-f1908ae35ec8": [
            "node_618"
        ],
        "261066cf-d0dc-4e5c-9669-5c75d0981b2d": [
            "node_618"
        ],
        "96608d83-53a9-4621-ad08-d5d952184c2c": [
            "node_618"
        ],
        "1e0bef1d-efc7-4b10-b53a-2c118d065a0d": [
            "node_618"
        ],
        "770465b0-842e-4c35-849f-6926d45b0448": [
            "node_898"
        ],
        "1dd221e7-759f-47e6-9ce4-90fcd2b1a0c9": [
            "node_898"
        ],
        "96fa15a0-4bdc-4847-90a3-bf161a174718": [
            "node_898"
        ],
        "4364b408-0d66-4114-a3a8-76ad2c9308ec": [
            "node_898"
        ],
        "23100f8b-408f-4f99-a75c-8f022397611c": [
            "node_898"
        ],
        "371171b6-564a-4c51-9322-2aecdf83af14": [
            "node_268"
        ],
        "f0a12fa6-9caa-4041-97c0-109f5ae1c525": [
            "node_268"
        ],
        "aaba5b86-4d19-462c-b795-2d95cc1ef66e": [
            "node_268"
        ],
        "49b656c8-f181-49a7-8e0e-96d2eb1cbc7a": [
            "node_268"
        ],
        "48a0b235-6996-425a-94c1-9d416263a7b2": [
            "node_268"
        ],
        "b0b08076-24c7-4dfc-97e9-0ddcfae795bd": [
            "node_1127"
        ],
        "685041bc-9530-44f4-96d9-d076cd634d01": [
            "node_1127"
        ],
        "63b6cd2e-610b-4a8d-bd68-92355169ebff": [
            "node_1127"
        ],
        "c8f2994b-30f5-4138-9538-32ae28f71ced": [
            "node_1127"
        ],
        "7c24ffc2-aed5-44ad-a82e-8a4222e1cc28": [
            "node_1127"
        ],
        "dfc77299-7a58-455e-8192-5e7d5a6e6281": [
            "node_365"
        ],
        "7f5468b1-bb5c-4071-9717-69e8418cb52a": [
            "node_365"
        ],
        "90d1bb35-720b-44cd-9ed7-c48b03e11555": [
            "node_365"
        ],
        "e3a66ea4-2f34-4053-9c53-3f79ab6fc480": [
            "node_365"
        ],
        "6a258251-5634-43bd-a784-97c3aa010b9e": [
            "node_365"
        ],
        "5c9b48af-bd6f-4e21-8d04-bd6f39665cd2": [
            "node_1315"
        ],
        "6e6770dd-3635-41d1-82a8-34d980c60661": [
            "node_1315"
        ],
        "e76df81a-3219-4264-b566-12244e218e0d": [
            "node_1315"
        ],
        "874e184f-516e-4975-8fd7-0ec05ea84b65": [
            "node_1315"
        ],
        "07f99f86-3fc5-47e8-b777-cf43200b70d0": [
            "node_1315"
        ],
        "58727107-0a2c-4f46-a6b7-c966073c9e2e": [
            "node_1079"
        ],
        "b351b99f-f7e0-4e11-abf9-353b3b0a8dae": [
            "node_1079"
        ],
        "83c68153-3d02-427d-9b0e-3802077953e6": [
            "node_1079"
        ],
        "f2bfc92c-33e2-4543-9b5f-59a79f88c998": [
            "node_1079"
        ],
        "4251ad9d-9cfe-41a3-ba11-de49c4647014": [
            "node_1079"
        ],
        "60ef5301-f407-4cc9-bccb-9c142aea1b02": [
            "node_1079"
        ],
        "d1226390-4041-4db6-b1b7-ae612b68b18a": [
            "node_1079"
        ],
        "3589454c-ef64-4419-a0bc-b7fda66fd220": [
            "node_1079"
        ],
        "3cfd73db-531a-46a3-82c1-71a05b96b3be": [
            "node_1138"
        ],
        "f171b258-0a9a-4b15-b53b-f7fcd7638cea": [
            "node_1138"
        ],
        "d7672a9c-983b-451d-af6d-9b6daf0e777b": [
            "node_1138"
        ],
        "648aa6e3-3e92-413d-83ea-3add2c076dde": [
            "node_1138"
        ],
        "d94a9c32-c93f-412c-938d-45afd0398126": [
            "node_1138"
        ],
        "8e2f0da4-8d7f-40f6-a010-750f87c5bf41": [
            "node_619"
        ],
        "2196a9c9-5c0b-4ddc-a3f4-daff87e0e6b6": [
            "node_889"
        ],
        "15199179-2da6-46d2-8d12-476054984c2b": [
            "node_655"
        ],
        "c39586bd-13e9-4487-9c76-909855fc5ffb": [
            "node_655"
        ],
        "b0b13251-4394-4ab7-b9fb-e1111be56c95": [
            "node_655"
        ],
        "f5be46a2-840c-42e4-998b-f1da4ad668a0": [
            "node_655"
        ],
        "ee5d67cb-3f1c-4135-9bba-f7dccd462270": [
            "node_655"
        ],
        "d0cabbca-041e-4af4-8c26-79c4721147de": [
            "node_655"
        ],
        "6d423df4-3c2a-4c81-bb6a-1ceb9f101569": [
            "node_883"
        ],
        "3f25c521-f6a2-4fa7-a150-b4b8a8330a20": [
            "node_883"
        ],
        "1a628e72-eb41-4022-84cb-345708466394": [
            "node_883"
        ],
        "5175de8a-d116-47d1-9eb2-00e48550b8c5": [
            "node_883"
        ],
        "1120383b-2aa3-4100-ba52-9c1a940b7f8b": [
            "node_883"
        ],
        "ab964d7f-69cc-4bd7-b3de-539b1a84cd0b": [
            "node_773"
        ],
        "c9a30d2e-f00e-4a19-a33d-b21dc9776b25": [
            "node_753"
        ],
        "bc3fd50d-fc52-4a7a-92ec-5f3c67a81072": [
            "node_753"
        ],
        "a9eb22ce-a248-4c74-9175-56161b8fea86": [
            "node_753"
        ],
        "462b2fc3-2723-4575-bf5c-771c07c4242a": [
            "node_753"
        ],
        "97534b65-4cbd-48ab-8a86-25cd3ce9b4fe": [
            "node_753"
        ],
        "a31b5d46-fbf6-41e2-bc0b-5f777576c625": [
            "node_23"
        ],
        "cc9773c2-4682-41d6-822a-79d6c7d39d2d": [
            "node_23"
        ],
        "e2017bb1-61f3-40a5-9009-ea6e2c7cf20e": [
            "node_23"
        ],
        "81adfcff-aeb3-4edc-b72b-cd51a1902744": [
            "node_23"
        ],
        "b775b3ff-7056-4f5d-afb8-1e7ed53feb55": [
            "node_23"
        ],
        "9cc8725f-079c-4fc4-8c07-2b18265dbb01": [
            "node_563"
        ],
        "5289908c-6181-4f9b-932c-4ff47b68a2a8": [
            "node_563"
        ],
        "bce2c371-0c0f-4198-a3d7-a36fb76e2781": [
            "node_563"
        ],
        "1ef39167-391c-4f0c-a492-ceaad8aa1c4e": [
            "node_563"
        ],
        "a5cfea53-19a6-48ef-8d41-6130474602ba": [
            "node_563"
        ],
        "b0ab4f0d-baff-49c1-bfcd-e2f03b592d24": [
            "node_518"
        ],
        "0ce5bde5-343d-4724-9211-d7bb2267dd55": [
            "node_518"
        ],
        "2f862c95-825a-4c15-8420-479d261020d9": [
            "node_518"
        ],
        "b0ac81d3-a051-4058-91d3-27e65d23d046": [
            "node_518"
        ],
        "d9a911e8-43e7-4c66-b3c9-267b401660f7": [
            "node_518"
        ],
        "6ce191f8-120d-40a8-a91f-b45d531e9a23": [
            "node_518"
        ],
        "fca60769-4332-4141-abb5-a08045e63ebc": [
            "node_518"
        ],
        "9e00c26f-2bd6-4de7-88ba-ddaf42097ff4": [
            "node_518"
        ],
        "6f0ab823-764b-422f-bcfe-c499555a1bcf": [
            "node_518"
        ],
        "279873ed-659b-444e-935b-cce6c78daa94": [
            "node_518"
        ],
        "f35a8962-b585-4507-a5e4-b2510e6f59ee": [
            "node_1116"
        ],
        "4cd42985-3eae-4ee3-975a-2d573f9370cb": [
            "node_1116"
        ],
        "348aaa81-eec4-408b-996b-b6ff40161a24": [
            "node_1116"
        ],
        "48ecc33f-6030-4bae-a9cc-8df0267d92ac": [
            "node_1116"
        ],
        "7791468f-94c7-415e-aad0-ab993c35b5aa": [
            "node_1116"
        ],
        "e1bd2adc-232e-40cf-bd46-6e2040bf71f6": [
            "node_207"
        ],
        "f95f6d96-660a-4549-b508-218a3b750eca": [
            "node_207"
        ],
        "903e50dc-c3ac-4e9d-955b-b8199f52c16f": [
            "node_207"
        ],
        "7d52a3a3-4b6c-416d-81c7-4a3ea682fdf5": [
            "node_207"
        ],
        "1863d793-9441-4aef-9001-a2938abfac0b": [
            "node_207"
        ],
        "57203a1c-ddc5-44a1-b6f1-7a515257d145": [
            "node_207"
        ],
        "150b78db-2f1b-4858-9528-d677751c8e6c": [
            "node_207"
        ],
        "9acc3bbc-8947-49c6-aea8-0b243c31a0fa": [
            "node_207"
        ],
        "43cea70f-3ad7-4a80-ac70-49094f960608": [
            "node_1308"
        ],
        "abdf8f7d-7508-42db-99b6-6331ce8f6402": [
            "node_1308"
        ],
        "fd36598e-e1fd-4f60-90d4-ceb4b0120c11": [
            "node_1308"
        ],
        "ccd8ef20-8609-4126-8bab-490f5712f71f": [
            "node_1308"
        ],
        "1feeafd9-c3a0-40e3-9a2c-c34133a7a49e": [
            "node_1308"
        ],
        "d9decec0-3234-4622-ae96-1ec06f5696f0": [
            "node_1104"
        ],
        "42fe56b8-a38c-4221-8358-3b5424c16c82": [
            "node_1104"
        ],
        "cc87e6f1-2f5e-4f0e-9fda-8f0b8f0e935f": [
            "node_1104"
        ],
        "c30fb4c5-ed6d-428f-bb8e-d3ea0779162e": [
            "node_1104"
        ],
        "086980cb-eefd-45f9-83f1-27fe150277af": [
            "node_1104"
        ],
        "8bd4434e-c94f-4c41-a69c-0f2919f0f7e6": [
            "node_206"
        ],
        "9b2ce10f-bee4-4ec5-a60f-75866316deba": [
            "node_206"
        ],
        "c0bca41e-8eed-487d-9725-e716116a6e25": [
            "node_206"
        ],
        "8a2d17eb-5174-4e2f-8aaa-c6a59e3936ae": [
            "node_206"
        ],
        "dec9b971-4f19-48cd-8bb7-3dc988e8b5dd": [
            "node_206"
        ],
        "bd5cf616-23ce-4c84-b963-7e991a0a2985": [
            "node_510"
        ],
        "dffea10b-2e3e-4154-af3a-e23b37142043": [
            "node_510"
        ],
        "be5aab51-8edc-4f21-8e07-3355fdaccf59": [
            "node_510"
        ],
        "ca32243f-6eb8-4b1d-b0cd-f605f7723218": [
            "node_658"
        ],
        "7bb96241-4535-4a74-8e6c-2148f038885d": [
            "node_658"
        ],
        "c7caee8b-fbfb-4396-8ca1-14e9ac245079": [
            "node_658"
        ],
        "7b09a6e7-1e91-4ae7-af64-11351fd26d05": [
            "node_658"
        ],
        "9acb6ca1-49f4-40a0-8998-b9153b430c68": [
            "node_658"
        ],
        "f1e8f6c4-1c7f-4008-afae-602f64b57d43": [
            "node_720"
        ],
        "e0e50afc-bd1c-4179-b808-84b1f801f10a": [
            "node_720"
        ],
        "6bdde5c7-edcf-452d-b4d7-fedc8b83fa2c": [
            "node_720"
        ],
        "d8b3592e-937c-495a-bdef-c12a137fa833": [
            "node_720"
        ],
        "1f231fbc-f781-4384-8c5f-71741d795a9c": [
            "node_720"
        ],
        "b6c5c495-829f-4e3c-aa57-2d77398f0570": [
            "node_1258"
        ],
        "c2449ffe-c842-4b6c-beb0-760dd9596afe": [
            "node_1258"
        ],
        "11cebef9-a4d5-4946-b2e5-a5eb725a7415": [
            "node_1258"
        ],
        "af75589e-12ac-4e19-908e-bb34c4ecab2c": [
            "node_1258"
        ],
        "ab7d1a28-73ad-434b-abd1-fc54c6ceb890": [
            "node_1258"
        ],
        "ec7a1fa7-f8f5-4094-9c88-ba36ad9fcfcc": [
            "node_701"
        ],
        "bc0c1999-34ca-42f5-86a6-ba0ea23d804d": [
            "node_701"
        ],
        "9cacb6bf-8f5e-4d0a-b22e-0730ae908436": [
            "node_701"
        ],
        "d32bc1ae-24d4-48ea-b663-e51de87c9e6d": [
            "node_701"
        ],
        "bd444b90-a188-4d48-b398-fe97cc0f9b5a": [
            "node_701"
        ],
        "05cdd79b-afb1-4fcd-a695-3b62e626da14": [
            "node_948"
        ],
        "e9cf3b54-0568-4732-b23e-eaf5229ae543": [
            "node_948"
        ],
        "225b85a5-6350-4e05-8dd9-480964bda3e4": [
            "node_948"
        ],
        "7389d28d-679d-4617-afe6-f3e489bec41e": [
            "node_430"
        ],
        "7d80bc91-6195-4d28-8fbd-3af34a509245": [
            "node_430"
        ],
        "1e03b5bb-8a0e-4fdc-bf1a-8c3b50e5ce0a": [
            "node_430"
        ],
        "b8ba3a37-9e8a-4ff5-ac46-4d50a70b3054": [
            "node_430"
        ],
        "0ab6df2c-1a7a-4b3c-8309-d496a7d1396a": [
            "node_430"
        ],
        "5e697ff6-156e-427d-8bd1-9ab790b62760": [
            "node_249"
        ],
        "242270d4-c251-4547-9abf-03359da363ca": [
            "node_249"
        ],
        "e0c28297-187d-4500-94e6-5657c24ed72b": [
            "node_249"
        ],
        "ad3e0048-d588-4cbd-9d39-025d333aae3e": [
            "node_249"
        ],
        "3b39a5f0-19bd-4fc5-8afe-b1f85919bda9": [
            "node_249"
        ],
        "4a1708fd-7b21-467d-a521-6d2867bbe2a1": [
            "node_1209"
        ],
        "53a00bb1-ea30-4415-86af-bcd9ffe73bad": [
            "node_1209"
        ],
        "50da1cd0-2ed4-4bed-a6c3-1fc06ae10453": [
            "node_1209"
        ],
        "30fdc795-ad78-476a-bcb5-92c0074e71f1": [
            "node_1209"
        ],
        "cafa1c33-a531-4553-8229-a8a325569dde": [
            "node_1209"
        ],
        "ee64714c-fc95-4388-8404-012ccf3b3524": [
            "node_1209"
        ],
        "ebc87a71-d9f2-47e7-8cc5-bcf511e1f8af": [
            "node_1209"
        ],
        "515b8f10-8edd-4683-a6b2-2240c089fbbc": [
            "node_1209"
        ],
        "58a96ea9-5f0c-407c-8dbf-1c26a9793e82": [
            "node_1209"
        ],
        "da2fe6ef-df1a-4645-b6f4-6bb422a80695": [
            "node_971"
        ],
        "3c1e512e-ff6d-4522-b655-b7e311e981c9": [
            "node_971"
        ],
        "b7aaee36-360f-4c6d-8da2-ff28d04b898e": [
            "node_971"
        ],
        "0bbf5169-a831-425f-8fe1-f47a601e7fce": [
            "node_971"
        ],
        "5797c2a8-cdec-4575-8dda-fa5aa831b67b": [
            "node_971"
        ],
        "0578cb7b-da87-49de-a1b9-3dbb49cafa1c": [
            "node_1300"
        ],
        "bf78da55-df07-4158-a231-04cef6cd5e0b": [
            "node_1300"
        ],
        "e01bf854-76f3-43cb-b56c-4f5c5452f7ed": [
            "node_1300"
        ],
        "7549e0ee-3a89-4896-a9b3-17f98f678512": [
            "node_1300"
        ],
        "3f364873-1114-4114-b328-f076a3c83425": [
            "node_1300"
        ],
        "fbf08bdf-3cd4-4c21-8a8e-539016d2cd62": [
            "node_1300"
        ],
        "3b576621-57f8-407d-80e8-51d2f89e8b67": [
            "node_1300"
        ],
        "362259ff-b3b5-4e26-bc5f-fd8f11ed555d": [
            "node_1300"
        ],
        "34941080-833b-4a65-a246-bfa6abf01be1": [
            "node_1300"
        ],
        "e5f742c5-fc35-43cd-8f3f-263390464eeb": [
            "node_1300"
        ],
        "767390ea-d2e9-4081-b847-9aceed8192d0": [
            "node_113"
        ],
        "831f42ea-8d88-4002-b9d6-c71c2083d6eb": [
            "node_113"
        ],
        "433cc6e1-97dc-4664-9565-992a35d53292": [
            "node_113"
        ],
        "8cda3e06-549f-40d1-8d73-f03f06bece63": [
            "node_113"
        ],
        "087e6618-d0df-4ed2-bc0c-bd2056c0a97f": [
            "node_113"
        ],
        "93c581fe-409c-4636-be46-87e5bd4220b6": [
            "node_113"
        ],
        "98eb6c9f-0ed0-436f-8f14-755eb4dc4df0": [
            "node_113"
        ],
        "9a6aa142-09e3-4d73-b78d-777106d5728a": [
            "node_113"
        ],
        "123504ad-f0e0-4ae4-832a-38c96f4eb2c9": [
            "node_113"
        ],
        "2d5fbc73-9b8d-4170-8a85-d28cce008d35": [
            "node_113"
        ],
        "65aaafe2-266c-42dd-b50d-436904e04b20": [
            "node_636"
        ],
        "a853a220-7c7f-427a-9a21-45ea12546f7b": [
            "node_636"
        ],
        "e2d704a3-9636-45d2-885d-06c91371e9e9": [
            "node_636"
        ],
        "bc7d534d-41b8-48e5-995b-bc232ddc0c72": [
            "node_636"
        ],
        "700c1de4-3728-4181-a562-253b94101a1a": [
            "node_636"
        ],
        "c45d2115-96a4-4eed-b061-f1fb0880e101": [
            "node_545"
        ],
        "352a3e5c-56bf-4d17-8c54-908c74684816": [
            "node_545"
        ],
        "ec31ae51-173d-4caf-b84b-f154500b03f3": [
            "node_545"
        ],
        "191d78f1-cf20-4aa6-8487-427121daa7a8": [
            "node_545"
        ],
        "a8d5df62-791e-4a6a-8110-e449899ad5c5": [
            "node_545"
        ],
        "a9782352-437f-4279-a920-5da92d8f16ca": [
            "node_545"
        ],
        "daf6f106-24a7-41d9-8751-5d719be53c5e": [
            "node_545"
        ],
        "57db705b-9899-40b8-8b5b-84fb02d2dc5c": [
            "node_545"
        ],
        "5a5c5c2c-8697-44d5-813f-f6d9e61f9ba0": [
            "node_545"
        ],
        "519828c0-1843-4da4-bc60-07ecd271d7a8": [
            "node_545"
        ],
        "2a650c78-0841-480e-9a94-d455a8901cd4": [
            "node_1309"
        ],
        "fe0d331d-e44c-4bdb-9768-321de1d67977": [
            "node_354"
        ],
        "e39d86f2-2cd6-4bfa-88a2-6f143fa9bb72": [
            "node_354"
        ],
        "3b0a1a6a-d055-4306-a8a8-1219e7a94413": [
            "node_354"
        ],
        "3bec0ab6-726b-478d-8864-639f190cb6c8": [
            "node_354"
        ],
        "db80300a-5396-45e5-8601-9f89e13cf59b": [
            "node_354"
        ],
        "f4926999-e260-412a-8938-d230ec2ac479": [
            "node_354"
        ],
        "5658a916-d52e-43e1-a9f0-5227ac15753d": [
            "node_354"
        ],
        "b6bba8b7-7d4c-4780-b764-61f9816205ed": [
            "node_354"
        ],
        "df0b2f78-ca45-47a0-959a-70dbb9874312": [
            "node_354"
        ],
        "cd5912af-1d69-4838-b93f-0f992db1a220": [
            "node_354"
        ],
        "b9e317be-6ae1-4827-88b4-7d4ba5540b0d": [
            "node_642"
        ],
        "a4c5cde2-c042-46f2-8c9b-456fe72916de": [
            "node_642"
        ],
        "c1b003a9-921c-4c65-9cd4-a20ae6fc26f9": [
            "node_642"
        ],
        "2d67ecfe-e48d-4fd6-83e8-3210c3611ac5": [
            "node_642"
        ],
        "77c756ca-a847-46dc-94b5-b302334993e4": [
            "node_642"
        ],
        "17c05f3f-91ae-4fe6-bc82-b2278fbd3768": [
            "node_833"
        ],
        "b61154de-8ace-4ea9-b2db-78703b4cd2a9": [
            "node_833"
        ],
        "b692fbc9-5f74-4e31-a923-bb0640b08304": [
            "node_833"
        ],
        "95ac17c7-92f4-464e-8d96-ae019cfe2021": [
            "node_833"
        ],
        "5a54e9cc-e27a-459c-a282-a61e1132a69d": [
            "node_833"
        ],
        "983f6367-e007-459f-94f2-d40a7d963c8c": [
            "node_1008"
        ],
        "567a01ab-1375-45b4-a068-e8e56cb6cc97": [
            "node_1008"
        ],
        "4a935613-71a4-41fc-8fe4-2525ec6bd7cc": [
            "node_1008"
        ],
        "d3ba380d-7a13-489a-a4f9-03e889b1611b": [
            "node_1008"
        ],
        "78448f98-fa4e-4c8c-8aba-890edacbfdf1": [
            "node_1008"
        ],
        "8aeb84dc-a168-425c-a094-8fe9836df108": [
            "node_1082"
        ],
        "65610fe6-fa2b-4250-a3ac-ed98ab1c5922": [
            "node_1082"
        ],
        "55d3f3f3-05f3-4469-af70-4f2c3c0da3aa": [
            "node_1082"
        ],
        "3d9c9ee7-3cd1-4d46-a108-a1962af3d3ba": [
            "node_1082"
        ],
        "10f168e3-2c3c-4938-b33c-c53ec21a29c6": [
            "node_1082"
        ],
        "47ef46fe-adc9-457f-83ed-b0617e01f695": [
            "node_1202"
        ],
        "fac306f1-ed4a-40ea-b6dc-d5b318a324aa": [
            "node_1202"
        ],
        "8b4a3c92-01d3-47cb-971a-39e1c5559833": [
            "node_1202"
        ],
        "6d8e9970-c77e-4a17-9324-1d510a8a2da8": [
            "node_1202"
        ],
        "d3c526c4-046c-495a-912a-1044846283b1": [
            "node_1202"
        ],
        "8fb2f1b6-1858-4adb-8321-5d4ce38d22bb": [
            "node_961"
        ],
        "e449f90a-abe5-4c76-ba16-19fa9253cae7": [
            "node_961"
        ],
        "f6f8064a-7cb6-4d10-9004-18f8c84a76b3": [
            "node_961"
        ],
        "7b952ccd-3a94-40b3-aa13-766b6f86a1d7": [
            "node_961"
        ],
        "5be076fa-2176-4a0b-ac6a-8c4cd50bac80": [
            "node_961"
        ],
        "28aa7163-50ae-4c58-9c7b-86784bba69f6": [
            "node_810"
        ],
        "a6021b20-9e7e-4326-8cc0-86ad79bcd1b6": [
            "node_810"
        ],
        "f1968d3a-8092-47b5-954a-c0459f337730": [
            "node_810"
        ],
        "a3ad548a-8c02-4dfc-b962-e23da8fce804": [
            "node_810"
        ],
        "224d42ac-4828-4a84-a893-7787cf7d534b": [
            "node_810"
        ],
        "55be591a-8ddc-4cbf-9f43-c65ec2bfcdd1": [
            "node_810"
        ],
        "0d7b1d39-4f17-4374-9f61-caff12a43168": [
            "node_810"
        ],
        "0d537cb3-e9c7-4bfc-8412-a83fb3cfccc4": [
            "node_810"
        ],
        "7be20263-4f9c-4d7d-9acf-2321179fd0e9": [
            "node_680"
        ],
        "1f4fd3ac-001d-4683-80fb-9743bf978d65": [
            "node_680"
        ],
        "5fa0a178-a41f-4cf7-b074-8c844bbd1b32": [
            "node_680"
        ],
        "2e3fb5f6-b1f5-4757-a98a-1d46cf7cebf9": [
            "node_680"
        ],
        "387b6c20-20ab-4284-b407-893355f305a0": [
            "node_680"
        ],
        "0d9d0ff2-3239-4aa4-8cc0-e23cb953b3e6": [
            "node_801"
        ],
        "e6824357-81a4-4c97-86b3-f48c35203b5d": [
            "node_801"
        ],
        "147e6f37-f01f-4dd9-9757-15b341875f8d": [
            "node_801"
        ],
        "547ede31-efe7-49a8-89ea-2797dacff1e0": [
            "node_801"
        ],
        "1e19b2b8-b759-4090-8b1a-d0dc32e9c62e": [
            "node_1211"
        ],
        "4a47b054-651e-4462-ac1a-fcc4b423d1c9": [
            "node_1211"
        ],
        "20c0d965-5a34-453f-906b-633a8aefa233": [
            "node_1211"
        ],
        "cf9e5c3f-6fd3-4a0a-89ff-2df332fadb36": [
            "node_1211"
        ],
        "f47f6057-35c6-4751-b7dc-8875140d4015": [
            "node_1211"
        ],
        "1a6481e0-bf89-491e-8383-f14106a363f5": [
            "node_1211"
        ],
        "dfc37271-649b-4382-9c54-a0e2e5692a8c": [
            "node_1211"
        ],
        "bd1366ef-cc7d-4a88-8447-d46f83224108": [
            "node_1211"
        ],
        "3e4f19cf-b26f-496f-bd02-a464d0a4114b": [
            "node_1211"
        ],
        "f7a8e374-9780-4895-9c85-9f3a9b64da0e": [
            "node_1211"
        ],
        "5fd62f15-25e8-43f8-89b3-dd13a3e3c390": [
            "node_598"
        ],
        "9296e1fa-fd54-4c70-bc6e-d0101d86724a": [
            "node_306"
        ],
        "74a94624-53d0-4a8a-8218-833639bc8568": [
            "node_726"
        ],
        "54f27326-93f0-4073-b9c3-99cfd34a5431": [
            "node_726"
        ],
        "b709e5e7-49c5-427f-84cd-258490bdc006": [
            "node_726"
        ],
        "41314583-cbc9-4df0-bdc5-8c17f4e2344b": [
            "node_726"
        ],
        "0fb52993-2230-4c8b-8542-2395203cd1c9": [
            "node_726"
        ],
        "afcc3da5-43b4-41cc-ab44-df3ba6768ae1": [
            "node_363"
        ],
        "a84f5584-b634-4131-8645-b2915f97bed2": [
            "node_363"
        ],
        "7416045b-0ce9-4cb6-a552-ae9560cfdcb2": [
            "node_363"
        ],
        "23b2058c-71f3-4e15-9bf8-0023f4c0b2f5": [
            "node_363"
        ],
        "509d4fad-6c51-474e-bb29-f70fafa353ed": [
            "node_363"
        ],
        "2a944896-d639-4097-817a-3136976d0d9f": [
            "node_234"
        ],
        "7a407144-548d-476e-bb82-899804de4341": [
            "node_234"
        ],
        "2d883164-ed6a-48c6-bb8b-b1dd47def258": [
            "node_234"
        ],
        "0ab79e5c-07de-4f81-babc-8ab6e40d3339": [
            "node_234"
        ],
        "526aa1a7-b3e3-468e-83f4-3638f6b9c5de": [
            "node_234"
        ],
        "b69569e8-2623-4aae-99d5-95530380e68f": [
            "node_150"
        ],
        "ef95749d-cbe1-430d-bd4c-adfd4f8d18b2": [
            "node_150"
        ],
        "d22c0008-862d-4772-af93-ab8619853208": [
            "node_150"
        ],
        "863b180b-8073-4b24-8b29-a3c6a67a0ebc": [
            "node_150"
        ],
        "b479e75c-30cb-45a5-8721-026b7db4fdf3": [
            "node_277"
        ],
        "ec3fc888-29cb-41e5-ae60-1eed499f1e8c": [
            "node_277"
        ],
        "84d61010-1f48-42ad-a093-065787593493": [
            "node_277"
        ],
        "e1cbd1a3-5090-4d30-93bf-4cf8f7606963": [
            "node_277"
        ],
        "4a45c3af-7caa-40e1-ba71-51b340c1609a": [
            "node_277"
        ],
        "3cdbf2a9-b480-4c04-b1dd-714afd3c294d": [
            "node_280"
        ],
        "2b3cfa0b-e14f-42a9-9346-16f257d81ad3": [
            "node_280"
        ],
        "0e738cb8-0cad-4580-b79e-22f2b6e26438": [
            "node_280"
        ],
        "d266b30e-8aac-49ae-9be2-609e9c311cf7": [
            "node_280"
        ],
        "74e2f9b4-2827-4119-b273-29408fb8ef87": [
            "node_280"
        ],
        "077ffe8a-438c-4dbd-b231-41a605f1da94": [
            "node_1174"
        ],
        "3efde0e6-5e74-4393-8c8c-9c699c893f43": [
            "node_1174"
        ],
        "8305918c-cd8a-4fdd-ac51-22954dae4cb7": [
            "node_1174"
        ],
        "556355d8-ed81-4ba4-8a2c-6cf7ffa840cf": [
            "node_1174"
        ],
        "ca96a693-e982-404b-a540-0da86c0d8d12": [
            "node_1174"
        ],
        "c1b0d51d-6886-4cfd-ab1f-9c0e5201d3ca": [
            "node_1174"
        ],
        "a6fdf80e-7375-49b9-ae8f-588f140bb246": [
            "node_1174"
        ],
        "dc8dcdb8-c2b3-4f4c-887a-eb87b4e996ed": [
            "node_1174"
        ],
        "86f19aea-0b3b-46bb-b8f0-229a516e848d": [
            "node_1011"
        ],
        "3a712eec-93a8-4f65-a840-c5c59f332709": [
            "node_1011"
        ],
        "d4bfba90-7d2d-4e6b-b3d3-581c51d851b5": [
            "node_1011"
        ],
        "132d8191-e197-4f15-9ecc-00b38ac9675d": [
            "node_1011"
        ],
        "0420895f-942a-4838-aac3-550fc0fd8970": [
            "node_1011"
        ],
        "75c7e2bf-cd90-4dfe-b41d-73cad482b3d3": [
            "node_203"
        ],
        "998cc0ee-8b31-4c96-998b-cec9a256c44b": [
            "node_203"
        ],
        "89774a05-f5b8-4b61-90b2-8e5300664158": [
            "node_203"
        ],
        "67abc9fc-71b6-474c-8efa-839dbc267493": [
            "node_203"
        ],
        "110532d1-767e-423f-a4c4-443872eff731": [
            "node_203"
        ],
        "e88ec81f-eadd-4cc7-9573-ba2a4da69b78": [
            "node_203"
        ],
        "7c745d67-3e32-46aa-9f40-2ed996adff68": [
            "node_203"
        ],
        "9f4a2b86-d7bd-4544-81a1-bf43f5cb0d7f": [
            "node_557"
        ],
        "0e9ca4e9-94b1-48db-bc0e-665c455eab93": [
            "node_557"
        ],
        "abc875f5-85a2-40d1-9909-649526c2cb49": [
            "node_557"
        ],
        "fc15b6cb-66b5-4a12-8c11-a2c9e5039b1d": [
            "node_557"
        ],
        "dae030d9-66e6-40e2-8806-b9728b4a3db5": [
            "node_557"
        ],
        "caab943a-60a3-418c-8f86-4016138999d3": [
            "node_391"
        ],
        "3a625ab6-571d-46f0-8ccd-3afb642a6eb0": [
            "node_547"
        ],
        "9439c80e-2c2f-459f-af3b-13a48c11bd3c": [
            "node_547"
        ],
        "2e4e2549-434c-4a6b-b406-63445b8355d3": [
            "node_547"
        ],
        "4a658dca-5891-4e2d-a9cd-16e637ae3ef4": [
            "node_547"
        ],
        "9babc842-8188-43fe-98b4-c27b894128ad": [
            "node_547"
        ],
        "e3028d65-9ac3-4498-baa1-b0787b74448d": [
            "node_547"
        ],
        "f3afb755-64d9-46f6-9ff8-1f9196e451f7": [
            "node_547"
        ],
        "e130b591-c048-4287-b8de-99caa7da8152": [
            "node_1010"
        ],
        "7eb46567-6afc-4bc4-a905-45b72eabfbfc": [
            "node_1010"
        ],
        "30d88cb8-3696-4359-a2fc-54f3e6706293": [
            "node_1010"
        ],
        "6bfb1c7b-59d3-4ce2-a483-6a3c6d79d051": [
            "node_1010"
        ],
        "18231210-1ec4-4714-80f4-669566480303": [
            "node_1010"
        ],
        "40206303-bab7-4499-9376-9d1d0edb7c48": [
            "node_494"
        ],
        "38eeed5c-48b1-49cd-a4f8-0a42cfe3f758": [
            "node_494"
        ],
        "7937d10a-0330-43bf-8c2d-e044b98059c2": [
            "node_494"
        ],
        "805e70e1-c759-4ab3-b0d4-6a2933a5b1b5": [
            "node_716"
        ],
        "ef97aa30-4dab-41e4-a98f-56440da59f8c": [
            "node_122"
        ],
        "d1782401-509a-4d52-b25d-c3913841e03a": [
            "node_122"
        ],
        "2dad2bfa-cd8a-47df-9f3c-3d19e67875a0": [
            "node_122"
        ],
        "f280e3ab-38de-4f76-9f77-b20230b9674f": [
            "node_122"
        ],
        "39fd97ab-8669-472a-af24-7467faef3c6f": [
            "node_122"
        ],
        "e57e287f-d5ab-449b-92c4-e600a5f22ec3": [
            "node_7"
        ],
        "efccd79b-04f8-4e1b-88bf-29af11cc2142": [
            "node_7"
        ],
        "8124fe2d-0b45-4a8e-ad27-34aa27bce68e": [
            "node_7"
        ],
        "2ccc1112-660e-4c1d-859a-98db6f510ef2": [
            "node_7"
        ],
        "ba232f53-fb28-4117-a9f1-8985bf4f5284": [
            "node_7"
        ],
        "d9f0e00c-fbdb-47c6-9869-4ce0038be9bf": [
            "node_238"
        ],
        "4be2b2c2-2eb2-47cd-9459-154cec17bfb2": [
            "node_238"
        ],
        "88798b25-f479-4987-b585-baba43f19220": [
            "node_238"
        ],
        "ad5bc050-69ae-43ee-a6bd-09b051d0902d": [
            "node_238"
        ],
        "97a78467-c08c-486c-951f-6e8fe9dee116": [
            "node_238"
        ],
        "a89d06ba-0139-46c8-9c4d-b50ecf432345": [
            "node_1204"
        ],
        "a4676534-dcd6-411e-917d-22d711378373": [
            "node_1204"
        ],
        "199e7cb1-f0d1-48a1-9052-ca6028ae171e": [
            "node_1204"
        ],
        "9ae8ad5a-aea4-4315-bc56-17e2bf49bfaa": [
            "node_1204"
        ],
        "4fdf08c6-8187-4a1b-9440-bd8ae5562161": [
            "node_1204"
        ],
        "03a4d293-9dba-495f-9d33-75616d412fb1": [
            "node_330"
        ],
        "0c1e4861-f028-496c-b88e-3e5610b3c62c": [
            "node_330"
        ],
        "e33ce6cb-590a-4e55-a617-a4f277ec4ca0": [
            "node_330"
        ],
        "aad45d92-3d2d-45b2-b6a4-6be294447b9c": [
            "node_330"
        ],
        "ce9af080-c289-4f5d-b4d9-447789f9b82a": [
            "node_330"
        ],
        "ce8c0b45-b8ba-42fe-9ed6-ddad0fc9029d": [
            "node_820"
        ],
        "30403bde-aae0-48ab-afc3-2b53366e7882": [
            "node_820"
        ],
        "d5b33747-a576-46e6-bb19-182e54ea1ebb": [
            "node_820"
        ],
        "594761fe-fdb0-41c1-8705-8aef5ebd685e": [
            "node_820"
        ],
        "7534f57d-4c16-4aee-a664-19cb0ee2af6b": [
            "node_820"
        ],
        "a50e9457-155e-4179-a459-9380757bd38c": [
            "node_24"
        ],
        "530c452c-de23-4590-a46d-3a8b0739373c": [
            "node_24"
        ],
        "e3d946b1-8e1f-4447-a001-bc8c0c6fa211": [
            "node_24"
        ],
        "4165e9df-2bf3-42ad-a5f4-551bcc6d7b8f": [
            "node_24"
        ],
        "bcca55a5-d76c-49ed-9d2b-66355fe4d54a": [
            "node_24"
        ],
        "997d5b43-3e99-4ac2-8548-e6409d7083eb": [
            "node_531"
        ],
        "c7805749-2af6-40dd-921d-7396a53ad05d": [
            "node_531"
        ],
        "168e5abb-519a-4962-aa66-90c197dce52d": [
            "node_531"
        ],
        "22a5e366-751a-4ef3-b2e7-b571ad6ea60e": [
            "node_531"
        ],
        "3b00a6de-fd2f-4f7b-9429-c368e766bcf5": [
            "node_531"
        ],
        "1792e223-002c-48ca-b971-bba1b7caf458": [
            "node_501"
        ],
        "6257d370-0bec-4025-8e35-4029d8e5c584": [
            "node_501"
        ],
        "903e20d2-0e4e-4701-99ce-dacf199905b3": [
            "node_501"
        ],
        "2ee14c57-98f2-45e0-b818-a6d73c37ed13": [
            "node_501"
        ],
        "b7069f95-c6c1-4331-bcf7-f4786c6aa0ea": [
            "node_501"
        ],
        "3f5ee512-f47e-4602-989e-516144c03acc": [
            "node_501"
        ],
        "db79a72f-13e3-4925-ae2c-714bbdadd0da": [
            "node_776"
        ],
        "edd364cf-68cf-49ba-9db8-af4961e0f873": [
            "node_776"
        ],
        "911202d5-f475-4d4e-a2d0-aa80eebb7807": [
            "node_776"
        ],
        "2e61f509-a8eb-44f3-822e-bf9539198fb1": [
            "node_776"
        ],
        "b7956c1c-bec6-4519-94e4-6be885eefbdf": [
            "node_776"
        ],
        "c32ac534-65d0-4284-9c4a-a686155c8ffc": [
            "node_459"
        ],
        "5d4a90e3-0368-4d68-a974-3e706dd28c00": [
            "node_459"
        ],
        "1e022415-b39b-4d4f-9ca7-f0ec89f9dc63": [
            "node_459"
        ],
        "46ba9f6d-0da4-4179-9a41-f3ff313440f5": [
            "node_459"
        ],
        "b3b835a5-2d78-4816-9908-4100766e6e6b": [
            "node_459"
        ],
        "bf71a512-a10b-4eef-9132-106ca50567ad": [
            "node_0"
        ],
        "86ff216f-2a47-4695-8cf0-d6525b9af625": [
            "node_0"
        ],
        "c48647eb-d263-447c-a2bf-58c5b7fef2e8": [
            "node_0"
        ],
        "30b63ab4-985a-488f-9f1f-d3c201f7c71a": [
            "node_0"
        ],
        "d81b51b9-55b0-477f-973c-5fc6064a639d": [
            "node_0"
        ],
        "414ec1a1-738e-4fd4-a091-c991de588f66": [
            "node_1287"
        ],
        "9f50b978-4718-44db-835b-0a952b8e9bde": [
            "node_1287"
        ],
        "ee8572b5-7d26-40c2-8b36-d10f5f68dbfa": [
            "node_1287"
        ],
        "6f5f72f5-16ef-4822-b1cf-371040a009d4": [
            "node_1287"
        ],
        "6aeb7d37-0bb5-4aeb-bcdb-c9df50b8cd76": [
            "node_1287"
        ],
        "8dd681c1-d30f-4739-99d3-fea55a1ff067": [
            "node_292"
        ],
        "f764c7b8-7a5a-43eb-8498-72016e56fad6": [
            "node_292"
        ],
        "d61d75cf-79c7-4365-9e4c-7894ad631b7a": [
            "node_292"
        ],
        "b2fcae9d-28ab-41aa-b19e-682152828e8c": [
            "node_292"
        ],
        "d1eedb8b-6170-428f-8128-3caafd1739fe": [
            "node_292"
        ],
        "3ae1a3d8-b5e3-4984-8e19-1040905fc354": [
            "node_1200"
        ],
        "c0cff382-c8ec-4399-af3f-778c3f5e031b": [
            "node_1200"
        ],
        "3f27876f-0943-49bd-b7ac-aedcd07b0a27": [
            "node_1200"
        ],
        "27d60f6e-f62b-459c-9cae-7d311e8d1bf3": [
            "node_1200"
        ],
        "12f3db99-634d-49c8-bea2-2ef1c3beecfa": [
            "node_1200"
        ],
        "7df11f30-990b-450a-bd9c-29c292e82bb5": [
            "node_868"
        ],
        "f697fb42-e020-45de-8125-1b5c1ea8c5e3": [
            "node_868"
        ],
        "3f38a7c2-5640-4957-b016-809a767706ef": [
            "node_868"
        ],
        "5e0c4ebe-ee82-49ad-9084-89ac51c0491b": [
            "node_868"
        ],
        "d411dbd6-3147-4104-acbe-873cc9a918da": [
            "node_868"
        ],
        "4ca7f734-6821-45ea-820a-c7a22b467c7a": [
            "node_878"
        ],
        "6b7a4978-b898-47a8-acf7-4fde7c7e7067": [
            "node_878"
        ],
        "c6ca36a8-147d-4895-a75c-5410a2f1fe37": [
            "node_878"
        ],
        "67abaca3-dd43-41b4-b66c-16c8f0888842": [
            "node_878"
        ],
        "9c668c60-23e2-4f35-b30f-e74dcbf1b3f8": [
            "node_878"
        ],
        "a90f548d-7f80-4b3f-966b-69078c13fbc4": [
            "node_878"
        ],
        "5e5c3c64-9f6b-42ff-95d2-30b9d26433cc": [
            "node_878"
        ],
        "5b4e5742-d169-425f-85d3-e046bae15a07": [
            "node_878"
        ],
        "e8ccd8a3-4166-4812-b589-c2a07cd07dd0": [
            "node_878"
        ],
        "415327e0-7f4c-4a8e-aa73-1233e0c8d376": [
            "node_878"
        ],
        "469033ca-37e0-4ccf-badd-293cbedd244a": [
            "node_299"
        ],
        "70d98a75-a7b4-4aac-9faf-ecd04aa4d70a": [
            "node_299"
        ],
        "3c57812f-6dc8-4483-9da1-5947997715b7": [
            "node_299"
        ],
        "64233a57-0490-44af-88bf-8af997c0ac30": [
            "node_299"
        ],
        "4d2655dd-ce70-496b-bf79-f1a82f5416f9": [
            "node_299"
        ],
        "740eb0b6-bfb7-44bb-9851-93d7c1011755": [
            "node_343"
        ],
        "ee2ca479-ad4c-43c4-a90a-b4caedccf86f": [
            "node_343"
        ],
        "2ae309a5-cab6-4e91-af20-ab70137dece1": [
            "node_343"
        ],
        "ec6e85c4-9a48-4a12-b235-6c7e43088d03": [
            "node_343"
        ],
        "49ede9fc-ba68-470a-823c-ef76ed324ea3": [
            "node_343"
        ],
        "ec3339eb-390a-49fd-af84-68444b1e6fd3": [
            "node_386"
        ],
        "898f9052-c54e-4172-bcf0-05e6cb462145": [
            "node_386"
        ],
        "a6460989-014c-46dd-b28e-1a751eeb4637": [
            "node_386"
        ],
        "6efd1c6d-7159-477b-ba7a-4e7a4f613b01": [
            "node_386"
        ],
        "8fa26f3e-7fc4-4a07-80da-a2442f8cde47": [
            "node_386"
        ],
        "40f15df4-5a30-4807-8d45-8de99fd53038": [
            "node_974"
        ],
        "0296f0b8-5508-4df1-9107-cc37b4491c06": [
            "node_974"
        ],
        "b5ef6378-e216-43b4-9c4b-10fb910be91f": [
            "node_974"
        ],
        "3a8bffb6-7d36-49d0-8f67-3b976f50bc1c": [
            "node_974"
        ],
        "4f38752b-f702-47c4-8c51-38dee4bf9117": [
            "node_974"
        ],
        "7d782c0d-e3d5-49db-97d3-5b56379b6f93": [
            "node_974"
        ],
        "e4de4beb-6496-4347-90ed-aa099897e672": [
            "node_974"
        ],
        "e099f0af-a489-4306-a324-56262691cf13": [
            "node_173"
        ],
        "3cf1f285-048c-4566-a13d-d1ecfe0dc6d2": [
            "node_173"
        ],
        "9d3672f7-832b-4585-9c8b-750541b35adc": [
            "node_173"
        ],
        "3b408c6e-3685-4fab-ba1e-04c07966152a": [
            "node_173"
        ],
        "3b2fee3a-bba1-4e95-864e-a3440b0b9e37": [
            "node_173"
        ],
        "d87f5688-2e5f-4bb9-9d14-91ffb17795a2": [
            "node_173"
        ],
        "431c626d-4b40-4325-bcab-8f4ed3fde29d": [
            "node_173"
        ],
        "a3e0c4bf-908b-4433-899f-ca7f419840c3": [
            "node_173"
        ],
        "16680c7b-ca86-4987-aa42-8855232a0a1e": [
            "node_173"
        ],
        "3f8eab1e-ab46-426b-a48f-8c59349d6604": [
            "node_173"
        ],
        "14fd8bcb-afe3-4895-96d5-cd8feff636d7": [
            "node_420"
        ],
        "ec70060f-c880-4102-ac51-122b343787fe": [
            "node_420"
        ],
        "3931932d-5ad3-40eb-a0dc-d249130a849e": [
            "node_420"
        ],
        "b19fef29-c395-4198-be17-5a2cd5158ab3": [
            "node_420"
        ],
        "e58b7e76-a787-4313-92b4-30a4e39504d6": [
            "node_420"
        ],
        "38105eec-6e2f-4973-8883-061142cd7a11": [
            "node_555"
        ],
        "7524632c-a524-4908-902f-be7c0c51e092": [
            "node_555"
        ],
        "3fb66621-ca4a-498b-8542-043e600a81cd": [
            "node_555"
        ],
        "b1c9ca2d-9159-4e85-815d-7a0da76b5e43": [
            "node_555"
        ],
        "3c01c36e-79d8-4058-8328-882fc8b80412": [
            "node_555"
        ],
        "c4fcc6bf-fbba-4d4f-9ebd-8a6cdb13f6f9": [
            "node_628"
        ],
        "344650f7-a7bb-46d8-8815-ac126335ef02": [
            "node_628"
        ],
        "2f98a488-d7a2-44af-b573-365860698b38": [
            "node_628"
        ],
        "9aaae3e4-2a44-4df7-973b-5c2adf3f8bc1": [
            "node_628"
        ],
        "89ba1aaf-e5ea-42fc-aca8-f1a0bd7cbf29": [
            "node_628"
        ],
        "37cee623-ea0d-4610-8ea7-d712f80b7d62": [
            "node_871"
        ],
        "e7a321c9-25e1-44f6-8c91-dc178c43226f": [
            "node_871"
        ],
        "9fdb0864-7a4a-4710-878b-5e8f2f916a63": [
            "node_871"
        ],
        "66a58f26-11ac-4f30-8a84-593d090a3643": [
            "node_871"
        ],
        "456a3844-ed3f-4bd0-abf7-a51628ec3c3a": [
            "node_871"
        ],
        "758aff53-2f3f-4e48-8dc1-7b3059ed45dc": [
            "node_1096"
        ],
        "0d33eb02-c545-4dc9-b144-20c6e780e2d1": [
            "node_1096"
        ],
        "576625a8-d832-4288-aa7b-e2546afd2e7e": [
            "node_1096"
        ],
        "b1c99930-d5d6-4bf4-ac67-d143c3335463": [
            "node_1096"
        ],
        "6fd45363-b920-4775-8981-12efb7f5a491": [
            "node_1096"
        ],
        "f49d71f3-6d6d-4406-8ca6-ebabe3076b27": [
            "node_138"
        ],
        "eb2aeefc-7b39-4bab-a640-f19498070db3": [
            "node_138"
        ],
        "aaebd32d-4336-47a4-9db8-38b0818f93c8": [
            "node_138"
        ],
        "145cd08b-ac7d-48c8-9230-9fcc027b3cbe": [
            "node_138"
        ],
        "98e337bc-4508-4ce8-a904-7bd7069dbe67": [
            "node_138"
        ],
        "0e7f3ec8-27f3-4c6f-888e-0b39fc12d8f8": [
            "node_887"
        ],
        "8583e9a8-269a-4918-a448-1ae66a3a26de": [
            "node_887"
        ],
        "990a35fc-19b0-46a9-84e7-c400416e729d": [
            "node_887"
        ],
        "88fef03e-8a99-40cd-8e86-8b894532893d": [
            "node_887"
        ],
        "229fc4bf-3a23-4f7b-a7f9-08b77c7a5559": [
            "node_887"
        ],
        "bfe17b41-8828-42e3-8517-772319660e64": [
            "node_887"
        ],
        "dece367c-b482-44de-9ab2-4579a2a0e718": [
            "node_887"
        ],
        "f8625081-09ac-4045-ad98-5d0d0bf2b147": [
            "node_887"
        ],
        "1a528447-af3b-493e-972e-9d8dd434abb9": [
            "node_950"
        ],
        "b19c3f10-8efc-40b5-91bf-b7ad520341a6": [
            "node_950"
        ],
        "895329aa-1ccb-4279-b451-61044c4cd7d5": [
            "node_950"
        ],
        "5ccb1380-d231-425f-a496-93f1a4b05829": [
            "node_950"
        ],
        "f95c6e81-a22a-4e98-bb18-3377f640a1ed": [
            "node_950"
        ],
        "9969eb15-a328-4779-8400-1fb515ddb8e8": [
            "node_1026"
        ],
        "5b2556e8-a0d1-48d2-835b-b5b7516b03c3": [
            "node_918"
        ],
        "9723cdc4-6439-4ee4-becf-711c0a64950e": [
            "node_1107"
        ],
        "38c9be58-7992-46e0-8a08-f6b62f01a9bd": [
            "node_1107"
        ],
        "d9dcb763-2588-4c0e-aa68-0fe4af778865": [
            "node_1107"
        ],
        "7c79f1a2-e44b-4566-8bd7-dab549c98496": [
            "node_1107"
        ],
        "31e1dc1d-22ae-4266-bd77-4efd2f5a5b27": [
            "node_1107"
        ],
        "a9c57f25-1bd1-4c84-9e5c-38df62d3ccc3": [
            "node_497"
        ],
        "4829596d-f255-4a12-9070-0dbd4caed540": [
            "node_497"
        ],
        "6057c3d2-62c1-438f-8e62-71c873e1178c": [
            "node_497"
        ],
        "9354b484-3004-46ce-ba18-68e20b75821b": [
            "node_497"
        ],
        "4aeb0dd2-812e-47ad-b0a5-90184fa0ccc1": [
            "node_497"
        ],
        "a8328514-08bc-4cd8-89fb-8d7171470e9f": [
            "node_803"
        ],
        "27f2923b-ffe5-43d3-bab8-c8a0ca78c3ec": [
            "node_77"
        ],
        "e9a34c58-6f39-4c6e-ac1d-ce255b987a40": [
            "node_77"
        ],
        "2fc9ca04-e6cf-480b-b1dc-103405fd0a17": [
            "node_77"
        ],
        "140074d1-ab6c-460d-80da-6fe8767fdec5": [
            "node_77"
        ],
        "5e1e95a3-48e7-40c7-8911-b4299a799065": [
            "node_77"
        ],
        "5246a65e-d0c9-4c7a-9046-8fd4aaba6f44": [
            "node_77"
        ],
        "5c3fa3d4-f4c2-4e60-a895-4f8e8b65604f": [
            "node_580"
        ],
        "d28cc908-4cb0-4326-8533-4134b7f8afaa": [
            "node_580"
        ],
        "f3d6f59c-19f5-4999-8566-87eaec1b147e": [
            "node_580"
        ],
        "32d652ef-3b92-4a6c-8103-1fdc7ea5f834": [
            "node_580"
        ],
        "8641ae2c-9ecf-47c8-9ac4-1c2f62654dba": [
            "node_580"
        ],
        "c87b78b1-f05a-4e5c-a6ec-fca75ea9ba4c": [
            "node_92"
        ],
        "2781ff55-ff25-48b8-a0d9-feb312e827a7": [
            "node_92"
        ],
        "3b0c6947-6432-4b74-9c13-c3b7a7d2db45": [
            "node_92"
        ],
        "62bf01dc-d268-41ba-8f36-7cd17fba0625": [
            "node_92"
        ],
        "330f601d-8a22-492b-887f-cfc41af9c177": [
            "node_92"
        ],
        "a665911d-f9f4-4dcf-82e9-c693caa145fc": [
            "node_1085"
        ],
        "6d135796-0e28-4caa-8e5d-5682004ee788": [
            "node_1085"
        ],
        "42a41365-65b6-4364-80a6-c267899cf577": [
            "node_1085"
        ],
        "31d5cb92-164c-4ada-b4ce-9685ef419b28": [
            "node_1085"
        ],
        "e8a1be23-e806-4609-bad5-55ad056ffae3": [
            "node_1085"
        ],
        "2a092559-c32d-4269-bf82-71ce646cd2d6": [
            "node_1101"
        ],
        "53b3cbbe-b192-48c3-9264-5663f0277463": [
            "node_1101"
        ],
        "7f9a6a94-45b6-45c2-b166-4a388379662b": [
            "node_1101"
        ],
        "2e8f3b4c-964c-40b3-84cb-011765ee5976": [
            "node_1101"
        ],
        "382bd4b4-8a16-4bcb-8bdf-5e763f971557": [
            "node_1101"
        ],
        "a9a095c9-4511-4a6b-8826-c8ffa560927c": [
            "node_575"
        ],
        "24be9541-512b-438b-bafa-b2b8c6297246": [
            "node_575"
        ],
        "69f30c5e-ccc2-41a4-b480-c7e62d3a9e9f": [
            "node_575"
        ],
        "855518f2-c8ea-4a5d-b61f-dfbd62cddf98": [
            "node_575"
        ],
        "fc43b367-6061-47eb-be58-81f76ffccc5f": [
            "node_575"
        ],
        "a31562ca-cceb-4c00-ba0b-9e768e4c2955": [
            "node_1257"
        ],
        "78b7b293-ad00-4695-8264-e5f30dd8ab15": [
            "node_1257"
        ],
        "b9dd440b-98f2-42ec-9597-afe2ad813cb0": [
            "node_1257"
        ],
        "ca0d3691-15ac-4821-be85-99c3f5b457c2": [
            "node_1257"
        ],
        "984be6ce-653c-480d-b12b-5035f65d4fe8": [
            "node_1257"
        ],
        "18b11651-f068-4078-b70a-c0193133e2ca": [
            "node_1024"
        ],
        "cc6e6ea8-64d5-40da-baab-7315e0102347": [
            "node_1024"
        ],
        "7b81cc66-a64d-475a-8b34-01b7b69d9e91": [
            "node_1024"
        ],
        "bb7619ae-cb9e-42d0-86a1-8e5ad26471a3": [
            "node_1024"
        ],
        "ea330fde-3cb0-4b15-b913-67ec1b53c0ef": [
            "node_1024"
        ],
        "0f05a8a2-173b-4990-a65a-22146684068b": [
            "node_1006"
        ],
        "34e7c81c-b878-4322-9579-2c2714fb9b00": [
            "node_1006"
        ],
        "3d55948f-0f64-4e31-aa86-14255fd43c0a": [
            "node_1006"
        ],
        "093f57e8-4016-483a-9b5f-584e6c9f1eeb": [
            "node_1006"
        ],
        "a8ea3f3f-a3b6-4e70-8091-eb8afaab7a83": [
            "node_1006"
        ],
        "4315a054-5360-447c-9b8d-7c87e534e35f": [
            "node_32"
        ],
        "255b9795-7f20-4515-948e-9086ca4c571e": [
            "node_32"
        ],
        "a34371f3-39e6-433c-bd3d-a387841eb78e": [
            "node_32"
        ],
        "4063708a-7e86-413a-a667-2cc548d785a5": [
            "node_32"
        ],
        "494186ea-565b-4860-af95-15d53811d065": [
            "node_32"
        ],
        "2cafebba-653d-4058-a647-4f8e9c5230cf": [
            "node_725"
        ],
        "40f5b225-6e2e-4b9c-a107-41d9b4ce3dd1": [
            "node_725"
        ],
        "87a8d382-a9a3-4f20-8d7e-6af9b82d9e56": [
            "node_725"
        ],
        "7e77cb5f-0f3a-4ce9-924e-9c543fef2211": [
            "node_725"
        ],
        "04bbb04b-30a3-4712-bbd6-cadb6696ec0f": [
            "node_725"
        ],
        "94e34702-5a40-44d5-be8e-4d8a3aaba390": [
            "node_39"
        ],
        "247e5a6d-38c0-452e-b269-78b232ada1bd": [
            "node_39"
        ],
        "42980ec9-72f0-4495-8120-d92a4167df75": [
            "node_39"
        ],
        "048e8e94-1cfc-40a2-8cdc-684df1fe4398": [
            "node_39"
        ],
        "6d8c7070-c0fa-4c37-a41c-0d09b882ac0e": [
            "node_39"
        ]
    },
    "mode": "text"
}