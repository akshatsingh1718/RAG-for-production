{
    "queries": {
        "bf218a93-1b07-4aba-b735-242aeca4bc33": "How does the `create_shape_tensor` parameter impact the reading of sample shapes in a dataset?",
        "1fb1d5c2-5714-4910-84a8-b1b4d188e69d": "What are the exceptions to the rule that no data is loaded until a sample is read from a dataset?",
        "66e45ea9-4b9a-4848-9b0f-97936c17faff": "How can credentials be added to a dataset for authentication purposes?",
        "cf2fd15e-6f94-4e60-a215-8ce86a3c2692": "What is the benefit of storing credentials as Managed Credentials on the Activeloop Platform for datasets?",
        "9b41963b-88ba-4a3a-94c4-3f33c35ad273": "How can you prevent the verification of links in a dataset?",
        "58626388-2c96-4eed-ab53-5e7eb1f4ff5e": "Explain the purpose of the `sequence` htype in the context of tensors and provide an example of how it can be used in a dataset.",
        "1644fdfa-8785-4180-a7e0-25b4804d42d0": "How does the `link` htype differ from other htypes in terms of storing external data in a dataset? Provide examples of variations of the `link` htype and explain when data is actually loaded from external sources.",
        "1e5eed95-f1e1-40e4-bcab-ba93a0f4780f": "How can you append a Deep Lake embedding sample to a dataset using the provided code example?",
        "2d1400dd-ef44-421a-8d7d-14541d06f2c7": "Describe the functionality of the `extend` method in the context of extending a dataset with Deep Lake embedding samples.",
        "528d8124-0fc4-45e0-8dc9-93ccd75bf534": "What are the exceptions to loading data when using the `link` htype in a dataset? Provide details on when the shape of a sample is read and when sample info is read.",
        "13f4bdb6-2fad-4f3b-8c78-36d4c1eca394": "What are the limitations of the Deep Lake Performant Dataloader in terms of supporting data formats?",
        "3928c0b6-360d-45ef-b6cc-9288d26b7960": "How can a nifti tensor be created using Deep Lake? What are the supported compressions for nifti data?",
        "0a3ad364-0c68-4092-8fb3-078fb3e72970": "How can nifti data be appended to a tensor in Deep Lake? What type of data can be appended as nifti samples?",
        "f9686329-bfdb-47f1-8d98-80ff804f55ab": "What are the key characteristics of the Point Cloud Htype in Deep Lake? How are point cloud samples represented?",
        "6785f730-6036-4f47-83a8-76769992869f": "How can a point cloud tensor be created in Deep Lake? What are the supported compressions for point cloud data?",
        "6cec35f4-ef57-464c-b75f-ecbfb6e3b9e8": "How can point clouds be appended to a tensor in Deep Lake? What type of data can be appended as point cloud samples?",
        "89446eb4-36a1-4566-b308-561466009033": "What are the supported compressions for creating a video tensor in Deep Lake Performant Dataloader?",
        "0646756c-0393-4bb5-bad5-ab50179e0bb5": "Can raw video frames be compressed when appending them to tensors in Deep Lake?",
        "f6c585bd-3c90-4cec-a531-1ed29c5eaddf": "How can you create an audio tensor in Deep Lake Performant Dataloader?",
        "a62cfeb7-b27a-48cd-b44c-aacb7c0bd1b8": "What is the default dtype when creating an audio tensor in Deep Lake?",
        "a0e8f120-4981-4337-b38a-ab7e24220f7a": "Is recompression of audio samples supported in Deep Lake Performant Dataloader?",
        "53be0048-a1e9-4fa0-8982-f0931389802d": "How does the `create_shape_tensor=True` parameter impact the reading of sample shapes in a dataset?",
        "9512d9cb-991a-46c5-98b6-e3887d65cb87": "What are the exceptions to the rule that no data is loaded until a sample is read from a dataset?",
        "8b615dba-ad56-4e6e-87d9-faa97b7cdb77": "How can credentials be added to a dataset for authentication purposes?",
        "faa92e0a-81d4-41d2-a1ff-504415d79251": "What is the benefit of storing credentials as Managed Credentials on the Activeloop Platform?",
        "44d33ea5-15f8-496f-bb7d-f1e9ac11e012": "How can one avoid verifying links in a dataset by setting certain parameters to `False`?",
        "d5699833-5101-4a53-a38d-6bc2d83a43e2": "How can you perform a search using an embedding in the vector_store?",
        "4cb39df2-31e7-4353-a3fc-04b050f2079d": "When would you use the `embedding_data` parameter in the search function?",
        "07b530ce-ddee-433a-ad99-32b86f2e764b": "What is the purpose of the `embedding_function` parameter in the search function?",
        "7b64d58c-c462-41e9-88b8-c798fde9e759": "How can you add a filter to your search in the vector_store?",
        "1b8e211d-6cd2-4e7b-a67d-c9038b310ff3": "When would you use TQL in the search function of the vector_store?",
        "8c704f2f-b9e7-4d87-8ca9-237843161bd0": "How can a tag tensor be created in the dataset using the `create_tensor` method?",
        "dfbf7c25-d0d1-452e-bdf1-dea71353eab2": "What are the supported compressions for chunk compression when creating a tag tensor?",
        "b4a9b7b5-0605-44e0-b3c5-6eaea7a9386f": "Provide an example of how a tag sample can be appended to a dataset.",
        "ebe3f7f9-684c-4c62-8800-27692b56fb73": "What are the sample dimensions for a bounding box in the dataset?",
        "72cda61e-82fa-41b1-890e-ff45459d2424": "How can a bbox tensor be created in the dataset, and what are the optional arguments that can be specified?",
        "1b14ad18-e6a1-4d20-aa2c-8cdcfc46d5b0": "Explain the difference between the \"pixel\" and \"fractional\" types for bounding box coordinates.",
        "1db025fe-29f8-4773-b19d-7f2ac8e1ef2a": "What are the different conventions for the 4 coordinates of a bounding box specified in the \"mode\" key of the coords dictionary?",
        "3cb5d45f-fe80-45c1-a915-dfb244eab844": "How can class names be set after creating a tensor in the dataset?",
        "8646f0fb-1ea8-4dd4-a4af-c1b08ca65c55": "How can you set the class names for a `tensor.info` object in a dataset?",
        "189ad014-ce9c-4c44-a8ce-6c5dd583164b": "What is the recommended compression option to use when the number of labels in one sample is too low?",
        "6b641621-581d-4dcc-a019-ed70d8e8847b": "How can you append class labels to a dataset in different formats?",
        "f9deb05d-3c9b-4038-a605-3210748351f5": "What is the purpose of the `tag` htype in the context of the document?",
        "746ab5c0-0759-449e-8c98-67c6a9418453": "How can you create a tag tensor in a dataset and what optional argument can be specified?",
        "2014231f-647c-4978-a0e9-925d4fe7bb1f": "What are the supported compressions for the `chunk_compression` option when creating a tag tensor?",
        "d4a725c0-ac52-43b1-91b7-9001ccb4a9a4": "How can you append tag samples to a dataset in the context of the document?",
        "3d620fa4-e969-464e-97fc-2d50ed7fca76": "What are the variations of the `link` type that can be used in the activeloop visualizer to correctly display data?",
        "061cca48-7f26-4b2a-b04c-9f48c5407776": "When is data actually loaded from a dataset?",
        "210b8d86-46aa-488c-8e17-cbf3edfce868": "What are the exceptions to the rule that no data is loaded until a sample is read from a dataset?",
        "3aca4f73-fdae-4614-9d4d-827bf19a364a": "How can credentials be added to a dataset for authentication purposes?",
        "26153047-ef40-45c0-8a12-7bffabeb1919": "What is the benefit of storing credentials on the Activeloop Platform as Managed Credentials for datasets connected to the platform?",
        "ee2dd077-39db-457d-b72f-9e321f5770ba": "Explain the components of the camera intrinsic matrix \\\\(K\\\\) and their significance in computer vision applications.",
        "8e2112fc-4a1b-40b9-bed3-e952e1af4436": "How can an intrinsics tensor be created in a dataset using Python code?",
        "c6b878f6-db66-4af1-8180-b6c08dde3581": "What are segmentation masks and how are they represented in computer vision tasks?",
        "e11e27ee-ee18-450f-a532-3814d842c4aa": "Describe the process of creating a segment_mask tensor in a dataset, including the necessary arguments and parameters.",
        "1724635f-f48f-44be-8c03-fac5060277cb": "How can intrinsics matrices be appended to a dataset in Python, and why is this step important in computer vision projects?",
        "6fc6a122-ab9a-4db3-beca-5767bed883b2": "How can you create an image tensor in Deep Lake using compressed bytes or raw arrays?",
        "bd5d31f7-3aa4-4a3d-9e93-ce93df8acea3": "What are the recommended compression formats for storing images in Deep Lake?",
        "35823ab2-ca9c-4128-b0be-bbb8d81c3f5a": "How can you append pixel data with an array to an image tensor in Deep Lake?",
        "d00ddee0-47bc-482c-ab32-9f90603ed5cd": "What is the significance of matching the compression format of the input sample with the sample_compression of the tensor in Deep Lake?",
        "309b2976-3c3a-431c-85e0-e03d6c617515": "How can you force your image samples to be of RGB or grayscale type in Deep Lake?",
        "7294863d-ab98-4b55-a603-4e98464f4c14": "What are the different types of paths that can be used to access datasets in Deep Lake?",
        "cdfcbb33-9f22-44b3-ab10-8be0f20d00f8": "What is the purpose of the tensor_params parameter in the dataset setup?",
        "fc486aa3-9646-4434-8ffc-325a629dc3c2": "How does the read_only parameter affect the dataset when set to True?",
        "80deba29-fc9c-431e-b5ca-345ddc08a0f5": "What is the significance of the ingestion_batch_size parameter in dataset setup?",
        "780eaf35-b798-4820-9650-c4ceabc2a14a": "Explain the role of the index_params parameter in creating a vector index for the dataset.",
        "04b61eeb-3c27-4d30-a8d8-62f8f1ab1bb8": "What are the possible arguments that can be passed to the `deeplake.empty()` function for creating a dataset?",
        "27293963-de99-4873-8006-740d3de4c516": "How can a DatasetDict be converted to a Deep Lake `Dataset` according to the provided information?",
        "b014be21-0b59-484d-976f-a82f3c7760b0": "What type of features are not supported when loading an existing dataset using `deeplake.load()`?",
        "640d1180-6644-4dc4-850d-8bf0c5bdd353": "Provide an example of loading an existing dataset from a specific version using `deeplake.load()`.",
        "3090e597-5d33-48e2-84db-c9e670d1fc4e": "What is the parameter `path` used for in the `deeplake.load()` function?",
        "e719e2c1-1aec-4910-b442-f7d4cec27e01": "Explain the difference between `Dataset.create_group` and `Dataset.create_tensor_like` in the context of tensor manipulation.",
        "1379de7e-fdd8-48ae-80bc-118dd2da4af7": "How can you delete a specific tensor from a dataset using the provided methods? Provide a step-by-step explanation.",
        "427f50ee-cf1c-4b5d-9d6b-0d4d9fe0ea2a": "Describe the process of adding a single sample to the end of a tensor using the `Tensor.append` method.",
        "330ebc95-f61f-4128-9474-c5e6eeeb221b": "What information can be obtained by using the `Tensor.numpy` method on a tensor? How is this different from the `Tensor.data` method?",
        "bc702242-781e-4385-8e6d-6182671e9f1e": "Discuss the significance of the `Tensor.shape_interval` method in accurately describing a tensor's shape. How is it different from the `Tensor.shape` method?",
        "298e96da-961f-41a9-93e0-c26ae16865eb": "What is the purpose of the `delete_group` function in the dataset class?",
        "6e93b74c-bb26-4841-a004-2082caf63b95": "Explain the parameters `name` and `large_ok` in the `delete_tensor` function.",
        "80277fdc-7ef6-4c8a-8bb8-22b16e57c42d": "How can you delete a view in the dataset using the `delete_view` function?",
        "8e55ff75-b2d3-40a2-99c6-641bded4e20f": "Describe the information provided by the `diff` function in the dataset class.",
        "6f7c4290-9e17-43a8-9bda-4eaa87205ba3": "When would the `TensorTooLargeToDelete` error be raised in the `delete_tensor` function?",
        "e2743a08-8146-4b3b-85b6-1d8034b71caa": "What is the purpose of the `token` parameter in the `ingest_classification` function?",
        "47cfd492-3b3b-494c-9944-c744838c0c79": "When would the `org_id` parameter be applicable in the `ingest_classification` function?",
        "b4ebfbe2-3305-4400-9c79-c578720c6c01": "What is the default value for the `public` parameter in the `ingest_classification` function?",
        "a149ae39-09bf-425d-8f05-8162e7393bc0": "How can you specify the organization id when enabling high-performance features for a local dataset?",
        "0bab4758-729d-4478-888e-c17139e74dc1": "What is the role of the `verbose` parameter in the `ingest_classification` function?",
        "c3f1717e-d9e9-45dc-8b0e-c2c3673c116e": "What type of object does the `ingest_classification` function return?",
        "c414c4a5-94aa-45e2-8538-20fd89a615ba": "What error will be raised if the `org_id` parameter is specified for a non-local dataset in the `ingest_classification` function?",
        "9d670f22-d76c-4997-986d-98b81a0bde30": "How should images be stored in subfolders for ingestion using the `ingest_classification` function?",
        "7c9649ca-5d05-42a5-83ab-35487ecfe3b1": "What are the different options for the `dest` parameter in the `ingest_classification` function?",
        "907ac458-91e9-4b22-85cd-7c1ebb44f4b2": "How can you authenticate to Deep Lake when writing to Deep Lake cloud datasets in the `ingest_classification` function?",
        "b4551b2a-ea07-4624-b5bf-8fbabd6baf3d": "What parameter can be specified to store datasets in the database with the \"tensor_db\" runtime?",
        "43e03792-7063-4f3a-9d46-37e2d2993922": "What is the default value for the \"embedding_tensor\" parameter?",
        "b498f379-ab97-4a5f-b684-88bcea01ffd2": "How can you specify to return data for all tensors in the dataset?",
        "4c310121-696b-4b47-b9be-054c75a61dec": "What is the purpose of setting \"return_view\" to True?",
        "5ae35ab1-5f13-4273-918a-712cc2aa26d4": "When is the \"deep_memory\" parameter set to True, and what does it imply for the search process?",
        "380ddadb-fa7b-4361-b7e9-874f1cfd07ec": "What exception is raised when invalid parameters are specified?",
        "fe21d96c-0370-483a-a637-daee2eaa0d80": "Under what conditions would a ValueError be raised for the \"deep_memory\" parameter?",
        "ac0ad536-7fdf-4b96-ad9b-d42f8d128159": "What is the significance of the \"return_tql\" parameter in the context of the document?",
        "c8de7fd6-31a5-463b-957d-a14ec51e7093": "What type of error is raised if a user does not have access to deep_memory for the dataset?",
        "4e50ccc0-0ff1-4025-9f2c-df95e96f21fa": "How can the distance metric be set for the search process when \"deep_memory\" is set to False?",
        "0dae81e3-67f1-420f-bd3d-694bcf72c8c4": "What is the default value for the `shuffle` parameter in the `DeepLakeDataLoader` object?",
        "ebb69498-cc3b-45e7-83fa-73fd3a340f1f": "What will happen if the `shuffle()` method is called after it has already been called once?",
        "02486c90-db5b-4821-b971-36d3b0b8cc65": "What is the purpose of the `collate_fn` parameter in the `tensorflow` function?",
        "93501578-886c-43f6-901b-22e38ff25afc": "How does the `prefetch_factor` parameter in the `tensorflow` function affect data loading?",
        "e18bc69a-d3e4-40a7-8c80-14fa8b92b297": "When would you set the `persistent_workers` parameter to `True` in the `tensorflow` function?",
        "ee7468b8-9586-4dc7-8907-60ff6ad2db33": "What is the purpose of creating a keypoints_coco tensor in the given context?",
        "e780472b-7a78-435f-aaf1-fa459e8193bb": "How can you create a keypoints_coco tensor using the provided code snippet?",
        "35d7a4d0-5eee-44ab-bcdc-27309e77a7f7": "What are the optional arguments that can be used when creating a keypoints_coco tensor?",
        "27e940be-b109-4475-84a2-c17974e08a4a": "How can you set the keypoints and connections after creating a keypoints_coco tensor?",
        "e1403789-148a-4f7d-87e5-56fc1ead2ed1": "How can keypoints be appended in the given context?",
        "955a1b60-1963-42ce-9238-dcd182c8fbc8": "Explain the purpose of the `Random Split` feature in Deep Lake and how it can be used to improve performance when creating dataloaders for training datasets.",
        "38b0b9bd-6068-45f5-8302-27e07e85509e": "How does the `Dataset.random_split` method work in Deep Lake, and what are the benefits of splitting a dataset into non-overlapping `Dataset` objects of given lengths?",
        "9f93e8fd-eccd-425c-b6e8-070bf706e1a1": "Describe the key concepts mentioned in the document related to Deep Lake, such as Datasets, Vector Store, Tensors, Htypes, Compressions, and PyTorch and Tensorflow Support.",
        "b28e5f9e-1a71-42e7-ae8f-de2c9e2920c2": "How can the `Weights and Biases` integration be beneficial for users of Deep Lake, and what functionalities does it provide?",
        "4312583e-8793-4a4d-97f3-c4186d803727": "Explain the high-performance features of Deep Lake, including Dataloader, Sampler, Tensor Query Language, Random Split, and Deep Memory, and how they contribute to improving the efficiency of data handling and processing.",
        "cc3f0a84-179c-41bc-8a6e-f80aea6a1441": "What is the recommended compression method for segmentation masks due to their large amounts of data?",
        "0ba693cd-c7c7-4512-853c-943e8a8e4ab2": "How can a segment_mask tensor be created in the dataset using the provided code snippet?",
        "15544dad-25ec-465e-8922-68543c72fb7c": "Explain the difference between segmentation masks and binary masks in terms of representing objects in an image.",
        "98270f53-0de7-417d-ac26-585146549348": "Why are segmentation masks not suitable for datasets where objects might overlap or where multiple objects within the same class need to be distinguished?",
        "ef67cc80-0001-49e8-931a-4275386b0c1a": "How can class names be set for a segment_mask tensor after its creation in the dataset?",
        "84afac0f-50fc-482e-9ba2-fa6cce4ada79": "How can you sample a dataset with specific weights using the deeplake library?",
        "a798abee-c0df-4c73-837e-80a7cb30b091": "What does the _sample_indices property return in a dataset view?",
        "826cf805-932f-40e0-b0e9-ea93b25a651d": "How can you save a dataset view as a virtual dataset (VDS) in deeplake?",
        "1c4b5f79-2789-4e4b-adc4-407fc566756b": "Provide an example of saving a dataset view with a specified path and ID.",
        "2ea42b67-74bd-4d69-b5e9-85df15da6487": "How can you load a virtual dataset (VDS) using its ID in deeplake?",
        "d97d0d35-a9e7-4555-8e21-35bcc8161a27": "Explain the purpose of the save_view method in the deeplake library.",
        "ce921962-f03b-47b3-88d0-9c5a26c39613": "In the given context, what does the sample_by method do when sampling a dataset with weights?",
        "4340b3f4-afef-43ff-9de2-033f6fe777a3": "How can you create a list of weights based on a specific condition for sampling a dataset in deeplake?",
        "5775c2b8-1f23-4922-ba7a-f673bb1a966d": "What is the significance of the replace parameter in the sample_by method when sampling a dataset?",
        "5880f4b9-c22d-41b9-9499-96855e2cbec2": "Can you explain the use of the num_workers parameter in the save_view method of deeplake?",
        "01ac432f-1c31-439e-86ab-9fefb4ee8301": "What is the purpose of specifying an htype for a tensor in Deep Lake datasets?",
        "48e322f1-9067-4267-b929-78943b9b7591": "How does specifying an htype contribute to the performance of datasets containing rich data like images and videos?",
        "db14d2dc-c706-4170-9f4a-320dbe2aad6b": "Can you provide an example of creating a tensor with a specific htype in Deep Lake?",
        "1841d486-3549-4b09-ac74-17d6465e5733": "What are some of the supported htypes in Deep Lake and their respective defaults?",
        "6d63c341-9bac-4c38-8699-af9c6f6ba16e": "How are images typically stored in Deep Lake, and what are the options for storing them?",
        "a4ca3af8-82f0-4219-b54f-a8f0dab65b56": "How can a mesh tensor be created in Deep Lake using the `create_tensor` function? What optional argument can be used for sample compression?",
        "f2f3d6dd-ca73-4835-960a-c61af8e239b8": "Explain the process of appending a ply file containing mesh data to a tensor in Deep Lake. Provide an example scenario.",
        "31fec093-d6f2-42c8-bfc7-0495a551268f": "What is the purpose of creating an embedding tensor in Deep Lake? What are the supported compressions for embedding tensors?",
        "033a37fe-33c2-496e-acfc-b5294b2ef0a5": "How can embedding samples be appended to an embedding tensor in Deep Lake? Provide examples of appending a single sample and extending with multiple samples.",
        "c4fcdcd3-e194-4d2b-b1d7-dbe48ab6e59d": "What is the significance of the Sequence htype in Deep Lake? How can it be used to wrap other htypes for sequences of different data types?",
        "865181fb-8d09-469c-b44d-97931959779d": "How can the htype of a tensor be specified at its creation in Deep Lake?",
        "4bc79cb9-c41c-4f5b-9dc2-a4ff9ee06205": "What is the default htype of a tensor in Deep Lake if not specified during creation?",
        "40148ebe-1e1d-4bed-ae42-a2896009b05b": "Why is specifying an htype important in Deep Lake datasets containing rich data like images and videos?",
        "fe18e460-8e97-4c24-97f4-e58ae5843212": "Explain the process of creating an image tensor and appending image samples using the Image Htype in the context of the provided information.",
        "7330c18a-bef2-4a0e-ba79-c1988503db32": "What is the purpose of the `skip_ok` parameter in the function definition? How can it be useful in certain transformations?",
        "ca8c823e-2ccc-49e3-8634-534260eff437": "Explain the significance of the `checkpoint_interval` parameter in the transform function. How does it help in handling intermittent failures?",
        "eb74337f-b203-41ef-97df-6149555f7672": "When will the `InvalidInputDataError` be raised in the transform function? Provide an example scenario where this error might occur.",
        "2179c6c9-2243-4f92-b762-3af488d4586b": "Why is it important for all tensors in the `ds_out` dataset to have the same length in the transform function? What potential issues could arise if this requirement is not met?",
        "06716ae6-4c8d-493c-9001-e04a95927a14": "How does the `ignore_errors` parameter impact the behavior of the transform function when set to `True`? Give an example of a situation where ignoring errors could be beneficial.",
        "4c7714df-6b67-457b-b8c3-c2d9ba11db13": "Explain the difference between `Dataset.save_view` and `Dataset.load_view` functions in the context of the provided dataset operations.",
        "ede19def-869c-4734-9338-ee39bbd08c1f": "How can you filter a dataset using the `Dataset.filter` function? Provide an example of a filter function `f(x: sample) -> bool`.",
        "3b202eeb-cd4e-421d-90f3-622ed9850e9e": "What is the purpose of the `Dataset.min_view` function? How does it differ from the `Dataset.max_view` function?",
        "c13ecb80-d4df-4d8d-9aea-bd1291368151": "How can you determine if a dataset is a view or not using the `Dataset.is_view` function?",
        "f0508d79-e4f9-460f-81b2-5f4fee2f7ab9": "Describe the functionality of the `Dataset.get_views` function and how it can be useful in managing datasets.",
        "dd49a550-e2ec-4707-9b0c-a9d18edc644b": "Explain the importance of specifying the format of the bounding box in the coords key in tensor meta information for correct display by the visualizer.",
        "6eea60e8-d08c-4042-9c1e-7cc92e80f908": "How can a 3D bbox tensor be created using the provided code snippet? Explain the optional arguments that can be included.",
        "e6b73174-f525-433b-be54-e31dbee00b01": "Describe the two different conventions for specifying the coordinates of a 3D bounding box using the \"mode\" key in the coords dictionary.",
        "969ddf7b-a54b-4cae-9bfc-102940210e7a": "Provide a detailed explanation of the \"center\" mode for specifying 3D bounding box coordinates, including the meaning of each parameter.",
        "3875a572-2885-4009-916d-a7f6c9ee4151": "How does the \"vertex\" mode differ from the \"center\" mode in terms of specifying 3D bounding box coordinates? Provide a detailed explanation.",
        "ded8fb72-0f7d-4ee9-b7e3-5a821e5d9a64": "What is the default data type for the 3D bbox tensor if the \"dtype\" argument is not specified?",
        "4a44d793-8492-43ed-99f4-0040dda1201e": "What is the purpose of the `org_id` parameter in the `deeplake` function?",
        "80f2c0e6-284c-4f67-a089-b0c2aad2726d": "When will a `LockException` be thrown in the `deeplake` function?",
        "8fe459e1-344f-463c-a621-a48d0dd4e126": "What is the danger associated with setting the `overwrite` parameter to `True` in the `deeplake` function?",
        "ad450899-3b12-4e46-bb52-e9f9deb7501e": "How can you create a new dataset by copying the structure of an existing dataset using the `deeplake` function?",
        "9b6cc3e9-ada7-4bf2-89b0-83408316bb1a": "What exceptions can be raised when using the `deeplake` function?",
        "8d909ea0-4809-48cb-bfc6-98cdecfb8262": "What is the default value for the scheduler parameter when rechunking a dataset?",
        "c174d987-4832-45d4-abd4-0b1dd5e794a1": "How can you rename a dataset to a new path using the `rename` method?",
        "4ed49504-6ca4-4f81-8890-a007fe01d00c": "What error will be raised if the `path` parameter in the `rename` method points to a different directory?",
        "32edc1f1-d052-4201-b404-3c5d1f47185b": "How can you rename a group within a dataset using the `rename_group` method?",
        "01744e35-fdb8-4404-811e-826b93ffd0db": "What errors may be raised when renaming a group within a dataset using the `rename_group` method?",
        "df3c2d19-8cd4-47fa-ad0e-5f51b363b247": "How can you rename a tensor within a dataset using the `rename_tensor` method?",
        "ba46bca2-80d4-47d7-ba89-a90345187942": "What error will be raised if the tensor being renamed does not exist in the dataset?",
        "9b0f55bf-6832-4f4e-9fdd-ca5714370530": "What is the return type of the `rename_tensor` method?",
        "336f79a1-c3d4-45ae-a361-88e7545a4bb8": "What is the purpose of the `progressbar` parameter in the context of the provided information?",
        "b0726c6d-1ad7-4817-ab9e-cb762a62e4e0": "How can you specify the scheduler to be used for rechunking a dataset other than the default value?",
        "6c82db69-d1c2-4695-9480-d39771a38e48": "What are the optional keywords that can be used with the `ORDER BY` statement to specify the ordering as ascending or descending?",
        "33408598-be14-4441-9689-953054e0a7ea": "How are `LIMIT` and `OFFSET` expressions used in TQL to limit the output of a query?",
        "34b08723-e42c-463a-8b58-2b370ac70a29": "Explain the types of values that can be used on the right side of a comparison operator in TQL.",
        "9f51fe0b-a1e6-4bd3-9f3b-ad11812a3440": "How does TQL handle string literals in comparisons for class labels, JSON, and text tensors?",
        "4ae81894-5967-45de-b9d4-a530518af32f": "Provide an example of how indexing can be used with multidimensional arrays or JSON in TQL expressions.",
        "54eeb8bb-1cb9-40be-9a30-53959e9708ab": "How can logical operators such as `AND`, `OR`, and `NOT` be used to combine boolean expressions in TQL?",
        "dde8b061-f87a-4389-b500-be16bb275dd5": "How can you store your credentials on the Activeloop Platform as Managed Credentials and use them for your dataset?",
        "437dc77c-d9f1-4c83-a7b4-e514de0111e2": "What is the purpose of adding managed credentials with names such as `\"my_s3_creds\"` and `\"my_gcs_creds\"` to your dataset?",
        "71ef0661-9cde-4009-bff4-b74d40e18f46": "How can you create a link tensor named \"img\" with sample compression set to \"jpg\"?",
        "bef46686-7290-4223-9ef0-3ea9f8e38178": "Provide examples of how you can populate the \"img\" tensor with links, including scenarios where credentials are required and where they are not.",
        "d6e5af3b-e4a0-4e4a-ab1b-6efd7f53b45f": "How can you access the data stored in the \"img\" tensor using a loop in Python?",
        "c89b67be-7f4e-44b4-a95b-c1053e5d2629": "How can you update a sample in the dataset by changing the link to a local path, such as \"./data/cat.jpeg\"?",
        "6bbecffc-37ba-460e-a017-6c833c85ce31": "How can audio samples be appended to tensors in Deep Lake?",
        "55175656-58b9-4833-9154-f1ee81fa386d": "What are the supported compressions for audio samples in Deep Lake?",
        "8198fab3-615f-4974-8108-ccfd305af27d": "How can a class label tensor be created in Deep Lake?",
        "9557d573-46b1-4656-90f8-cbeb92c75776": "What are the optional arguments that can be specified when creating a class label tensor in Deep Lake?",
        "27de9ab4-1ed6-440d-8331-8fd9e2e513ee": "How can the class names be set for a class label tensor after tensor creation in Deep Lake?",
        "5700dd0e-bb53-4b93-a4e4-4756fba54308": "What is the purpose of the `tiled()` method in the `deeplake` module, specifically in the `deeplake.api.tiled` sub-module?",
        "158bd160-fc1b-412e-8c4e-da70d5577701": "How can you handle a `TokenPermissionError` in the `deeplake` framework?",
        "a7b3aa8f-1b3c-46a5-b1c3-aa873e4356c0": "Explain the difference between the `train()` method in `deeplake.core.vectorstore.deep_memory.deep_memory.DeepMemory` and the `transform()` method in `deeplake.enterprise.DeepLakeDataLoader`.",
        "ea722eb9-5d01-4274-9e46-56e51be1e4aa": "When would you encounter an `UnableToReadFromUrlError` in the `deeplake` framework, and how can it be resolved?",
        "d3709a44-8ac9-4409-90a5-dd72481b35e9": "What is the significance of the `update_embedding()` method in the `deeplake.core.vectorstore.deeplake_vectorstore.VectorStore` class?",
        "c5aba064-250f-438c-bef6-154f5fbb2cc4": "Explain the process of training a deep memory model on the DeepMemory managed service.",
        "344cd961-07bc-454d-97b6-1d323e1ecf06": "How can a training job be canceled or deleted on the DeepMemory managed service?",
        "928ce060-1f20-4ed2-937a-c4b9bac8d6a6": "What information can be obtained using the `DeepMemory.status` property?",
        "e485ac9e-3dc9-4810-b1cf-7797aa0f43e1": "How can all training jobs on the DeepMemory managed service be listed using `DeepMemory.list_jobs`?",
        "afb9cf2c-a34a-4994-bfae-9aaed8272438": "Describe the steps involved in preprocessing the dataset before training a deep memory model.",
        "dba909a3-faef-4865-a34e-b843f9638fd1": "What are the supported values for the \"scheduler\" parameter in the function?",
        "58924f82-291f-49d7-aad8-5feba7a728c0": "What is the default value for the \"scheduler\" parameter if not specified?",
        "65d1428b-14bf-4fbb-8608-280bcdfd110e": "When is the \"progressbar\" parameter used in the function?",
        "03edcc8a-258a-47f1-befb-e62395124ae7": "What is the default value for the \"progressbar\" parameter?",
        "8cf01405-6d14-408a-906c-6e7e46c1befe": "What type of object does the function return?",
        "4c55e6bf-c44d-408f-abe1-88a98564470c": "What exception is raised if a view with a given ID does not exist?",
        "47531b0c-225d-45af-990e-b408defa5f17": "What does the log() function do?",
        "23d63e0a-4476-4d11-87f5-b0bdc7a78045": "What does the _max_len property return?",
        "368b18cb-7af7-46e5-a425-0a226a9b9839": "How does the _max_view property handle shorter tensors in the dataset?",
        "c9e3883c-93e4-4158-9050-cd4a51dfe858": "Can you provide an example of how the _max_view property works with a dataset containing images and labels?",
        "3f58a5f6-da4b-4feb-83be-124854fe6041": "What is the purpose of creating a keypoints_coco tensor in the given context?",
        "8a75146b-b8fd-4c6d-8833-7ddb1f966e0b": "How can you specify the keypoints and connections when creating a keypoints_coco tensor?",
        "043622cd-3306-43cc-b487-1f586492635b": "What are the supported compressions for the keypoints_coco tensor?",
        "387c76f6-8792-4672-bbd6-a38d51bcdbc7": "How can you update the keypoints and connections after creating a keypoints_coco tensor?",
        "c6616a00-15d8-4ec2-af1f-3d1268f6ca3b": "How can keypoints be appended to the keypoints_coco tensor?",
        "78cfcd68-4251-47d1-9803-9ade7e39ed0c": "What is the difference between `deeplake.copy` and `deeplake.deepcopy` in terms of copying datasets?",
        "310fef52-cd23-409c-be2d-36900c190237": "How can you append samples to multiple tensors at once in a dataset?",
        "ec0a4584-e226-4f32-bddf-8d10d0a229a2": "Explain the purpose of the `Dataset.delete` operation.",
        "43d89598-1d03-4389-9f8f-e259987d6655": "How can you estimate the size of a dataset in bytes using Deep Lake?",
        "e222e9cf-0a46-44a4-9275-6fd1da4d8f5f": "Describe the process of visualizing a dataset in a Jupyter notebook using Deep Lake.",
        "a032d2bd-62c1-4bba-94e1-baddd6879f84": "What is the purpose of sample compression when creating tensors, and how does it work in the context of provided data formats?",
        "118c1b62-0e3b-45fb-9186-cdfd43a7fc53": "Can you explain the difference between sample compression and chunk compression when creating tensors, and provide examples of each?",
        "931f954d-b77a-4d4d-86b4-6b4403592b12": "Why is chunk-wise compression not supported for certain data types like audio, video, and point cloud in the context of creating tensors?",
        "eb6e62a6-4938-4a6d-94df-606c833692d8": "How does the process of chunk compression work when adding samples to tensors, and what happens if the data is already compressed?",
        "b8219f42-94ef-4b42-8009-2554cdc6a812": "How can you specify the compression format for samples and chunks when creating tensors, and what are the implications of leaving the compression format as \"None\"?",
        "1b282bee-09a3-470e-a6bf-1bb74dcc73cd": "Explain the key concepts mentioned in the context, such as Datasets, Vector Store, Tensors, Htypes, Compressions, PyTorch and Tensorflow Support, and Utility Functions.",
        "aa1b78ec-cbe7-4c6a-9ed6-4242eb228b20": "How does the deeplake package store data, and what are the advantages of storing data as compressed chunked arrays for deep learning models?",
        "ea67d5bf-6cc5-464a-a3a9-95086b014e45": "Describe the API reference for the deeplake package, including functions like `dataset()`, `ingest_classification()`, `load()`, `delete()`, and `compute()`.",
        "155b3cfd-89f7-43f1-872b-83bbff7d9042": "What are some of the high-performance features of the deeplake package, such as Dataloader, Sampler, Tensor Query Language, Random Split, and Deep Memory? How do these features enhance the functionality of the package?",
        "3b3d87ef-f3e5-4b85-bc4d-f97d9efceee8": "How does the deeplake package integrate with external tools like Weights and Biases and MMDetection? What benefits do these integrations provide for users working with deep learning models?",
        "d31f4512-de8d-40a3-b456-8fbe61f57ac2": "What is the difference between `deeplake.copy` and `deeplake.deepcopy` in terms of copying datasets?",
        "740bde56-3e5b-4d83-8a7f-f2b646847ec3": "How can you append samples to multiple tensors at once in a dataset?",
        "0445814f-5813-4dab-8fea-3a6070183cca": "Explain the purpose of the `Dataset.delete` operation.",
        "d084389c-a7dd-47c4-a6ee-dc7ab36ff89b": "How can you estimate the size of a dataset in bytes using Deep Lake?",
        "001d6cd2-077f-4d39-a565-53afa868114c": "Describe the process of splitting a dataset into non-overlapping `Dataset` objects using `Dataset.random_split`.",
        "02c10f41-8e6c-48e2-82c7-021269976334": "Explain how to play a video in a Jupyter notebook using the deeplake library. Provide an example code snippet.",
        "f8749da6-1f61-420f-9300-2ecf072af679": "Why is video streaming not supported on colab when using the deeplake library?",
        "669cb74b-c2f7-4e66-9e89-d4d7d60cd16a": "How can you remove an element at a specific index or indices in a dataset using the pop() method?",
        "da147586-b7a9-45c3-a5f1-629d23968689": "What information does the _sample_indices property return in the deeplake library?",
        "9b21f2e1-d5a7-47a1-8822-c814da3f8bc4": "Provide an example of the type of information that can be retrieved using the _sample_info property for a video sample and an image sample in the deeplake library.",
        "622662de-7c18-41e1-87ff-98a180feb524": "How can you determine the shape of a tensor in the deeplake library?",
        "d1325d15-d5cd-4ce9-827f-d71e81b16994": "What is the difference between the `InvalidShapeIntervalError` and the `InvalidKeyTypeError` in the context of the `DynamicTensorNumpyError`?",
        "cdaebb7d-399a-450d-8be5-d43b61dc97f2": "How would you handle a `ProviderListEmptyError` in a dynamic tensor numpy operation?",
        "66d502cf-f6b0-44ee-a7da-8ce5fcea1765": "Explain the potential consequences of encountering a `ServerException` during a data processing task.",
        "9264315f-e4c7-44dd-a23d-9c6fefdd1213": "How would you address an `AuthenticationException` when trying to access a secure dataset?",
        "ba8c936e-239f-49f7-b931-505ee5ed8976": "Can you differentiate between the `S3GetError` and the `S3SetError` in the context of working with S3 storage in dynamic tensor numpy operations?",
        "701fa49d-70b2-41fc-961f-d6a4714b0de3": "What method should be used to save a view in a Dataset object?",
        "9ca70551-2dfd-4408-8cbd-80fd83dc4c09": "How can you retrieve a saved view in a Dataset object?",
        "6679da68-b74e-4ea9-bac1-746e3217cd76": "What exception is raised if a view with a specific ID does not exist in a Dataset object?",
        "3caf5dea-6475-4f36-8013-a994587cce7d": "How can you retrieve a list of views stored in a Dataset object?",
        "433b9bf8-3713-4f12-8016-c5521a4dd711": "What property indicates whether a Dataset object has uncommitted changes at the head node?",
        "90332c21-da77-4bed-bf05-c8d5979c23e2": "How can you load a specific view in a Dataset object by its ID?",
        "864acd33-4b99-4c00-b61c-5afe0bf48b26": "What parameter can be set to optimize the loading of a dataset view in terms of copying and rechunking data?",
        "2a198a7b-ac11-452a-9423-4714cfb5bea1": "What property indicates whether a Dataset object is a view or not?",
        "2255bb88-87e9-4217-9cd6-90c00fd6f9c2": "What is the hierarchy of errors mentioned in the context information, starting from the most general to the most specific?",
        "7542e4b3-0456-4e4d-b9bd-9d8411d5c3f0": "Can you provide an example of a specific error mentioned in the context information related to credentials?",
        "12c7208c-c5e5-49f3-8936-e048a4d8b75a": "What type of error is `OutOfSampleCountError` and what does it indicate?",
        "04c4e6bb-aa99-4ce9-bc5a-c25707600887": "How is the error `InvalidTokenException` different from `TokenPermissionError`?",
        "b301b496-dd77-43d5-82cf-39d133a5be1f": "Explain the significance of the revision `ccc63099` mentioned in the context information.",
        "43d14205-d74b-49dd-a512-b3accf35c699": "How can you set the `connections` attribute in `tensor.info.keypoints`?",
        "5624fec1-dd86-458e-a367-8fdd97dd23d6": "What is the default data type for `dtype` in `tensor.info.keypoints`?",
        "ed1f1590-bde6-44e0-811f-caf53ac09938": "How can you append keypoints to a sample in the dataset?",
        "59e1faeb-786f-4286-adbf-017be6b033b5": "Why is it important for all objects in every sample to have the same number of keypoints in the same order?",
        "56c11e75-efbc-4914-9a64-1287d459aa9b": "How can you prevent keypoints from being drawn in the visualizer if they are not present in an image?",
        "f2f87db1-4d74-44b9-8670-59a7d3900737": "What are the different types of paths that can be used as the destination for the dataset?",
        "86ca5e3e-89c7-4652-aaf7-facb7f38e0a8": "How can credentials be provided to access the source data?",
        "1e6b6fba-58c5-4f96-8f15-6a25efdd5100": "What is the purpose of the `creds_key` parameter in the function?",
        "877bb5bd-4927-48fb-bbd9-8119c9802b0e": "How can you enable or disable the ingestion progress bar?",
        "7532513a-391d-461f-b7bb-58d2151ea77b": "What is the significance of the `token` parameter in the function?",
        "0e8dfdde-e12a-4902-bdcb-3b8af798fe05": "How can additional arguments be passed to the dataset creator function?",
        "872d006b-389c-4922-b64c-e10eba331afe": "What is the default value for the `shuffle` parameter in the `DeepLakeDataLoader` object?",
        "1f8e147c-b74a-4675-8fbf-61554bccf0ce": "What will happen if the `shuffle()` method is called more than once?",
        "79aea006-39c6-4509-96d6-a55222379e97": "What is the purpose of the `collate_fn` parameter in the `tensorflow` function?",
        "1d41ae8e-3463-4f15-ae0e-e5bc20b5a67e": "How does the `persistent_workers` parameter affect the behavior of the data loader in the `tensorflow` function?",
        "20f6da26-d2cd-48c1-a3c2-9dbb32380127": "Explain the significance of the `return_index` parameter in the `DeepLakeDataLoader` object.",
        "6b752bbd-1ce0-4760-b1a3-0a0e20145552": "How does the `create_shape_tensor` parameter impact the reading of sample shapes in a dataset?",
        "998ffc23-465e-4e6c-b154-79d43faac252": "What are the exceptions to the rule that no data is loaded until a sample is read from a dataset?",
        "0b55522f-615e-468f-ab30-38ad5fba9d01": "How can credentials be added to a dataset for authentication purposes?",
        "9387686d-cf16-4b30-a9c7-a8873cc63005": "What is the benefit of storing credentials as Managed Credentials on the Activeloop Platform for datasets?",
        "53061e96-11e6-4a76-a065-b9a39f0dae73": "How can one avoid the need to repopulate credentials on every dataset reload?",
        "92d8c39c-61dd-4413-ab19-5da50710a4c2": "What are the two options for setting the `tensor.info.class_names` list?",
        "28709a2e-6e4e-4d49-afbf-5ffeb3cac9eb": "How can you update the class names after tensor creation?",
        "be4e4ffb-58c8-4621-9430-273829354ce6": "Why is `chunk_compression` recommended when the number of labels in one sample is low?",
        "9ec06de7-6f76-4817-afd6-2abc80c05176": "How can class labels be appended to a dataset?",
        "4a2e1762-db8c-49eb-922b-4930b00a282d": "What are the different types of data formats that can be used to append class labels?",
        "156aca8d-d051-4739-8ff8-b7ce9bd6e668": "How can a tag tensor be created in a dataset?",
        "9208d038-2c34-4b77-8b98-80dce2910b3a": "What is the purpose of the `tag` htype in the context of sample tagging?",
        "2449664c-07f6-428c-aadc-fa2ec9f94e42": "What are the supported compressions for `chunk_compression` when creating a tag tensor?",
        "89ac4124-a5df-410e-89a0-e0302f595d74": "How can tag samples be appended to a dataset?",
        "2d22702a-ffe7-4960-8c1e-f3a0be254a33": "In what scenarios would using the `tag` htype be beneficial for organizing data samples?",
        "82950b5f-1eb7-44b8-9b32-cb4715bb2377": "What are some key concepts related to Deep Lake, as mentioned in the context information? Provide a brief explanation of each concept.",
        "83bd7e39-1486-4e6c-8a66-e7279d62b52c": "How does Deep Lake support PyTorch and Tensorflow? Explain the significance of this support in the context of AI development.",
        "bc23a854-4dc8-48a1-8d53-3759e87c0400": "What integrations does Deep Lake have with external tools or platforms? Discuss the importance of these integrations in enhancing the functionality of Deep Lake.",
        "672681eb-57fc-4ab7-a763-4e3c0ad74e29": "Explain the purpose and functionality of the Dataloader and Sampler features in Deep Lake's high-performance features.",
        "4053edbe-61c9-4f7d-98c1-e324676e728f": "How does Deep Lake utilize the Tensor Query Language, and what advantages does it offer for users working with datasets in the database?",
        "50678bdc-d69b-4549-a589-454aaba034f9": "How can you store your credentials on the Activeloop Platform for datasets?",
        "f453ecc3-6a6c-48b3-944b-7d71b6d07b8e": "What is the purpose of using managed credentials in the context of the Activeloop Platform?",
        "b692f250-5fba-48ac-b043-e4303d50159e": "How can you add managed credentials to a dataset using `Dataset.add_creds_key`?",
        "c373c063-8b6e-496a-9f62-d0675cfa7c8d": "What is the function of `ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")` in the context of the document?",
        "861bda92-45e9-4a61-8b89-564c350c854a": "Explain the significance of using `deeplake.link` when populating the tensor with links in the dataset.",
        "37a636cd-875d-43f9-a31d-99de3205a7a6": "Why does the statement `ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))` throw an exception according to the context information provided?",
        "be6684dc-c0ca-4cbe-8394-df9488d028a6": "How can you access the data stored in the `img` tensor in the dataset?",
        "883c348c-443c-425d-bd8f-2998337cbf51": "In what scenario would you use `ds.img[0] = deeplake.link(\"./data/cat.jpeg\")` to update a sample in the dataset?",
        "e623c347-a89a-4bf8-91a0-0973bd25c379": "Explain the process of creating a new tensor in a dataset using the `Dataset.create_tensor` function. What are the key steps involved in this process?",
        "f7866bb3-4a59-49cd-8e88-942df3629b2b": "How can you delete a tensor from a dataset using the `Dataset.delete_tensor` function? Provide a step-by-step explanation of how this operation is carried out.",
        "45212671-198d-4bc9-82ff-7b8c32fcb628": "Describe the functionality of the `Tensor.append` method in the context of adding samples to a tensor. How does this method differ from the `Tensor.extend` method?",
        "fe29701d-e991-4449-91e1-7d80d9deee8f": "What is the significance of the `Dataset.create_group` function in the context of managing tensors within a dataset? How does it contribute to organizing and structuring data effectively?",
        "f33ba942-d722-4853-aab5-6e157ad0f340": "Discuss the role of the `Dataset.rename_tensor` function in the process of managing tensors. How does this function help in maintaining data integrity and clarity within a dataset?",
        "58d8581d-ec4f-41d2-825f-fc1bddec60da": "How can keypoints that are not present in an image be stored in a dataset?",
        "9ce5db4f-4da1-4328-a4a7-5bf46aaaa585": "What are the sample dimensions for points in a 2-D coordinate system?",
        "5c19c462-cc07-4cd2-a8ce-430047bfc39d": "How can a point tensor be created in a dataset using Python code?",
        "ec5864aa-c3ee-4c5a-9f70-ef5838c84772": "Can you provide an example of appending 2 2-D points to a dataset?",
        "cde97804-b5cb-4919-9dac-f71ad1416c71": "What are the sample dimensions for polygons in a dataset with the polygon Htype?",
        "5b433956-3792-4e35-babb-6d3e2f996dd0": "What is the requirement for all points in a sample in a tensor of polygon Htype?",
        "f18bdf30-3823-4c0a-a0eb-b735fa99c3c1": "Can different samples in a dataset with the polygon Htype have a different number of polygons?",
        "1b4ccc1b-1804-4c2a-a34f-bca0dd1061f0": "How can you append 2 3-D points to a dataset using Python code?",
        "7c0988c3-ed34-4564-af59-48d5ed509cc4": "What is the purpose of using dummy coordinates for keypoints that are not present in an image?",
        "0fde868f-8feb-4c56-b6c3-694e9ae325ff": "How can a mapping between point order and real-world objects be achieved in a dataset with the point Htype?",
        "bb3296b3-1105-48fb-87a8-10369da34d8d": "Explain the difference between directly uploading embeddings and uploading embeddings via an embedding function in the context of the deeplake_vector_store.",
        "f652f2cd-1005-42f2-9d79-bf703719caa7": "How can user-defined embedding tensors be utilized when uploading embeddings using multiple embedding functions in the deeplake_vector_store?",
        "d3182e60-9d26-4763-85fe-043b241b34c8": "Describe the purpose of the metadata parameter in the deeplake_vector_store add function.",
        "3072f23b-964a-4f2c-8881-988571878a59": "How does the deeplake_vector_store handle cases where the data for each tensor is not of equal length?",
        "e592d443-09a2-4880-8f93-cfcbe24a787c": "Discuss the significance of specifying tensor names as parameters when adding data to the deeplake_vector_store.",
        "ec9ee05a-8d35-428f-a973-9b7a29b649bc": "What are some of the key features and functionalities of Deep Lake as described in the provided context?",
        "f6dc9238-3bc0-403a-8a5f-4db3b7cf8c77": "How does Deep Lake simplify the deployment of enterprise-grade LLM-based products?",
        "b3d1e75d-5b3a-405b-b8b8-49d95f1b67b2": "Can you list some of the popular tools that Deep Lake integrates with, as mentioned in the document?",
        "99b0d091-a228-4f1f-a687-11df8b04942c": "What types of data can be stored in Deep Lake while building LLM applications?",
        "4b64dfbe-a089-4875-aef8-0ed5984c8aa7": "Which organizations or institutions are mentioned as users of Deep Lake in the context information?",
        "767cf447-363a-4aff-8cda-a346dbefa626": "Explain the process of creating a Deep Lake Vector Store using the `VectorStore.__init__` method. What does this method do and what are its parameters?",
        "212d9a36-2488-4223-a984-5f52b0039d7d": "How can you set the `connections` and `sample_compression` for `tensor.info.keypoints`?",
        "3f898c8b-bcdc-4291-ae79-55c754c83491": "What is the default data type for `dtype` in `tensor.info.keypoints`?",
        "2ff061a1-ff5d-49a6-b9fa-7797601e8d57": "How can you append keypoints to a sample with 3 keypoints and 4 objects?",
        "b0d3f707-dede-4b8b-84df-64a23305c31e": "Why is it important for all objects in every sample to have the same number of keypoints in the same order when using the keypoints and connections metadata?",
        "9bf94eff-d5a6-4d86-b981-3006187bfae3": "How can you update the keypoints and connections after tensor creation for `tensor.info.keypoints`?",
        "1edf5c42-8f40-49b3-bec2-580afdc5c111": "Explain the importance of compressing segmentation masks using `lz4` and why it is recommended for masks containing large amounts of data.",
        "565997c3-db25-42ec-a75f-b7204d77af1c": "How can binary masks be appended in the dataset using `np.ndarray`? Provide an example of appending a binary mask with 5 objects along with their corresponding labels.",
        "729621cb-ae11-4167-8f1e-04bb2fb132e3": "What are COCO keypoints and how are they represented in a tensor? Explain the structure of a set of `K` keypoints of an object in terms of coordinates and visibility values.",
        "9d88c082-5856-4558-9555-aaac813da07d": "How can a keypoints_coco tensor be created in the dataset? What are the optional arguments that can be specified during the creation of this tensor?",
        "0a15ed39-181e-4c6d-aac0-bf2c6e6459fc": "Discuss the significance of setting `keypoints` and `connections` in a keypoints_coco tensor. How can these attributes be modified after the tensor creation?",
        "101da9e6-89bd-47fd-9e8e-de767a596678": "What method can be used to return the bytes of a tensor?",
        "f8ba30bb-5fae-4583-95f9-7b228ac48001": "How can you access the text data of a tensor?",
        "23d29ad4-fd2f-4334-9e20-36d46bdd274f": "What property of a tensor returns the number of dimensions it has?",
        "cc12ed83-1d4a-4e75-a86b-dd8ccd04af86": "How can you play a video sample stored in a tensor?",
        "f84bbcfa-0d8b-4063-ada2-e121425d8b2e": "What does the `Tensor.is_dynamic` property indicate about a tensor?",
        "ac094b91-9c61-4c1c-803f-df285cfa2ed0": "What is the common syntax for a `SELECT` statement in TQL?",
        "5f884daa-4454-4432-aff1-77bb0e573725": "How is the `FROM` expression used in a TQL query, and what effect does it have on the query?",
        "6f58f2a4-fce9-4e62-9496-19778e2b3b48": "Explain the purpose of the `WHERE` expression in a TQL query and provide an example of a condition that can be used for filtering.",
        "95cff3c1-b516-4675-a9aa-ebe16f6f3307": "How does the `ORDER BY` expression work in a TQL query, and what criteria can be used for ordering the output?",
        "b148460c-4aad-4988-826d-33484b051273": "What are the optional keywords that can be used with the `ORDER BY` statement to specify the ordering direction?",
        "697109f1-1d28-4883-8f14-211793c04e96": "Describe the use of `LIMIT` and `OFFSET` expressions in a TQL query and how they can be used to limit the output.",
        "57d22776-5f7c-4ee4-95fd-ea1de018bd3f": "What types of comparison operators are supported in TQL, and what are the requirements for the left and right sides of the comparison?",
        "cf841bf9-4235-4acb-9c1e-444e7d5a614d": "How are string literals represented in TQL queries, and in what contexts can they be used for comparison?",
        "94c2a818-c291-4381-bc33-9af245f5c9bd": "Explain how TQL handles comparisons for class labels, JSON objects, and text tensors in queries.",
        "2315ef3f-240d-4241-91ec-270ffa897c0e": "Can you provide an example of a TQL query that includes a `SELECT` statement with `WHERE`, `ORDER BY`, `LIMIT`, and `OFFSET` clauses?",
        "8d9a2420-8d87-467e-92f9-ef90a290ec5e": "What is the purpose of the `token` parameter in the `deeplake.connect` function?",
        "421e05b9-7b78-41fd-a5c9-b4f9b8db6b3d": "What are the supported values for the `scheduler` parameter in the `deeplake.connect` function?",
        "638c287e-425e-4e65-8884-80d79b9479f5": "When will a progress bar be displayed during dataset copying?",
        "e5a11f69-5297-4b7a-8416-4865c4104ef4": "What is the default value for the `public` parameter in the `deeplake.connect` function?",
        "a5d7b7ee-c61b-46fe-9546-4599b08bcebe": "What error will be raised if a dataset already exists at the destination path and overwrite is set to False?",
        "f745b0cb-cd36-4c61-b465-7f3407675f66": "How can you store your credentials on the Activeloop Platform for datasets?",
        "6434292f-5f9b-4cbe-a369-973edacc104f": "What is the purpose of using managed credentials in the context of adding keys to a dataset?",
        "597dac53-84e3-4c8f-a275-c21731e5f0d5": "How can you create a link tensor in the dataset?",
        "66496750-a808-4d6d-878d-7e9a9080c9d8": "Provide examples of different ways to populate the \"img\" tensor with links in the dataset.",
        "2090c8a1-4ace-4b6d-8b20-3f462fd7468b": "Why does a link with a cloud path always require a \"creds_key\" in the dataset?",
        "4d912e0c-d16e-422b-9a93-6edac4a8649e": "How can you access the data stored in the \"img\" tensor in the dataset?",
        "3da44855-0d8b-4e3c-bcf1-c79bae9e2713": "How can you update a sample in the \"img\" tensor of the dataset?",
        "9802754e-e1c4-431b-aa8e-c8b7675fdc28": "What is the return type of the `shapes()` method in the provided context information?",
        "5e603d07-1277-4edc-a73e-5eb4a3a63b88": "How can you obtain the timestamps for video samples in the tensor?",
        "4fab5d04-7f3a-49fc-b91c-0dd83284eafb": "What does the `tobytes()` method return and under what conditions does it work?",
        "c9238ede-58ef-41c5-add3-ea0b0b79640c": "When would the `_verify` property be applicable, and what does it determine for tensors with a specific `htype`?",
        "60df18ec-1ff4-49b1-b4bf-5d2e54c55091": "Explain the concept of a dataset view and how it is created in Deeplake. Provide an example using the provided code snippet.",
        "525addc7-7f1d-466d-988f-430e404b7e8a": "What are the different methods available in Deeplake to create a dataset view? Provide a brief explanation of each method.",
        "4591b1d8-5d5f-4fa9-a3bf-2dddaf08a14f": "When can a dataset view be saved in Deeplake? Why is it important for the dataset to be committed and have no changes on the HEAD node before saving a view?",
        "9aa86ca0-6d2c-4c6a-832c-90e3e63bc51c": "How can you retrieve a dataset view in Deeplake using the `load_view` method? Provide an example using the given code snippet.",
        "7bf26939-1884-4bdb-a6e5-adef8a7d1352": "Discuss the significance of preserving data lineage when saving a dataset view as a virtual dataset (VDS) in Deeplake. How does this help in maintaining the integrity of the underlying data?",
        "88ddf8e3-9091-476f-bc79-d0ebf5ebee12": "How can keypoints that are not present in an image be stored in a dataset?",
        "2b88c05f-7bad-4250-abe2-b9d1a1251f50": "What are the sample dimensions for points in a 2-D coordinate system?",
        "9fdcab16-5bbe-493f-9a30-043f67a97782": "How can a point tensor be created in a dataset?",
        "4654e57a-957a-41b2-9a7a-bf11194ac224": "What is the purpose of the visibility parameter in storing keypoints with dummy coordinates?",
        "dac43fea-8184-48e1-a788-7312d43689fe": "Can you mix 2-D points with 3-D points in a sample of the polygon htype?",
        "872bd5dd-37f8-49c3-88a5-924d034be8a5": "Explain the importance of specifying the format of the bounding box in the coords key for correct display by the visualizer.",
        "afeafcbb-bc1c-4f9d-87c6-89b6310b55d7": "How can a 3D bbox tensor be created using the provided code snippet?",
        "f45e881e-1e30-4493-8e68-ca7c50df5ac2": "Describe the different modes available for specifying the convention for the bbox coordinates.",
        "e9ef14c9-ff5c-4b74-925b-afecbe2c71b5": "What are the dimensions of the sample data when using the \"center\" mode for bbox coordinates?",
        "f42324fe-8ca0-4fe1-8583-78a2ea3815cf": "Can you explain the vertex order for the \"vertex\" mode of bbox coordinates?",
        "6eea5537-a513-4b20-8d2f-0a1406b228fe": "Explain the purpose and functionality of the LRUCache method in the deeplake.core.storage module.",
        "474fa4cb-c39a-43a0-9930-8e374c1f59e0": "How does the __init__() method in the deeplake.core.index.Index class relate to other methods within the deeplake package?",
        "196a00ae-3a62-4614-baed-2169d90cd659": "What is the significance of the __iter__() method in the deeplake.core.storage module, and how does it differ from the __len__() method?",
        "804dd724-576d-404e-9563-742ff7f60621": "Discuss the role of the __repr__() method in the deeplake.core.index module and its importance in the context of the document.",
        "2bf46a27-48c1-4e6a-9a45-02ac161aa656": "What is the default mode datasets stored on Deep Lake cloud will open in if your account does not have write access?",
        "19ade416-f4e7-4a5c-8093-f497727135a1": "What are the two cache sizes that can be specified in the configuration?",
        "01f66021-7dae-42e0-baa2-b271d685e7fd": "How can credentials be provided to access datasets at a specific path?",
        "03c60f94-5f30-4767-a31b-a74344b8a8f0": "When would specifying 'ENV' as the credentials option be useful?",
        "4efb6f8b-0d2c-486e-964c-90347d65ad60": "What is the purpose of the Activeloop token in the configuration?",
        "9d781ffd-636b-4af1-a5d8-de3502ce61c5": "What is the organization id used for in the configuration?",
        "7060d5e5-377e-4af3-b543-f2f19aca4ba2": "What does the 'verbose' parameter control in the configuration?",
        "77c2f0f9-51df-4c9d-813b-572e0e42151f": "What are the two access methods that can be used for the dataset, and what is the default method?",
        "e38c84dd-f273-435a-8493-23dd342e4244": "How does the 'download' access method differ from the 'stream' access method?",
        "fcb21122-93aa-41c4-abd6-fd5b80deb20d": "How can the 'download' access method impact the local filesystem?",
        "9bc6c867-b9c7-4bea-b65a-64534ca203cc": "Explain the components of the camera intrinsic matrix \\\\(K\\\\) and their significance in computer vision applications.",
        "8b01b8fb-62b7-40b7-8ec1-70a1b1f37b47": "How can an intrinsics tensor be created in a dataset using Python code?",
        "61e14e22-e523-4afc-9352-a73571d91936": "Describe the purpose of segmentation masks in computer vision and how they are represented in a dataset.",
        "00e31414-03bf-43db-bfd4-52aa1d1940e5": "Provide an example of creating a segment_mask tensor with specific class names and compression settings in a dataset using Python code.",
        "a886f232-9c15-45dc-a86f-6ebbfeb0f512": "What are the optional arguments that can be specified when creating a segment_mask tensor in a dataset?",
        "4b64ea22-0d9e-4c0b-82b1-9924a7f05816": "What is the default markup language used by Sphinx for documentation, and what other markup language can be read via third-party extensions?",
        "ec38210f-1517-422d-913e-501646dfb6e5": "How can themes be used in Sphinx to modify the look and feel of outputs?",
        "a373a9cf-9d59-4319-9ca3-8ae005a45511": "What are some of the basic steps involved in getting started with Sphinx, as outlined in the documentation?",
        "68cdc002-fd1c-49dd-98c0-b6d2033cb12f": "How can Sphinx be installed on different operating systems, and what are the various installation methods available?",
        "24aaf88e-d8db-47c2-bc1f-fc71767904a3": "What are some of the topics covered in the Tutorial section of the Sphinx documentation, and what is the purpose of each topic?",
        "f0183136-58bf-49ce-b116-baed58701bb4": "What are User Guides in Sphinx, and how do they differ from the Get Started section?",
        "01a2800a-bfba-41a3-a35b-8c2d1e63936b": "How does Sphinx build upon Docutils to parse and write documents, and what is the significance of this functionality in documentation workflows?",
        "6310b9c5-1c10-4c69-9dfd-e91b4f208671": "How can third-party extensions be used to enhance the functionality of Sphinx, and what are some examples of contributed extensions mentioned in the context information?",
        "c220933d-13ab-4388-82c0-44cfe6222755": "What is the purpose of the Sphinx documentation Table of Contents, and how can it help users navigate the Sphinx documentation?",
        "f99e59ed-f135-4f56-a30a-902bb45ad921": "Why is it recommended for new users to start with the Get Started section before exploring the User Guides in Sphinx?",
        "d144f0bd-b903-42ed-9b32-316279636cf1": "Explain the key concepts of Datasets, Vector Store, Tensors, Htypes, Compressions, PyTorch and Tensorflow Support, and Utility Functions in the Deep Lake framework.",
        "ff2ac809-3fc9-452a-81b1-2a9dc2504b86": "How does the Dataloader in Deep Lake contribute to high-performance data processing?",
        "815e5b31-8faa-4fac-b112-2b0f4d9281da": "Describe the API references for deeplake.VectorStore and deeplake.core.dataset in the Deep Lake framework.",
        "358051db-c9db-4a03-a2af-4298e4cb3f1f": "How does the Deep Memory feature in Deep Lake enhance the handling of large datasets?",
        "f93b6a50-e4d6-4609-8f85-f7b842ff0b5d": "Discuss the integrations with Weights and Biases and MMDetection in the Deep Lake framework.",
        "ac1aba0e-68c7-41cf-a7d3-b0d2a0f2e00e": "Explain the key concepts mentioned in the document, such as Datasets, Vector Store, Tensors, Htypes, Compressions, PyTorch and Tensorflow Support, and Utility Functions.",
        "190f5672-a8a4-41a0-9ecc-f0bee149af53": "How can you create dataloaders from datasets using the `dataloader` method mentioned in the document?",
        "3f6d09c3-118d-4b57-a8e9-88d9f9e32e71": "Describe the `DeepLakeDataLoader` class and its methods like `batch()`, `close()`, `numpy()`, `offset()`, `pytorch()`, `query()`, `sample_by()`, `shuffle()`, `tensorflow()`, and `transform()`.",
        "79a4f305-a749-4411-bb24-1a3fae168127": "What is the purpose of the `batch()` method in the `DeepLakeDataLoader` class and what parameters does it take?",
        "90184223-99d5-47f2-a4cb-1b1da0443b39": "Explain the significance of the `Deep Memory` feature mentioned in the document and how it can be utilized in training models.",
        "90a1341f-f448-4d46-8fa0-e01295460093": "Explain the purpose of adding a creds key to a dataset in Deep Lake. How does the parameter 'managed' affect this process?",
        "70b5c86c-e41c-401c-ac71-e83969bbf99e": "How can you connect a Deep Lake cloud dataset through a deeplake path using the `connect` method? Provide an example scenario and explain the parameters involved in the process.",
        "345773f9-cdcb-42a2-ba39-3367480d64bd": "What is the significance of the `_client` property in the dataset class? How can it be utilized in the context of working with external data in Deep Lake?",
        "1babeca6-3367-4162-9827-01add4cf5571": "What is the purpose of the `ingest_kaggle` function in the given context?",
        "67d8087a-b2fb-45c9-96f2-bbc7ed69dd54": "What is the significance of the `tag` parameter in the `ingest_kaggle` function?",
        "c7a03e98-70e4-44f9-842b-6a6d700b303b": "Explain the different types of paths that can be used for the `dest` parameter in the `ingest_kaggle` function.",
        "66c09305-c090-432b-ae10-fa85320aa83a": "When would an `IngestionError` be raised in the `ingest_kaggle` function?",
        "8819292c-b1cc-4126-89ca-2c486594efa4": "How does the `ingest_kaggle` function handle downloading and storing Kaggle datasets?",
        "f7080800-58c2-4c77-b045-c2db47512195": "What parameters are required when initializing the DeepMemory class?",
        "f529e63e-952b-4277-a35b-963a1659d72e": "How can you cancel a training job on the DeepMemory managed service?",
        "40b9754c-d817-40b0-9ebb-7b0c5fd1e63b": "Explain the purpose of the `evaluate` method in the DeepMemory class.",
        "ac78b0f4-17cb-4614-a0de-f8201d0018be": "What is the role of the `embedding_function` parameter in the DeepMemory class?",
        "2c738081-49a8-4f60-9722-2f000aa87161": "How can you delete a training job on the DeepMemory managed service?",
        "106baefb-71b3-43e8-9560-f243619c56ec": "How can you set the `tensor.info.keypoints` list after tensor creation?",
        "a871562b-625a-4762-8106-27e6be83baa5": "What are the supported compressions for `sample_compression` or `chunk_compression`?",
        "2ab0d73f-d6d4-4db6-8fc6-666f5e074920": "How can you append keypoints as `np.ndarray` or `list` in the dataset?",
        "f05a548f-cec2-43b9-b7d7-201faac876ed": "Why is it important for all objects in every sample to have the same number of keypoints in the same order?",
        "82421864-4481-410f-8771-f95d918196b6": "How can you prevent keypoints that are not present in an image from being drawn in the visualizer?",
        "52803b18-0a12-4385-aeea-e401f0dc1370": "How can bounding boxes be appended in the dataset as `np.ndarrays` or `list` or `lists of arrays`?",
        "662f1773-e6c1-4be5-b323-dfb10671f1f0": "What is the required format for 3D bounding boxes to be correctly displayed by the visualizer?",
        "b20e055f-67d0-43f4-ac76-edfe6107bdd1": "How can a 3D bbox tensor be created in the dataset?",
        "0242f331-2f08-4761-b1ce-a4551cb00e1d": "What key must be specified in the coords key in tensor meta information for 3D bounding boxes to be correctly displayed?",
        "074fcf21-f100-44aa-80bf-75ada2616be2": "Why is it important for the intrinsics tensor to exist in the dataset or for the intrinsics matrix to be specified in the `ds.img_tensor.info` dictionary when projecting 3D bounding boxes onto 2D data?",
        "bfda9b59-eb54-456e-a017-8d60db69cc9a": "Explain the purpose of the `sequence` htype in the ActiveLoop framework and provide an example of how it can be used with a dataset.",
        "e729caa7-dbab-4940-a57a-bfb5359a7699": "How does the `link` htype differ from other htypes in ActiveLoop, and what is its main function in relation to external data?",
        "59d318d7-a0a0-4de0-92a9-0f776ac1509d": "Can you provide an example of how the `link` htype can be used with different variations, such as `link[image]`, `link[video]`, and `link[audio]`?",
        "125a3f6d-f9b0-4bfe-8068-9ed108c47eee": "What are the exceptions to the rule that no data is loaded until a sample is read from a dataset when using the `link` htype in ActiveLoop?",
        "050c54fb-0446-4aea-9e84-6cc164ac2b6c": "How can the `create_shape_tensor` and `create_sample_info_tensor` parameters impact the behavior of the `link` htype when adding it to a dataset in ActiveLoop?",
        "253e4e46-b29d-4edd-83e0-f614736fa2bb": "What are the different types of paths that can be used in the `src_path` parameter of the function?",
        "d139b373-6c79-4e69-835b-6dcf631e1c3f": "What is the purpose of the `creds_key` parameter in the function?",
        "6a861452-5ca1-4f97-8448-44f29aaa047d": "Explain the significance of the `dest_path` parameter in the function.",
        "bd369f89-b9a4-4042-b04d-af7693b02efe": "How is the name of the connected Deep Lake dataset determined if the `ds_name` parameter is not provided?",
        "2e07245e-2031-426f-968c-8099b0df5348": "What is the role of the `token` parameter in the function?",
        "af9fd01e-2ea3-46db-84f3-ec23843aa0f5": "What is the expected return type of the function?",
        "911e42d3-b278-41ac-817f-55ad7df1cb6c": "What are the possible exceptions that can be raised by the function?",
        "35d1e05a-60a8-4373-8fb1-0472698aeca2": "Explain the purpose of the `deeplake.exists` function.",
        "c4a6c7d3-8094-4b20-b117-e07969b7ab91": "What parameters does the `deeplake.exists` function take and what are their roles?",
        "57b70413-3d27-44be-aca1-b3c98e722e34": "How does the `creds` parameter in the `deeplake.exists` function prioritize credentials for accessing the dataset path?",
        "a88f564a-d30f-4ac5-9d8c-4b8f41c855fb": "How can you append a Deep Lake embedding sample to a dataset?",
        "8fbf9643-432d-4a2d-b450-07a48f3ca1d0": "Provide an example of extending a dataset with Deep Lake embedding samples.",
        "3a127b30-9943-48b6-800b-887254882c48": "Explain the concept of the Sequence htype and provide an example of how it can be used.",
        "8098820b-7e4c-4a52-991a-9a0dc9614242": "What is a Link htype and how does it differ from other htypes in a dataset?",
        "189e41cd-258c-49c6-ac79-5a26fb04ca16": "What are the exceptions to loading data when using the Link htype in a dataset?",
        "37a77726-f938-4dbb-a6d7-00eebb31504c": "Explain the difference between sample_compression and chunk_compression in the context of the provided information.",
        "a84aeb1d-dea1-4bda-8d55-fa6e64d9356c": "How can 3D bounding boxes be appended in the dataset? Provide an example using either np.ndarrays or lists.",
        "cec76f69-e3f6-43e6-8c71-94181e1f93b8": "What is the purpose of the intrinsic matrix in the context of camera parameters? Explain the components of the intrinsic matrix and their significance in a projective transformation.",
        "fa802104-9b9f-4e31-ba59-821f6e7c6d09": "How can images be stored in subfolders based on class name in the dataset?",
        "9bb7ac60-90b1-447c-933b-2941bed1a07b": "What are the different types of paths that can be used as the destination for the dataset?",
        "0e46eddb-20da-4ff9-90a8-e68541c87d3b": "What is the purpose of the image_params and label_params dictionaries in the function?",
        "b2c33c23-3657-4974-97ce-299e4e9c087e": "How can credentials be provided for accessing the destination path of the dataset?",
        "ae24923b-a3ef-4c0a-a81d-c2c713a20f14": "Why is shuffling the input data important prior to ingestion, especially when data is arranged in folders by class?",
        "098b0d7f-b95d-431d-af68-0d80b1b5a021": "How can you store your credentials on the Activeloop Platform as Managed Credentials and use them for your dataset?",
        "c0d8a4d7-dc04-473c-b010-032c76e2d5bd": "What method can you use to add managed credentials with names \"my_s3_creds\" and \"my_gcs_creds\" to your dataset?",
        "28cdadb1-9ad7-4125-a5f7-d08d187f1acf": "How can you create a link tensor named \"img\" with a sample compression of \"jpg\"?",
        "7b076e19-631e-4f67-ba60-9afc04007ca4": "Provide examples of how you can populate the \"img\" tensor with links, specifying when credentials are required.",
        "84760531-f659-42ab-9f86-eca2d75d7924": "How can you access the data in the \"img\" tensor using a loop in Python?",
        "8a22b3e1-5a79-4eec-91ba-a009defd8ee0": "How would you update the first sample in the \"img\" tensor to point to a local file \"cat.jpeg\"?",
        "612f3140-3541-4e5b-a83a-6b90e4800b76": "How can you create an image tensor in Deep Lake, and what are the recommended compression options for storing images?",
        "bdc8d0f2-1937-4381-afaa-48391bd46123": "What are the supported compressions for storing images in Deep Lake?",
        "422e8765-0f1d-4cd1-9896-0bc34b8ec7db": "How can you append pixel data with an array to an image tensor in Deep Lake?",
        "ba679a15-2071-4fc4-ad19-47db68a94d6c": "What is the significance of matching the compression format of the input sample with the sample_compression of the tensor in Deep Lake?",
        "85677974-0156-4468-9b50-6d386f008a37": "How can you force your image samples to be of RGB or grayscale type in Deep Lake using htypes?",
        "a441d232-5bbc-48c0-960d-9733f2090ca6": "Explain the process of creating a point cloud tensor using the provided code snippet. What are the optional arguments that can be used during the creation of a point cloud tensor?",
        "9eb33590-4b0f-4ff5-b82a-76472b449214": "How can point clouds be appended to a dataset using numpy arrays? Provide an example of appending two point clouds with different numbers of points.",
        "ddb334e0-5601-4c59-854c-36b334bcb478": "Describe how samples can be added to a dataset using the `deeplake.read()` method for point clouds. What is the expected shape of the point cloud tensor after adding a sample with 100 points?",
        "86eb5585-b83e-4b63-936c-ddab9f8c6ce2": "What are the dimensions of a sample in a tensor of `mesh` htype? How can mesh samples be represented in the dataset?",
        "f4a3bc73-ab19-4878-a4ad-e44bc58d658f": "Can different meshes have a different number of points? Explain how the mesh data is structured within the dataset.",
        "395efe86-5e1a-4690-aa21-0fc45f5fc8ac": "How can you specify the htype of a tensor at its creation in Deep Lake? What is the default htype if not specified? Why is specifying an htype important for datasets containing rich data like images and videos in Deep Lake?",
        "e11379e5-e6eb-4288-8660-346fe6e10827": "What codecs are supported by Chrome for videos?",
        "74b1857e-6d71-4f63-8a34-dc0d80822829": "How can a video tensor be created in Deep Lake, and what are the supported compressions?",
        "c756d2bd-4894-4843-9250-c08b15abdebc": "Can the Deep Lake Performant Dataloader support videos?",
        "356255ba-ad5b-4dcf-ac44-dfe6b55282c7": "What is the recommended dtype for creating an audio tensor in Deep Lake?",
        "aacbcb8b-ef99-480b-8529-24ca7d9425d7": "Is recompression of audio samples supported in Deep Lake?",
        "4842240c-3663-4638-baba-486d22e072d8": "Explain the difference between the pop() method in the deeplake.api.info.Info class and the popitem() method in the same class. How are they used differently in the context of the deeplake framework?",
        "e68943aa-3fc2-4e76-808f-ba607625500a": "How does the random_split() method in the deeplake.core.dataset.Dataset class work, and in what scenarios would it be useful for data manipulation?",
        "e567f6aa-8087-4716-b6c1-33f5955ab2cc": "What is the purpose of the register_deeplake_object() method in the deeplake.core.storage.LRUCache class, and how does it contribute to the functionality of the deeplake framework?",
        "bcdad768-82dc-478c-b18b-0c932f49d2c6": "Describe the functionality of the read() method in the deeplake module, specifically in the context of the deeplake.api.read submodule. How is data reading handled within the deeplake framework?",
        "21f105f6-7ca2-4f6c-8051-438b3c832790": "How does the rename() method differ in its implementation across various classes within the deeplake framework, such as deeplake.api.dataset.dataset, deeplake.core.dataset.Dataset, deeplake.core.storage.GCSProvider, and deeplake.core.storage.LocalProvider? Provide examples of when each implementation would be used.",
        "90065421-4add-4984-a0bb-5e101299397a": "What is the revision number of the document?",
        "313aa2a9-3a34-4f4b-a81c-02494ede78a7": "What theme is being used for the document?",
        "ad4684a8-3533-49ce-8901-395a2cff1a72": "What version of Read the Docs is currently being used?",
        "263f4331-ea41-4564-9c40-907104999c8f": "How many versions of the document are available for download on Read the Docs?",
        "4776e86a-d455-4afa-b766-034986f7bf8e": "Where can you find the project home and builds for the document on Read the Docs?",
        "97d00f83-5312-44b3-9ddf-fed3a4810b67": "Explain the importance of compressing segmentation masks using `lz4` and why it is recommended for masks containing large amounts of data.",
        "3166093c-f9cd-4a86-8734-34d1b911302c": "How can binary masks be appended in a dataset using `np.ndarray`? Provide an example of appending a binary mask with 5 objects along with their corresponding labels.",
        "781c1674-bd45-4914-874e-59de0f3cd2d8": "What is the structure of COCO keypoints and how are they represented in a tensor? Explain the meaning of the visibility values (0, 1, 2) associated with each keypoint.",
        "a8e3da47-4959-41e8-9c43-3ceb818dbad6": "How can a keypoints_coco tensor be created in a dataset? What are the optional arguments that can be specified during the creation of this tensor?",
        "a130375f-081a-42d6-80b2-f372bf51dfa0": "Discuss the significance of setting `keypoints` and `connections` in a keypoints_coco tensor after its creation. How can these attributes be modified post tensor creation?",
        "35436d83-e35b-4be7-bbaa-41764082809c": "What are the different types of paths that can be used when creating an empty dataset using the deeplake.empty() function?",
        "399ad17d-4612-4dfa-8c9f-94682ea98a0a": "What is the significance of setting the `access_method` parameter to \"download\" when creating an empty dataset?",
        "347bc5a1-c749-4312-9868-8d0c662a08e2": "How can you ensure that changes made to the dataset in download/local mode are only reflected in the local copy and not the original dataset?",
        "db4b3272-d9cd-4062-a42d-6dd20a6e5b54": "When creating an empty dataset, what does the `overwrite` parameter do and what is its default value?",
        "46b95f9a-0dd9-4575-969d-64920a8e595f": "In what scenarios would you use a memory path (`mem://path/to/dataset`) when creating an empty dataset, and what should be considered when using it?",
        "0f8e9372-665d-45bd-af41-99c3751ff07c": "Explain the components of the camera intrinsic matrix \\\\(K\\\\) and their significance in computer vision applications.",
        "002fafce-f8d6-4ba7-83ef-cde5cb69e601": "How can an intrinsics tensor be created in a dataset using Python code?",
        "51054381-7bd2-4bae-923c-19bdb5e3ec59": "What are segmentation masks and how are they used in computer vision tasks?",
        "f05c65d3-f445-4d61-a946-a2e2002eb0be": "Describe the process of creating a segment_mask tensor in a dataset, including the necessary arguments and parameters.",
        "1a8ee347-20cd-4e53-9bed-146d5108f474": "Discuss the relationship between focal length in pixels and focal length in world units, and how it is calculated in the context of camera intrinsic parameters.",
        "4614249a-b3ad-41ba-ab84-f85bec732a7e": "How can segmentation masks be compressed in order to reduce the amount of data stored?",
        "fff7224d-e370-47d1-8d6a-b59dc7bafcf2": "How can binary masks be appended to a dataset using np.ndarray?",
        "c55c5f1b-2dee-45f9-ae8a-dc48e310e718": "What are COCO keypoints and how are they represented in a dataset?",
        "ae0bb56e-17bd-4ffc-82ce-88b1aecfecd4": "How can a keypoints_coco tensor be created in a dataset?",
        "9459fc41-57ed-4cca-b923-4767b7dd7c98": "What are the three possible values for visibility in COCO keypoints?",
        "9a75d5da-5e06-4d04-889e-337ddf3701ce": "What are the optional arguments that can be set when creating a keypoints_coco tensor?",
        "3e35e75b-9e5b-4944-bcd7-ce2a7e5e78a9": "How can the compression method be specified when creating a keypoints_coco tensor?",
        "cde468f6-7b89-4517-a83e-ffc693faf16d": "How can the list of keypoints and connections be set after creating a keypoints_coco tensor?",
        "ca5a52a2-4627-4ce5-9936-75c211797003": "Explain the process of creating an image tensor and appending image samples using the Image Htype in the context of the provided information.",
        "4628baf6-8cbf-4897-a5e9-c4b088f51091": "What are the two types of units specified for bounding box coordinates in the given context information?",
        "f8b54a85-cfa0-4944-90a8-021014af3e67": "Explain the difference between the \"LTRB\" and \"LTWH\" modes for specifying bounding box coordinates.",
        "88c230ca-0a21-452a-936c-0a695ae44fb7": "How can bounding boxes be appended in the dataset, according to the examples provided in the context information?",
        "3959f465-6fc3-4140-8d70-130ce2076425": "When will the visualizer assume a YOLO format for bounding boxes, and when will it assume a COCO format?",
        "494bda3e-868d-41c3-8c59-d9f01cc87c2d": "Why is it important to specify the format of the bounding box for 3D bounding boxes to be correctly displayed by the visualizer?",
        "2de0ca46-4e1f-45de-95cb-a7876664916c": "Explain the difference between using precomputed embeddings and an embedding function in the context of evaluating a model in deep memory.",
        "2efdf9fb-570c-4aaf-9005-6c78304da1b8": "Explain the purpose and functionality of the LRUCache method in the deeplake.core.storage module.",
        "fe5608ee-20b4-4a0c-9ece-9066e58a4eb4": "How does the __len__() method differ in implementation between the GCSProvider, GDriveProvider, LocalProvider, LRUCache, MemoryProvider, S3Provider, and StorageProvider classes in the deeplake.core.storage module?",
        "5ca3a964-5ef7-4696-93fe-a243d63d55a5": "Describe the significance of the __repr__() method in the Index class of the deeplake.core.index module.",
        "96441dd3-60da-44c4-988b-57bd4cf756e6": "Compare and contrast the __setitem__() method implementation in the GCSProvider, GDriveProvider, LocalProvider, LRUCache, MemoryProvider, S3Provider, StorageProvider, and Tensor classes within the deeplake.core.storage module.",
        "93fe7c89-22dc-47dc-af6b-a7f80576bab9": "What is the purpose of the __setstate__() method in the LRUCache class of the deeplake.core.storage module?",
        "36f73b36-1cf5-47f8-9e4e-3aa95ab79183": "Discuss the role of the __str__() method in the Index class and IndexEntry class of the deeplake.core.index module.",
        "42c3e0a4-6db0-4f84-9f2b-94395c973c6f": "How are the __weakref__ attribute utilized in the Index, IndexEntry, and StorageProvider classes within the deeplake.core.index and deeplake.core.storage modules?",
        "047c5d4c-6b1e-43b8-828a-05d0a6f8ee3b": "Explain the functionality of the _all_keys() method in the GCSProvider, GDriveProvider, and StorageProvider classes within the deeplake.core.storage module.",
        "71477014-6026-4be2-985f-364d8b5547b6": "Explain the difference between `Dataset.create_group` and `Dataset.create_tensor_like` in the context of tensor manipulation.",
        "000783a1-9468-4439-96c9-89bb5bf742ad": "How can you delete a tensor from a dataset using the provided functions? Explain the steps involved in the process.",
        "8c4294d6-3ccd-4924-a58c-465c590339fa": "Describe the process of adding a single sample to the end of a tensor using the `Tensor.append` function. Provide an example scenario where this operation would be useful.",
        "69b52972-b1ba-4e1b-ac1b-0f63c7ed00e9": "What information can be obtained by using the `Tensor.numpy` function on a tensor? How is this different from the `Tensor.data` function?",
        "c44c501a-ffdb-4b3a-a9c8-333103050a1d": "Discuss the significance of the `Tensor.shape_interval` function in describing a tensor's shape more accurately. How does it differ from the `Tensor.shape` property?",
        "a8db593c-56da-4909-bd23-da4577b96015": "Explain the difference between sample_compression and chunk_compression in the context of the provided information. How are they used in the dataset?",
        "dde1865e-49da-4713-a9d2-0235e9249042": "How can 3D bounding boxes be appended to a dataset? Provide an example of appending one bounding box and another example of appending a sample with multiple bounding boxes.",
        "1e0cf45b-0916-4791-b2fe-16310a16abb5": "Define the intrinsic matrix in the context of camera calibration. What are the components of the intrinsic matrix and what do they represent?",
        "000f2fc6-fecf-4a76-9ff3-f5c30733c26c": "How is the intrinsic matrix represented in the dataset in terms of dimensions and values? Explain the significance of the values in the intrinsic matrix for camera calibration.",
        "00df84fa-6c4d-47b0-824e-0c58799d28ab": "How does Deep Lake handle the compression format of input samples that do not match the sample_compression of the tensor during the upload process?",
        "11c0b5f2-6706-4373-b8c2-61a12defaea8": "What happens if RGB images are appended to an image.gray tensor in Deep Lake?",
        "740e5380-66d9-49f3-8e9f-6ed41ec3fda1": "What limitations are there for visualizing videos in the Deep Lake App?",
        "d0cd4adf-a394-4ea2-8edd-4b75e63886f5": "How can a video tensor be created in Deep Lake?",
        "d6222c53-4f0a-40ec-a13b-cd4cb7871648": "What compressions are supported for video tensors in Deep Lake?",
        "3478017a-3d2d-4355-bc37-6c145296fa7e": "Can raw video frames be compressed in Deep Lake? If so, under what conditions can they be compressed?",
        "30b37d92-3454-480a-a82a-15915b5fd97f": "How can image.rgb and image.gray tensors be created in Deep Lake?",
        "d59821a2-1fb4-4c3d-90cf-6a0c08f24c20": "What is the purpose of the sample_compression parameter when creating a tensor in Deep Lake?",
        "4eae264e-8d46-47fc-82da-74dd82595720": "How does Deep Lake handle the conversion of RGB images when they are appended to an image.gray tensor?",
        "fa5a5f64-e043-466a-aac5-c3667202e112": "What is the default dtype for video tensors in Deep Lake?",
        "af66534c-ee4f-4e28-b27c-b521c0bd0085": "What are the two types of units specified for bounding box coordinates in the given context information?",
        "3b81a7e6-022b-4c95-942e-76fabe552896": "Explain the difference between the \"LTRB\" and \"LTWH\" modes for specifying bounding box coordinates.",
        "019f33d1-78c1-43a7-a854-e86813bdb512": "How can bounding boxes be appended in the dataset using numpy arrays or lists?",
        "16ad613e-d983-4443-9efd-63ae91f25dbc": "When will the visualizer assume a YOLO format for bounding box coordinates?",
        "d5142051-3708-474b-bbf3-550d43896197": "Why is it important to specify the format of the bounding box for 3D bounding boxes in the given context information?",
        "f88affc2-99dc-417b-b49a-b0b70940a53c": "What are the possible exceptions that can be raised when using the `update_creds_key` method in the `DeepLakeCloudDataset` class?",
        "bdafe150-9dd9-4cbc-87c5-398e82777ec6": "How can you visualize a dataset in a Jupyter notebook using the `visualize` method? What parameters can be specified for visualization?",
        "4c37cce3-df4e-4718-bbeb-9edddf7d898e": "Explain the difference between a regular dataset and a Deep Lake cloud dataset in the context of Activeloop servers.",
        "3efbb085-9b44-4a6d-a1d3-a92dc2636501": "Describe the process of adding and managing credentials keys in a dataset connected to the Activeloop platform.",
        "b59993d3-fc73-4eba-aecb-9e9b315cf550": "Why is it important to ensure that credentials have been created on the Activeloop platform before changing the management status of a key in a dataset?",
        "eb66e3dc-ea75-4236-964b-7f7c02331272": "Explain the process of creating a new tensor in a dataset using the `Dataset.create_tensor` function. What are the key steps involved in this process?",
        "685b1783-da51-4872-9dd5-478003c5e975": "How can you delete a tensor from a dataset using the `Dataset.delete_tensor` function? Provide a step-by-step explanation of how this operation is carried out.",
        "60eded04-a1ab-41cd-868d-802e12215ea4": "Discuss the significance of the `Tensor.append` function in adding samples to a tensor. How does this function differ from the `Tensor.extend` function in terms of functionality and usage?",
        "41e1869c-d7a7-4bcc-b11d-447c8725cdb5": "What is the purpose of the `Dataset.rename_tensor` function in the context of managing tensors? How does this function contribute to organizing and maintaining datasets effectively?",
        "906fcd09-d195-4a25-995a-a8f560e1d904": "How does the `Dataset.create_tensor_like` function facilitate the creation of a new tensor based on the meta information of a source tensor? Explain the advantages of using this function in data manipulation tasks.",
        "1c4c1499-bf70-41ca-adab-1355eaebf968": "How can you specify the htype of a tensor at its creation in Deep Lake?",
        "59449a1c-2ef3-4854-b520-e81866d13d7a": "What is the default htype of a tensor in Deep Lake if not specified?",
        "2ed753fc-e33c-441f-b523-aff239d693a8": "Why is specifying an htype important in Deep Lake datasets containing rich data like images and videos?",
        "ed62435d-5833-403b-b5a4-c0a744d907a0": "How can specifying an htype help in error handling and performance improvement in Deep Lake datasets?",
        "d72590bd-98de-4239-aa59-8f47b90efd1a": "Can you provide an example of creating a tensor with a specified htype in Deep Lake?",
        "db17d2f9-3f5a-473c-90f9-026f4d91a135": "What method can be used to return the bytes of a tensor?",
        "c82f7bf9-6668-4220-8f76-5b33c0253d21": "How can you access text data from a tensor?",
        "85a69e74-45a8-4e0b-a894-2a64be065fa8": "What property of a tensor returns the number of dimensions it has?",
        "7f7cc023-2109-4165-b85d-63d810bdfe9a": "How can you determine if a tensor is a sequence tensor?",
        "41c6a782-72bb-4fc4-b6d9-aca7334fe4e3": "What method can be used to play a video sample from a tensor?",
        "51340d14-a758-4263-95cf-dc0a62265ff6": "How can dataset views be created in Deeplake? Provide examples of methods that can be used to create dataset views.",
        "0315441a-f0a2-4cba-b413-a86cfa39996e": "What is the significance of saving a dataset view only when the dataset has been committed and has no changes on the HEAD node?",
        "fb49f9a4-5b8f-41f5-9ce1-514e04fa003b": "Explain the difference between filtering a dataset using a user-defined function and using simplified expressions in Deeplake.",
        "90576f0c-429f-4642-a637-1284f29be0fa": "How can a dataset view be loaded and accessed in Deeplake? Provide a step-by-step example.",
        "0f1a5c9d-8c86-40c9-afe4-6d655d260b98": "When would you use `Dataset.query()` and `Dataset.sample_by()` methods in Deeplake? Provide a scenario for each method.",
        "3648f8d2-70f4-4a16-beb3-c9c3fdbcbdfa": "Explain the process of creating a point cloud tensor using the provided code snippet. What are the optional arguments that can be used during the creation of a point cloud tensor?",
        "da883b7f-c707-42d5-96f1-1926e1c3e09a": "How can point clouds be appended to a dataset using numpy arrays? Provide an example of appending two point clouds with different numbers of points.",
        "19d2fe84-2c19-478e-bc19-04f3513dfacf": "Describe how samples can be added to a dataset using the `deeplake.read()` method for point clouds. Provide an example of adding a sample with 100 points to the dataset.",
        "89babb3c-7364-40d7-bce2-a886fe56ee0a": "What are the dimensions of a sample in a tensor of `mesh` htype? How are mesh samples represented in the dataset?",
        "ac45e1d7-c6c7-4a1b-8d88-c0170645f0dc": "Can different meshes have different numbers of points? Explain how the mesh data is structured within the dataset.",
        "d919bee4-4c06-4945-9a57-c1efe1010a88": "What is the default value for the `overwrite` parameter when creating a Vector Store?",
        "9d76d52e-4b4c-46a0-8a45-12bc02966b3a": "How can credentials be provided to access a dataset at a specific path?",
        "3c9039af-30b4-4d65-8733-37e58d80e1fd": "What precautions should be taken when setting the `overwrite` parameter to `True`?",
        "051ac692-b09c-439c-9e36-a38034462a8f": "When creating a Vector Store in Deep Lake's Managed Tensor Database, what parameter should be set to enable this feature?",
        "13ca2178-34a6-4d88-9519-82801328a866": "What keys are supported in the `creds` dictionary for providing credentials to access a dataset?",
        "61b8d2f8-0fa9-408d-88cc-45d4b5701a02": "Explain the components of the camera intrinsic matrix \\\\(K\\\\) and their significance in computer vision applications.",
        "5c88f375-7981-4c72-942e-939e63284ba0": "How can an intrinsics tensor be created in a dataset using Python code? Provide the necessary code snippet.",
        "0bd05190-fd51-40ef-bae5-cfcd6f9f073a": "Describe the purpose of segmentation masks in computer vision and how they are represented in a dataset.",
        "4ed291ca-7900-4223-a2f5-4e3c09509caf": "What are the optional arguments that can be specified when creating a segment_mask tensor in a dataset? Provide an example using the given context.",
        "ca638127-eb6a-420f-99b4-3a89ab268b71": "Discuss the relationship between the focal length in pixels and the focal length in world units, and how it is calculated in the context of camera intrinsic parameters.",
        "e2fe4908-33d3-4559-b630-a9ff810fdc1a": "How can you append 2 2-D points to a dataset named `ds`?",
        "78c10670-3e58-45a8-88ce-bcfc71d8fdf0": "How can you append 2 3-D points to a dataset named `ds` using NumPy?",
        "28bb512a-1fc5-44d0-8f8d-a21b77f8e3fd": "What are the sample dimensions for the `polygon` htype?",
        "3a4b2973-c950-4556-8529-bcd140fff953": "How can you create a polygon tensor named \"polygons\" in a dataset named `ds`?",
        "c998d113-47e8-4cf4-a94e-beee7e8df7e6": "What are the requirements for all points in a sample within a `polygon` htype tensor?",
        "2c6e1013-92a7-4d3a-b4e7-f5a23024c439": "Can you mix 2-D points with 3-D points within the same sample in a `polygon` htype tensor?",
        "f41d196c-26cc-4d1f-ab92-f8bcebc40289": "How can you append polygons to a dataset as a list of tuples?",
        "7cf603c9-e1c3-47e5-87dc-c6815e7b59d1": "What are the supported compressions for creating a polygon tensor?",
        "a80697e3-2748-4dda-9780-0cc26d43ce38": "What is the default data type for a polygon tensor if not specified?",
        "aae82da0-5cdc-47ec-a5d6-23147122fd6b": "How can you append polygons to a dataset as a NumPy array?",
        "07968237-f394-4ee0-a296-b83605d7f1d4": "How can you compare class labels in TQL when they are represented as strings?",
        "8fc91d6c-bd78-43d3-905e-6fe7463bc858": "Give an example of how you can index a multidimensional tensor in TQL.",
        "2533fafb-de39-46c7-a1ef-59e36bcb25d1": "How can you combine boolean expressions using logical operators in TQL?",
        "a5c75972-c2ea-4e2f-bfa6-c08faa177393": "What are the two keywords supported in TQL that are also found in SQL for filtering data within a range or a specific set?",
        "0da18ffd-e533-42c1-8231-0cb6e64a10e7": "Explain the function `CONTAINS` in TQL and provide an example of how it can be used in a `WHERE` expression.",
        "038ce90b-a6ec-4a2c-a9ab-ae9a799c49b4": "Explain the purpose and functionality of the `sample_by()` method in the `deeplake.core.dataset.Dataset` class.",
        "20bf4f54-40d9-4798-9dfe-84ea00a8e114": "How does the `set_model()` method in the `deeplake.core.vectorstore.deep_memory.deep_memory.DeepMemory` class differ from the `set_bytes()` method in the `deeplake.core.storage.StorageProvider` class?",
        "71cd6250-767c-49d7-9550-cef31e065e75": "What is the significance of the `seed()` method in the `deeplake.core.seed.DeeplakeRandom` class, and how is it used in the context of the dataset?",
        "3ef48d73-7bd4-4dcd-bfe8-de2cfb5d5c3b": "What is the purpose of the `verbose` parameter in the `deeplake.connect` function? How does it affect the behavior of the function?",
        "d76d1d43-1a93-4a18-9efd-57ecdc04116a": "What are the possible exceptions that can be raised when using the `deeplake.connect` function? Provide a brief explanation of each.",
        "669890f1-dd2e-462d-a8d4-6e05373c56c4": "Can you provide an example of how to connect an S3 dataset using the `deeplake.connect` function? Include the necessary parameters and their values in your answer.",
        "588aaf62-59f9-466b-84e6-c57ff5c1fe40": "What is the significance of the `creds_key` parameter in the `deeplake.connect` function? Why is it required?",
        "acf4addf-9591-4296-94da-7d283c9f6903": "Explain the difference between the `src_path` and `dest_path` parameters in the `deeplake.connect` function. How do they impact the connection of a dataset to Deep Lake?",
        "7ced8f13-734a-4118-bd1b-143785be39f4": "Explain the purpose of the `sequence` htype and provide an example of how it can be used in a dataset.",
        "c34689ce-d1f8-4886-aaa5-9f56478679b1": "How does the `link` htype differ from other htypes in terms of storing external data in a dataset?",
        "206101f8-ae79-483d-add3-f7c0534df5c1": "What are the variations of the `link` htype that can be used in datasets, and how do they affect data visualization in the activeloop visualizer?",
        "96084eb9-e257-4f6f-a98c-6014eea50de9": "Under what circumstances is data actually loaded when using the `link` htype in a dataset?",
        "f7f9784f-6b4e-42ee-89fc-78cf02186a3a": "Can you provide an example of how the `link[image]` htype can be used to link external image data to a dataset?",
        "a521e058-b7a1-49c5-8c5b-28f4f791385a": "Explain the difference between creating an empty dataset using `deeplake.empty` and creating a new dataset by copying the structure of an existing dataset using `deeplake.like`.",
        "edd70a33-7abb-408d-8fb6-eafac16ce2a2": "How can you ingest a dataset of images from a local folder to a Deep Lake Dataset using the `deeplake.ingest_classification` function?",
        "81a30824-11bd-4690-b268-46fc57cf54da": "Describe the process of ingesting images and annotations in COCO format to a Deep Lake Dataset using the `deeplake.ingest_coco` function.",
        "74b5dce8-ca55-49cd-ae3b-a2b8560c5db6": "What is the purpose of the `deeplake.ingest_yolo` function and how does it help in ingesting images and annotations in YOLO format to a Deep Lake Dataset?",
        "bd75ea83-00d0-4c3a-bd7c-361df15daeec": "How can you download and ingest a Kaggle dataset, storing it as a structured dataset to a destination using the `deeplake.ingest_kaggle` function?",
        "5f9e158b-1ab6-4aba-97c0-8b340ba7a082": "What are the limitations of the Deep Lake Performant Dataloader in terms of supporting data formats?",
        "fa08a826-8b73-4614-8d1f-76564a0c8374": "How can a nifti tensor be created using Deep Lake? What are the supported compressions for nifti data?",
        "ca259c0a-df7b-4e65-a5fb-124549acd482": "How can nifti data be appended to tensors in Deep Lake? What type of compressions are supported for raw nifti data?",
        "b45ed564-0cf7-4555-9109-2a8807ee89e1": "What are the key characteristics of the Point Cloud Htype in Deep Lake?",
        "2b160fba-ebc0-4404-9e57-17a8e8e360f4": "How can a point cloud tensor be created in Deep Lake? What are the supported compressions for point cloud data?",
        "95b58959-0215-4409-85e5-289af4572d55": "How can point clouds be appended to tensors in Deep Lake? Can point clouds be of different sizes in a single sample?",
        "2d6e48bb-e13b-4e48-9732-0eea0a911fae": "What are the supported values for the `scheduler` parameter when optimizing for optimization?",
        "8b6e6482-4682-4d81-a47e-ad300765bc35": "When saving a view inplace, what error will be raised if the user doesn't have write access?",
        "676db95b-6378-4bf9-a2d2-04752205ca75": "How can you estimate the size of the dataset in bytes using the `size_approx()` method?",
        "bd7d3298-27cd-4c50-bdfa-6561f95a6734": "What is the purpose of the `set_token()` method in the context of the provided information?",
        "706ce7e0-875e-4aa0-9e85-4934a5f720a7": "How can you print a summary of the dataset, and what parameter can be used to force the summary to be printed regardless of the number of samples in the dataset view?",
        "e23850e1-a8d0-4666-9b83-bb44e71c22b8": "Explain the key concepts of Datasets, Tensors, Htypes, Compressions, PyTorch and Tensorflow Support, and Utility Functions in Deep Lake. Provide examples for each concept.",
        "85a558dc-3465-406a-b265-286928653710": "Explain the difference between binary masks and segmentation masks in the context of object representation in an image.",
        "6cca9567-b2f1-41d0-9c21-75944a65b985": "How are objects represented in a binary mask tensor? Provide an example to illustrate your answer.",
        "c205d308-d6fe-4199-8577-4052906d05d6": "Why is it recommended to compress segmentation masks using `lz4` compression?",
        "8afd2df0-3e7c-4f12-97cb-ada4fa5cb1e3": "Describe the process of appending a binary mask with 5 objects to a dataset. Include the necessary steps and data dimensions.",
        "98f10842-a949-4571-b252-776dd730939f": "What is the purpose of COCO keypoints in storing points of interest in an image? Explain the values associated with each keypoint in the COCO convention.",
        "d6e0f0d6-92fd-4d3f-b1af-115e8c0cce1f": "What are the possible exceptions that can be raised when attempting to update a creds key using the `update_creds_key` function?",
        "50f5438c-dfeb-4506-aeb8-cadae955d8b2": "What is the purpose of the `add_creds_key` method in the dataset class?",
        "960d4f63-ce76-460f-8786-397440a89428": "How can you specify whether the credentials corresponding to a key should be fetched from the Activeloop platform when using the `add_creds_key` method?",
        "f38476d4-f44f-479c-bcce-ac112f1d6271": "What does the `_allow_delete` property indicate about a dataset?",
        "74c5b381-268e-4aeb-898f-5504e4d9ae6a": "When using the `append` method to add samples to multiple tensors at once, what happens if a tensor specified in the `sample` dictionary does not exist in the dataset?",
        "9c5faea9-202f-43cc-9c3b-50fcf370e255": "In what scenario would the `append_empty` parameter be useful when using the `append` method?",
        "1603ce71-1955-4e65-b2d4-ca77eb654ccc": "Explain the process of creating a polygon tensor using the provided code snippet. What are the optional arguments that can be used during the creation of a polygon tensor?",
        "29223bb3-d373-4730-8392-ea67842440aa": "How can polygons be appended to a dataset using lists of tuples or numpy arrays? Provide examples for both 2-D and 3-D points.",
        "ef0f1242-347b-464d-89c1-148958ea24e9": "Discuss the concept of sample compression and chunk compression when creating a polygon tensor. How can compression be implemented in this context?",
        "fae1dd8f-f22d-4d5c-acfc-74678311899a": "Can you explain the Nifti Htype mentioned in the context? What are the sample dimensions for Nifti data and how does it differ in the case of time-series data?",
        "4fe01ccc-0bb0-49ee-bcc3-4bbedf24a700": "How can numpy arrays be used to append polygons to a dataset? Provide an example of generating random numpy arrays for polygons with different numbers of points.",
        "3ef7409f-1b1b-45fc-8796-1dd1921220db": "How can audio samples be appended to tensors in Deep Lake? What type of compressions are supported for audio samples?",
        "520e1dc1-feb6-4dac-8f2e-dc93b5a1f37f": "How can class label tensors be created in Deep Lake? What are the optional arguments that can be specified when creating a class label tensor?",
        "8cad2ec3-e59b-4194-ac03-7e85df937038": "What is the purpose of the `class_names` parameter when creating a class label tensor in Deep Lake? How can it be set after tensor creation?",
        "947e1f31-ff02-4bda-bdaa-512bc5b39fbe": "Why is `chunk_compression` recommended over `sample_compression` when specifying compression for class label tensors in Deep Lake?",
        "7ea53d03-c696-492b-b4a5-75f101ca7a29": "Can you provide an example of how to extend a Deep Lake audio sample using the `extend` method?",
        "0004eb91-2cc6-4d3d-a054-843bb5cb6f54": "What is the purpose of Deep Lake, as described in the document?",
        "f1712447-6122-46aa-abf9-0d6286b94bea": "What are some of the key features of Deep Lake that make it suitable for deep-learning applications?",
        "72a57275-72ff-483e-90af-ef713f7331bf": "How can Deep Lake be utilized in the context of building LLM applications?",
        "789cc0dc-e9a5-4a41-b2d2-ef258cf768ac": "What are some of the additional resources and information available for Deep Lake users, as mentioned in the document?",
        "e91e80b1-315d-45dc-8d8d-65c2f328c967": "How is Deep Lake described as being optimized for AI applications in the document?",
        "7bbc5c00-e807-4c18-a25f-a5048ad3fdec": "Explain the difference between sample_compression and chunk_compression in the context of the provided information.",
        "500c39f3-8775-4526-940e-7d30240f1c44": "How can 3D bounding boxes be appended in the dataset using np.ndarrays or lists of arrays? Provide an example for each method.",
        "d8c7ccb8-a003-44a9-bcae-450773e67b53": "What is the purpose of the intrinsic matrix in the context of camera calibration? Explain the components of the intrinsic matrix and their significance in the projective transformation from 3D camera coordinates to 2D image coordinates.",
        "8c5bb35c-38c6-42e1-ae5b-5ffda8e5e299": "What is the purpose of the `deeplake.ingest_kaggle` function in the Deep Lake framework?",
        "28da4a09-6c07-441d-8127-bc6b7c874d0d": "How can you create a new dataset by copying the structure of an existing dataset to a new location using Deep Lake?",
        "8cb1f0ef-5d72-4df3-aa98-a048c85b3b03": "Explain the difference between `deeplake.copy` and `deeplake.deepcopy` functions in the Deep Lake framework.",
        "340fb31f-0dcd-43a9-8896-430609886667": "Describe the dataset operation `Dataset.query` and provide an example of when it might be used.",
        "962c578d-847c-4e43-8647-eda69ac92658": "How can you delete a dataset in the Deep Lake framework using the provided functions?",
        "87fbe489-5c06-497c-ae81-92aec26cede1": "What are the arguments required for the transform function mentioned in the context information?",
        "1f93547b-6729-4d57-aa57-3842dc494b82": "What is the purpose of the `ds_out` argument in the transform function?",
        "5464509b-c64c-4a51-b919-292c125ea70c": "How does the `num_workers` argument impact the processing of the transform function?",
        "b6d0e0db-e87b-49d6-a1aa-e17e72608eab": "What are the supported values for the `scheduler` argument in the transform function?",
        "e952fe90-6f67-406b-8b57-3c36da277bfd": "When would the `skip_ok` argument be useful in the transform function?",
        "345d141a-5bea-4850-9432-8171531f5fef": "How does the `ignore_errors` argument handle input samples that cause the transform to fail?",
        "636f9bc6-3b87-4af5-aa2b-d3df9d25625f": "What error is raised if the `data_in` passed to the transform function is invalid?",
        "efaea00e-f55c-4abe-9a8e-8cb7aa633c5e": "How does the initial state of the `ds_out` dataset impact the behavior of the transform function?",
        "ef73fc58-2557-45c0-a274-8a4abc51e371": "What is the default value for the `scheduler` argument in the transform function?",
        "54587970-c653-4c6e-bb9b-7a730d29344a": "How does the `progressbar` argument affect the display during the transformation process?",
        "1b6c475b-6ceb-4de4-8b65-ef0148763d93": "What is the purpose of the `extend()` method in the tensor class?",
        "47408dea-da01-4b31-bcb5-b9bb6293d245": "How can you add multiple elements to the end of a tensor using the `extend()` method?",
        "cdfc5f9e-5a5d-4ffa-a080-3c974cff29f0": "What is the significance of the `ignore_errors` parameter in the `extend()` method?",
        "9123a1fe-fed0-4ff6-92ff-db5319582e26": "How can you add data to a tensor using numpy input?",
        "3296ca18-f63b-4e5e-b795-bf68a50b3986": "What error may be raised if the dtype of the input array is not compatible with the tensor's dtype?",
        "6a04b626-00ce-432d-a7ee-6feaa7199f42": "Explain the process of creating a dataset in Deep Lake, including the steps involved and any considerations that need to be taken into account.",
        "cce62873-fed1-437f-98da-b89ec77c78a2": "How can you visualize a dataset in Deep Lake, and why is this visualization important for data analysis and interpretation?",
        "fa67d714-1fe2-40ce-993e-e92913554c52": "Describe the different types of Htypes available in Deep Lake and provide an example use case for each type.",
        "d864fb31-8287-43f1-863d-16605b8f8bad": "What are the key features of the Dataloader and Sampler in Deep Lake, and how do they contribute to high-performance data processing?",
        "2de91d6b-699d-440c-a104-8a0807b958d9": "How does Deep Lake support PyTorch and Tensorflow, and what are the benefits of this support for machine learning tasks?",
        "bc9fb46c-b52b-4ffc-a3e4-4c11bd9e34cf": "What are the different options available for the `exec_option` parameter when fine-tuning the index?",
        "e9923b91-8ef1-4c2c-bb2f-324627ba9a99": "Why is using the `python` option discouraged for big datasets when executing searches?",
        "a924ff42-1f58-4635-9ced-1bd10a7c950d": "How can you ensure that the Vector Store is overwritten if it already exists?",
        "486c50d9-e1b6-449a-a8a7-66d07e4a1ba4": "What is the purpose of the `token` parameter in the additional_params for fine-tuning the index?",
        "6d6ef3f9-abd4-4f76-8881-abcc7778e309": "Can you explain the role of the `creds` parameter and the different keys it supports for accessing the dataset at the path?",
        "83da3797-1008-4b4e-842c-5e42a8691b72": "How can a mesh tensor be created in Deep Lake using the `create_tensor` function? What optional argument can be specified during the creation of a mesh tensor?",
        "4e5db231-0961-4e0e-806a-328db6a3827f": "Explain the process of appending a ply file containing mesh data to a tensor in Deep Lake. Provide an example of appending a sample mesh and specify the resulting shape of the mesh tensor.",
        "3040a4cd-3b1e-452e-a140-5eb4cc2616f9": "What is the purpose of an embedding tensor in Deep Lake? How can an embedding tensor be created and what compressions are supported for embeddings?",
        "13397256-7796-4e77-8508-057dbcafe56f": "Describe the process of appending embedding samples to a tensor in Deep Lake. Provide examples of appending a single embedding sample and extending the tensor with multiple embedding samples.",
        "32747c41-c423-407d-ae79-030e4fb5525e": "What is the Sequence htype in Deep Lake used for? Can you provide examples of different types of sequences that can be wrapped using the Sequence htype?",
        "e724d080-4f8d-446d-bfce-0909d46a1a89": "How can keypoints that are not present in an image be stored in a dataset? What dummy coordinates are typically used for these keypoints?",
        "a8c041bc-7dc5-4467-b3b9-444999342db6": "What is the sample dimensions for points in a 2-D scenario? And what about in a 3-D scenario?",
        "144d085b-8f98-421c-86f7-ccf3730936c7": "How can a point tensor be created in a dataset using Python code?",
        "e78f5e46-a141-4c14-9088-12ce4738336d": "What is the purpose of the COCO Keypoints Htype compared to the regular Point Htype?",
        "dfc6997b-cc88-43fb-a9f5-c10b8614f8c3": "Can you provide an example of how to append 2 2-D points to a dataset?",
        "99a05dbe-a0b6-42a6-a0d7-c74de156b3da": "What are the key characteristics of the Polygon Htype in a dataset?",
        "1ddaa2a8-939a-433b-8de7-621f2260cce6": "How should the co-ordinates of all points in a sample be structured in a tensor of Polygon Htype?",
        "6ac71ed1-7df7-4303-aa54-a87ed887db15": "Can different samples in a dataset have a different number of polygons? If so, explain how this flexibility can be useful in real-world applications.",
        "5fa22afb-20c9-4cd8-b93d-660c5bc921b3": "What is the recommended compression method for segmentation masks due to their large data size?",
        "cc7fc1b7-cec9-4b6c-a59b-d9f24103bfd4": "How can you create a segment_mask tensor in the dataset?",
        "56e86e01-a887-422d-b91e-31bb8e83ea20": "What is the difference between segmentation masks and binary masks in terms of representing objects?",
        "df37279e-b609-45f4-a21b-bdee80728a08": "Why are segmentation masks not suitable for datasets where objects might overlap or where multiple objects within the same class need to be distinguished?",
        "7ae02da0-682d-45a8-9776-f9f233f01734": "How can you append segmentation masks to the dataset?",
        "e81a9e2e-f19c-433e-b804-3b4a26235ef5": "What should be stored in an adjacent tensor of htype class_label when using binary masks?",
        "7c0c4614-3695-422f-9c88-0face0db5ba8": "Explain the key concepts of Datasets, Vector Store, Tensors, and Htypes as mentioned in the document.",
        "0828cd4b-770b-4abd-a7bf-c8d1824ebd11": "How can an image tensor be created according to the document?",
        "3fdef5cc-4952-4692-aa1d-e9b323b67c6c": "Describe the process of appending image samples as outlined in the document.",
        "53da7d2c-9b4a-49b5-9411-a155e8d28172": "What are the differences between image.rgb and image. as discussed in the document?",
        "5072f2a4-6996-4a65-b59d-e3416e99502a": "What is the purpose of the `ds_out` parameter in the transform function?",
        "1e70bf53-ad5c-4155-989c-00201a254c1f": "How does the `num_workers` parameter affect the performance of the transform function?",
        "87003029-11d3-4dff-bfd3-9c693d2a86da": "What are the supported values for the `scheduler` parameter in the transform function?",
        "7ebff365-ed0f-46a1-8d05-9df965abd2fd": "When would you set the `skip_ok` parameter to `True` in the transform function?",
        "28cb9327-189a-45ae-b4fe-896ee75a6666": "Why is it important to set the `check_lengths` parameter to `True` in the transform function?",
        "eaadf400-e6d3-4e80-8ede-1b2763d7a46d": "How does the `pad_data_in` parameter impact the transformation process in the function?",
        "0e3f1292-50da-4475-8826-bcf805ecad65": "What is the significance of the `cache_size` parameter in the transform function?",
        "6aaf2e97-7e6c-4b63-aa0c-2fb3c467c053": "What are the supported values for the \"scheduler\" parameter in the function?",
        "c9739012-8ab4-4001-b036-e4700b127b6f": "What is the default value for the \"progressbar\" parameter in the function?",
        "7cfe2e13-367d-4a05-b5de-92985082d9ac": "What does the \"log()\" function do in the context of the dataset?",
        "3ad54602-af22-4604-9d90-2386ce2e2e9f": "How does the \"_max_len\" property function in the dataset?",
        "fcb4a389-c2db-409a-90c9-619c1dcc645e": "Can you explain how the \"_max_view\" property works in the dataset with an example?",
        "4f7a6845-081a-4161-81b3-b26799c44d4e": "What is the default value for the `overwrite` parameter when creating a Vector Store?",
        "2c882eae-0bd0-4d85-becf-bcee5f4cda27": "How can credentials be provided to access a dataset at a specific path?",
        "50a56681-5203-4b14-a752-4738f6025c90": "What precaution should be taken when setting the `overwrite` parameter to `True`?",
        "5a24895a-27a6-4753-ae44-000b88364455": "When creating a Vector Store in Deep Lake's Managed Tensor Database, what parameter should be set to enable this feature?",
        "014d06bd-40da-4875-8b08-9a7f8b1434ef": "What keys are supported in the `creds` dictionary for accessing cloud datasets?",
        "335c9a20-fde0-43e4-8ba8-923229d0d9e4": "Explain the components of the camera intrinsic matrix \\\\(K\\\\) and their significance in computer vision applications.",
        "5ea71157-7ffc-4f2b-bff7-89dab2fbb811": "How can an intrinsics tensor be created in a dataset using Python code?",
        "07e63f9b-2b95-48a4-81c3-0e862c3ad1f9": "Describe the purpose of segmentation masks in computer vision and how they are represented in a dataset.",
        "29a2ce7c-33dc-4ae2-b2ca-f2fadd306703": "What are the optional arguments that can be specified when creating a segment_mask tensor in a dataset?",
        "193276d1-d5a2-4acb-a372-ea22a041c11a": "Discuss the relationship between the focal length in pixels and the focal length in world units in the context of camera intrinsic parameters.",
        "157fc7e6-40c6-4638-9494-3a332a44f670": "How does setting the `pin_memory` parameter to `True` affect the data loader in terms of memory usage?",
        "533df82e-83fb-4a25-a184-2be988053727": "What is the purpose of the `buffer_size` parameter in the data loader and how does it impact the shuffling of data?",
        "a5458044-5760-4811-95d1-0e829a6e65f2": "Explain the significance of the `use_local_cache` parameter in the data loader and when it would be beneficial to set it to `True`.",
        "2a144607-c2e7-41c9-a9a5-3af739c00984": "How does the `return_index` parameter impact the structure of the returned dataloader?",
        "281c98ef-be4e-4ca0-aa53-20bdf6981d3c": "Can you provide an example of when setting the `pad_tensors` parameter to `True` would be useful in a data loading scenario?",
        "07cbf6fe-8d89-4c4b-b1d2-c48c6bde386e": "What is the difference between `deeplake.copy` and `deeplake.deepcopy` in terms of copying datasets?",
        "eb4e6d05-5a10-425b-a70f-a45b2a04ae6e": "How can you append samples to multiple tensors at once in a dataset?",
        "a464b73b-3274-47b7-807e-88dbed74cc09": "Explain the purpose of the `Dataset.delete` operation.",
        "5ebfbbe4-e7d5-4e5c-83ae-cf16a350a78f": "How can you estimate the size of a dataset in bytes using Deep Lake?",
        "2163c27b-0ed4-4ac8-a358-dca5db9414d5": "Describe the process of visualizing a dataset in the Jupyter notebook using Deep Lake.",
        "773494f3-f67b-48f6-89da-5f313c4bd43b": "Explain the purpose of the `link` utility and how it differs from the `link_tiled` utility in the context of storing raw data and multiple images that act as tiles, respectively.",
        "32f87930-01c1-4a39-bdae-cce0f287d28f": "How does the `compute` decorator function work in the context of parallelism, and what is its role in creating a pipeline of functions?",
        "e5407351-e1e4-4156-aaae-f218fc699930": "Describe the process of evaluating transform pipelines created using the `compute()` and `compose()` functions using the `eval` function.",
        "b3b37aea-d3a1-4ff2-8d8e-895ce3981c58": "How can a list of functions decorated with `deeplake.compute()` be combined using the `compose` function, and what is the significance of this in data processing?",
        "8daf0d48-b681-4d8c-964f-0680ca6d203f": "What are the possible errors that can be raised when using a scheduler other than \"threaded\" with a deeplake dataset having memory as the base storage for `data_in`?",
        "3d3a824c-39e6-4598-904d-e0f80e46b4e4": "Explain the purpose of the `deeplake.compose()` function and provide an example of how it can be used in a pipeline.",
        "1263afe1-06d6-4b13-bc0b-d5db5a32ecaa": "What are the requirements for the `data_in` input passed to the `eval` method for evaluating a pipeline/transform function?",
        "64c8ac72-e213-4b42-8db4-2c2f14d8b155": "When should the `ds_out` parameter be provided in the `eval` method, and what are the conditions that the `ds_out` dataset object must meet?",
        "68ed2d47-157b-4658-a0dc-4b2b7f05bcae": "What are the supported values for the scheduler parameter in the `eval` method, and what error will be raised if an unsupported scheduler is passed?",
        "e004e042-6975-4451-9810-5168e4a4c841": "What are the different types of paths that can be used as the destination for the dataset in the given context?",
        "98d3bbd9-4f9f-4230-a014-a07056a0d1ef": "How can one specify credentials for accessing an s3 path in the dataset destination?",
        "0171f0c1-a68f-4f22-9820-494d4a24a5c0": "Why is shuffling the input data prior to ingestion important, especially when the data is arranged in folders by class?",
        "b0e7add2-a01a-4bb2-bced-5b9f40793945": "What is the purpose of the `images_compression` parameter in the context of image classification datasets?",
        "44854745-a060-4cf7-a59e-8977383d1efd": "How can one ensure that ingestion proceeds without error if a Kaggle dataset was already downloaded?",
        "31d8d31f-d029-4a88-bf5e-0d3ecad0e39f": "How can you specify the htype of a tensor at its creation in Deep Lake?",
        "0416e94e-3dc4-4770-bb10-2ca1ae191c09": "What is the default htype of a tensor in Deep Lake if not specified during creation?",
        "549673af-a38c-408c-bfd7-307fb145f3f7": "Why is specifying an htype important in Deep Lake datasets containing rich data like images and videos?",
        "5e7d04b6-930c-46b1-9dd8-0870ef401319": "How can a mesh tensor be created in the given context? What are the optional arguments that can be used during the creation of a mesh tensor?",
        "b531ef76-6b85-4dc2-a295-70afab431021": "Explain the process of appending a ply file containing mesh data to a tensor. What is the expected shape of the tensor after appending the mesh data?",
        "035d4064-c6f4-4e99-97b7-2abfa2590703": "What is the purpose of creating an embedding tensor in the context provided? What are the supported compressions for embedding tensors?",
        "5ce6d76f-43f2-415f-b6aa-2eca2f330b5d": "How can embedding samples be appended to an embedding tensor? Provide examples of appending a single embedding sample and extending with multiple embedding samples.",
        "322843cd-d645-4f5e-a617-b57ab46209c7": "What is the significance of the Sequence htype in the context provided? How does it differ from other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.?",
        "b3aa449b-4006-4a03-bd75-cdfd78076d80": "How can a polygon tensor be created in the given context?",
        "2293f29a-fa40-48e4-88d2-3cddeeae23b4": "What are the requirements for the points in a sample of a polygon tensor?",
        "ecff880e-82f1-4602-ac12-b2495ba4e76a": "Can different samples in a polygon tensor have a different number of polygons? Explain.",
        "492d24c1-6bc9-4dd5-854b-b309f4b0ba64": "What are the supported compressions for creating a polygon tensor?",
        "ee0bec12-a1b0-4790-a989-811c91c97139": "How can polygons be appended to a polygon tensor in the given context?",
        "52e795ef-3fb9-4740-a0ca-be69fb39895f": "Explain the purpose of the `link` and `link_tiled` utilities in the context provided.",
        "f6c9e92e-6b43-417a-89a0-7b360c557bd3": "How does the `compose` function work in relation to functions decorated with `deeplake.compute()`?",
        "b98fb119-043b-4f0c-a39b-66c203c93dfa": "Describe the process of evaluating transform pipelines using the `eval` function mentioned in the context.",
        "2d176898-98c8-495c-a5af-ed95c264c38b": "How can a pipeline created with `compose` be evaluated to produce an output dataset?",
        "be5600b6-3a2f-4576-98c0-386a33422cde": "Discuss the concept of parallelism as it relates to the `compute` decorator for functions in the context provided.",
        "8d169e46-7786-494c-8ae4-9e362ec9f237": "What are the different types of paths that can be used as the 'dest' parameter in the dataset setup?",
        "4c2e6c59-8a99-40ca-9116-dbe8623cec90": "What is the purpose of the 'class_names_file' parameter in the dataset setup?",
        "234005f6-3baa-47c7-8a47-ac95fefb6795": "How can you specify the path to the directory containing annotations in the dataset setup?",
        "97240209-c066-4aad-87ab-00617eba6dbe": "What does the 'allow_no_annotation' flag determine in the dataset setup?",
        "c32e2298-1c40-433b-8663-7761531b1850": "Explain the use of the 'coordinates_params' parameter in the dataset setup.",
        "b4cfd89f-97d1-4d27-9418-5479afd042d9": "Explain the difference between directly uploading embeddings and uploading embeddings via an embedding function in the context of the deeplake_vector_store.",
        "e50afc76-ef82-4d59-abd5-badbfca78f4f": "How can user-defined embedding tensors be utilized when uploading embeddings using multiple embedding functions in the deeplake_vector_store?",
        "8b19d77c-9edc-431b-a2dc-3e7d844bc9a7": "Describe the purpose of the metadata parameter in the deeplake_vector_store add function.",
        "f85ca3d1-a5d9-4245-a5c7-32a9b432214a": "How can the embedding_tensor parameter be used to specify user-defined embedding tensors when uploading embeddings in the deeplake_vector_store?",
        "2ecaff65-be27-4176-bd2b-a57dbd806aa5": "Discuss the significance of ensuring that all data provided for each tensor in the deeplake_vector_store is of equal length.",
        "2a3da9f1-b657-49f8-8e0e-5881548a518f": "How can a mesh tensor be created in Deep Lake using the `create_tensor` function?",
        "0a3518c6-6721-476e-9893-9e55d924788f": "What are the optional arguments that can be used when creating a mesh tensor in Deep Lake?",
        "21013e3e-d47b-4198-a777-208bc218d600": "How can a ply file containing mesh data be appended to a mesh tensor in Deep Lake?",
        "9c4d16ed-2b82-40e7-8e3e-4b1f452f9e3e": "What is the shape of a mesh tensor after appending a sample with 100 points and 200 faces?",
        "0b1396d9-c03e-412d-ae95-5fa4f49ee664": "How can an embedding tensor be created in Deep Lake using the `create_tensor` function?",
        "7af3121c-c280-4db5-8752-7d33c0612320": "What are the supported compressions for an embedding tensor in Deep Lake?",
        "be32327b-e1c8-4b89-afed-7d9c39da85cb": "How can a Deep Lake embedding sample be appended to an embedding tensor?",
        "97f1685d-e7db-40b1-8579-f9e2a604ec82": "How can an embedding tensor be extended with multiple Deep Lake embedding samples?",
        "833b83f9-a89a-4fff-827b-a48e87c3708d": "What is the purpose of the Sequence htype in Deep Lake?",
        "e733a782-6afa-49fd-abab-bdc3b6f714a7": "Can the Sequence htype wrap other htypes in Deep Lake? If so, provide examples.",
        "674c530c-41ec-4e82-aea2-803ed60eb85c": "How can you shuffle the output of a query in SQL using the `ORDER BY` clause?",
        "685ed4bd-6aa2-4896-b3e9-c35f3664499d": "What does the `SHAPE` function return when applied to a tensor?",
        "821e1ae9-31cb-4418-a3f2-4eaa00bf456f": "Explain the difference between the `ALL` and `ALL_STRICT` functions when applied to an array of booleans.",
        "e12c194c-93ef-41cf-8e2e-62219e9833d7": "How does the `ANY` function work when applied to an array of booleans?",
        "50b64441-971f-450d-a45f-800a55159e96": "Describe the functionality of the `LOGICAL_AND` function when applied to two boolean arrays.",
        "26bd147b-9ea6-4662-9c86-09e52d799ccf": "When can the `LOGICAL_OR` function return `False` when applied to two boolean arrays?",
        "15629552-ed07-4fba-840b-830933fca477": "Provide an example of using the `UNION` set operation in a query with the COCO Train Dataset.",
        "c4ab880a-e349-4909-86a6-3a91f00cb9d9": "How many images containing the digit 0 are there in the MNIST Train Dataset based on the provided query example?",
        "12956f46-dd9a-41b3-915a-eef9ac235e95": "In the context of the provided examples, what is the purpose of the `EXCEPT` set operation in a query?",
        "13e491dc-a634-40ae-8927-0781fc71d29e": "How can you combine multiple `SELECT` statements in a query using set operations?",
        "29389e0d-86b9-41f5-82fa-355a80848b44": "What is the default setting for the `shuffle` parameter in the `ingest_yolo` function?",
        "0d06f390-d611-4453-bf64-fedf4d2494cf": "How many workers are used for ingestion by default in the `ingest_yolo` function?",
        "e9e784fa-5159-4572-b4fa-29e6362b13d8": "What is the purpose of the `token` parameter in the `ingest_yolo` function?",
        "e5a662a4-afbd-475e-8678-60a66116d859": "How can the dataset be connected to Deep Lake in the `ingest_yolo` function?",
        "2579c4ec-de81-45d3-95a8-ee0ff1482e7a": "What error will be raised if `key_to_tensor_mapping` or `file_to_group_mapping` are not one-to-one in the `ingest_yolo` function?",
        "3acda66b-a858-4753-b543-bc9cbfb704b6": "What is the purpose of the `inspect_limit` parameter in the `ingest_yolo` function?",
        "97895cd2-c309-45a2-9dd7-dff64a4d4f0a": "How can images and annotations be ingested in YOLO format using the `ingest_yolo` function?",
        "5e1e7834-c46d-4533-b848-548963f027cb": "What is the significance of the `progressbar` parameter in the `ingest_yolo` function?",
        "da7a3b8d-ff9b-4cf5-a0e5-62db6a8cac55": "How can the number of workers for ingestion be specified in the `ingest_yolo` function?",
        "4a68df6b-dac9-44e5-948b-80422078c540": "What type of data is returned by the `ingest_yolo` function?",
        "95a14e9e-14dc-49bb-b33c-9325a0b342be": "What are the limitations of the Deep Lake Performant Dataloader in terms of supporting data formats?",
        "e0be00cc-2ee7-44bb-813c-516df0db2987": "How can a nifti tensor be created in Deep Lake, and what are the supported compressions for nifti data?",
        "aa7323d5-925a-4020-8532-ef122ccc6b87": "How can nifti data be appended to tensors in Deep Lake, and what is the restriction when it comes to compressing raw nifti data?",
        "e62299c0-db6c-42f7-aacc-2c769a2b238b": "What are the key characteristics of the Point Cloud Htype in Deep Lake, in terms of sample dimensions and data types?",
        "e03b6fc5-b7e9-455c-ad15-a301d2ba8123": "How can a point cloud tensor be created in Deep Lake, and what are the supported compressions for point cloud data?",
        "03214314-2cbf-4bf6-917d-39501416d6e2": "How can point clouds be appended to tensors in Deep Lake, and what type of data can be appended as point clouds?",
        "129da165-1896-4368-942f-c8d9f7b1e6ad": "What are the two different ways in which the source data can be stored for ingestion in the Deep Lake dataset?",
        "b4182d23-4c87-4129-9540-5147afc82c03": "How can you specify the mapping of keys from the annotation files to tensors during the ingestion process?",
        "34cb7609-15a2-44d8-b8b4-bfa959f94e38": "What parameter can be used to specify the destination path for the dataset being created during the ingestion process?",
        "ea187566-6082-4c3b-a886-d6427e95eff3": "How can you specify the compression settings for the images being ingested from a cloud storage location?",
        "78cf3e05-ec1e-496a-a9b8-202051a5d9ac": "What parameter can be used to specify the number of worker processes to use during the ingestion process?",
        "e0c67068-5eb0-418a-9247-98fa7f34bd28": "What is the purpose of the `query` parameter in the function described above?",
        "0106acdc-a88b-4f57-8701-35060a84759e": "Explain the difference between the `exec_option` values: `\"python\"`, `\"compute_engine\"`, and `\"tensor_db\"`.",
        "bf766ad5-dba2-492a-9131-43bff04ddd27": "When would it be discouraged to use the `exec_option` set to `\"python\"`?",
        "2ff0c11a-498d-4e8f-accf-203913d239d6": "What is the significance of the `delete_all` parameter in the function?",
        "173857e5-4293-480b-a65a-753e631f4550": "What type of error will be raised if neither `ids`, `filter`, `query`, nor `delete_all` are specified?",
        "53b6b31d-5ca8-4b1d-8637-6b711eda8952": "How can you delete a Vector Store using the `_static_delete_by_path` function?",
        "eb0ec302-ada6-48d9-abd9-f246b63c0534": "What is the purpose of the `token` parameter in the `_static_delete_by_path` function?",
        "7398b6f7-da0f-442e-9ad2-fe0e1333cc21": "Can you explain the role of the `force` parameter in the `_static_delete_by_path` function?",
        "3ac1d9b4-1ed6-4a35-a904-ab48d5fbcaf6": "What is the significance of the `creds` parameter in the `_static_delete_by_path` function?",
        "26145583-fefd-4b8f-8753-b688ad505570": "What type of value does the `_static_delete_by_path` function return?",
        "66b57110-2b53-4bef-91e6-6c6f38ec7cf8": "How can you create an image tensor in the Vector Store?",
        "58d10851-8766-4b7e-8e84-4b264f4acb73": "What are some key concepts discussed in the document related to datasets and tensors?",
        "62a7f76e-66c1-4145-bd31-3845e3c38279": "Explain the process of appending image samples in the Vector Store.",
        "82b914d0-5b9a-4649-bd31-6d71103ccbb0": "What is the purpose of the Image Htype in the context of the document?",
        "baf66fd5-df55-48f0-b1fa-2c9185cafb7b": "How can you differentiate between image.rgb and image. in the context of the document?",
        "8e9de0b9-6aad-4687-a3c9-c31db19a1914": "How does TQL syntax for the `SELECT` statement differ from traditional SQL syntax?",
        "8c9dee25-cb60-4ae7-9459-18fc71628670": "What is the purpose of the `WHERE` expression in a TQL query?",
        "e3abe9a1-b951-44ef-8043-5e95387973af": "Explain the functionality of the `ORDER BY` expression in a TQL query.",
        "9042f30b-366f-4d64-879f-ed253ea87160": "How are expressions evaluated in TQL queries when filtering samples in the dataset?",
        "8bbec35c-dcff-498f-b1e4-cbbac77aa0ec": "Describe the use of `LIMIT` and `OFFSET` expressions in a TQL query.",
        "97dd7cd5-8f5c-4a7b-a967-bf1533bdb2ec": "Can you provide examples of comparison operators supported by TQL?",
        "514445ea-de7e-49fc-b493-b2212d9a9cd3": "How does TQL handle string literals in comparisons for class labels, JSON, and text tensors?",
        "8cd850f5-4b14-46ec-9faf-bb6020be061e": "What is the default ordering for the `ORDER BY` statement in TQL?",
        "acb62000-cb95-4e7c-a37a-c918f58c1fa9": "How does TQL handle the `FROM` expression in a query, and why is it not necessary in the syntax?",
        "47f57cc4-4f3f-4487-94dd-2d7435ff8691": "In what scenarios would you use the `SELECT *` statement in a TQL query?",
        "7aac1a5b-3827-49b8-a4d5-d99844146efd": "What method of the `Tensor` class returns the bytes of the tensor?",
        "c5a780f0-23f5-491f-acb0-34af08a38825": "How can you access text data from a `Tensor` object?",
        "75d6bb7d-4c3a-4472-843a-dbcbb9d3a16c": "What property of a `Tensor` object returns the number of dimensions of the tensor?",
        "893a79a1-055d-4541-a9df-57152b9f3717": "How can you play a video sample from a `Tensor` object?",
        "bc6f8892-6c62-4be1-995b-3b00eba3d4a3": "What does the `Tensor.is_dynamic` property indicate about a tensor's samples?",
        "2e84c913-07dd-480b-a21c-2ccec4c3e0ef": "What is the purpose of specifying an htype for a tensor in Deep Lake datasets?",
        "9e59c9fa-158c-4d1c-8f88-795962f5978d": "How does specifying an htype contribute to the performance of datasets containing rich data like images and videos in Deep Lake?",
        "95732590-73bf-4b04-b226-c46cb552fad1": "Can you provide an example of creating a tensor with a specific htype in Deep Lake?",
        "febec912-414e-499e-9249-cda12dd78cf0": "What are some of the supported htypes in Deep Lake and their respective defaults?",
        "945efbc6-5e37-431a-a4bc-788b595d0799": "How are images typically stored in Deep Lake, and what are the options for storing them?",
        "e962ebed-88fa-47bc-adcb-78e0ef6ea168": "How can you determine if a dataset is in read-only mode or not?",
        "b33e63e9-b3ed-4398-aa25-d65617bcb64c": "What information does the `Dataset.info` method return?",
        "f8567ee7-d067-4e2d-aa42-f9f59ef842aa": "How can you find the maximum length of a tensor in a dataset?",
        "49b72f20-9da3-4e72-a74e-d129e249d06c": "Explain the difference between `Dataset.commit` and `Dataset.checkout`.",
        "424e0786-38d9-4aad-98fc-ffcbafc52bec": "When can a dataset view be saved?",
        "f15e1de0-ed46-4818-8143-e19cd5855d3b": "What happens if a tensor is renamed on both the target and current branch in the dataset?",
        "2ecec9c1-2300-4396-851b-bd5ae66152ea": "What exceptions can be raised when working with the dataset, according to the context information?",
        "5b6ffbe2-f775-41e0-94b3-8c05d87db2d5": "How can you access the metadata of the dataset?",
        "52f8679f-1da2-4584-89a4-4262a970bb61": "What does the _min_len property return in the dataset?",
        "79b8cb3b-d8a4-46c1-888d-0f3f043ae2e4": "How does the _min_view property modify the dataset?",
        "b3e7ec04-077d-479e-a7db-605f8d2202a2": "Can you provide an example of creating a dataset with images and labels, and then using the min_view property?",
        "8b26cfdd-c930-4d36-af25-29d4f15352aa": "What does the _no_view_dataset property return?",
        "d88aa532-b0f1-4b33-9a4b-24e5ccef2754": "How does the _num_samples property calculate the length of the smallest tensor in the dataset?",
        "3594fc95-0fca-4ba1-a40e-ad6b7ada98c3": "How can you access the parent of a group in the dataset?",
        "70e3927c-162f-4874-ac63-3b95654b7e51": "What is the revision number of the document provided in the context information?",
        "838386ef-d5c8-4301-b917-21a87195cf34": "What tool was used to build the document?",
        "0a3b57e7-b6ba-4257-a643-fe25d631f848": "How many versions of the document are available for download?",
        "074cbbd4-3b62-4e11-95f1-d922e215b698": "What formats are available for download?",
        "6c85661a-6c4b-4b45-95a5-09493c547a1d": "Where can the project home and builds be accessed on Read the Docs?",
        "ff067bb7-071d-4dea-9fb1-5e8bcf221c39": "How can you append 2 2-D points to a dataset named `ds`?",
        "7b977b9f-7627-4c43-ae4f-d81d84348678": "What is the structure of a sample in a tensor of `polygon` htype?",
        "51021452-b763-48d1-bbbd-d1c1ec389329": "Can you mix 2-D points with 3-D points in a sample of a `polygon` htype tensor? Why or why not?",
        "da416fde-d199-4343-bbc3-ddf151205ef7": "How can you create a polygon tensor named \"polygons\" in a dataset?",
        "acfb1fe5-2881-473d-bfe4-0533dbcff10a": "What are the optional arguments that can be used when creating a polygon tensor?",
        "e1c333ab-6811-406b-bc63-b10aa0a5105f": "What are the supported compressions for a polygon tensor?",
        "dd6158c1-96eb-4650-8b32-4e0a8ebb0ea8": "How can polygons be appended to a dataset in the context of this document?",
        "c2bbdb54-875d-416f-b90e-7eeb1ea5cfb8": "What error would be raised if an attempt is made to delete a file from an S3 bucket fails?",
        "333d1e60-d070-45eb-a480-4c202fa83f43": "How would you handle a situation where there is a mismatch in tensor data types?",
        "deb016bb-d28a-4620-9564-559827eb3841": "What error would be raised if an attempt is made to access metadata that does not exist?",
        "944d365c-c355-4d18-90d0-606d416c5d29": "How would you address a situation where there is a conflict during a merge operation in version control?",
        "d1ed382d-b10d-45aa-8093-f3430db5ed12": "What error would be raised if an attempt is made to compress a sample using an unsupported compression method?",
        "4811e805-7f8a-48ed-82c7-9bff0610afba": "Explain the difference between sample_compression and chunk_compression in the context of the provided information. What are the supported compressions for each?",
        "394683c3-e77b-4e39-ab32-154052e539a3": "How can 3D bounding boxes be appended in the dataset? Provide an example of appending one bounding box and another example of appending a sample with three bounding boxes.",
        "d5c9e34d-ded2-43a5-b6c7-c8638077594c": "What is the significance of the intrinsic matrix in computer vision? Explain the components of the intrinsic matrix and their roles in a projective transformation from 3D camera coordinates to 2D image coordinates.",
        "a899e1d8-1adf-4c88-8548-913f7b4dd478": "What codecs are supported by Chrome for videos?",
        "02bffbe0-63ae-4b6c-8fec-23a4fce6cbfa": "How can a video tensor be created in Deep Lake, and what are the supported compressions?",
        "218e5e88-d317-4ee8-a63d-132d3b6a3324": "Can the Deep Lake Performant Dataloader support videos?",
        "aba3811b-55a3-43c2-8b73-aa87e48c7934": "How can audio tensors be created in Deep Lake, and what are the supported compressions?",
        "7a85271e-2bb5-46ea-8aa8-2d595cdda034": "What type of samples can be appended to video tensors in Deep Lake?",
        "8c48ee48-5a64-4fa8-83aa-841eca29910d": "Is recompression of samples read with `deeplake.read` supported for videos?",
        "7b01cfa4-a2d5-4d80-b872-1c60357f0980": "What are the optional arguments for creating an audio tensor in Deep Lake?",
        "b99f8347-cd80-4fac-8a56-c8e569657272": "Can audio samples of type `np.ndarray` be appended to tensors with compression in Deep Lake?",
        "26782de3-48b9-42da-9b0f-203013ca5dcf": "What are the sample dimensions for the audio htype in Deep Lake?",
        "d6ce7083-f010-465d-b51f-7e9e13032035": "How can multiple videos be extended in a Deep Lake dataset?",
        "3e90b60a-7074-418c-839d-e43e35672560": "What is the purpose of specifying an htype for a tensor in Deep Lake?",
        "e6f8d7b1-0824-41bf-84a4-4e478f03a603": "What are some of the supported htypes in Deep Lake and their respective defaults?",
        "4ba8b122-2afb-4f6b-86df-c0ed95cd216a": "How can you create a tensor with a specific htype in Deep Lake?",
        "54593071-c746-41c7-bd85-85cc96f7a849": "What are the sample dimensions for the Image Htype in Deep Lake?",
        "7db44e33-1ee6-400d-b6ce-346a7ef3c619": "Why is specifying an htype important for increasing the performance of Deep Lake datasets containing rich data like images and videos?",
        "f1a4e6e0-b8ad-437c-a61c-77bfaeb24e5e": "Explain the process of creating a polygon tensor using the provided code snippet. What are the optional arguments that can be used while creating a polygon tensor?",
        "a1ae3904-8ba3-4a45-ad2c-5084c6272753": "How can polygons be appended to a dataset using lists of tuples or numpy arrays? Provide examples for both 2-D and 3-D points.",
        "5b8ac256-69eb-4905-9764-e19eb4a861bf": "Discuss the supported compressions for creating a polygon tensor. How can compression techniques be utilized in this context?",
        "6e7885ef-803a-4eb0-912d-65138049882d": "Can you explain the structure of a polygon tensor in the context of the provided information? How are polygons represented within the tensor?",
        "1d9743e2-8e22-4e91-8024-c5992c8aecb5": "In the Nifti Htype section, what are the possible dimensions for sample data in terms of height, width, slices, and time units? How does this relate to the representation of time-series data?",
        "20281e9c-c78f-42c9-9f60-d790f238b583": "What is the purpose of the `_commit_id` property in the dataset class?",
        "63fe02aa-4f1e-43ff-9591-d7e155ce3001": "How can you list all the commits leading to the current dataset state using the `commits` property?",
        "c1f09cd9-e301-4e72-9066-3545a1f56e26": "Can you explain the behavior that occurs when committing from a non-head node in any branch in the dataset?",
        "7250e3a2-6f98-426c-b2e4-f742b39547d4": "How can you connect a Deep Lake cloud dataset through a deeplake path using the `connect` method?",
        "c9fbe0b0-34fa-4c9c-a176-da920ce62042": "What parameters are required when using the `connect` method to connect a Deep Lake cloud dataset?",
        "26ca30a8-542c-46cc-8963-67c14f32faaf": "What is the default value for the `ingestion_batch_size` parameter?",
        "df0925d4-c53b-425e-a393-2ef280b2e5e9": "Explain the purpose of the `index_params` parameter and provide an example of how it can be customized.",
        "95026700-e108-4c06-b261-6ed84833a102": "What are the possible values for the `distance_metric` key in the `index_params` dictionary, and what do they represent?",
        "b5bdf22e-7652-4f04-91c6-712b1d29674f": "When the `exec_option` parameter is set to `\"auto\"`, how is the search execution method determined?",
        "c40ee9c7-0120-4dd2-a913-634f81d34532": "Why is using the `\"python\"` option for the `exec_option` parameter discouraged for big datasets?",
        "73e50efd-6e87-4c5b-8dbf-0c96f3ad0cf3": "What is the purpose of the `log()` method in the `Dataset` class of the `deeplake.core.dataset` module?",
        "a021f778-c3ed-4bce-b725-3ed80d33406c": "Explain the difference between `ManagedCredentialsNotFoundError` and `MetaDoesNotExistError` classes in the `deeplake.util.exceptions` module.",
        "fb16c3d7-8286-4baf-adb0-4c4aa70762bf": "How does the `merge()` method in the `Dataset` class of the `deeplake.core.dataset` module work?",
        "44df94ff-6ead-4ed8-836e-96d11ad6d3dc": "What is the significance of the `min_len` and `min_view` properties in the `Dataset` class of the `deeplake.core.dataset` module?",
        "8fde3249-ac39-4ae9-9738-751045904b5d": "Can you describe the functionality of the `maybe_flush()` method in the `StorageProvider` class of the `deeplake.core.storage` module?",
        "51d58000-f4f1-4f7f-88d3-2cd1da3a8b5b": "Explain the components of the camera intrinsic matrix \\\\(K\\\\) and their significance in computer vision applications.",
        "226ca28b-9c5f-4df8-9093-796515074c01": "How can an intrinsics tensor be created in a dataset using Python code? Provide the necessary code snippet.",
        "be193e12-aafc-4232-9e79-6510bc793a75": "What is the purpose of the focal length in the context of camera intrinsic parameters, and how is it related to the pixel size?",
        "ae55bc5a-c7b1-45a5-93c9-cf3009e169da": "Describe the structure of a segmentation mask tensor and how it is used to represent class labels in computer vision tasks.",
        "4ccc22c0-f8a2-43a7-8629-48359277ee68": "How can you append intrinsic matrices to a dataset in Python using the provided code snippet?",
        "413b5221-87eb-41bb-b903-ede80d83da8b": "What is the purpose of the `clear_cache()` function in the dataset class?",
        "22de830f-d7ed-4c9b-a9b0-2195b390219d": "How can you retrieve the client of the dataset using the `_client` property?",
        "5aae7442-27a0-49a4-b55a-9b508064de5e": "Explain the parameters and return type of the `commit()` method in the dataset class.",
        "f9583e53-6eef-486f-b45c-f06129bba1a8": "What is the significance of the `commit_id` property in the dataset class?",
        "a39b3012-4f69-40c8-9e31-919deb66ce35": "How can you list all the commits leading to the current dataset state using the `_commits` property?",
        "8701f1f1-62aa-4e32-bb34-9665b91eb4fe": "Describe the purpose of the `connect()` method in the dataset class and list the parameters it accepts.",
        "1fc29370-8436-4735-ab2d-1031835a3dea": "How can you store your credentials on the Activeloop Platform for datasets?",
        "df439aa5-0e5b-485c-9b61-3bdeaac5b746": "What is the purpose of using managed credentials in the context of adding keys to a dataset?",
        "c6b6d84e-a690-441e-a713-8e27a970e6ab": "How can you create a link tensor in the dataset?",
        "be4d0693-73ac-465b-a986-24beed47cc2b": "Provide examples of different ways to populate the \"img\" tensor with links in the dataset.",
        "5cd1b573-154f-42eb-a751-73abfd440f04": "Why does the attempt to append a link with a cloud path without a creds_key result in an exception?",
        "4f5e6072-bb8d-42dd-bdce-ce67acc78e33": "How can you access the data stored in the \"img\" tensor in the dataset?",
        "7049d1ff-3785-423e-b4d8-a9599f634de3": "How can you update a sample in the dataset with a new link?",
        "27833204-ea76-446a-95d9-84cf63b8adbc": "Question: How can a polygon tensor be created in the given context? What are the optional arguments that can be specified when creating a polygon tensor?",
        "a2dc3a97-fbc4-487a-99ea-96fe57d54e92": "Explain the process of creating an image tensor and appending image samples in the context of the Image Htype.",
        "f50256b4-9ee1-4ba4-bbe6-80614494c762": "What are the limitations of the Video Htype and how can a video tensor be created and appended with video samples?",
        "9d4ca566-6aab-479d-885a-d11597c28720": "Describe the steps involved in creating a class label tensor and appending class labels in the Class Label Htype.",
        "a289cac3-a7ff-4815-b11f-7d643d4bc96d": "How can a segmentation mask tensor be created and appended with segmentation masks in the Segmentation Mask Htype?",
        "c78a4e42-785e-4cfd-9841-5b84eb383ae3": "Discuss the process of creating a point cloud tensor and appending point clouds in the Point Cloud Htype.",
        "3ddf34f0-b049-4467-8f72-e8b833afd331": "What are the variations of the `link` type that can be used in the activeloop visualizer to correctly display data?",
        "8b12dc96-afc1-452b-a4af-cf559b18daf1": "When is data actually loaded from a dataset?",
        "fe1b5f9d-c0dd-402c-9125-835b8467ce8e": "What are the exceptions to data not being loaded until a sample is read from a dataset?",
        "333004c8-e0dd-4084-b9d5-666e0e4a4180": "How can credentials be added to a dataset?",
        "b3c534a5-9ec5-4603-aac6-1354379a735b": "What is the benefit of storing credentials on the Activeloop Platform as Managed Credentials for datasets connected to the platform?",
        "e13822fb-f5cf-4edf-ace0-e26a8048804f": "What method can be used to return the bytes of a tensor?",
        "3d73991d-f8f5-4a0d-9eee-ce021564d543": "How can you access text data from a tensor?",
        "ee23ea98-de49-4322-94e4-f5e9d52fb82b": "What property of a tensor returns the number of dimensions it has?",
        "f7604f89-fc3c-4e38-b3c9-4e60afb7ad39": "How can you play a video sample from a tensor?",
        "8cd87101-756f-46a4-8825-27aa10352068": "What does the `Tensor.is_dynamic` property indicate about a tensor?",
        "bc087255-2abd-4873-9624-d1511b28f16e": "How can you access json data from a tensor?",
        "902a7c39-30f1-46e6-8814-8e11f89fd734": "What does the `Tensor.num_samples` property return?",
        "99871a4c-c453-4116-a07b-e0edcc4ca923": "How can you verify linked data when adding samples to a tensor?",
        "ff025dbe-a254-4451-bdcd-a1a1d9c14330": "What information does the `Tensor.info` method provide?",
        "ac16da4f-08ee-40c2-b87c-40bae0971f73": "How can you access the shape of a tensor more accurately using a specific method?",
        "fcba74d7-7be0-44e1-a59d-2e9ab73b0711": "What is the purpose of the `delete_branch` method in the dataset handler class?",
        "02580448-13fa-4861-8657-681ca20adac9": "Under what conditions can a branch be deleted using the `delete_branch` method?",
        "50ed2c40-3b98-4f2d-a381-ecdd6583c13f": "What exceptions may be raised when attempting to delete a branch using the `delete_branch` method?",
        "e2cc864e-2ae3-42dc-b788-91d731d7e667": "How can you delete a specific tensor group from the dataset using the `delete_group` method?",
        "55432d19-220f-4ca9-a552-45c09aa9efe1": "What is the default behavior of the `delete_group` method in relation to deleting large tensor groups?",
        "bd920f1c-0c0d-4de4-ac6e-6667ea22dc8f": "How can bounding boxes be appended to a dataset in the form of np.ndarrays or lists?",
        "75def62d-d916-45bb-ad28-dc2aca8aea8b": "What is the required format for 3D bounding boxes to be correctly displayed by the visualizer?",
        "60a431ae-0278-4031-bb2e-8bc5f0c389d4": "How can a 3D bbox tensor be created in a dataset, and what optional arguments can be specified?",
        "252ef1e7-46fa-4043-a852-1deb412e067f": "What key must be included in the coords dictionary when creating a 3D bbox tensor?",
        "b095ac90-7ecf-4315-904a-a8513e4a0ffc": "Why is it important to specify the intrinsics tensor or matrix when projecting 3D bounding boxes onto 2D data?",
        "8a15d048-3b31-4f2f-815a-4ce92c694968": "How can you append 2 2-D points to a dataset named `ds`?",
        "293d343b-be5f-483a-9f49-d8aaafbedc6a": "What is the structure of a sample in a tensor of `polygon` htype?",
        "864eed27-9fd0-4a49-a3ae-e30656a20b8b": "Can you mix 2-D points with 3-D points in a sample of a `polygon` htype tensor? Why or why not?",
        "777a6374-16ab-4870-ad51-2f08cbdca046": "How can you create a polygon tensor named \"polygons\" with no sample compression?",
        "3a976604-0839-43c2-bc24-bac6de994592": "What are the supported compressions for creating a polygon tensor?",
        "b9b35260-453d-4b9b-927f-16315dbc5c3b": "How can polygons be appended to a dataset as per the given context information?",
        "0f9686e6-2fe8-4a77-a2aa-34bc217cd6cb": "How can you reset the seed for training models and running randomized Deep Lake operations?",
        "f3589321-1765-467d-b6f5-eaf525287811": "What features are affected by specifying a seed in Deep Lake?",
        "00be1277-9e77-4ab7-b7d1-805ee3aaaebe": "How can you specify a random seed using `deeplake.random.seed`?",
        "89ed02d4-2927-4d9b-985e-af2847659d5f": "Does the Deep Lake random seed affect random number generators in other libraries like `numpy`?",
        "8620e969-5e1b-4158-9fe0-bf310b8f8704": "How does the seed in other libraries impact the code where Deep Lake uses those libraries?",
        "c50db239-a9e5-4ba7-86fb-e152e9348a0e": "What is the purpose of the `_delete_by_path` method in the given context?",
        "e0a4d24e-e24e-45f0-bee7-3cf618974ca5": "What are the parameters required for the `_delete_by_path` method to delete a Vector Store at a specified path?",
        "b57a81e2-a602-4f14-ac8d-838da0bf7203": "What is the potential risk associated with using the `_delete_by_path` method according to the provided context information?",
        "c32f85c0-6f10-4907-b140-9e2e7d189af5": "How does the method handle credentials for accessing the dataset at the specified path?",
        "fb81c7a3-23e7-4d07-a6e2-660da3f60930": "What type of error will be raised if neither `ids`, `filter`, `query`, nor `delete_all` are specified when using the `_delete_by_path` method?",
        "ecf8514f-19f9-404d-b5e3-4bbb06724b0d": "Explain the difference between `Dataset.flush` and `Dataset.clear_cache` in the context of dataset management.",
        "ce8cdf31-dba6-45b8-b409-8295a76152c9": "How can you estimate the size of a dataset using the `Dataset.size_approx` method?",
        "c54aeb37-18b2-4f97-a6d1-5ede7bb22e40": "Describe the functionality of `Dataset.random_split` and provide an example of how it can be used in a dataset.",
        "6c867fdd-dc8c-497e-8259-5ff42ddf4c84": "What is the purpose of `Dataset.add_creds_key` and how does it contribute to dataset credentials management?",
        "7daa1935-e270-44a4-b801-e72d3b9f385c": "How can you retrieve information about the commits and branches in a dataset using methods like `Dataset.diff` and `Dataset.log`?",
        "18a32b21-df99-4755-90ff-fe6f58a4c49c": "How can you set the `connections` attribute in `tensor.info.keypoints`?",
        "9b901e49-8e84-4e8c-a1fd-511f559b9792": "What is the default data type for `dtype` in `tensor.info.keypoints`?",
        "17930dec-259e-4c4d-8f69-2c8fca37af78": "How can you append keypoints to a sample in the dataset?",
        "5c16b2f2-24cb-4b9d-95aa-b27742f35734": "Why is it important for all objects in every sample to have the same number of keypoints in the same order?",
        "2c4a4ffe-8807-4dc1-b489-e79f4ec058f7": "How can you update the `keypoints` and `connections` after tensor creation in the dataset?",
        "404c1729-a7c0-4f05-ba07-2875b32a7020": "Explain the purpose of the `rename_tensor` function in the context of the provided information. How does it work and what are the parameters and possible errors associated with it?",
        "d17f4daa-cdf8-4a20-b378-f8a5bf8251f3": "What is the significance of the `reset` function in the context of the dataset operations described in the document? How does it differ from other functions mentioned?",
        "15fe43a8-3363-42b2-be40-669456037a9f": "How does the `sample_by` function work in the context of dataset manipulation? What parameters can be passed to this function and what does it return?",
        "54ff0b2a-890e-4d01-bcbd-9382bdf71f00": "Discuss the importance of avoiding duplicate tensors and tensor groups in the dataset, as mentioned in the provided information. Why is it necessary to handle errors related to duplicate tensors and groups?",
        "5e4ac249-6d68-44bf-ae5b-3e1f9abb9a30": "Explain the concept of the `_root` property in the context of a dataset group. How can this property be useful in dataset management and organization?",
        "51282e86-a3b7-4117-b3a2-9bbfddb4cda4": "What is the purpose of the `sample_by` method in the `DeepLakeDataLoader` object?",
        "5990eee5-1920-4bf4-a240-ebcf3bdb6401": "How can you sample the dataloader to have more samples with `labels == 5` compared to `labels == 6` using the `sample_by` method?",
        "42e053db-7668-49fe-81a4-6a488d5a65f0": "Explain how you can sample the dataloader treating the labels tensor as weights.",
        "7a3e788b-0288-4d1a-afeb-da30bd9558a4": "How can you sample the dataloader with given weights and ensure that the samples are not repeated in the result view?",
        "95756de4-a896-4216-b443-913be829e435": "What is the significance of the `shuffle` method in the `DeepLakeDataLoader` object?",
        "340704dd-440c-4b75-b4e6-37193a0fd14f": "What parameters can be adjusted when using the `shuffle` method and what are their default values?",
        "9426e5c1-1a60-430b-b14d-ed123342201b": "What error will be raised if the `shuffle` method has already been called on a `DeepLakeDataLoader` object?",
        "f2341afe-f7ce-4fdb-8846-da800fc0d591": "How can you set the `tensor.info.keypoints` list after tensor creation?",
        "f82118dd-9df3-4b1c-9a57-7402d2f4c881": "What is the purpose of the `connections` list in the `tensor.info.keypoints`?",
        "c951c45c-abf9-4721-982d-01628e8454ab": "How can you append keypoints to a sample with multiple objects?",
        "e545fd8d-c3bb-4c40-8a77-550038561d60": "Why is it important for all objects in a sample to have the same number of keypoints in the same order?",
        "de8102dc-ca3e-49ab-9efc-a8a45198f147": "What should be the coordinates for keypoints that are not present in an image to prevent them from being drawn in the visualizer?",
        "40852c11-651f-4a5b-b411-859d856c1f3a": "Explain the importance of compressing segmentation masks using `lz4` and why it is recommended for masks containing large amounts of data.",
        "0ae6efcc-29cb-4ca6-b960-4b2c5780fa55": "How can binary masks be appended in a dataset using `np.ndarray`? Provide an example of appending a binary mask with 5 objects and their corresponding labels.",
        "f88e6168-f707-4549-8fe1-d7b73ea26298": "What is the structure of COCO keypoints and how are they represented in a tensor? Explain the meaning of the visibility values (0, 1, 2) associated with each keypoint.",
        "99324f8b-b127-48a1-8dcf-d35cd1fe5b42": "How can a keypoints_coco tensor be created in a dataset? Provide the necessary code snippet and explain the optional arguments that can be included in the creation process.",
        "4a60abdc-ed7d-4531-91b0-264afa97f27d": "Discuss the significance of setting `keypoints` and `connections` in a keypoints_coco tensor after its creation. How can these attributes be modified post-tensor creation?",
        "cadcfba8-39c0-42cf-9f63-91c1aacd13f0": "Explain the key concepts of Datasets, Vector Store, Tensors, Htypes, Compressions, PyTorch and Tensorflow Support, and Utility Functions in the context of Deep Lake.",
        "e4b272e7-200a-4cea-8ed3-a4cd40510044": "How does the Dataloader in Deep Lake contribute to high-performance features?",
        "d71c25cd-ec42-42f4-9faa-00c521708e4a": "Describe the API reference for deeplake.VectorStore and deeplake.core.dataset in Deep Lake.",
        "0758d775-e836-4274-b693-a5224de02b75": "What is the purpose of the deeplake.api.link function in Deep Lake?",
        "7851548e-e8e1-41ab-9790-71ba9d1de233": "How does the deeplake.core.vectorstore.deep_memory feature enhance the functionality of Deep Lake?",
        "cc287698-0638-412b-aaae-7ee5c831891a": "What are the supported filetypes for automatic ingestion in the dataset creation function?",
        "319a40e3-eeae-4c8a-aaa5-27b2bb09cb1c": "How are classes defined in the dataset structure for image classification datasets?",
        "f7b7cc82-f59b-4504-a2bd-c73fe7370519": "What exceptions may be raised if the source directory does not meet the requirements for automatic ingestion?",
        "a3f8fd4d-1d47-4c45-8cfd-57ace072db6d": "Can filenames be mapped to classes from an external file in the current implementation?",
        "8e396de9-2785-4474-8769-d20325b3b04b": "How are sub-directories structured in the valid source directory for image classification datasets?",
        "6fe4fc60-aaa2-457a-9b68-247ad224480f": "What is the purpose of the `num_workers` parameter in the `DeepLakeDataLoader` object?",
        "ae760ed8-8bd5-4be3-a19a-14edbc8e00f7": "How does the `persistent_workers` parameter affect the behavior of the data loader?",
        "826350dc-41d7-4847-8893-2cdd47331d0f": "Can you explain the different decode methods supported by the `decode_method` parameter in the `DeepLakeDataLoader` object?",
        "7ae8a21e-5cc7-4c7f-a349-b9fd9bb6bd2f": "What does the `offset` method do in the `DeepLakeDataLoader` object?",
        "7d1c4548-362c-431c-b845-e923ea243602": "How does the `prefetch_factor` parameter impact the data loading process in the `DeepLakeDataLoader` object?",
        "e9e164c4-bc17-419a-98a2-d62651e348bc": "How can bounding boxes be appended to a dataset in the form of `np.ndarrays`, `list`, or `lists of arrays`?",
        "f14fec48-91bb-445c-8156-c388427b0d99": "How can you append a sample with 3 bounding boxes to a dataset?",
        "c8034dae-9265-498e-a415-e527850e3362": "What must be specified in the `coords` key in tensor meta information for 3D bounding boxes to be correctly displayed by the visualizer?",
        "b7e2d649-a2ca-4055-bffe-1210c220ef33": "What is the optional argument `coords` used for when creating a 3D bbox tensor?",
        "89e96e54-c853-454d-be65-f491d4afb254": "In the context of 3D bounding boxes, why is it important to have the intrinsics tensor or matrix specified in the dataset?",
        "f90fb66f-0d24-45be-b6be-e16c1b1268fc": "How can dataset reads be logged in Weights and Biases when using a Torch dataloader?",
        "24aff881-b3fb-44e2-a653-6e75449ad1f1": "What is the purpose of committing changes to an existing dataset with an active Weights and Biases run?",
        "37ae4088-e383-4c18-bc7a-5443b7c59119": "How can you log a dataset read when iterating over a dataset in Weights and Biases?",
        "7181b11a-6f3c-42a1-9a15-1f8cd56207ed": "What are the two methods mentioned in the context for logging a dataset read in Weights and Biases?",
        "aff3378e-4f12-4c3e-8911-731d859f5867": "What is the recommended approach for logging dataset reads in Weights and Biases when working with tensors?",
        "d9ddad03-1188-4b47-9c9f-2a1099a68906": "How can you store your credentials on the Activeloop Platform for datasets?",
        "4fb68e58-ae1a-468a-9f6e-7b3fb92f747c": "What is the purpose of using managed credentials in the context of the Activeloop Platform?",
        "b855ce85-1b91-4a74-aad7-493fe511d308": "How can you add managed credentials to a dataset using `Dataset.add_creds_key`?",
        "c81ac613-0709-487b-a65c-47cf1e6a4784": "What is the function of `ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")` in the context of the document?",
        "3ad11c83-c55b-4f37-aca3-be19abc548f8": "Explain the different ways in which you can populate the `img` tensor with links in the dataset.",
        "6aa5dc1c-5b59-4f9f-bddc-18966a30619c": "Why does the statement `ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))` throw an exception?",
        "004842f0-ad31-47b2-a0db-755306a638ee": "How can you access the data stored in the `img` tensor in the dataset?",
        "82d50244-94b7-4515-aec5-4aff4907664d": "What is the purpose of the statement `ds.img[0] = deeplake.link(\"./data/cat.jpeg\")` in the context of updating a sample in the dataset?",
        "f0f765b1-9ca7-4f3a-82a7-ad58ab1c3dc5": "How can a polygon tensor be created in the given context? Provide the necessary code snippet and explain any optional arguments that can be used.",
        "65887465-8608-4e87-87f5-1d4eced2c9e2": "Describe how polygons can be appended to a dataset using lists of tuples or numpy arrays. Provide examples for both 2-D and 3-D points.",
        "bd9a2916-90ab-4257-a88a-851eece40330": "What are the supported compressions for creating a polygon tensor? Provide the list of compressions and explain their usage.",
        "990e9cae-c4af-4a90-81d1-c76b98a78846": "In the Nifti Htype section, what are the possible sample dimensions mentioned for the data? Explain the dimensions in the context of the data being discussed.",
        "a31f73f6-fec4-4245-be82-b71473ca4547": "How can polygons be appended to a dataset using numpy arrays? Provide an example using randomly generated data and explain the structure of the numpy array used for appending polygons.",
        "39d98dee-4aad-41c2-84c3-f37e6029d88c": "What is the purpose of sample compression when creating tensors in the context of this document?",
        "634e9559-02d7-42a6-9624-051e29e5e094": "Can raw frames of audio and video data be compressed according to the provided examples?",
        "d3c21f53-8c04-44fa-9494-cae604cef812": "What is the difference between sample compression and chunk compression when creating tensors?",
        "454c0bcd-a913-4894-b553-bc8c11371413": "Why is chunk-wise compression not supported for certain data types like audio, video, and point cloud in this document?",
        "bfea4385-66ac-4a1f-ad87-4d3529734bb8": "How can data be read from files and populated into tensors according to the information provided?",
        "815e1770-a9d9-472b-bc5c-194d74a03c47": "How does Deep Lake handle image compression when the compression format of the input sample does not match the sample_compression of the tensor?",
        "83a7d63f-f271-43f2-8c33-62dea6f7e8ee": "What happens when RGB images are appended to an image.gray tensor in Deep Lake?",
        "f99fd4a4-6bcb-4d1b-8db9-cafe793f57be": "What limitations are there for visualizing videos in the Deep Lake App?",
        "e59b061a-e56d-4180-b602-b81c4efd4a7f": "How can a video tensor be created in Deep Lake?",
        "3b4bc569-f5e9-4850-be11-4d8fdec5801d": "What compressions are supported for video tensors in Deep Lake?",
        "bf7182f3-0237-4e67-bac1-a3b267cab352": "Can raw video frames be compressed in Deep Lake? If not, which tensors support the appending of raw video frames?",
        "e8d0d287-f7e5-4061-9812-ba49870ec5d7": "Question: What is the purpose of the `num_threads` parameter in the `DeepLakeDataLoader` object? How is the default value determined if this parameter is not specified?",
        "14021f40-ff52-4f04-96d7-f71df75eb16a": "What are the key concepts covered in the Deep Lake v3.1.0 documentation?",
        "9ad1629d-fedf-4b79-a2a5-59ec0ee2df8d": "How does Deep Lake support PyTorch and Tensorflow?",
        "e44c859b-d9e8-46bf-98fc-c9826f47a6d9": "What enterprise features are included in Deep Lake?",
        "b377426b-37de-4041-8ce1-d2f2c7779396": "What are some of the API references provided in the Deep Lake documentation?",
        "e2e6ace0-55e2-4af2-b056-0bd92380143f": "How is Deep Lake described in the context information provided?",
        "78a1740e-5080-4eac-88a0-fc1d9795ff3c": "How does Deep Lake support instant visualization of datasets, and what types of visualizations are available in the Deep Lake Visualizer?",
        "0cfe1b52-ea54-4555-8904-06f04af8e652": "What is the performance improvement of Deep Lake's dataloader built in C++ compared to Hub 2.x, as mentioned in the context?",
        "f499a663-c08b-42b8-9289-a195a75b93b8": "How can Deep Lake be installed, and what dependencies are not installed by default?",
        "8203f30d-7764-4ee1-8f68-31b946117e92": "What are some examples of image, video, and audio datasets that are available in Deep Lake?",
        "298a59c3-244f-4e01-9899-f62187e00710": "What is the recommended step to access all of Deep Lake's features mentioned in the context?",
        "df24587c-0ce1-479d-84e8-2f4b0b66f6d2": "What codecs are supported by Chrome for videos?",
        "b9492c3d-24ea-41da-889f-40878c7e9377": "How can a video tensor be created in Deep Lake, and what are the supported compressions?",
        "41be5f94-83de-4e97-a824-189643f92943": "Can the Deep Lake Performant Dataloader support videos?",
        "9a7e8628-bb7a-4094-b6c6-a916a503d174": "What is the recommended compression for creating an audio tensor in Deep Lake?",
        "4975b983-ed46-4239-8ada-70f2cdc14d33": "Can raw video frames be compressed when appending them to tensors in Deep Lake?",
        "29a9f80d-a853-427a-a515-9127bb7e3edb": "How can audio samples be appended to tensors in Deep Lake, and what type of samples can be appended?",
        "f872a269-a254-4546-9f92-0273e1f598b3": "What is the sample dimension for audio tensors in Deep Lake?",
        "49384e61-8454-4cc6-bc75-867269ef9955": "Is recompression of audio samples supported in Deep Lake?",
        "e8421dc8-5f2c-4328-880b-f85ca329e13c": "How can multiple videos be extended in a Deep Lake tensor?",
        "ad4bb9d4-1941-4c36-a5e0-0eb5f5f87a86": "What is the default dtype for creating an audio tensor in Deep Lake?",
        "0ef28e9e-6d28-480a-a8d5-d0e6e01a102e": "Explain the process of creating a polygon tensor using the provided code snippet. What are the optional arguments that can be used while creating a polygon tensor?",
        "ca732932-e4b8-4fe3-a38a-6fc427dabd33": "How can polygons be appended to a dataset using a list of tuples or numpy arrays? Provide examples for both 2-D and 3-D points.",
        "2e3d7c5d-a2a1-4057-a3d4-5eaf755255ce": "Discuss the supported compressions for creating a polygon tensor. How can compression techniques be utilized in this context?",
        "e4aed332-e3ed-4269-b691-a7aaad7355cd": "Can you explain the structure of a polygon tensor in the given context? How does the number of polygons and points vary in different samples?",
        "f5137b71-e910-4f0c-b710-9fe1b666b5cc": "Describe the Nifti Htype mentioned in the document. What are the sample dimensions for Nifti data, and how does it differ for time-series data?",
        "7b88a9d5-328c-4007-99f8-68d2cf7c6933": "How does Deep Lake handle the compression format of input samples that do not match the sample_compression of the tensor during the upload process?",
        "f165b53e-1b38-4c6e-a612-dc4824cd8286": "What happens if RGB images are appended to an image.gray tensor in Deep Lake?",
        "3262d31e-fb58-477e-8de0-e1c4bfde1449": "What limitations are there for visualizing videos in the Deep Lake App?",
        "6864a7f8-4596-4c31-a4a2-58f422ff3f36": "How can a video tensor be created in Deep Lake?",
        "d53bd163-e3fe-431d-b19c-0a5a964018c5": "What type of compressions are supported for video tensors in Deep Lake?",
        "865dae40-b4c9-4807-81c8-8edfbd691cb0": "What are the arguments required for the transform function mentioned in the context information?",
        "c9792c42-9a51-4b30-9c1c-b4761b5fbd67": "What is the purpose of the `ds_out` argument in the transform function?",
        "3547a8a8-db5f-4c09-a214-40a2762b52ee": "How does the `num_workers` argument impact the processing of the transform function?",
        "e6109efe-3f77-4b61-bad3-f4cb69c16b8d": "What are the supported values for the `scheduler` argument in the transform function?",
        "5756a152-197c-4714-8e7f-36edd3a7c77c": "When would it be useful to set the `skip_ok` argument to `True` in the transform function?",
        "d5e4eb86-71fa-4adc-a37c-ead9c5aa14ca": "What does the `check_lengths` argument do in the transform function?",
        "138831ef-ad23-4081-b0c4-ca27bfa87de9": "How does the `pad_data_in` argument affect the input data in the transform function?",
        "b851f6b6-0977-48d1-a3eb-f3360c93994c": "In what scenario would you use the `ignore_errors` argument in the transform function?",
        "265cdc86-bc03-443b-bb0c-3a4134750247": "Explain how a keypoints_coco tensor can be created using the provided code snippet. What are the optional arguments that can be included in the creation of this tensor?",
        "73a2f17e-1521-4be0-9655-ac38630574da": "How can you update the `keypoints` and `connections` attributes after creating a keypoints_coco tensor in the dataset?",
        "02a23b68-75bc-4b11-850f-8f537dc6d842": "Describe the supported compressions for the keypoints_coco tensor. How can you specify the compression method to be used?",
        "4d602e87-c958-4513-82e2-25bc6bdc8f61": "Can you provide an example of how keypoints can be appended to the keypoints_coco tensor? What data types can be used for appending keypoints?",
        "3b390112-b3b3-4548-a17d-563aa40228e6": "Discuss the significance of the `connections` attribute in the keypoints_coco tensor. How does it impact the visualization of keypoints in the visualizer?",
        "e3d96d60-0fa9-49b0-b8f4-873275d3fd66": "What are some key concepts covered in the Deep Lake documentation, and how are they relevant to data processing and manipulation?",
        "2701008a-6c9e-41d9-8de4-7b28e80d1dc9": "How does Deep Lake support integration with Weights and Biases and MMDetection, and what benefits does this integration provide for users?",
        "ee201951-926e-4576-8fa9-22680b347512": "Explain the high-performance features offered by Deep Lake, such as Dataloader, Sampler, and Deep Memory, and how they contribute to efficient data handling.",
        "caaff8cb-b219-4c01-b2d7-033f0f58407b": "Describe the API references available in the Deep Lake documentation and how they can be utilized for data management tasks.",
        "01205ab8-b399-4180-b9e3-5c199c9a48da": "How does Deep Lake support PyTorch and Tensorflow, and what advantages does this support offer for users working with machine learning frameworks?",
        "7b7e619d-3d7c-4787-a3a2-15cff47952d4": "What is the purpose of the `progressbar` parameter in the function for extending samples?",
        "f6a15e13-b2a5-49d1-b22c-57168c179ba3": "When would the `ignore_errors` parameter be useful in the function for extending samples?",
        "48f8996f-3c10-4b2d-8adc-d2132cf7ee95": "What error is raised if the dtype of an array is not compatible with the tensor's dtype?",
        "cf3bb0c0-1cf2-4e9a-8b98-20f0d1e75b5b": "How can you check if a tensor is hidden?",
        "58423ec3-7ea2-4a9a-b7d3-88f2e6d1cb01": "What does the `invalidate_libdeeplake_dataset()` function do?",
        "4948c4ff-5d97-4faa-8722-b2d8589b9000": "How can you determine if a tensor has unequal shapes for its samples?",
        "9931d469-77d6-4f30-9921-5f9e0f3eb528": "In what scenarios is the `list()` method applicable for tensors?",
        "036283a2-630d-4891-b2bd-ec2eeaff2dd6": "How can you retrieve only the modified or added elements of a tensor?",
        "82f23b2f-07e1-4ac0-ab1a-9235d053060f": "What information does the `_meta` property provide for a tensor?",
        "d9f7de7e-be65-4da6-be58-47f24e098ff6": "How can you update the information associated with a tensor?",
        "f114623a-e607-4ae2-b3a6-775b66e31ebf": "Explain the components of the camera intrinsic matrix \\\\(K\\\\) and their significance in computer vision applications.",
        "e1176e60-d44f-46c9-aa65-45b5633221c7": "How can an intrinsics tensor be created in a dataset using Python code? Provide the necessary code snippet.",
        "ee4d5ad1-b346-4f76-a09f-b64394915118": "What is the purpose of the segmentation mask tensor in computer vision tasks? How is it different from other types of tensors?",
        "c0ebf6ed-d446-446b-9265-25423117b31e": "Describe the process of appending intrinsic matrices to a dataset. Provide a step-by-step explanation with an example using Python code.",
        "eeb6277e-e511-4ce6-b120-8ceae14fcaec": "Why is it important to specify the class names when creating a segment_mask tensor? How does it impact the segmentation process in computer vision algorithms?",
        "9aeb0526-b061-4b14-81de-95d5b5936bfc": "What method can be used to return the bytes of a tensor?",
        "75f80c43-d539-4d03-baa1-f1e075bc5d4d": "How can you access the text data of a tensor?",
        "6fdc9094-5237-4260-b943-e6cea361c54e": "What property of a tensor returns the number of dimensions it has?",
        "bd8c4cc9-5585-43aa-9c7b-db273da8d655": "How can you play a video sample stored in a tensor?",
        "b8430735-eb9f-4ad5-a022-2510ff48324f": "What does the `Tensor.is_dynamic` property indicate about a tensor?",
        "79341e72-e9aa-4d5f-9415-ae965445e000": "Explain the difference between `Dataset.save_view` and `Dataset.get_view` in the context of virtual datasets (VDS).",
        "6f578d13-6c23-47fe-902c-928dc22e7404": "How can you ensure that all tensors in a dataset have the same length using the functions `Dataset.min_view` and `Dataset.max_view`?",
        "923f99de-8e3b-444a-a1ea-b36f21f299f3": "Describe the purpose of the function `Dataset.filter` and provide an example of a filter function `f(x: sample) -> bool` that could be used with this function.",
        "721fdc89-dd88-4f0b-9005-4980dcc41719": "How can segmentation masks be compressed to optimize storage space, and why is it recommended to use `lz4` compression specifically?",
        "1a245be4-c91a-4132-b3ae-c8962fe28647": "Explain how binary masks can be appended to a dataset using `np.ndarray` and provide an example of appending a binary mask with 5 objects.",
        "9cf6487c-6310-4b6c-8c62-f0a3ac6d4eb7": "What is the structure of COCO keypoints and how are they represented in a tensor for keypoints_coco?",
        "646125aa-a10c-40ef-a7e3-8787fc8b4a68": "How can a keypoints_coco tensor be created in a dataset, and what are the optional arguments that can be specified during creation?",
        "bd35af4f-f332-4d53-be81-1f8e9c08455f": "Describe the three possible values for visibility in COCO keypoints and explain what each value represents.",
        "ef338735-bc7d-4916-955c-129f44660881": "Explain the difference between the delete() method in the DeepLake API for various classes such as Dataset, DeepLakeCloudDataset, ViewEntry, DeepMemory, and VectorStore.",
        "809e5391-2ada-410e-9670-c2c2bd1c4e1f": "How does the delete_branch() method in the DeepLake API work and in which class is it defined?",
        "c599a801-a7de-4799-b074-363a4644413b": "What is the purpose of the delete_by_path() method in the VectorStore class of the DeepLake API?",
        "2510ff2e-5b18-490d-8db9-6745f74b59b1": "Describe the functionality of the download_kaggle_dataset() function in the deeplake.auto.unstructured.kaggle module.",
        "cb3916fc-e9ba-4993-9010-30592afd6b6f": "What is the DirectoryAtPathException class in the DeepLake API used for and in which module is it defined?",
        "c13b1cf7-2b92-4f72-8fa3-727f043e4425": "What is the purpose of the `transform` parameter in the `DeepLakeDataLoader` object?",
        "1b34281b-0952-4618-8187-bed721a8b366": "How can additional arguments be passed to the `transform` function?",
        "3603e5dd-1283-414d-8b02-1c46239d10db": "What type of object does the `transform` parameter need to be in order to create a `DeepLakeDataLoader` object?",
        "7bcd63a3-8efb-43e8-a1db-0c50afcdb481": "What will happen if the `.transform()` method has already been called before creating a `DeepLakeDataLoader` object?",
        "eef4843d-917f-4041-8775-db72ad69fb36": "Can you explain the significance of the `kwargs` parameter in the context of the `transform` function?",
        "f0bbdadf-d7cf-4393-8c6b-3487ab12bb33": "What is the purpose of the `base_htype` property in a tensor?",
        "e1fdad41-bba1-4faf-b867-2af11b8d6b27": "How can you delete all samples from a tensor using the `clear()` method?",
        "b2eebb41-8812-46eb-8cce-5745c1a2e24c": "Explain the `data()` method and provide examples of its usage for tensors with different base htypes.",
        "c75200b6-91c1-4350-ad0a-f429204bf9e2": "When would the `creds_key()` method be applicable for a tensor?",
        "4057100c-9504-4a65-b577-e4c8ed08f097": "Describe the format in which data is returned by the `data()` method for `video` tensors.",
        "8ed92c2b-fec0-471f-bd3c-730d90376a12": "How is data returned by the `data()` method for `class_label` tensors different from other types of tensors?",
        "38c58bdb-43fe-4bd7-b5c8-d4813a1134a1": "What information is included in the data returned by the `data()` method for `image` or `dicom` tensors?",
        "9eff9718-2604-41ec-8239-34478c4906ba": "Explain the key concepts of Datasets, Vector Store, Tensors, Htypes, Compressions, PyTorch and Tensorflow Support, and Utility Functions in the context of the document.",
        "e61c6b61-9901-4e88-81dd-e4a6a8e169d9": "How does the deeplake API support integration with Weights and Biases and MMDetection?",
        "5d88bfe8-c30a-4bef-a889-cee881f49979": "Describe the high-performance features of Dataloader, Sampler, Tensor Query Language, Random Split, and Deep Memory as mentioned in the document.",
        "acc07a60-ae1e-4846-858a-97af2fac6c1a": "Provide a detailed explanation of the methods and functionalities associated with the `Dataset` class in the deeplake.core.dataset module.",
        "0d7a40b8-d257-4f0b-9de6-51b0ec30e73f": "How does the `Dataset` class handle operations such as creating tensors, branches, commits, and views in the context of the document?",
        "be4c728a-f053-4c46-a950-3069f7ad0082": "How can the Read the Docs Sphinx Theme be installed in a Sphinx project?",
        "5b46cabc-9803-43cd-9402-1da52c8192a0": "What is the purpose of the `html_theme` setting in the `conf.py` file of a Sphinx project?",
        "43371348-e4b1-407d-8f0c-f0a2985d6b31": "What is the primary use of the Read the Docs Sphinx Theme?",
        "199bbd06-181a-4c29-97fc-002b9ec8307d": "What are the officially supported and tested browser/operating system combinations for the Read the Docs Sphinx Theme?",
        "928b516c-4c1b-47e6-a75e-6c69db431adc": "How can the Read the Docs Sphinx Theme be customized on both the page level and on a global level?",
        "84450a24-77bf-4861-ae2c-d8a30449947c": "Explain the purpose of the `exists` utility function in Deep Lake and provide an example of how it can be used.",
        "014e023a-f60e-4f19-962e-b999003f0a13": "How does the `read` utility function in Deep Lake work, and what is its primary function?",
        "a0a90225-a195-44ad-8a6a-0d74195aa4e6": "Describe the functionality of the `compute` decorator in Deep Lake and how it can be used in parallel processing tasks.",
        "bee03ddc-5163-49cd-bfc7-62857db465e4": "What is the significance of the `Tensor Query Language` in Deep Lake, and how does it enhance data manipulation capabilities?",
        "f6be7501-c4e0-464b-8bd3-2e22269af789": "How does the `eval` function in Deep Lake work, and what is its role in evaluating transform pipelines created using `compute()` and `compose()`?",
        "b129905f-fd53-440e-bb5b-490dff1ba056": "What is the purpose of the `Tensor.hidden` attribute in the `deeplake.core.tensor` module?",
        "a25d42c1-b027-43d4-8c3a-78cce4e94c27": "How can you determine the length of the primary axis of a `Tensor` object in the `deeplake.core.tensor` module?",
        "394ef68b-9034-482d-a08a-e5484919b3a8": "Explain the functionality of the `Tensor.extend()` method in the `deeplake.core.tensor` module.",
        "2dc9ea57-9834-4a94-ba03-8a17b9e46512": "How can you update samples with new values using the `__setitem__` method in the `deeplake.core.tensor` module?",
        "5ef02930-eff4-449e-9f7e-66613b3e95d2": "What is the significance of the `Tensor.is_dynamic` attribute in the `deeplake.core.tensor` module?",
        "1f4d0251-ff5a-4246-bd3e-ffa0a952ac7f": "Explain the key concepts of Datasets, Tensors, Htypes, Sample Compressions, PyTorch and Tensorflow Support, and Utility Functions as outlined in the context information.",
        "851fdfcc-5549-443c-b11f-05d857045d16": "What are the key concepts covered in the Deep Lake documentation?",
        "3a66a4d6-5571-42bc-8448-7c7bda950163": "How does Deep Lake support PyTorch and Tensorflow?",
        "5db0471a-08ec-40e9-b84c-6606b4d07000": "What enterprise features are included in Deep Lake?",
        "e1512f72-8e04-435f-af00-36518009ab66": "What are some of the API references provided in the Deep Lake documentation?",
        "697d34bc-42b3-4c62-a6e6-776ea8b23b26": "Can you explain the purpose of Deep Lake as mentioned in the context information?",
        "a4465ba3-6178-47e1-afc8-75e3e708f61e": "What method raises an error if the tensor is not compatible with a certain operation?",
        "187cfcfa-793e-4201-9102-33515b1986ff": "How can you retrieve a summary of the configuration of a tensor?",
        "1463a0a9-a48e-4eee-a16c-2a4221eab9c4": "When using the _linked_sample() method, in what scenario is it applicable and what type of tensor is required?",
        "2bba8273-6e91-4430-818a-589edcebcb23": "Explain the functionality of the _pop(_index : List[int]_) method and the requirement for the input indices.",
        "f1345d34-3fca-4dbb-9e05-e0871da955e0": "Provide examples of how to append data to a tensor using the append() method with both Numpy input and file input.",
        "a34bd753-5802-4a87-98c2-d8972ad84d54": "What does the _base_htype property represent in a tensor and how is it related to the tensor's htype?",
        "d89f775e-1ec7-42fd-b9c1-c0002589cb75": "Describe the purpose of the clear() method in a tensor.",
        "0da9b6bb-92b7-4370-9dc9-76c98fb194c1": "When is the creds_key() method applicable and what type of tensors does it work with?",
        "ed38c093-c38f-4393-a9e4-8822cd8f4e05": "What does the data(_aslist : bool = False_, _fetch_chunks : bool = False_) method return and how is the format determined?",
        "e74f1287-2b93-4e3b-a0ce-afd88fce4429": "What file types are supported for the images in the LinkedTiledSample object?",
        "19b7c34b-ca99-4da7-87cc-02c2e8bb1293": "How can you create a LinkedTiledSample object in the Deep Lake Dataset?",
        "4c7a79c3-16ba-4b97-be78-24d5fd33cf73": "What is the purpose of the `creds_key` parameter in the `link_tiled` function?",
        "59d78e9f-7763-4bdf-b269-72e6ea0c5f82": "How can you allocate an empty sample of a specific shape using the `deeplake.tiled` function?",
        "1430ce23-54a4-4e30-b0f5-b595728c9ded": "Explain the significance of the `path_array` parameter in the `link_tiled` function.",
        "9b16db98-3906-4205-9483-152bb6d5fab1": "What are the key concepts in Deep Lake, as mentioned in the context information?",
        "700b7bfc-c0ac-4249-87d0-18500a75ebc0": "How does Deep Lake support PyTorch and Tensorflow?",
        "322be874-c84b-4113-a234-397f481a7bbb": "What are the different types of compressions supported by Deep Lake for various data formats?",
        "18a0cadd-5a98-4c14-8f8d-47e93096fc7b": "How does sample compression work in Deep Lake when creating tensors?",
        "5d76272b-7141-4e90-b799-c6afde90831f": "Explain the purpose and functionality of the Deep Memory feature in Deep Lake.",
        "d71ad1f1-2272-48fb-bd0d-bf65596f9b13": "What are the two types of units for bounding box coordinates specified in the context information?",
        "30c99b5b-0c98-44fe-8ca0-715bdbfd8332": "Explain the difference between the \"LTRB\" and \"LTWH\" modes for specifying bounding box coordinates.",
        "1f30f314-ddf9-4886-aaa6-cfff29d1d2fb": "How can bounding boxes be appended in the dataset, according to the examples provided?",
        "963cd275-c398-404d-bbee-d3ba63e231f4": "When will the visualizer assume a YOLO format for bounding boxes, and when will it assume a COCO format?",
        "2c511ba5-b6a4-4f63-94e2-69c7cb1a015a": "Why is it important to specify the format of the bounding box for 3D bounding boxes to be correctly displayed by the visualizer?",
        "3395a2de-8d3b-4aad-a2de-138bc087fb0f": "What is the purpose of the `pytorch()` method in the `DeepLakeDataLoader` class?",
        "1a740a7d-d4fa-4491-987e-5ada1e6dd6cc": "What parameters can be specified when calling the `pytorch()` method in the `DeepLakeDataLoader` class?",
        "7f0fdaf8-8bc3-4d13-8b8a-c96a208d29b9": "When is the `pytorch()` method particularly useful in the `DeepLakeDataLoader` class?",
        "42802a9f-dc61-4a5b-87c8-bf9083522999": "What exception is raised if the `offset()` method has already been called in the `DeepLakeDataLoader` class?",
        "f890b489-0b3f-4a84-8196-b27fa753440d": "How can you shift the starting index of iteration in a `DeepLakeDataLoader` object using the `offset()` method?",
        "394e0868-e80d-41ca-b614-f26d2a15b90b": "What are the two options for setting the `tensor.info.class_names` list?",
        "bfa06ef0-5450-4f93-b9e9-7720bf54138f": "How can you update the class names after tensor creation?",
        "06cc80aa-8b78-4bef-bc8f-a0023b1d1316": "Why is `chunk_compression` recommended when specifying compression for class labels?",
        "133aed69-d45c-44ce-a719-2f769de6341c": "How can you append class labels to a dataset?",
        "443f27b5-53a8-40e8-9a53-92294234ddbc": "What is the purpose of the `tag` htype in creating a tag tensor?",
        "7ad4b428-42f5-4378-9c6d-807f7b445804": "How can you create a tag tensor in a dataset?",
        "5200eb9b-2761-469b-98be-e39141cf63cd": "What are the supported compressions for `chunk_compression` when creating a tag tensor?",
        "6b1ac39e-d058-483d-b2b3-6abbdde48cbf": "How can you append tag samples to a dataset using the `tag` htype?",
        "a0bf4377-ba35-4874-b2f1-e0ee7dfc877a": "Can you provide an example of extending a dataset with a list of indices for class labels?",
        "8db878db-525a-42ef-9229-b4ff70e6cbc3": "How can you append text labels to a dataset for class labels?",
        "e7a3143d-7e90-470f-a518-e8bb561e1311": "Explain the components of the camera intrinsic matrix \\\\(K\\\\) and their significance in computer vision applications.",
        "9286f33d-f1cd-40fb-86a8-7794a3ed1fe5": "How can an intrinsics tensor be created in a dataset using Python code? Provide the necessary code snippet.",
        "c8572580-2364-4c40-ac03-15697390836e": "Describe the purpose of segmentation masks in computer vision and how they are represented in a dataset.",
        "0f58c909-4644-4fa4-aaca-790c28ce2266": "What are the optional arguments that can be specified when creating a segment_mask tensor in a dataset? Provide an example using the given context.",
        "45eff6ef-4528-41a5-9cab-c060ec2aa1cf": "Discuss the relationship between the focal length in pixels and the focal length in world units, and how it is calculated in the context of camera intrinsic parameters.",
        "8d38ae88-fe5b-4740-91be-73c606706e45": "What is the purpose of the `list(_fetch_chunks : bool = False_)` method in the tensor class?",
        "ab804177-55d9-4028-a0b5-327e791e5fba": "How can you retrieve a slice of the tensor with only the modified or added elements using the `modified_samples` method?",
        "4344f222-69c6-440b-af20-1a572475dd90": "What does the `_property _ndim _: int` represent in the tensor class?",
        "6cbaac2d-9b44-4471-b8f1-e52dba1388f1": "Explain the significance of the `numpy(_aslist =False_, _fetch_chunks =False_)` method in the tensor class.",
        "f278438b-a0e9-4aaf-bd4b-00648560abcf": "How can you determine whether a tensor is a link tensor or a sequence tensor using the properties provided in the context information?",
        "920fa3d9-a810-4aa2-859e-aa35dc2b9a69": "How can you set the `connections` and `sample_compression` for `tensor.info.keypoints`?",
        "53beffa1-f807-4081-9a01-9f7649bae8d0": "What is the default data type for `dtype` in `tensor.info.keypoints`?",
        "472e59f9-e481-41b6-b211-abff2f75d94b": "How can you append keypoints to a sample with 3 keypoints and 4 objects?",
        "2f79aa9a-84c7-4422-84d9-29635669992a": "Why is it important for all objects in every sample to have the same number of keypoints in the same order when using the keypoints and connections metadata?",
        "470ab3f8-949b-44c6-8ff2-dec5dccd30b4": "What are some of the major features of Sphinx mentioned in the welcome section?",
        "7e7b88dd-9590-494a-ba6c-3cdb07b2769f": "How does Sphinx handle code highlighting?",
        "aa40dc8f-2679-475b-a9ed-fbb56e259dba": "What are some of the output formats supported by Sphinx?",
        "823c325a-cf28-40ad-8cc4-5c58b4b320d5": "How does Sphinx create a hierarchical structure for documentation?",
        "f290918e-b986-44a3-b43b-4de0dd8eeedd": "What is the default markup language used by Sphinx, and what other markup language can it read with the help of third-party extensions?",
        "0de446ac-84be-47f1-92f2-ccffb38f8d8d": "Explain the difference between `Dataset.save_view` and `Dataset.get_view` in the context of virtual datasets (VDS).",
        "f1ca65bb-f94b-4aba-b370-9fec35f7fea1": "How can you ensure that all tensors in a dataset have the same length using the functions `Dataset.min_view` and `Dataset.max_view`?",
        "1e65eec3-c2fb-4ca3-883e-4f82adc65646": "Describe the purpose of the function `Dataset.filter` and provide an example of a filter function that could be used with this method.",
        "7a484355-3ecf-42ea-b2a4-ea6d3eab548a": "How can you retrieve a list of views stored in a dataset using the function `Dataset.get_views`?",
        "3f2583e1-5344-4bc5-bfb6-32f37e8c06f0": "Can you explain the significance of the function `Dataset.is_view` in the context of datasets and virtual datasets?",
        "d4164f0d-bc6b-491f-9d66-8e46f74eebf8": "What are the parameters that can be specified when creating a visualizer canvas, and what type of values can they accept?",
        "044c416e-8e0e-4f07-a611-a5623b9e925a": "What exception is raised if a visualization is attempted in colab with a dataset that is not a Deep Lake cloud dataset?",
        "e1e3f02e-1062-429f-9b28-86c036d6b5d3": "Explain the purpose of the DeepLakeCloudDataset class and how it is related to the Dataset class.",
        "7e6cdfea-111e-47cd-b657-e1eeeacf5995": "How can a new creds key be added to a Deep Lake cloud dataset, and what is the significance of this key?",
        "f20dd66e-0711-4d04-a8be-8ebdba1065ae": "What does the connect method do in the DeepLakeCloudDataset class, and how is it used to establish a connection to a dataset stored in Activeloop servers?",
        "8fc7d6f6-2232-4ebd-9a71-b508bfcad15f": "How can you log the creation of a Deep Lake dataset using Weights and Biases? Provide a code example and explain the steps involved in the process.",
        "e26f1f91-7709-4841-bf68-9adeb2d09521": "Explain the importance of specifying the format of the bounding box in the coords key in tensor meta information for correct display by the visualizer.",
        "f9d70b5d-7812-4167-ae62-9190c5f616c6": "How can a 3D bbox tensor be created using the provided code snippet? What is the significance of specifying the htype as \"bbox.3d\"?",
        "90474971-9ba3-4ad4-9d69-100033441590": "Describe the different modes available for specifying the convention for the bbox coordinates when creating a 3D bbox tensor. Provide examples for each mode.",
        "c29073f2-a52a-4fc0-9efc-3595326b8c33": "What is the purpose of the intrinsics tensor in projecting 3D bounding boxes onto 2D data? How can the intrinsics matrix be specified in the dataset?",
        "6ac4e69e-696f-4994-a70a-5b8f149ecac0": "Explain the structure and dimensions of the bounding box when using the \"center\" mode for specifying bbox coordinates. Include details about the rotation angles along each axis.",
        "54eca9a5-81ae-43b4-8ddc-744c9ab2e324": "What are the main modules included in the VectorStore package?",
        "0e5d698d-9e26-492d-8a62-2d24f6d3055e": "What is the purpose of the deeplake.core.vectorstore.deep_memory module?",
        "63ec9631-b26d-47f0-9a76-9efdb110ac8c": "Who is the copyright holder of the content in the document?",
        "9c6cd520-13fa-4957-8b0b-49bbe87a1a59": "How is the document built and what theme is used?",
        "78a27a7b-0f59-450d-bff7-f64ec0b58de6": "What versions of the software are available for download on Read the Docs?",
        "0b4c4166-3fe5-47af-a871-a4b86d0b986a": "What is the purpose of the `create_tensor` method in the given context?",
        "24ff76f4-4aa2-4be3-af4b-e3f33c35dbf0": "What are the possible exceptions that can be raised when using the `create_tensor` method?",
        "d8f92878-5b28-42d0-a23c-03eb699ccc74": "Explain the functionality of the `create_tensor_like` method and provide an example of how it can be used.",
        "8a457f7c-6239-46cc-becc-d10d4c18580d": "What parameters are required for the `create_tensor_like` method?",
        "9e139f35-b65d-46e0-a92c-4e8bc6d690e9": "How can the `dataloader` method be used in the context provided?",
        "0915bdbd-176a-4416-ae94-6671ccc9fcac": "What are the optional parameters for the `dataloader` method and what are their default values?",
        "f638150f-649a-474c-9bf7-35adf76ce353": "How can the new tensor created using the `create_tensor_like` method be accessed in the dataset?",
        "25f22e4e-24fc-4e65-9445-3005f887d6da": "What is the significance of the `unlink` parameter in the `create_tensor_like` method?",
        "8d157361-d837-45d8-9357-91b4336d6b49": "What type of object does the `dataloader` method return?",
        "37f09d82-efa5-4ad7-98c6-217970f02955": "Can you explain the purpose of the `ignore_errors` parameter in the `dataloader` method?",
        "e5042dbc-7030-483b-b394-c5444b984e37": "Explain the purpose of the `query` method in the `Dataset` class and provide an example of how it can be used to filter data based on specific criteria.",
        "c2a99ce6-a9c0-4875-b78f-5a2d2b13e5ac": "What parameters can be passed to the `query` method and what is the significance of each parameter?",
        "192f91d2-cdae-4ead-a6df-5faa32451b76": "How can you use the `query` method to extract samples from a dataset based on certain conditions, such as selecting samples with labels other than a specific value?",
        "a4009eec-6163-4dfb-b8c2-0e7213e8d1b8": "Describe the functionality of the `random_split` method in the `Dataset` class and explain how it can be used to split a dataset into non-overlapping parts.",
        "39e6bf73-526a-4c02-a76c-d0101cdb0c9e": "If you have a dataset with a total of 3000 samples, how would you split it into two parts using the `random_split` method with lengths of 0.6 and 0.4 respectively?",
        "7a473da2-4f5c-4bdc-be75-d00e650ed49e": "What is the purpose of the Tensor Query Language (TQL) in the Activeloop Platform and Python API?",
        "1132dc4c-fd0c-44dc-90a6-4b88cc37c519": "Explain the syntax of the SELECT statement in TQL.",
        "d448f9d7-0000-4584-a039-e82166997079": "How does the WHERE expression work in TQL and what is its purpose?",
        "872ee725-a305-4d9d-a922-83942fc00927": "Can you provide an example of a TQL query using the SELECT statement with all its components?",
        "90b794b3-a0bb-4dd1-ae02-480e8165fb2d": "How does TQL handle the FROM expression in a query, and why is it not necessary in the current context?",
        "01ab283f-42fb-4805-9be4-23c2937b6211": "What are some of the key concepts related to TQL that are mentioned in the document?",
        "ad84f19d-1108-4f84-b1b1-cd5cb436b6ed": "How does TQL differ from traditional SQL in terms of its functionality and usage?",
        "d071206c-29f7-45b5-a7e1-ebb2180ed660": "How can TQL be used to filter samples in a dataset based on specific conditions?",
        "29fae014-27c6-4705-8ae1-145b767b4ae2": "What are some of the high-performance features mentioned in the document that are related to TQL?",
        "a26c2c4a-6f49-48d9-b4a5-bcb95ec013e2": "How does TQL support PyTorch and Tensorflow in the Activeloop Platform?",
        "8187550b-3838-44c3-b2d6-fe439f6db414": "Explain the purpose of the `query` method in the `Dataset` class and provide an example of how it can be used to filter data based on specific criteria.",
        "b02141b1-3af8-453e-81e8-bbd0769b4f19": "What parameters can be passed to the `query` method and what is the significance of each parameter?",
        "aaff198c-654b-4133-a548-a7e16b5e3a0f": "How can you use the `query` method to extract samples from a dataset based on certain conditions, as shown in the examples provided?",
        "6f30bce3-5d8d-4322-a2e5-f9eb95b17aca": "Describe the `random_split` method in the `Dataset` class and explain how it can be used to split a dataset into non-overlapping parts.",
        "93125d89-b1b2-4e29-a145-e1506cb59a56": "If you want to split a dataset into multiple parts with specific lengths, how can you achieve this using the `random_split` method? Provide an example.",
        "c830d07a-37d9-4253-9720-1c8f50c609cb": "How does the \"docs as code\" approach allow developers to write documentation without changing their workflow or tools?",
        "0d117c4b-3453-435b-a073-c6445493f238": "What are some of the documentation tools supported by the platform mentioned in the context?",
        "a6d2ad53-d534-4dba-8fe5-a3265ddb75f2": "How does the platform enable users to preview each pull request before releasing any changes?",
        "2f5c30f9-a819-472e-a245-a561e7106bb2": "What is the significance of having versioned docs in relation to a product release cycle?",
        "6730f103-94d4-49c2-94f9-1c41f5c76a11": "What are the features of the paid plan that allow for more secure and controlled access to documentation?",
        "974aa1ab-11c0-47c4-8bfa-e9e4094fa99a": "How can users clone private repositories using the platform?",
        "52286277-a34b-402d-990d-99ee5c5cf58f": "What is the purpose of the `.readthedocs.yaml` file mentioned in the context?",
        "61d1d31e-2d9d-45d3-9806-5cfc575094d5": "How can users sign up for an account on the platform?",
        "e6ce451d-883f-4303-b97e-a465323747ac": "What is the process for importing existing Git repositories into the platform?",
        "dd04149d-fbf0-444b-8abc-b48ffdc8280a": "How does the platform ensure that documentation builds on every commit?",
        "44264ac5-d899-4e0c-879a-b6bec5e83813": "How can a tag tensor be created in a dataset using Python code?",
        "af2f761d-8427-4fcd-835a-ee6776a3c6e6": "What are the supported compressions for chunk compression when creating a tag tensor?",
        "941e995d-1970-43bb-8a4a-cccae6442561": "Provide an example of how to append a tag sample to a dataset.",
        "3852d383-8b2d-41e0-91fc-28fdbceb2312": "Explain the format of bounding boxes in the context of the Bounding Box Htype.",
        "08ccd921-67a1-4607-aa0a-5c69ed8385d1": "How can a bbox tensor be created in a dataset, and what are the optional arguments that can be specified?",
        "f07ae3e7-01cf-4a6a-851b-5c5afec4914a": "Describe the different conventions for bounding box coordinates specified in the \"coords\" key when creating a bbox tensor.",
        "d9c3ecaf-878f-4df3-9a22-b0674fa80603": "What are the supported compressions for sample_compression or chunk_compression when creating a bbox tensor?",
        "8c4a704d-c50e-4a12-8081-59407c46f875": "How can class names be set after creating a tensor in a dataset?",
        "d5e4cdf6-a832-46b0-8a73-7eb4894a0bcf": "What error will be raised if a dynamically-shaped array slice is read without setting `aslist=True`?",
        "26853523-ba09-4497-a9f7-99846d5d0b0d": "When is the `aslist` parameter always set to `True` for tensors of htype `polygon`?",
        "6674429d-6969-4ea2-853b-2f12581ae88c": "What type of data does the `path` method return, and when is it applicable?",
        "2f19dc16-c830-4100-a0f9-68932ce53359": "What parameter can be used to retrieve full chunks of data from storage in the `path` method?",
        "2be91189-0415-44f6-9fa3-82eb75ed9163": "What method can be used to play a video sample from a tensor, and where is the video streamed from?",
        "64d939a5-595b-4b8c-a50f-99b2e9d5d5aa": "What will happen if the `play` method is called on incompatible htypes for video streaming?",
        "223b243e-e845-49ca-a2c2-a84899623cac": "What does the `pop` method do, and how can it be used to remove elements from a tensor?",
        "8f1ff53b-b781-4ff4-ad0b-5cc37e760464": "What information does the `_sample_indices` property return for a tensor in the dataset view?",
        "2c5a529b-bf35-44b5-becc-07dbe2fe64e8": "What type of information is returned by the `_sample_info` property for a tensor, and how does the format of the returned data depend on the tensor's htype and sample?",
        "a24a0d75-f94e-424c-bd01-e9c9d5328a3f": "Explain the difference between `deeplake.ingest_classification`, `deeplake.ingest_coco`, `deeplake.ingest_yolo`, `deeplake.ingest_kaggle`, `deeplake.ingest_dataframe`, and `deeplake.ingest_huggingface` in terms of their functionalities and input formats.",
        "ddb66a36-7452-4c0d-8895-d5b58bc89768": "How can you load an existing dataset using the `deeplake.load` function? Provide a step-by-step explanation of the process.",
        "edf8cfee-e614-45ed-8a58-1960fdb232bc": "Discuss the dataset operations `Dataset.append`, `Dataset.extend`, `Dataset.update`, `Dataset.query`, `Dataset.copy`, and `Dataset.delete`. Provide examples of when each operation would be useful in a real-world scenario.",
        "e3d9ee90-1a5d-4323-aed2-ffa6bbec7465": "What are the variations of the `link` type that can be used in the activeloop visualizer to display data correctly?",
        "863f817a-860f-4028-b4d5-ecc4c3033280": "When is data actually loaded from a dataset?",
        "d346ef9a-aa30-46d4-8f66-9c9aef2a5fae": "What are the exceptions to the rule that no data is loaded until a sample is read from a dataset?",
        "b0e54e0b-eb6a-47d5-99ab-e30555a37908": "How can credentials be added to a dataset?",
        "6765c07b-a6c5-495c-aa09-5c7bdc2cdca2": "What is the benefit of storing credentials on the Activeloop Platform as Managed Credentials for datasets connected to it?",
        "7e30f233-1167-4714-976c-e49099a14097": "What codecs are supported by Chrome for videos?",
        "ee540278-99c3-4997-b3e1-a0daa8c512fd": "How can a video tensor be created in Deep Lake, and what are the supported compressions?",
        "0f5898e5-aa6d-4e9d-878e-37c7ca3f1e49": "Can the Deep Lake Performant Dataloader support videos?",
        "fcdfe002-5ca3-4ee0-96f6-a78c8d05bdb1": "What is the sample dimension for audio tensors in Deep Lake?",
        "da54099f-34ff-46c9-a870-fb8f97a64a1c": "How can an audio tensor be created in Deep Lake, and what are the supported compressions?",
        "b7655e0b-1c77-4e1a-b4e4-21006c01c977": "What type of samples can be appended to tensors with \"None\" compression in Deep Lake?",
        "8d919a54-5dd3-4628-a8ec-d0907d368973": "Is recompression of samples read with `deeplake.read` supported for audio tensors?",
        "a6087081-d89a-4e42-b9bb-437c01164e5a": "Can an array of raw frames be compressed and appended to tensors in Deep Lake?",
        "97364086-693a-4fdd-82e4-cf9dd0e2723f": "What type of samples can be appended to tensors with \"None\" compression for videos in Deep Lake?",
        "b7e1a3e7-c4bc-4923-83ae-934f61785133": "What is the default dtype for audio tensors in Deep Lake?",
        "04b643d9-213f-4693-a0a4-ed1d8c5dcdbc": "What are the main modules included in the VectorStore package?",
        "6c9ceb09-d725-49dc-9bff-9cf49b008b21": "What is the copyright year mentioned in the context information?",
        "3ebd0b14-f989-4205-b7b6-3b1f8e00e282": "Which theme is used for building the documentation with Sphinx?",
        "d0e42925-061c-4860-bddf-12e1858c8516": "What is the purpose of the deeplake.core.vectorstore.deep_memory module?",
        "ec0a3029-60cf-4f07-b819-72cb20ec809d": "How is the documentation built on Read the Docs structured for navigation?",
        "91964e20-9c13-46d4-b161-7781cbfe9cc5": "What are the main modules included in the VectorStore package?",
        "f2182e8f-1909-4f2d-b12d-018e6b8a89db": "What is the purpose of the deeplake.core.vectorstore.deep_memory module?",
        "3ee7721c-8f88-4ddd-889f-69cdcb09a970": "Who is the copyright holder of the content in the document?",
        "c2179081-44d1-4aab-a0ad-a6f82d631d1e": "How is the document built and what theme is used for it?",
        "737785da-fd15-4d75-8959-88899974dc97": "Can you explain the significance of the deeplake.random.seed module in the context of the document?",
        "76b63f35-4c8e-43e3-9d02-f90b7fc64e01": "Explain the difference between `Dataset.create_group` and `Dataset.create_tensor_like` in the context of tensor manipulation.",
        "beb2260a-5bb5-4196-8749-f6e76721b4f1": "How can you delete a specific tensor from a dataset using the methods provided in the context information?",
        "a3ded64f-910b-4b1d-958f-ed49552ead53": "Describe the process of renaming a group in a dataset using the `Dataset.rename_group` function.",
        "8ed0f1f1-cb89-41ac-8f0c-7e7ca35fabdc": "What is the purpose of the `Tensor.extend` method in the context of adding and deleting samples in a tensor?",
        "1b0c2b4c-2e31-4890-8e52-6c32f724afb4": "How can you retrieve the contents of a tensor in numpy format using the methods mentioned in the context information?",
        "f3c0d54a-0290-4391-bca5-08b2a4f04df7": "Discuss the significance of the `Tensor.shape_interval` property in describing a tensor's shape accurately.",
        "e98ca3e2-1ee1-419e-828c-8ab83ff37715": "Explain the difference between `Tensor.dtype` and `Tensor.base_htype` in the context of tensor properties.",
        "fef4af26-3908-4e5b-a63a-26a0409b16ba": "What are the limitations of the Deep Lake Performant Dataloader in terms of supporting data formats?",
        "5105455b-7ce8-44e7-9486-56fed38ce447": "How can a nifti tensor be created in Deep Lake, and what are the supported compressions for nifti data?",
        "5fde5fdf-26a7-430b-a571-38f0cd766fde": "How can nifti data be appended to a tensor in Deep Lake, and what type of data can the nifti samples be?",
        "cb007f10-53b9-4320-a88c-e46beaabe758": "What are the key characteristics of the Point Cloud Htype in Deep Lake, in terms of sample dimensions and data types?",
        "7ae1340c-9162-472d-aaa2-e9c51d997453": "How can a point cloud tensor be created in Deep Lake, and what are the supported compressions for point cloud data?",
        "13787da9-c50b-484f-b672-1392b344f861": "How can point clouds be appended to a tensor in Deep Lake, and what type of data can the point cloud samples be?",
        "7a50c53d-2fd8-4a8c-93ad-c2cf004c1a2c": "What are the key parameters supported by the deeplake.copy function for copying datasets?",
        "c1bda325-a20d-4d86-823d-bbccb582dba1": "How does the deeplake.copy function handle credentials when working with cloud datasets?",
        "a89d0053-9c4e-45d7-a020-cca0378a0b60": "What is the purpose of the 'token' parameter in the deeplake.copy function?",
        "2de498cc-4f74-465a-8a05-a2b46cfc0da5": "Can you explain the significance of the 'overwrite' parameter in the deeplake.copy function?",
        "792954ec-ed42-4637-8ccc-3cd34337aad6": "How does the deeplake.copy function handle version control history when copying datasets?",
        "0308e846-f808-4ed8-aece-df7a2b07fd82": "What is the role of the 'runtime' parameter in the deeplake.copy function when working with hub:// paths?",
        "a6c3efb1-1fd4-4b16-b575-2e5a5e2dbd20": "How does the deeplake.copy function handle the copying of specific tensors within a dataset?",
        "1d47859f-81f2-4e3e-8155-f157e21ae532": "In what scenarios would the deeplake.copy function raise a DatasetHandlerError?",
        "d5f89057-457b-4f75-9df1-40d78f5d2cf1": "How does the deeplake.copy function handle the number of workers and the scheduler during the copying process?",
        "4dc7114e-f562-43cf-b477-87ea187ba05a": "Can you explain the significance of the 'progressbar' parameter in the deeplake.copy function?",
        "d50283c9-7dad-4aa7-93f5-9497f2a49f63": "How can you specify a specific version of a dataset when loading it from the Deep Lake cloud?",
        "31ae8e30-1016-4498-a561-f3ad7a51cfc3": "What are the different types of paths that can be used to access datasets, and can you provide an example of each?",
        "adde3a4a-7519-4618-b8d2-273793ff179a": "What parameters are available for the Activeloop DB Engine when using a hub:// path?",
        "a2e9b6af-f2d9-47f5-98c6-0da993aa772e": "When opening a dataset in read-only mode, what parameter should be passed as True?",
        "48c909b9-5202-4826-b028-644b6c975dbd": "How can you ensure that a dataset is overwritten if it already exists?",
        "c5762669-d364-42e2-8ec4-0f6ae866159b": "In what scenario would you use a memory path for a dataset, and what should it be used for?",
        "bfb256e7-24f6-4c05-9daf-33e691cf33be": "When creating a new dataset on Deep Lake cloud storage, what parameter can be used to define if the dataset will have public access?",
        "74af8343-4992-41f4-b26b-62d8eba24ebc": "What is the purpose of the memory_cache_size parameter?",
        "2ebb9806-268d-4b11-aea9-3cbddbcc0c11": "How can you specify the size of the local filesystem cache to be used when accessing datasets?",
        "d93862a6-7e7b-4cab-bfda-f5bb12c78898": "Can you provide an example of how to load a dataset to a specific version using either a commit_id or branch?",
        "2d8e46b1-793f-492f-9bfb-0c05bb36e6a6": "How can you store your credentials on the Activeloop Platform as Managed Credentials and use them for your dataset?",
        "e6ef3dbc-8be6-4583-b039-a118f88cb0a0": "What is the purpose of adding managed credentials with names such as `\"my_s3_creds\"` and `\"my_gcs_creds\"` to your dataset?",
        "78bfbe10-dfab-4e8b-8b68-6ccb8cfd6978": "How can you create a link tensor named \"img\" with sample compression set to \"jpg\"?",
        "7b580405-e40a-4441-b707-a193264f2c49": "Provide examples of how you can populate the \"img\" tensor with links, including which links require credentials and which do not.",
        "f5274b00-ec42-4526-9837-7a32dfb05969": "How can you access the data stored in the \"img\" tensor using a loop?",
        "6048f907-486a-4dde-8342-5ca7bd02492d": "How can you update a sample in the dataset, specifically the first sample in the \"img\" tensor?",
        "d9393ebf-cccb-4e59-a20b-255bc995c3fe": "Explain the process of creating a polygon tensor using the provided code snippet. What are the optional arguments that can be used during the creation of a polygon tensor?",
        "474b1a3d-d6eb-4136-b43d-e17669a03161": "How can polygons be appended to a dataset using lists of tuples or numpy arrays? Provide examples for both 2-D and 3-D points.",
        "cd056c45-49b5-4f1f-aa6e-3f051306b34d": "What are the requirements for the points in a sample when creating a polygon tensor? Can different samples have a different number of polygons?",
        "a3220242-3a9a-4a97-95f8-9e8abc7ce01c": "Discuss the Nifti Htype mentioned in the context. What are the possible dimensions for sample data in the Nifti Htype?",
        "f44a3d4b-6113-4a4f-a853-309e283919b9": "How can compressions be applied when creating a polygon tensor? Provide examples of supported compressions and their usage.",
        "932b2516-3541-4ea9-a737-8574343addcb": "How can a polygon tensor be created in the given context? Provide the necessary code snippet.",
        "8007c119-c607-454a-8c28-76e83abad1ed": "Explain the process of appending polygons with 2-D points using lists of tuples.",
        "5d1c3c61-546e-44a3-8f1e-2a006c076f16": "What is the significance of ensuring that all points in a sample have the same number of coordinates when working with polygons?",
        "1636a6e6-0d26-4e5b-9e1c-a2c40370d2a0": "Describe how polygons can be appended with numpy arrays in the provided context.",
        "02df3268-c900-495f-a4bc-50bb7bf7f909": "In the Nifti Htype section, what are the possible sample dimensions mentioned for the data?",
        "3bd6f124-3b10-4e33-8bfc-f2f109023b54": "Explain the difference between the \"point\" and \"polygon\" Htypes in the context of keypoint data storage.",
        "8927e594-8811-426b-aeaf-36a08316cb94": "How can dummy coordinates be used to store keypoints that are not present in an image?",
        "b7407819-4211-4f96-aa3b-8d1cb73885a1": "What is the sample dimensions for the \"point\" Htype in case of 2-D coordinates?",
        "235d8322-ac2c-4f11-9d56-af05ccdec30a": "How can a point tensor be created using the provided code snippet?",
        "96f9bf94-070d-4456-a77f-3a81bb3cdd6f": "Can you provide an example of how to append 2 3-D points to a dataset using the \"points\" attribute?",
        "e998e51b-37b8-46e0-82e4-d894d030b7b4": "What are the restrictions when working with the \"polygon\" Htype in terms of the number of coordinates per point?",
        "21991dc6-1121-4e86-adbd-7d29c7e8bb06": "How can different samples in a tensor of \"polygon\" Htype have different numbers of polygons?",
        "e0591e0c-126d-4a81-a495-9c307f596688": "Explain the importance of visibility in preventing keypoints with dummy coordinates from being drawn in the visualizer.",
        "55277326-d23d-46a5-a7b6-cf3e867a06ad": "What are the supported compressions for creating a point tensor?",
        "9b03ac1f-eff0-432f-a949-456c0986be36": "Can you explain why there is no fixed mapping between the point order and real-world objects in the context of keypoint data storage?",
        "2b522e4b-7153-4a92-beb4-b959266a67c7": "What is the purpose of specifying an htype for a tensor in Deep Lake datasets?",
        "60e2b29f-2b21-4508-a9bd-c1f8bdb46ae4": "Can you provide an example of creating a tensor with a specified htype in Deep Lake?",
        "8dd68a10-9af2-4386-b182-001e1e91a171": "What are some of the supported htypes in Deep Lake and their respective defaults?",
        "5bf19acd-f13c-40dd-abbf-4537d6af9fe2": "How are images stored in Deep Lake, and what are the options for storing them?",
        "a8b30e5d-a4ea-4cf8-bf27-c9dd343dde42": "Why is specifying an htype important for increasing the performance of datasets containing rich data in Deep Lake?",
        "e12f9a77-7927-4ff0-88fb-77174593eb9c": "How can audio samples be appended to tensors in Deep Lake?",
        "b3cb4e60-18e0-4beb-8e6d-7cd4632f5730": "What are the supported compressions for audio samples in Deep Lake?",
        "986eb6da-42c3-42ee-adbf-5c3b4a153e77": "How can class label tensors be created in Deep Lake?",
        "271d6994-2790-4ccd-a0b0-90fcac71a27b": "What are the optional arguments that can be used when creating a class label tensor in Deep Lake?",
        "13057dca-920a-4264-8805-c4f730bc0eae": "How can class names be set for a class label tensor after tensor creation in Deep Lake?",
        "45fe70d7-e3f7-4f52-8bb5-29d61fb1bd43": "What are the different languages used in the development of the Sphinx theme for readthedocs.org, and what percentage of the codebase do they each represent?",
        "98dd5770-94d1-4ee7-9982-beaa77e02016": "What are the parameters required for the `copy` method in the dataset object?",
        "6c3fe2a7-5fc6-4825-8c1f-a8dc1fc7d838": "Explain the significance of the `overwrite` parameter in the `copy` method.",
        "79df7a16-37ac-402d-b146-47a5685f9df7": "How can you specify which tensors to copy when using the `copy` method?",
        "65db84e0-850c-4558-9961-4fb10b00caa8": "What is the purpose of the `num_workers` parameter in the `copy` method?",
        "99c34bc8-49d0-4f0e-b597-3e448a22533e": "Describe the difference between the `scheduler` values supported in the `copy` method.",
        "2fe41b7c-a275-494b-944c-deec1c05e1be": "When creating a tensor group using the `create_group` method, what does the `exist_ok` parameter control?",
        "78538f71-a93f-40ae-9ec6-06eaf6618694": "What exception is raised if a dataset already exists at the destination path and `overwrite` is set to False?",
        "349d6962-b1cb-4371-8b6a-997c5f4f342f": "How can bounding boxes be appended in the dataset for object detection tasks?",
        "7167856f-92dd-4f83-a28c-3d79fc699786": "What is the required format for 3D bounding boxes to be correctly displayed by the visualizer?",
        "fc86487e-47d5-4693-a42d-959b189ababa": "What key must be specified in the coords dictionary when creating a 3D bbox tensor?",
        "4139e386-2486-4540-831b-fa64c93abe0d": "Why is it important to have the intrinsics tensor or matrix specified when projecting 3D bounding boxes onto 2D data?",
        "71208050-cb26-4973-99b6-ea25b0aa19ae": "Can bounding boxes be appended as both np.ndarrays and lists in the dataset?",
        "0c8d7298-5034-4014-ad06-91b7609f5657": "How can you specify the htype of a tensor at its creation in Deep Lake? Why is specifying an htype important for increasing the performance of datasets containing rich data like images and videos?",
        "c7272655-9146-429c-bf90-22fb71f0fce4": "What is the purpose of the deeplake.VectorStore class in the Deep Lake framework?",
        "abbc3dae-5bbe-4b2b-b8a1-c0aac7b8eb89": "What parameters can be passed to the __init__ method of the VectorStore class?",
        "11f5ef35-f714-4bb1-97db-6b79d4336b9b": "How does the VectorStore class handle the 'embedding' data type?",
        "5582f733-c474-4362-a1fc-e83bd51e0a68": "What is the significance of the 'read_only' parameter in the VectorStore class?",
        "d5095873-b345-41d7-a710-d9f3ee765f01": "How does the VectorStore class handle data ingestion batch sizes?",
        "70344369-d923-4ea1-8289-b1db6c2a8378": "Can you explain the role of the 'index_params' parameter in the VectorStore class?",
        "2aacdcbc-e125-4e64-b5d8-f7645029ae8e": "How does the VectorStore class handle token authentication?",
        "1fe9e5c7-f5f2-498c-9c16-111d19fb9798": "What is the default value for the 'verbose' parameter in the VectorStore class?",
        "a6225d25-7f86-4da0-87aa-f513efca0e52": "How does the VectorStore class handle credentials for accessing data?",
        "52f16189-4f90-48d1-be62-6cd249764f99": "Can you explain the purpose of the 'overwrite' parameter in the VectorStore class?",
        "05e367c1-6496-4c42-a30c-03e371e2d0bb": "Explain the purpose and functionality of the __setstate__() method in the LRUCache class of the deeplake.core.storage module.",
        "af24724d-68b6-4cbb-b4cb-d000be95fcde": "How does the _check_is_file() method in the LocalProvider class of the deeplake.core.storage module contribute to the overall functionality of the storage system?",
        "3cd84ee1-f9a7-4ffc-ad8d-cc2b04f59052": "Discuss the significance of the _config property in the Tensor class of the deeplake.core.tensor module.",
        "6b1908b2-bcba-4c0d-aeaa-2c3797d0b24b": "How does the _all_keys() method in various storage provider classes of the deeplake.core.storage module help in managing and accessing data keys?",
        "ea19109a-970a-4af8-b662-2aeab4dc496e": "Explain the role of the _flush_if_not_read_only() method in the LRUCache class of the deeplake.core.storage module in managing cache memory efficiently.",
        "b2f55364-9fb0-4ef0-8e60-996ac5012d83": "What is the difference between the `InvalidShapeIntervalError` and the `InvalidKeyTypeError` in the context of the `DynamicTensorNumpyError`?",
        "9a3f42a4-5035-4aee-8563-28613a38342d": "How would you handle the `ProviderListEmptyError` in a dynamic tensor numpy operation?",
        "fd18e39c-dc96-4e23-aa78-f11020f213d1": "Explain the potential consequences of encountering a `ServerException` during a tensor operation.",
        "b59f41b5-09f6-493f-aa84-11721a540994": "How would you address the `MetaAlreadyExistsError` when working with tensor metadata?",
        "7eb15b5e-d3df-45b7-9ed8-8f4062870a9a": "Can you provide an example of when the `UnsupportedCompressionError` might occur in a tensor operation?",
        "1df84b50-729b-4cd1-af6d-acd57791bc47": "Explain the key concepts of Datasets, Vector Store, Tensors, and Htypes as mentioned in the document.",
        "69c365d8-026e-480c-beda-782e21902df4": "How can an image tensor be created according to the document?",
        "e9095768-2630-491d-8af3-87409ef19580": "Describe the process of appending image samples as outlined in the document.",
        "a63c045d-773a-4f07-a341-9ba6f30375ca": "What are the differences between image.rgb and image. as mentioned in the document?",
        "874db484-3d72-4f64-a8e5-fe1218c3fa61": "Explain the process of creating a dataloader with custom transformations and a specified batch size using the Deeplake library. Provide a step-by-step explanation of the code snippet provided.",
        "5e379340-434b-4691-a11e-d91cdfd80b8a": "How can you create a dataloader and apply a query to filter specific data from a dataset using the Deeplake library? Provide an overview of the code snippet given and explain the purpose of the query used.",
        "3076fb81-cccf-4116-82d0-b91b95c89583": "What is the purpose of the `delete()` function in the Deeplake library? Explain the parameters that can be passed to this function and the implications of using this function on a dataset.",
        "7254ef9c-7584-479e-aa85-0c2b6615991a": "Explain the purpose of the `sequence` htype and provide an example of how it can be used in a dataset.",
        "c984f379-ca4b-4a5c-9a94-d7d213dbf2ba": "What is the significance of the `link` htype in a dataset? How does it differ from other htypes?",
        "a9c3feec-61e1-4158-bb14-383664d2fbeb": "How can you extend a dataset with Deep Lake embedding samples? Provide an example code snippet.",
        "0a906ef2-d131-418a-b3a7-c77b4d119174": "What are the exceptions to loading data when using the `link` htype in a dataset? Provide details for each exception mentioned in the context.",
        "a9e0ceb7-bda8-40fa-ae9e-606b691ce771": "What method can be used to return the bytes of a tensor?",
        "fd150a41-69c0-4cae-8483-205fc6611069": "How can you access the text data of a tensor?",
        "031d7b24-a899-41f2-9205-d27fb2c94b27": "What property of a tensor returns the number of dimensions it has?",
        "aab08d45-4874-43fd-836c-ff08f5695f35": "How can you play a video sample stored in a tensor?",
        "93a09b87-4d0e-4ede-bde8-95146ccde5fd": "What does the `Tensor.is_dynamic` property indicate about a tensor?",
        "08d5e0ae-ca3e-42e7-bc35-bfae2dd95bcd": "Compare and contrast the primary focuses of Deep Lake and HuggingFace in terms of the types of datasets they offer access to.",
        "f461fff6-4879-4c0d-8bac-f091182a0ccc": "How do Deep Lake and WebDatasets differ in terms of their data streaming capabilities and features?",
        "2e65af30-2a02-4884-8b47-d14178aaf483": "Explain the difference between Deep Lake and Zarr in terms of how they store and handle data, particularly focusing on their use-case-optimized formats.",
        "9d6d8e77-6b7d-455c-b56c-2cd3c0217721": "Discuss the advantages of Deep Lake over WebDatasets in terms of random access, shuffling, API usability, and dataset modification.",
        "c97a12e8-e15e-4102-861d-b6e0941cb2fb": "How does Deep Lake differentiate itself from HuggingFace in terms of the computational tools and features it offers for natural language processing and computer vision datasets?",
        "a98368d5-9ac6-4945-82a3-adc644370bf0": "What are the parameters required for the `update_creds_key` method?",
        "5f80f847-38f0-449e-8926-898b1f95330e": "What exceptions can be raised when using the `update_creds_key` method?",
        "5a8ca071-e21e-4d80-91db-f8cb054e12d8": "Provide an example of how to use the `update_creds_key` method in the given context.",
        "d79d7685-58f7-473b-84d1-3b17f52180aa": "What is the purpose of the `visualize` method in the provided context?",
        "8ecd38de-a29a-4baf-924f-88896b3a8b90": "How can you customize the width and height of the visualizer canvas when using the `visualize` method?",
        "ade305aa-1a99-4389-a994-74a39f4bc299": "Explain the process of creating an image tensor and appending image samples in the context of the Image Htype.",
        "f6234b65-fdf1-4b27-9a94-552c047c68f5": "What are the possible values for the `exec_option` parameter in the function described in the context information?",
        "4328b029-204e-49c7-a05b-5e99113eeddc": "How does the `filter` parameter work in finding samples for replacement in the function?",
        "55c19b8a-5969-4c13-83c8-d86db1b6067c": "When would it be discouraged to use the `\"python\"` option for search execution in the function?",
        "592eeab5-cb5e-4bbb-89ce-85f416f99c21": "What is the purpose of the `embedding_function` parameter in the function, and when is it valid to use it?",
        "fc1b38ae-961d-439b-8517-ea2730e18c16": "How can datasets be stored in the Managed Tensor Database according to the context information?",
        "428570ca-e1be-46b2-9b5b-f52cc76d0237": "Explain the difference between `deeplake.ingest_classification`, `deeplake.ingest_coco`, and `deeplake.ingest_yolo` in terms of the input data format they accept and the output they generate.",
        "03684a20-4c80-466f-983d-99414b7bb324": "How can you load an existing dataset using the `deeplake.load` function? Provide a step-by-step explanation.",
        "0a335ac8-b78d-4ea0-b627-d1c466a984d0": "Describe the dataset operations `Dataset.append`, `Dataset.extend`, `Dataset.update`, and `Dataset.query`. Provide examples to illustrate each operation.",
        "1aa502e8-e3bc-498a-af7c-7f3245d42c43": "What is the purpose of the `deeplake.delete` function? How does it differ from the `deeplake.rename` function?",
        "10ff6680-195c-45fe-8a19-ea4efabb75ea": "How can you copy a dataset from one location to another using the `deeplake.copy` function? Explain the process involved in copying a dataset.",
        "f0148272-8f09-4e47-ae3a-9266ed9510f9": "Explain the process of creating an image tensor and appending image samples in the context of the Image Htype.",
        "7e5c9ebe-248d-41a5-abe3-4cbba984759b": "What is the purpose of the `reset` parameter in the `load_dataset` function?",
        "f7aa45f8-7bcd-4575-bdba-a9f29fa0fa60": "When would the `check_integrity` parameter be set to `True` in the `load_dataset` function?",
        "028a240f-0bb8-40b8-8551-a399bd52c557": "What exceptions could be raised if a Dataset does not exist at the given path?",
        "07e242cb-412b-4b2d-8a48-47eb014a2ef9": "How does setting `access_method` to download affect the local copy of the dataset?",
        "ee2ab59a-4f99-4c34-9263-d4270647a9dd": "In what scenario would the `reset` parameter be rejected due to being in read-only mode?",
        "a24a15d8-0539-480e-831d-a485d58ac08d": "Explain the process of creating an image tensor and appending image samples in the context of the Image Htype.",
        "a1e9e2a2-da8e-4d61-a4e6-5f77e8fd8dfc": "How can keypoints that are not present in an image be stored in a dataset? What dummy coordinates are typically used for these keypoints?",
        "8953d382-394b-44ef-b31f-cfc327733f3f": "What is the difference between the \"point\" and \"polygon\" Htypes in the context of creating a tensor?",
        "572465ba-0a7c-47fa-9a0e-124bddefc6cd": "How can a point tensor be created in a dataset using Python code?",
        "6202f37c-f18f-49bb-8c39-4aecee076271": "Can you provide an example of appending 2 2-D points to a dataset in Python?",
        "4b5a53bf-f56e-427e-aec5-6e0a6f96daca": "What are the requirements for all points in a sample of the \"polygon\" Htype in a dataset?",
        "8dc82bbe-fb92-4191-b1fe-0699b61fcefc": "Explain the significance of the `cache_size` parameter in the function described. How is the default value determined and what is its purpose?",
        "27e57f93-18ad-45fa-ac41-8aae2635feeb": "What is the purpose of the `query` method in the provided context? How does it differ from traditional SQL queries?",
        "d40228ff-e86b-449f-abce-797404a755c2": "Discuss the implications of PyTorch not supporting certain dtypes like uint16, uint32, and uint64. How are these dtypes handled within PyTorch?",
        "5b0c2cc4-1541-4999-9bcf-3fed95d11710": "How does the `query` method handle the return of raw data? What conditions must be met for raw data to be returned along with the view?",
        "6dcfd637-3119-48e5-a426-3c837a17fe88": "Explain the importance of the `sample_compression` parameter in relation to the supported tensors for the function. How does it impact the data processing within the function?",
        "66f2afcf-2e98-4ee4-a18a-1e60b6a651db": "What are the two options for storing images in Deep Lake, and why is it recommended to store compressed images?",
        "24134992-7347-4589-953d-a2e5419e6140": "How can an image tensor be created in Deep Lake, and what are the supported compressions for sample compression?",
        "59503292-4580-440e-96cf-81e0e7bc72bf": "How can image samples be appended to a Deep Lake dataset, and what is the benefit of using the `extend()` method?",
        "a85b22e4-db5b-4557-a158-c4b85e23ac7b": "What happens if the compression format of an input sample does not match the sample compression of the tensor in Deep Lake?",
        "6ab269a0-8974-49bd-8da2-49e156ff068d": "How can the `image.rgb` and `image.gray` htypes be used in Deep Lake to specify the color type of image samples?",
        "ea241835-2476-432e-9425-5aa1f0df57ed": "What is the required format for specifying 3D bounding box coordinates in order for them to be correctly displayed by the visualizer?",
        "e91dd328-accb-4214-b032-e0a468094003": "How can a 3D bbox tensor be created using the provided code snippet?",
        "b929c967-eba4-43ba-8a6c-cc59ab6c68db": "Explain the difference between the \"center\" mode and the \"vertex\" mode when specifying the coordinates for 3D bounding boxes.",
        "fe9533cd-120d-4717-b3cd-e73e15c6afaf": "What information is included in the coordinates when using the \"center\" mode for 3D bounding boxes?",
        "bc289224-e6b1-420d-93b3-3a6c0ac324e5": "How many dimensions does the sample data have when using the \"vertex\" mode for 3D bounding boxes?",
        "6881f82b-0fda-4013-aee0-168a2d35d422": "Explain the process of creating a new tensor in a dataset using the `Dataset.create_tensor` function. What are the key steps involved in this process?",
        "e09ae867-0e8b-4322-82d6-a8d9bfa454d5": "How can you delete a tensor from a dataset using the `Dataset.delete_tensor` function? Provide a step-by-step explanation of how this operation is carried out.",
        "c95a53c3-bf75-4bfd-9c45-87944929c998": "Describe the difference between appending a single sample and extending the end of a tensor by appending multiple elements from a sequence using the `Tensor.append` and `Tensor.extend` functions, respectively. When would you choose one method over the other?",
        "90cce896-6dc3-4655-a575-846b36892492": "What is the purpose of the `Dataset.rename_tensor` function in the context of working with tensors? How does it help in managing and organizing tensors within a dataset?",
        "8544d3dc-5e40-425e-88e7-511be28ecb6f": "How can you copy the meta information of a source tensor and create a new tensor with it using the `Dataset.create_tensor_like` function? Explain the significance of this operation in the context of tensor management.",
        "5c135aa0-79fa-4c72-91c8-9cffe20364e2": "What parameters are required when using the `copy` function in Activeloop, and what are their respective data types?",
        "3666e792-bab7-4758-b382-f048d1a8802f": "How does the `overwrite` parameter in the `copy` function affect the destination dataset?",
        "716e706b-c0a4-4261-a711-dd0e7e06bf2d": "Explain the purpose of the `src_creds` parameter in the `copy` function and provide examples of keys that it supports.",
        "a4ef3959-1c2b-4fd2-85d7-e8be29bb24bc": "How does the `num_workers` parameter impact the copying process in Activeloop?",
        "4056becc-08a2-47b5-8ce0-b65b23c496b7": "Can you explain the significance of the `token` parameter in the `copy` function and when it is typically used?",
        "e03ce03b-1fa2-4501-9b76-7f5ff8ea3c03": "What is the recommended compression method for segmentation masks due to their large amounts of data?",
        "46930074-5234-42e8-ba98-f6f340762382": "How can a segment_mask tensor be created in the dataset using the provided code snippet?",
        "78fac61c-b48f-4cbb-9ea0-343871a10647": "What is the difference between segmentation masks and binary masks in terms of representing objects in an image?",
        "627d1781-3c84-4f12-a8c3-1ce765569a72": "Why are segmentation masks not suitable for datasets where objects might overlap or where multiple objects within the same class need to be distinguished?",
        "44ee5c22-a110-40e9-8784-2157a93b32ce": "How can class names be set for a tensor after its creation in the dataset according to the given information?",
        "04761e8f-aab9-458b-a994-7f6fa749a74c": "What are the two options available for performing computations in Deep Lake, and why is it discouraged to use one of them with big datasets?",
        "55ada801-9fe4-4622-8426-c299d65d59fb": "How can datasets be stored in the Managed Tensor Database in Deep Lake?",
        "3130d7e7-a842-467a-84b0-e52bee600a31": "What is the purpose of the `embedding_function` parameter in the Deep Lake Compute Engine?",
        "c09913b4-aa53-4cbf-8bf8-71c040f3c6e2": "When creating a dataset, how can you specify that it should be stored in the Managed Tensor Database?",
        "4449689d-1a1c-497a-93fb-54a12e6d94fe": "What is the default value for the `embedding_source_tensor` parameter in the Deep Lake Compute Engine?",
        "8d07672e-f666-4b2d-a736-25593982645a": "What is the purpose of the `dest` parameter in the function described in the context information?",
        "4e5a0fbd-01e8-496f-8616-b235ba3ddbb3": "How can you specify if a progress bar should be used to show conversion progress in the function?",
        "484d4240-f11a-4805-9e71-0fc2c87b44e2": "What is the significance of the `token` parameter in the function?",
        "66dd4419-0054-4525-beda-1e8cd83ec234": "How can you connect the dataset to Deep Lake using the function?",
        "eb93c84a-69d8-4895-8ebc-3c1a42ea3d77": "What will happen if the DatasetDict provided has features of the type `Sequence(feature=Value(dtype='string'))`?",
        "e26207c4-9e9f-4b9c-90a4-b2ca429ca1a6": "Can you provide an example of how a DatasetDict would be converted to a Deep Lake Dataset based on the given context?",
        "71a92c5d-1d32-46e8-85ee-2af9daefc2d5": "What type of error will be raised if the `dest` parameter is not a path or a Deep Lake Dataset?",
        "21c67d00-aa0c-47cc-bd3c-536029bb6b65": "How can you pass additional arguments to the dataset creator function in the context described?",
        "6518ee1f-4779-412e-8d4b-1616f8fd9066": "What are the possible tensor groups under which data from different splits of a DatasetDict will be stored?",
        "919f84ad-eeed-476c-b14b-f63709723317": "Why are features of the type `Sequence(feature=Value(dtype='string'))` not supported in the function described?",
        "198d41eb-a446-4d1c-82e9-00c483b2bb02": "What is the purpose of the `num_workers` parameter in the `DeepLakeDataLoader` object?",
        "125494b2-ae8f-4a3e-940e-32880ea85de0": "How does the `collate_fn` parameter contribute to the data processing in the DataLoader?",
        "2b9d3fe7-e7ad-4dbb-89f8-61711a27bb49": "Explain the significance of the `prefetch_factor` parameter in the DataLoader.",
        "dbe46d04-5379-4c17-8163-61974d2c5c10": "When would you set the `distributed` parameter to `True` in the DataLoader?",
        "420de84a-0757-4926-ad56-1137136f3b7f": "What are the supported decode methods for each tensor in the DataLoader, and how do they differ from each other?",
        "12829f39-994a-4294-aea3-0e3c433267a8": "What are the parameters that can be specified when creating a visualizer canvas?",
        "432a609a-8c61-4c8b-96cc-ee7385c3fc2a": "What exception is raised if a visualization is attempted in colab with a dataset that is not a Deep Lake cloud dataset?",
        "ee980518-4e75-4ac8-94b7-b49a1b428371": "How is the DeepLakeCloudDataset class related to the Dataset class?",
        "837e1b4d-62d2-4ccf-9aae-c999cecd0b3d": "How can a new creds key be added to a Deep Lake cloud dataset?",
        "028b256a-ba60-44a8-bd14-1888f8ff3b2e": "What is the purpose of the connect method in the DeepLakeCloudDataset class?",
        "ea2f3de4-76cc-4729-9ab2-31272a4497d2": "How can audio samples be appended to tensors in Deep Lake? What are the supported compressions for audio samples?",
        "de09126b-5638-49bf-ba7a-22ee2740eec5": "How can class label tensors be created in Deep Lake? What are the optional arguments that can be specified when creating a class label tensor?",
        "d6df9a31-5707-4958-a84f-0f1a61a52eff": "What is the purpose of the `class_names` parameter when creating a class label tensor in Deep Lake? How can it be updated after tensor creation?",
        "f0bd6216-8460-4e6d-b248-8dff8f0720f0": "Why is `chunk_compression` recommended over `sample_compression` when specifying compression for class label tensors in Deep Lake?",
        "3469a11d-f461-4a5d-bf6f-2369ca41c834": "Can samples of type `np.ndarray` be compressed when appended to tensors with Deep Lake? If so, under what conditions can they be compressed?",
        "364dcd4e-7075-4955-8c53-a1a5fbe1bed6": "Explain the difference between `Dataset.save_view` and `Dataset.get_view` in the context of virtual datasets (VDS).",
        "b936a969-6dc4-4346-9428-6d28e3ba897a": "How can you filter a dataset using the `Dataset.filter` function? Provide an example of a filter function `f(x: sample) -> bool`.",
        "8cf8a75f-0270-451e-81d3-f822a04eecde": "What is the purpose of `Dataset.min_view` and `Dataset.max_view` in the Activeloop Dataset API? How do they differ from each other?",
        "d04adb7b-b6d3-41e6-be59-0b61c3bedd67": "How can you retrieve a list of views stored in a dataset using the `Dataset.get_views` function?",
        "de2ae808-81d2-4a25-82c9-02fbf4b0138b": "Can you explain the significance of the `Dataset.is_view` function in determining whether a dataset is a view or not?",
        "a6b29b76-cb8e-450c-83c6-844527aa1a0f": "Explain the purpose of the `exists` function in the Utility Functions section of Deep Lake. How can this function be used in practice?",
        "9def2df9-ddc8-4e33-b8ce-48889937a774": "Describe the functionality of the `read` utility function in the Making Deep Lake Samples section. How does it contribute to data processing in Deep Lake?",
        "09a31138-d53e-4f8f-9585-ba37b9889aac": "How does the `compute` decorator in the Parallelism section enhance the functionality of functions in Deep Lake? Provide an example of how this decorator can be applied to a function.",
        "cf094945-a90a-4ed5-89d2-c61423a35c72": "Discuss the significance of the `Tensor Query Language` in the High-Performance Features section of Deep Lake. How does it facilitate data manipulation and retrieval within the platform?",
        "8056cda9-6d31-4b5e-9e71-2facc8b52fcf": "Compare and contrast the roles of `deeplake.VectorStore` and `deeplake.core.tensor` in managing data within Deep Lake. How do these components differ in their functionalities and applications?",
        "c10f2cc4-9a33-4492-b9d1-8c3b0b7d9591": "What is the purpose of the `delete()` function in the context of the provided information?",
        "9a8a04fb-7e58-4b46-a937-789a7fc00389": "How can you retrieve the id of a view using the `_property _id _: str_` attribute?",
        "54901e75-f9cc-4fbf-af25-6b17b68c63c5": "Explain the significance of the `load()` function and how it can be used in the context of the provided information.",
        "94fe6f63-537d-48f9-aef0-420921b5b75a": "When optimizing a dataset view, what does the `unlink` parameter do and how does it affect the optimization process?",
        "0f0be0dd-9e54-4e28-9587-2496a45f709d": "Describe the steps involved in optimizing a dataset view based on the information provided.",
        "b478c6e6-33bc-4b7f-901f-d539cbe6ba4d": "What is the recommended compression method for segmentation masks due to their large data size?",
        "5dae9a64-a401-4a43-83f5-f0e4e60ba0e1": "How can a segment_mask tensor be created in the dataset?",
        "cb07410e-f168-4c6b-a167-6d504e5be891": "What is the difference between segmentation masks and binary masks in terms of representing objects in an image?",
        "b5502832-d8ee-4907-98eb-672790a76df9": "How can class names be set for a segment_mask tensor after its creation?",
        "f78f473a-29eb-484a-b4df-a37925b757e1": "Why are segmentation masks not suitable for datasets where objects might overlap or where multiple objects within the same class need to be distinguished?",
        "494d66c0-bff3-40cb-b4eb-8b7d24a439da": "What are the two types of units for bounding box coordinates specified in the context information?",
        "bdd30e6b-d545-4352-9ab5-19caf3c8e52a": "How can you specify the convention for the 4 coordinates of a bounding box in the context information?",
        "2635066b-59db-4f37-b2f4-ae37db30bd13": "When appending bounding boxes, what are the supported data types that can be used?",
        "0f982175-aa32-4443-9cc8-c71bfd54e17d": "How can you append a single bounding box to a dataset according to the examples provided in the context information?",
        "162af543-35a0-4213-b2d5-08783567be35": "Why is it important to specify the format of the bounding box for 3D bounding boxes in the context information?",
        "f0038ce4-9af4-419d-93e8-c5b72a88a894": "Explain the process of creating a dataset using the `deeplake.empty` function.",
        "775cf92f-4573-4565-a014-b229be1ed816": "How can you ingest a dataset of images from a local folder to a Deep Lake Dataset using the `deeplake.ingest_classification` function?",
        "4e441a99-ffcb-4ea8-bc06-62791969b418": "What is the purpose of the `deeplake.like` function in creating a new dataset?",
        "0de5de97-0b68-473d-99c9-eaae5010a9bf": "Describe the difference between ingesting images and annotations in COCO format versus YOLO format to a Deep Lake Dataset.",
        "12120981-57f5-46e1-ae87-85a583a5820a": "How can you download and ingest a Kaggle dataset using the `deeplake.ingest_kaggle` function?",
        "10bee498-41b5-476f-93fd-98c58504c73c": "What is the purpose of the `deeplake.ingest_kaggle` function?",
        "7d00e51d-0921-49b6-a5f6-94d513f1a011": "How can you create a new dataset by copying the structure of an existing dataset to a new location?",
        "6de103c3-5789-4ab4-8bc7-ce0ff204a901": "Explain the difference between `deeplake.copy` and `deeplake.deepcopy` functions in terms of dataset copying.",
        "eede1d1f-fd84-4015-9243-2deabf8743cc": "How can you load an existing dataset using the `deeplake.load` function?",
        "c74968cc-6084-47ef-ae2a-63f33fd10f42": "Describe the functionality of the `Dataset.query` method in the context of dataset operations.",
        "8cdd8fed-6549-411e-9c07-a2dfbbc23331": "Explain the difference between the \"point\" and \"polygon\" Htypes in the context of keypoint data storage.",
        "28c1c677-dee4-455a-9d73-7fdf7c65ebde": "How can a point tensor be created using the provided code snippet? What are the optional arguments that can be included?",
        "c0dd2bc1-2dca-4306-98c6-12b589661bc9": "Can you provide an example of how to append 2 2-D points to a dataset using the given code snippet?",
        "3de58c8e-ebd5-4f82-bd1e-9ef7019a79d6": "What are the restrictions when working with the \"polygon\" Htype in terms of the number of coordinates per point and the number of points per polygon?",
        "b293e357-b22f-4613-a4af-05a34eb8b0e0": "How can dummy coordinates be used to store keypoints that are not present in an image?",
        "e87be08f-2ff1-4029-84f6-147dff7ede7e": "What is the purpose of the `local_cache_size` parameter in the context information provided?",
        "26fc8c13-dc6a-48c5-ad0d-48860e0c94fd": "How can credentials be provided to access a dataset at a specific path according to the information given?",
        "01ddf161-a4cc-469d-8af8-4f88f975c160": "When would the `token` parameter be used in the context of accessing a Deep Lake dataset?",
        "265431d7-7ec1-491b-879c-f935b3e8b006": "What is the significance of the `org_id` parameter in the context of enabling high-performance features for local datasets?",
        "cb050c3e-b5c7-46e9-b0bf-e5c7efe813f2": "Explain the role of the `lock_timeout` parameter and when it would be useful in dataset management.",
        "b942c0c3-e1ff-42f0-9d03-42b4afe511e4": "Why is it important to set the `lock_enabled` parameter to True in dataset management, as mentioned in the context information?",
        "f2e2dbb2-3661-4401-a00a-a5d779ccea3a": "How can the `index_params` parameter be utilized while creating a vector store for a dataset?",
        "391518ae-76ed-4210-ac1b-d860f9b4340d": "What exception will be raised if a Dataset already exists at a given path and the `overwrite` parameter is set to False?",
        "13817af1-d952-48db-b324-45c67683c076": "What are some features of Deep Lake that are not readily available in Zarr?",
        "e03691b9-4f8a-4052-9ea3-3ff7a7cf7cac": "How can users connect data to ML Frameworks using Deep Lake?",
        "daab0513-49a3-4801-b82e-4450cbe2ed10": "How can individuals join the community to learn more about unstructured dataset management using Deep Lake?",
        "7a810a08-d7bb-40ce-bfca-755f37acc99c": "What disclaimer is provided regarding dataset licenses in Deep Lake?",
        "98f414f4-c726-40d7-93bc-1fe03f193baf": "How can users add a README badge to their project if they are using Deep Lake?",
        "c21d5dd8-e9e1-4d06-a11d-f23212091f7f": "How does Deep Lake support instant visualization of datasets, and what are some of the visual elements that can be displayed using Deep Lake Visualizer?",
        "1b469d87-0ddc-4bc9-88f4-84db22b2457e": "According to the performance section, how does Deep Lake's dataloader built in C++ improve data streaming compared to Hub 2.x?",
        "639399bd-7e1c-4cfd-b8dc-8dfa213e5476": "What is the recommended method for installing Deep Lake, and what additional dependencies are not installed by default?",
        "46a38042-7d18-453b-b156-b027d15f385f": "What is required in order to access all of Deep Lake's features, as mentioned in the installation instructions?",
        "5e0a1f74-c7fa-40cf-a3a2-55badfd28c3c": "How can Deep Lake be utilized as a Vector Store for building LLM applications, and what are some of the resources available for getting started with this application?",
        "fc50b54b-6c94-40c6-8367-124423cfbe26": "How can Deep Lake be used for managing data while training Deep Learning models, and what are some of the resources available for getting started with this application?",
        "d6ad396d-253d-4098-b99e-ec304601c332": "What types of tutorials are available for training models and creating datasets using Deep Lake for Deep Learning applications?",
        "33cf731c-f9cb-4a1f-a348-27def40e6cad": "How does Deep Lake streamline deep learning workflows through its integrations with other tools, as mentioned in the document?",
        "15462f63-1ef3-4fa1-b1ab-d4211aa1909d": "Explain the key concepts in the Deep Lake framework, including Datasets, Vector Store, Tensors, Htypes, Compressions, PyTorch and Tensorflow Support, and Utility Functions.",
        "01406802-050e-4aa6-8939-a7e7244703b4": "Describe the high-performance features in Deep Lake, such as Dataloader, Sampler, Tensor Query Language, Random Split, and Deep Memory.",
        "08f04c3a-800d-4396-9a8d-2df0a766889f": "How can you interact with the VectorStore class in Deep Lake? Provide a brief overview of the methods available in the VectorStore class.",
        "42d091c4-2e04-476b-80fc-6bea9be801ee": "How can dataset views be created in Deeplake? Provide examples of methods that can be used to create dataset views.",
        "b4fe2992-7478-4225-87b7-77a697a2ee4b": "What is the significance of saving a dataset view only when the dataset has been committed and has no changes on the HEAD node?",
        "8895fc30-0a7b-43a4-9313-b8aa12d513cb": "Explain the difference between filtering a dataset with a user-defined function and filtering with simplified expressions in Deeplake.",
        "7d731a5c-f7c7-4fe6-bc88-f135afa40ecc": "How can a dataset view be saved as a virtual dataset (VDS) in Deeplake? Provide a step-by-step example.",
        "90032d2f-d5ce-43aa-a2a2-ec462cd98658": "When using Deeplake, what method would you use to retrieve a dataset view based on its unique identifier (id)?",
        "b5aa5811-02a5-4eb9-8528-84e51e4ad057": "How can dataset views be created in Deeplake?",
        "70483fbe-e442-4e97-8156-89dbe0d19d60": "When can dataset views be saved in Deeplake?",
        "41e15944-db70-4efb-8957-61407decf865": "Explain the difference between filtering a dataset with `Dataset.filter()` and querying a dataset with `Dataset.query()` in Deeplake.",
        "f55fa7b8-b51d-4a9b-8def-abc9c959e21b": "What is the purpose of saving a dataset view as a virtual dataset (VDS) in Deeplake?",
        "3494459a-3440-429a-9216-df3f3f393848": "How can you retrieve a dataset view in Deeplake using its ID?",
        "5454110b-d9a7-462c-83df-989bea17edcb": "Can a dataset be modified after creating a dataset view in Deeplake? Why or why not?",
        "0c925801-f6f0-448a-a306-c6225120a68b": "Describe the process of deleting a dataset view in Deeplake.",
        "5ec86ea8-c8c3-403a-8ddc-1ec2fb4fe4d4": "How can you determine if a dataset is a view or not in Deeplake?",
        "75ef2afe-3a7f-44a8-8c98-05859c91ab8a": "Provide an example of creating a dataset view in Deeplake using the provided code snippet.",
        "86e0a46b-83cd-4ed9-9b43-e602169d804d": "What methods can be used to slice a dataset in Deeplake?",
        "8e6594be-00fa-4427-b559-cd54d7d9849e": "Explain the difference between sample_compression and chunk_compression in the context of the provided information. How are they used in the dataset?",
        "40ad8f41-6505-453b-9b95-404e35b6e5eb": "How can 3D bounding boxes be appended in the dataset? Provide an example of appending one bounding box and another example of appending a sample with three bounding boxes.",
        "931558e2-9f42-444c-a767-dc5a7009653d": "Define the intrinsic matrix in the context of camera calibration. What are the components of the intrinsic matrix and what do they represent?",
        "cd00126a-6a8a-4985-a38d-1d5640ecfe4e": "How is the intrinsic matrix represented in the dataset in terms of dimensions and values? Explain the significance of the values in the intrinsic matrix for camera calibration.",
        "fa21334b-e397-4ef7-bf07-55142a3b926a": "What are the two types of units specified for bounding box coordinates in the context information?",
        "e69a5e95-b558-48f7-a5aa-206e7962db89": "How can you specify the convention for the 4 coordinates of a bounding box?",
        "33c0b63e-93f0-4c64-ae04-abeea2abcb7d": "What is the default data type for bounding box coordinates?",
        "15f525ed-dcac-4cf1-9b88-8220c4eca714": "What are the supported compressions for bounding box data?",
        "38b1cedd-779a-4211-ac68-d468651b7371": "How can you append one bounding box to a dataset?",
        "fbfa2f6e-508d-493b-b3a2-7f4078f727ea": "How can you append a sample with 3 bounding boxes to a dataset?",
        "409b0d24-d114-4c8a-b80e-f657adec9e68": "When will the visualizer assume a YOLO format for bounding box coordinates?",
        "11a453c5-8aea-4877-a08a-c29764c088ec": "Why is it important to specify the format of the bounding box for 3D bounding boxes to be correctly displayed by the visualizer?",
        "280ab1ea-5f97-46d8-b65f-d8b9fbcd0633": "What is the difference between using the `shape` property and the `shape_interval` property to describe a tensor's shape?",
        "5a164b40-8d1a-4289-8595-d40697a569f8": "How can you retrieve the shapes of all the samples in a tensor using the provided methods?",
        "a69321ec-6136-4622-8c8e-f96a33aebf4c": "When would you use the `text` method on a tensor object?",
        "b3bb359c-b0b6-4573-9a9b-689db996730a": "How can you access the timestamps for a video sample in a tensor object?",
        "a0e942ec-87d5-4ee9-aa24-d80e1e967782": "Explain the significance of the `summary` method in the context of a tensor object.",
        "5b3fdd7c-dc7c-466e-bd6b-d3267e6eb902": "Explain the difference between sample_compression and chunk_compression in the context of the provided information. How are they used in the dataset?",
        "6d40843f-a51c-46a1-88b8-d9b70951febf": "How can 3D bounding boxes be appended to a dataset? Provide an example of appending one bounding box and another example of appending a sample with multiple bounding boxes.",
        "fd232f4e-6566-4bf6-be91-58d501401b7c": "What is the purpose of the intrinsic matrix in computer vision? Explain the components of the intrinsic matrix and their significance in relation to camera calibration.",
        "0f16b310-7cce-49e5-87cf-7b460821336a": "What error will be raised if all the tensors of `ds_out` passed to transform do not have the same length?",
        "5df94983-c164-4156-9409-f8e35ef6de1d": "What are the supported values for the scheduler parameter when using the `eval` method in Deep Lake?",
        "4ae50d21-aba1-416a-8709-d43db93ba417": "How can the `my_fn` function be used in a Transform pipeline along with other functions?",
        "64fd3814-6cfd-4736-9818-c063afe63d1a": "When is the `pad_data_in` parameter applicable in Deep Lake datasets?",
        "808974a2-04b7-4890-b7ce-ef5dd377217d": "What error will be raised if one or more of the outputs generated during transform contain different tensors than the ones present in \u2018ds_out\u2019 provided to transform?",
        "b200a4ff-5e35-4c1f-9125-ca87686d4843": "What is the purpose of the `local_cache_size` parameter in the dataset creation process?",
        "2180caad-22b1-4009-adc8-4954e1b7a9ed": "How can credentials be provided to access a dataset at a specific path?",
        "18f02e37-6cee-4c0e-9ec3-b52d22deadac": "What is the significance of the `token` parameter in the dataset creation process?",
        "cd254803-95de-465e-b2a8-7aec1c7608fc": "When would you use the `org_id` parameter in dataset creation?",
        "216b1e19-fb10-4358-9116-1f01a1f3cc50": "Explain the role of the `verbose` parameter in dataset creation and what happens if it is set to False.",
        "d5cece95-3fb5-47c8-a96e-8cac243b6eee": "What is the purpose of the `lock_timeout` parameter and what happens if it is set to None?",
        "0549a633-a7fb-4281-ad1b-1521e9245a09": "When would you set the `lock_enabled` parameter to False in dataset creation?",
        "5626402c-7059-4874-844d-c04b7892aa3c": "How are index parameters used in creating a vector store for a dataset?",
        "6a13f936-bb43-4d58-bef7-12a99ce43c16": "What type of error is raised if a dataset already exists at a given path and `overwrite` is set to False?",
        "9128a556-c461-47fc-8869-3896c9312e7a": "What are the limitations of the Deep Lake Performant Dataloader in terms of supported data formats?",
        "d84f1edc-7431-4723-a1c4-88468f339fa6": "How can a nifti tensor be created using Deep Lake? What are the supported compressions for nifti data?",
        "e0e80024-b3bf-4d9e-b9bb-c7df641181bd": "Can raw nifti data be compressed when appending it to tensors in Deep Lake? If not, what compression can be used?",
        "759d0c52-8261-4f4d-acc6-fd29477abdce": "What are the key characteristics of point cloud samples in Deep Lake, in terms of dimensions and data types?",
        "cafac8e0-2751-4620-b303-f50d9633cb62": "How can a point cloud tensor be created in Deep Lake? What are the supported sample compressions for point cloud data?",
        "628a23be-8a81-4b2e-9b41-5933d2848d6c": "What are the limitations of the Deep Lake Performant Dataloader in terms of supported data formats?",
        "b3976d5b-4b08-44aa-90c7-882b8954c942": "How can a nifti tensor be created in Deep Lake, and what are the supported compressions for nifti data?",
        "1031a81f-ea72-4164-abee-4e08157995ec": "Can raw nifti data be compressed when appending it to tensors in Deep Lake? If not, what is the alternative?",
        "692c4400-fb0a-4d25-92b6-f492a3d40a5e": "What are the key characteristics of the Point Cloud Htype in Deep Lake, in terms of sample dimensions and data types?",
        "8d5e926f-cd17-4dc5-a40b-84ce295d45f4": "How can a point cloud tensor be created in Deep Lake, and what are the supported compressions for point cloud data?",
        "b7254cb0-b126-443b-81ef-2c12dbfba63d": "What is the purpose of the `ids` parameter in the function described in the context information?",
        "a3bd05ef-17b1-4a2c-9559-8993d1cc2a87": "How does the `filter` parameter work in finding samples for replacement in the function?",
        "e2f6fdba-a0ba-454a-bdde-9dc0b275d0a6": "Explain the difference between using the `exec_option` values of `\"python\"`, `\"compute_engine\"`, and `\"tensor_db\"` in the function.",
        "9615bf9c-a49b-458e-a7b6-835de1d2095f": "When would it be appropriate to use the `embedding_function` parameter in the function, and what does it do?",
        "647569b2-d46f-4c41-a395-1195472b806d": "Can you provide an example of how the `query` parameter can be used for direct evaluation in finding samples for deletion in the function?",
        "3d32835a-8130-4815-bd55-9a594df74e06": "How can you set the class names for a `tensor.info` object in the given context?",
        "30ccad49-691a-4da0-98f2-5851adb90c39": "What is the recommended compression option to use when the number of labels in one sample is low?",
        "fb79e0e8-e8bb-44a9-a47d-f391f02c78da": "How can you append class labels to a dataset in the given context?",
        "d03d852d-7126-4018-9dbe-e6751ca760b4": "What are the different types of data formats that can be used to append class labels in the context provided?",
        "a791f4bb-6434-4307-9c72-d091bf81b858": "How can you create a tag tensor in the given context?",
        "f7949543-ea06-47a8-8a39-76494827df6a": "What is the purpose of using the `tag` htype in the context provided?",
        "9b630500-cfea-470c-a0f2-0e149bfcb765": "What are the supported compressions for creating a tag tensor in the given context?",
        "5fdd599a-6c5a-4e3a-921f-df01870e74ed": "How can you append tag samples to a dataset in the context provided?",
        "290f7dfd-9f93-475b-afb2-e24d297bb168": "How can you append 2 2-D points to a dataset named `ds`?",
        "838c8b26-5a28-43bd-b1a1-b6e0d6731600": "What is the structure of a sample in a tensor of `polygon` htype?",
        "3a1fd221-e3b5-4593-8631-e618a0d3c6f4": "Can you mix 2-D points with 3-D points in a sample of a `polygon` htype tensor? Why or why not?",
        "caf4fdd5-0838-447f-9b91-a63578a7d05d": "How can you create a polygon tensor named \"polygons\" in a dataset?",
        "ef6cf42d-a597-4381-8f83-e79cd11d486d": "What are the optional arguments that can be used when creating a polygon tensor?",
        "c7957482-7df1-4579-a873-fb568af9eba5": "What compressions are supported for the creation of a polygon tensor?",
        "67cf0efc-fa9f-4152-b2c4-5f334e371375": "How can polygons be appended to a dataset as per the given context information?",
        "87c42fdc-f085-4087-ab51-71915be8fc45": "What are the different parameters that can be specified when creating an empty VectorStore or loading an existing one?",
        "2ea43272-9cfe-4882-84ba-6503bb26f2cf": "How can you create a vector store with default tensors?",
        "cc93de4e-1f76-4727-96f2-d42d1875199e": "Explain how to create a vector store in the Deep Lake Managed Tensor Database.",
        "38a7e32e-6c38-40cb-9749-d87aa748f592": "What is the purpose of specifying the `path` parameter when creating a VectorStore?",
        "e89240fb-e676-42e4-826a-ac79a4668d7a": "How can you create a vector store with custom tensors?",
        "d6c78e62-4e70-4b3c-829e-2230c265b1eb": "How can you store your credentials on the Activeloop Platform for datasets?",
        "0ee20065-6883-4fef-9e39-577ee71b0d6c": "What is the purpose of using managed credentials in the context of adding keys to a dataset?",
        "ada8ceed-e98f-4f0f-98e9-da6d27f6df9b": "How can you create a link tensor in the dataset?",
        "21c9c25b-af95-46c0-ba5f-cb64bf83fca3": "Provide examples of how to populate the tensor with links, including scenarios where credentials are and are not required.",
        "d5dc69db-2177-438b-bb6a-8be625349f9f": "How can you access the data stored in the dataset using Python code?",
        "22ff0416-f2d3-476e-8645-cd027b4f2195": "How would you update a sample in the dataset with a new link?",
        "8f59e75a-3a49-4243-9232-c37e752bfc20": "What are the different options for storing source data in the `ingest_yolo` function, and how are they specified in the `dest` parameter?",
        "a6bd5f88-69f4-485d-ab76-72b059a970eb": "How can you specify the path to the directory containing data (images and annotation files) in the `ingest_yolo` function?",
        "2797edb7-3537-4903-a7b6-3e81e6296500": "Explain the different formats in which the `dest` parameter can be specified when using the `ingest_yolo` function.",
        "cf4dfb70-3145-430b-9882-1967d6ad4e96": "What credentials are required when specifying an s3 path in the `dest` parameter of the `ingest_yolo` function?",
        "36cedd47-dc09-4925-bd93-fe33c6d8ee73": "How can you authenticate to Deep Lake when writing to Deep Lake cloud datasets using the `ingest_yolo` function?",
        "ac303c5d-705b-4d2e-97a6-9aca5c787373": "How can keypoints that are not present in an image be stored in a dataset?",
        "df641f64-b17e-4181-a7df-6dc3912eee9b": "What are the sample dimensions for points in a 2-D coordinate system?",
        "4a49ade5-7ead-4451-ba9f-458ca1a7b775": "How can a point tensor be created in a dataset?",
        "2194baa8-8b3b-4559-bbe5-9e6bfc4106f2": "What is the purpose of the COCO Keypoints Htype?",
        "81cb822d-8b1c-46f5-bc95-1ff88c6bb24c": "Can you mix 2-D points with 3-D points in a sample of the polygon Htype?",
        "0f18562e-2298-4874-b790-bc6bad29cfc6": "Explain the process of creating an image tensor and appending image samples using the Image Htype in the context of the provided information.",
        "3f9a992e-415d-4285-ba2e-c46ed5b210db": "What are the different types of paths that can be specified for the destination of the dataset when using the annotation_files function?",
        "2ead4d0f-7458-46cb-9df9-2653cf63413a": "How can you authenticate to Deep Lake cloud datasets when writing to them using the annotation_files function?",
        "32056038-1ae4-4947-8a4e-850d10b6b5b0": "What is the purpose of the key_to_tensor_mapping parameter in the annotation_files function?",
        "fbfcd9c1-f4f8-4f2f-b1ac-3c9d65aa5b0f": "How can you specify the credentials required to access an s3 path for the dataset when using the annotation_files function?",
        "f6f0b95b-efb3-4ca1-a3c5-a9fa71ef343c": "What is the significance of the ignore_one_group parameter in the annotation_files function?",
        "7e4b6259-662d-4b9c-863a-cd069e098b82": "How can you ensure that a group is not created when there is only a single annotation file using the annotation_files function?",
        "469fe6b2-d1a9-42ed-a424-cf9e8d180d64": "What is the use of the image_params parameter in the annotation_files function?",
        "f7457b8c-e4ba-4481-abb4-831632be8cca": "When would you use the image_creds_key parameter in the annotation_files function?",
        "0021381b-0bca-4481-93ca-3b64ccfaa765": "How can you provide credentials to access the source data if they are not inferred from the environment in the annotation_files function?",
        "ec9291d8-79a5-47f7-9a3d-27e0fbc05cbf": "Explain the difference between binary masks and segmentation masks in the context of object representation in an image.",
        "f233d6c9-ef03-4cfa-8637-958501a72140": "How are binary masks created and what are the recommended compression techniques for handling large amounts of data in segmentation masks?",
        "b6a0005c-aeb0-495f-a44d-fde1e67b0f9a": "Describe the structure of a binary mask tensor and how it encodes values for individual objects in an image.",
        "ad971cfc-1fdf-40aa-a245-d2d7ad5a1c1c": "How can binary masks be appended to a dataset using numpy arrays? Provide an example of appending a binary mask with multiple objects.",
        "729415e5-3114-4661-86c9-558f8b9d3687": "What is the purpose of COCO keypoints and how are they conventionally stored in an image? Explain the significance of the three values associated with each keypoint.",
        "94cacbd2-fee9-4aeb-8d51-0ef1dbae35f3": "What are the optional parameters that can be passed to the `ingest_dataframe` function?",
        "70508b6e-cc06-4cd3-a18e-71dec8aea439": "How is shuffling important in data ingestion for optimal training results?",
        "5222ec9f-7e0e-4150-9195-94f1c0b51b16": "What type of datasets are currently supported for automatic ingestion in Deep Lake?",
        "2b26b8ea-5a8f-4c56-95a1-96d3681e4980": "How can a pandas dataframe be converted into a Deep Lake Dataset?",
        "e4c68915-79a8-4a4a-adb9-4767cc0f3670": "What exception is raised if the source and destination path are the same in the ingestion process?",
        "86af4052-606b-46f6-a0f9-4d0adbc940b9": "How can you log the creation of a Deep Lake dataset using Weights and Biases? Provide a code example to demonstrate the process.",
        "34311103-3f05-44b8-93d4-1e9b53a3e4d2": "What is the default value for the `decode_method` parameter in the `DeepLakeDataLoader` object?",
        "c6ebc16b-80dc-45b8-929d-723043a13b15": "What are the supported decode methods for each tensor in the `decode_method` parameter?",
        "85250beb-cdfd-459d-8982-0573d7793c54": "How can you create a dataloader with specific transformations and batch size in the provided example?",
        "98420810-354a-4b16-abcf-034d29eaae34": "What exception will be raised if the `.pytorch()` or `.tensorflow()` or `.numpy()` method has already been called?",
        "c672e844-b816-4fe1-b6ac-08bf4631472e": "How can you use the `query()` method to extract results based on SQL-like queries from the dataset?",
        "e02abe4e-078b-4e51-8f34-cc4427bab53c": "How can dataset reads be logged in Weights and Biases when using a Torch dataloader?",
        "b95ca7e2-c54d-4897-9002-88502faebf14": "What is the significance of committing changes to an existing dataset with an active Weights and Biases run?",
        "69f6a6a5-83f2-4177-91ca-4f82414439bd": "When will a dataset read be logged in Weights and Biases?",
        "daf2f5bb-78d5-42c7-9217-28c04b307a7b": "What is the purpose of the code snippet provided for logging dataset reads in Weights and Biases?",
        "4209601d-a2fc-4081-801a-4382944e29a8": "How can you log a dataset read when iterating over a dataset in Weights and Biases?",
        "50153e68-0445-40ce-852b-a560a20e715a": "How can you set the `connections` attribute in `tensor.info.keypoints`?",
        "71a2189b-0842-485d-9a37-49cbaed93640": "What is the default data type for `dtype` in `tensor.info.keypoints`?",
        "aee4852b-c55e-4d91-ae2a-64a3424ab7ee": "How can you append keypoints to a sample with multiple objects?",
        "a6dddb83-e5e6-4de2-bd26-1945d9763b2f": "Why is it important for all objects in a sample to have the same number of keypoints in the same order?",
        "2790bb70-78af-41d5-bdd8-3a546130d04e": "How can you update the `keypoints` and `connections` after tensor creation in the context provided?",
        "eb2c4434-bb11-4007-9d25-c0a3afb54b29": "What is the purpose of the `dest_creds` parameter in the function described in the context information?",
        "2e5498b0-e4b8-42a5-93ea-7cadf22f9077": "How does the `shuffle` parameter impact the ingestion process of the dataset?",
        "fbbb2f5f-1429-4642-8ba1-02a9b6500075": "What is the significance of setting the `num_workers` parameter to `0` by default?",
        "f7be11ec-f29d-47ed-913e-938734d62b85": "What exceptions are raised by the function if the source directory does not exist or if the source and destination paths are the same?",
        "0eff54a7-412b-4bff-b111-98733dbc48cb": "What are the supported filetypes for automatic ingestion mentioned in the context information?",
        "256db365-6799-42ae-8fe4-d840af3bbbdb": "What is the purpose of the `num_workers` parameter in the dataset filter function?",
        "cdbd68ee-241e-4b24-adaf-6e88aa2e4de1": "How can you specify the scheduler to use for multiprocessing evaluation in the dataset filter function?",
        "7a4a8c8f-2a68-4bd6-a936-6a65071f9665": "When would you use the `save_result` parameter in the dataset filter function?",
        "9209302c-e739-4958-ab79-1a9ce8beae75": "How can you rebuild version control info in the dataset using the `fix_vc()` function?",
        "dcad79ea-e629-4340-ad89-9709e2c94a2b": "Why is the `flush()` function necessary after writes in the dataset?",
        "6d46ceda-b155-45ab-b910-781a5672998c": "How can you retrieve details of a specific commit in the dataset?",
        "399f6d77-0c2e-4d0c-91e9-0ba320accfa5": "What does the `get_creds_keys()` function return in the dataset context?",
        "64db6f8d-374a-4cf9-bac3-e656d2a237ed": "How can the htype of a tensor be specified at its creation in Deep Lake?",
        "fb04ab84-0b01-4b09-85d4-56f3f3a55a4f": "What is the default htype of a tensor in Deep Lake if not specified during creation?",
        "252c766a-0c14-4c1c-a0d2-c0738a90489d": "Why is specifying an htype important in Deep Lake datasets containing rich data like images and videos?",
        "319fbc8d-ec71-4fb8-ba25-53e35f66caa5": "How does Deep Lake handle image compression when the compression format of the input sample does not match the sample_compression of the tensor?",
        "285c5f3f-5135-45ed-92a3-12f17b9b3c7c": "What happens when RGB images are appended to an image.gray tensor in Deep Lake?",
        "f8895379-1d65-4210-87f0-f740b68e928b": "What limitations are there for visualizing videos in the Deep Lake App?",
        "bf3fc8d4-5c39-4ed2-9513-2c5d9d8f0568": "How can a video tensor be created in Deep Lake?",
        "040a1292-f660-4ddb-a347-aef6990df6e8": "What compressions are supported for video tensors in Deep Lake?",
        "19509396-716f-4fb1-b5cd-a8d3e65aa94d": "Can raw video frames be compressed in Deep Lake? If not, what type of tensors can raw frames be appended to?",
        "fa159102-7626-4359-8286-180948849b47": "How does the `collate_fn` parameter affect the mini-batch formation in a DataLoader when using batched loading from a map-style dataset?",
        "6bd0e48c-4bc1-47b5-b1fb-21d105708eeb": "What is the purpose of setting the `pin_memory` parameter to `True` in a DataLoader?",
        "4a0b93ce-ffb9-4654-b363-334fb33cd292": "How does the `shuffle` parameter impact the data indices in a DataLoader?",
        "22688846-f5bc-4707-aae1-cfc88418806e": "Explain the significance of the `buffer_size` parameter in shuffling data within a DataLoader.",
        "0185ba50-02a8-49f5-8998-2140638759eb": "When would it be beneficial to set the `use_local_cache` parameter to `True` in a DataLoader?",
        "face7929-8a5d-4801-a97c-b7a2a41340c7": "What is the role of the `return_index` parameter in a DataLoader?",
        "67cc4fa2-b502-48b1-a210-17e5a42e84d0": "How does the `pad_tensors` parameter affect the handling of shorter tensors in a DataLoader?",
        "f1675c6e-d7c7-43a4-8373-967c385cd21e": "Can you provide an example of when you would use the `transform_kwargs` parameter in a DataLoader setup?",
        "f0ab34a4-1160-4ced-9e33-70f729c6a736": "What is the purpose of the `decode_method` parameter in a DataLoader, and why is it set to `None` by default?",
        "8a4ff6eb-fe0a-47cc-86bb-6eb1c01bb95c": "Explain the difference between the \"point\" Htype and the \"polygon\" Htype in the context of keypoint storage in images.",
        "7dde7f1d-503e-480b-8ba5-5f09bd08cd0c": "How can a point tensor be created using the provided code snippet? What are the optional arguments that can be included?",
        "3ece4f8d-1b0c-46c6-aa3c-8dadd89ed19e": "Can you provide an example of how to append 2 2-D points to a dataset using the \"points\" Htype?",
        "b5d90e3a-5ab7-463d-b37f-d173f5c9ae9a": "What are the restrictions when working with the \"polygon\" Htype in terms of the number of coordinates per point and the number of points per polygon?",
        "1f3af598-d07a-4606-a1f4-e8876f3bbd55": "How can dummy coordinates be used to store keypoints that are not present in an image?",
        "833ae4f2-9242-4977-8fe4-1ae7582dc9ee": "What is the purpose of the token parameter in the deeplake.read function?",
        "4d5bf016-e679-4ee6-99d6-8faf799323d8": "What does the deeplake.read function return?",
        "f0830aa5-831b-4d25-81a6-a21538926dc2": "When will the function raise a ValueError?",
        "7bc538e2-6cdf-40e4-af43-250b78fe8947": "How does the utility function handle data when reading raw data from supported files into Deep Lake format?",
        "6706e015-5bc7-4641-9299-0be841c242ca": "How does the utility function maximize upload speeds when copying data from a file?",
        "5ebb83f8-e698-45fc-a1ee-41ac986cf3d4": "What is the revision number of the document?",
        "6a4827f8-57c7-4767-b9f7-ad72a6e63284": "What theme was used to build the document?",
        "83c68464-6a9b-44e4-ac26-f283eb9bdf7a": "What is the version number of the document that is currently being viewed?",
        "883926fa-26d2-4f69-aa53-8f6ded37e03e": "How many versions of the document are available for download on Read the Docs?",
        "0d990f3a-d95a-4423-8f1b-e329ad78d1e2": "What is the latest version of the document available for download?",
        "81da9af0-356b-48ca-993c-b8afeae61f6a": "How can dataset views be created in Deeplake? Provide examples of methods that can be used to create dataset views.",
        "a982a946-b000-4362-9288-ef10eee3b58d": "What are the restrictions for saving a dataset view in Deeplake? Why is it important to ensure that the dataset has been committed and has no changes on the HEAD node before saving a view?",
        "c45904b3-ed8d-44c4-bb6e-f31693824726": "Explain the difference between filtering a dataset with a user-defined function and filtering with simplified expressions in Deeplake.",
        "173ff351-98ab-46ae-9618-fc2d76383872": "How can you retrieve a dataset view in Deeplake using the `load_view` function? Provide an example scenario where this function would be useful.",
        "bac201a4-1d16-4679-82d8-a61c40efee29": "What is the purpose of saving a dataset view as a virtual dataset (VDS) in Deeplake? How does this feature contribute to data lineage and preservation?",
        "cc0e9bca-7dbd-4307-9668-a1ffe1524255": "What is the purpose of specifying an htype for a tensor in Deep Lake datasets?",
        "dae3a607-c4fa-4262-8d87-443427fabb0c": "How does specifying an htype contribute to the performance of datasets containing rich data like images and videos?",
        "5c1619b8-0ea4-4d27-a4d3-50082175830c": "Can you provide an example of creating a tensor with a specific htype in Deep Lake?",
        "6229646a-5463-4e7f-8764-4ae199013328": "What are some of the supported htypes in Deep Lake and their respective defaults?",
        "1c01e8b2-7c7f-4b78-aba6-f7ac6561e2e4": "How are images typically stored in Deep Lake, and what are the options for storing them?",
        "9622945c-2ad7-442b-b7d3-bfd23296d09b": "How can you append a Deep Lake embedding sample to a dataset using Python code?",
        "98f3e598-73dd-4cb2-bdca-d2fac55febdc": "Explain the concept of the Sequence htype with an example.",
        "edacf459-fb9c-4be2-84f4-d0786b6ebcbe": "What is the purpose of the Link htype in a dataset, and how does it differ from other htypes?",
        "69b2701e-eff8-4d83-99aa-e7fac17f4da3": "When working with the Link htype, under what circumstances is data actually loaded from external files?",
        "131b24f9-1357-4c30-bb11-27d01401e855": "How would you create a tensor with the htype \"sequence[image]\" for storing image sequences in a dataset?",
        "7b8edf44-f285-4a04-9955-f0f91c68e442": "How can a point cloud tensor be created using the provided code snippet?",
        "d59d74eb-6f9c-4aad-bec8-cf6dd8e2f71b": "What are the optional arguments that can be used when creating a point cloud tensor?",
        "b1bc2516-c500-4873-a8d0-0fc973fc34dc": "How can point clouds be appended to a dataset using numpy arrays?",
        "12336b82-dcd2-4ead-80fe-43ef5062fe0c": "What is the shape of the dataset after appending two point clouds with different numbers of points?",
        "a1552295-8a28-4cd8-bd38-0e63854c9c02": "How can samples be added to a dataset using the `deeplake.read()` method?",
        "3bdc05c8-30ef-477a-9952-daa937df5999": "What are the dimensions of a sample in a tensor of `mesh` htype?",
        "46571ebb-1e9f-4701-86f0-eeb18b461638": "Can mesh samples be of type other than `np.ndarray` or `Sample`?",
        "60958dd3-6241-4dba-a324-cfc0f271a20e": "How are different meshes represented in a tensor of `mesh` htype?",
        "1d3feaff-c68b-4a98-98b3-33eecefbc233": "What is the significance of having the same number of coordinates for all points in a sample?",
        "2d388c50-75d2-4ff9-8312-9122fafafe13": "How does the `sample_compression` argument impact the creation of a point cloud tensor?",
        "80340300-930d-4cb7-b61f-1be52124168b": "How can you append 2 2-D points to a dataset using the provided examples?",
        "94fa2ee1-b7d0-4abe-a756-b32c11b9628d": "What are the sample dimensions for the 'polygon' htype?",
        "59d3c4e6-fd0e-464b-98ab-9ffa354d118c": "How can you create a polygon tensor using the provided code snippet?",
        "dc5083ba-644a-4d7e-b9f3-0909106c2ec3": "What is the requirement for all points in a sample within a 'polygon' htype tensor?",
        "c31ec5ac-d624-4b41-9cdd-04368f9bdf23": "What are the supported compressions for creating a polygon tensor?",
        "35213c0b-e29b-433c-8e52-34cbbf85b1ac": "How can polygons be appended to a dataset according to the context information?",
        "8a88780f-efb0-4c33-9f3f-4b201b3e0027": "What is the purpose of the `delete` method in the provided context? Explain the parameters and potential risks associated with using this method.",
        "80397aac-2348-4835-a2d6-b8da50c6b36f": "How does the `delete_branch` method differ from the `delete` method in terms of functionality and usage? Provide an example scenario where you would use `delete_branch`.",
        "d49f60f0-609e-4884-8f48-947204ff90bb": "In the given code snippet, how is the `train_loader` object created and what is the purpose of the query specified within it? Explain the significance of limiting the data based on categories like 'car' and 'motorcycle'.",
        "7db89ce2-48f4-4d17-94c7-ba3457cd7d4e": "How can you specify the htype of a tensor at its creation in Deep Lake? What is the default htype if not specified? Why is specifying an htype important for datasets containing rich data like images and videos in Deep Lake?",
        "03559bd9-42cb-451b-a701-e589d486fcfd": "What is the purpose of the `dest_creds` parameter in the function described in the context information?",
        "bd73a6b4-c33b-4ca9-ac78-59dbc1c4dfa2": "How does the `shuffle` parameter affect the ingestion process of the dataset?",
        "d6790045-5eb5-4779-8632-c763522c4ac6": "What is the significance of setting the `num_workers` parameter to `0` by default?",
        "dbc9b7cb-344a-47cd-a0b4-7816a25d52a5": "What exceptions are raised in the function if the source directory does not exist or if the source and destination paths are the same?",
        "15dcb9e6-5473-4965-b070-6e0a31d52cf6": "What filetypes are supported for automatic ingestion in the function described in the context information?",
        "b4ad36ec-61f3-4414-8027-e31889b59bd0": "Explain the importance of compressing segmentation masks using `lz4` and why it is recommended for masks containing large amounts of data.",
        "707ea0de-1acb-4be4-9bf9-79f5ebadc8c2": "How can binary masks be appended in the dataset using `np.ndarray`? Provide an example of appending a binary mask with 5 objects and their corresponding labels.",
        "56987097-fdca-417b-a689-aac95ad569b6": "What is the structure of COCO keypoints and how are they represented in a tensor? Explain the meaning of the visibility values (0, 1, 2) associated with each keypoint.",
        "5ae66cfe-1467-425c-823e-026cb17b6f04": "How can a keypoints_coco tensor be created in the dataset using the `create_tensor` function? What are the optional arguments that can be specified during tensor creation?",
        "675573b4-3bdd-42b9-b5f7-0af18fb5bc68": "Discuss the significance of setting `keypoints` and `connections` in a keypoints_coco tensor. How can these attributes be modified after tensor creation?",
        "939e5872-bf7e-4986-b1f9-eb0945329a07": "What is the significance of passing 'ENV' as a parameter when fetching credentials for cloud datasets?",
        "c02f52cd-7e25-47c9-a87d-0a2756abc2eb": "What are the supported values for the 'scheduler' parameter in the deeplake.deepcopy function?",
        "72d38d60-3fe1-4309-b2ad-28af071b6497": "When would the DatasetHandlerError be raised during the dataset copying process?",
        "37e774be-815e-4448-9a10-14b0d79efbe5": "How does the 'num_workers' parameter affect the copying process in the deeplake.deepcopy function?",
        "556cf847-1352-45ab-a67a-14a9cf343f37": "Explain the purpose of the 'token' parameter in the deepcopy function and when it is typically used.",
        "539fc141-a2bb-4bb9-aa73-a2748b5570f5": "What are the parameters required for the `update_creds_key` function?",
        "b3144560-a6de-41e1-9caf-0084d5fac910": "What exceptions are raised if a partial update of a sample is attempted in the `update_creds_key` function?",
        "7f2783c1-4887-4b67-9b1c-f8a6fd88b6fc": "How can you update the name and management status of a creds key using the `update_creds_key` function?",
        "e04ce5b6-cd9b-48bf-853a-e1e494b97e75": "In the provided example, what steps are taken to rename a creds key and change its management status to True?",
        "22c43b23-13ff-4c5d-9d6c-acb7cda525d1": "What is the consequence of not providing a new key in the `update_creds_key` function?",
        "28140a12-fbc5-4b23-a831-c78f899652eb": "What action should be taken if the dataset is not connected to the activeloop platform when using the `update_creds_key` function?",
        "23163342-3b6b-41f2-bb4e-8cb61bbbbe39": "What is the purpose of the `populate_creds` function mentioned in the example?",
        "b0b4d968-8d72-4130-8575-fc3be0e5a312": "Explain the difference between binary masks and segmentation masks in the context of object representation in an image.",
        "5f61fda6-f0d3-4bed-bd5e-705497afc1c1": "How are objects represented in a binary mask tensor? Provide an example to illustrate your answer.",
        "cb7f2774-822d-46b7-ae0c-815f0015be12": "Why is it recommended to compress segmentation masks using `lz4` compression?",
        "e14d785d-9ab4-4b26-b81b-c7b109f74ea8": "How can you create a binary_mask tensor using the provided code snippet? What are the optional arguments that can be used?",
        "05cbec8c-a70d-4d4f-a460-fd3b656514a7": "Describe the structure of a COCO keypoints tensor. What information does each keypoint consist of?",
        "5a1acca2-69bd-4785-9590-8956b806bec2": "Explain the difference between binary masks and segmentation masks in the context of object representation in an image.",
        "b855ade4-f8da-4389-a977-cf432510fc2c": "How are binary masks created and what is the recommended compression method for handling large amounts of data in segmentation masks?",
        "31985253-6339-46c8-b964-59d30bca2f74": "Describe the structure of a binary mask tensor and how it encodes values for individual objects in an image.",
        "97894baf-fda6-4b6b-81d4-892211c49b95": "How can binary masks be appended to a dataset, and what information should be stored in an adjacent tensor of htype `class_label`?",
        "68051f1f-d578-4f5a-aff0-a0f8c3c99cea": "What is the purpose of COCO keypoints and how are they conventionally stored in an image?",
        "df69934b-fc93-4f0a-bfd5-45a771ab36b8": "What are the recommended ways to store images in Deep Lake, and why is it important to use the `sample_compression` input when creating image tensors?",
        "b7415f41-1363-4940-bdfb-02821a43d5e8": "How can an image tensor be created in Deep Lake, and what are the optional arguments that can be specified during creation?",
        "02dea8c7-143e-4fc1-9c79-7f0f83fa4c0d": "Explain how image samples can be appended to an image tensor in Deep Lake using both numpy arrays and Deep Lake `Sample`.",
        "d7d508b6-a597-4596-8fc4-d2d8310609e0": "What is the impact on the upload process if the compression format of the input sample does not match the `sample_compression` of the tensor in Deep Lake?",
        "e5d7355e-aae8-4b0d-bd39-eca8b353d8d2": "How can the `image.rgb` and `image.gray` htypes be used to specify the color type of image samples in Deep Lake?",
        "e409bc65-e64e-4654-9f3c-bf373e67a89c": "Explain the key concepts of Datasets, Vector Store, Tensors, Htypes, Compressions, PyTorch and Tensorflow Support, and Utility Functions in the context of Deep Lake.",
        "5c0cfa8a-98cb-40e5-8f95-a90aad03c864": "How can you query for images containing the digit 0 in the MNIST Train Dataset using `ds.query`?",
        "5f446115-a57f-435a-8e10-15f1bd8d11b2": "In the COCO Train Dataset, how would you query for samples that contain either the category \"car\" or \"motorcycle\" in the `categories` field using `ds.query`?",
        "73e077fb-8447-406a-bdf1-4d6951e794bf": "What is the total number of samples returned when querying for images containing the digit 0 in the MNIST Train Dataset?",
        "3b017558-c590-48e8-9a2b-f71068a5212c": "How many samples are retrieved when querying for samples with the categories \"car\" or \"motorcycle\" in the COCO Train Dataset?",
        "1c6eb9f5-1c66-487c-a44c-2d22832a693e": "Explain the process of querying datasets using the `ds.query` function based on the provided examples.",
        "36ebc17c-9dbd-4ae5-96e5-5d1e7a2de5b7": "Compare and contrast the compatibility of Deep Lake datasets with PyTorch and TensorFlow versus TFDS with TensorFlow.",
        "253e08fb-e32d-4dbc-aeb0-37269f7ec0e6": "Explain the key difference between Deep Lake and TFDS in terms of data streaming and local download requirements.",
        "8f7a3df3-d926-416e-b72f-4b2fba0f6ccc": "Discuss the primary focus of Deep Lake in comparison to TFDS when it comes to dataset management and creation.",
        "1e7d4dc2-bfeb-47e6-980b-7a738392ab18": "Compare the focus of Deep Lake and HuggingFace in terms of the types of datasets they offer access to.",
        "c469f94d-2486-4d8f-97fe-5de30a6979a4": "Analyze the differences between Deep Lake and WebDatasets in terms of data streaming capabilities, random access, and dataset modification.",
        "d7a46bfc-a34c-4b3e-9cbe-9a15f7096b7d": "What are some of the functions available in the `deeplake.util.remove_cache` module?",
        "7b8a2705-4593-4e7e-8a74-d2d1114d0341": "Can you list some of the exceptions defined in the `deeplake.util.exceptions` module?",
        "f83f2cd3-50f1-492b-a086-73c038c79022": "How can you determine if you are working in a Jupyter notebook using the functions provided in the `deeplake.util.notebook` module?",
        "1659ef78-ec0c-43e6-ae47-8219a9039430": "What is the purpose of the `ShapeInterval` class in the `deeplake.util.shape_interval` module?",
        "cb3128a7-4300-4835-a4f4-49aa81c59149": "What error would be raised if a user tries to access a resource that does not exist in the `deeplake.util.exceptions` module?",
        "f921b00e-6e23-4795-98b4-076c7f1e3037": "What are the key concepts covered in the Deep Lake documentation?",
        "8804e55d-74bd-4890-8a16-1f18927ad648": "How can Deep Lake be installed using pip?",
        "aa51a1f5-cdf0-49cc-8df2-4b5392f2c483": "What are the extras available for installation with Deep Lake and how can they be installed?",
        "e250e850-c75d-4c54-aa34-c469cefc43a0": "What is the purpose of the \"Visualize Deep Lake datasets within notebooks\" extra installation command?",
        "aff77601-6c5e-43b1-aa8d-65ad5a335472": "Can you explain the difference between the `deeplake.VectorStore` and `deeplake.core.tensor` API references?",
        "a38e4385-3938-40d8-b816-0dc19d7ceddd": "What are the parameters required for the evaluate method in the DeepMemory managed service?",
        "2b085a2a-9786-45b1-a0c1-d1cb1a128108": "How can you cancel a training job on the DeepMemory managed service?",
        "8fe5f53a-7185-4344-8f82-c361ecf60ba6": "Explain the purpose of the delete method in the DeepMemory managed service.",
        "7964951c-dce1-4114-b05e-9566ca27bb52": "Describe the evaluate method in the DeepMemory managed service and its parameters.",
        "65e3ca05-29ea-45aa-91ef-adf13813ef8b": "Explain the key concepts of Datasets, Vector Store, Tensors, and Htypes as mentioned in the document.",
        "4bb56af8-0381-48da-a29d-1c378d1cd2ef": "How can an image tensor be created according to the document?",
        "b16c0031-93c9-4651-8aed-6568dc95ee29": "Describe the process of appending image samples as outlined in the document.",
        "b68ff603-348b-43dd-b1ae-c084720270dc": "What are the differences between image.rgb and image. as mentioned in the document?",
        "a12df5a4-289e-4e58-ac82-9b06e43afa9c": "How can you specify the htype of a tensor at its creation in Deep Lake?",
        "d9e447c5-f78f-48f1-b8da-32ba10d6f17b": "Why is specifying an htype important for increasing the performance of Deep Lake datasets containing rich data such as images and videos?",
        "14558a19-ad7c-4a4c-bc25-aea29addf586": "What is the default htype of a tensor in Deep Lake if not specified during creation?",
        "22953cec-cc72-4d21-99dd-c1b8cf144e80": "How does specifying an htype allow for strict settings and error handling in Deep Lake?",
        "88e44668-e850-44f8-9d10-19a1ebc95653": "Can you provide an example of creating a tensor with a specified htype in Deep Lake using the ds.create_tensor() function?",
        "dc338672-389e-45b8-9e4f-d0c99079cf1b": "What is the purpose of the `pytorch()` method in the `DeepLakeDataLoader` class?",
        "6833d298-50a9-4582-9057-405741d23c75": "What parameters can be specified when calling the `pytorch()` method?",
        "6162b077-8564-48df-9ebc-7e67315eea8c": "What type of object does the `offset()` method return?",
        "5bea24be-67d5-44d0-92d3-6e9ced9ad893": "When is the `pytorch()` method especially useful?",
        "7b29371c-b113-461a-b617-9f1f2339e7ad": "What error will be raised if the `offset()` method has already been called?",
        "0f466bef-74ad-45f3-aa26-42377e049883": "Explain the purpose of the `flush()` operation in the context of version control and data storage. Why is it necessary after writes if caches are being used?",
        "4f59c517-2055-4f39-af94-3ef85ca052c7": "How can you retrieve details of a specific commit using the `get_commit_details(commit_id)` function? What information is included in the dictionary returned by this function?",
        "c53e824f-fdd0-4276-b724-b129cddd1417": "What is the significance of the `get_creds_keys()` function in the dataset management process? How are these keys used to fetch external data in linked tensors?",
        "a58eabda-8bcd-4afb-89c5-bddbe241b156": "Describe the difference between `get_managed_creds_keys()` and `get_creds_keys()` functions in the context of dataset management. How are these keys utilized within the Activeloop platform?",
        "8b7f8960-a6b9-4a0e-8735-d789ecf4a765": "How can you access a specific dataset view using the `get_view(id)` function? Provide an example of how this function can be used to retrieve a dataset view and display its contents.",
        "ad5b21a5-2dd5-43f5-a9b2-88041546c58b": "What does the `get_views(commit_id)` function do in the dataset management process? How does the optional `commit_id` parameter affect the views returned by this function?",
        "53a71ccf-df50-4901-b02d-f7f6c34fa529": "What are the two options for storing images in Deep Lake, and why is it recommended to store compressed images?",
        "4832aa94-9e20-4daa-982f-0ceb42c582e1": "How can an image tensor be created in Deep Lake, and what are the optional arguments that can be specified?",
        "2b600143-0180-41eb-b681-bdd0346951a3": "What are the supported compressions for storing images in Deep Lake?",
        "02f6efd8-b696-4cf9-b653-e8b4131be8e7": "How can image samples be appended to the image tensor in Deep Lake, and what are the two types of samples that can be used?",
        "af4dbb80-4bae-4d23-8c36-ca308edfb45c": "What happens if the compression format of the input sample does not match the sample compression of the tensor in Deep Lake?",
        "7c197997-e553-43a7-889b-1f41240f7d34": "How can multiple samples be appended to the image tensor at the same time in Deep Lake?",
        "685a9300-7a95-4312-9e48-ea009306e25c": "What are the `image.rgb` and `image.gray` htypes used for in Deep Lake?",
        "7f60b1c7-6559-4199-830c-e44e63ce2e42": "Explain the purpose of adding a creds key to a dataset in Deep Lake. How does the parameter 'managed' affect this process?",
        "361929d6-4a2e-42c2-b69b-3f3345da075d": "How can you connect a Deep Lake cloud dataset through a deeplake path using the `connect` method? Provide an example scenario and explain the parameters involved in this process.",
        "996b15b8-7a3d-495c-a41c-2cf86e572239": "What is the significance of the `_client` property in the dataset class? How can it be utilized in the context of working with external data in Deep Lake?",
        "85d4a536-7f81-4c53-877b-54b3b3efd170": "How can a tag tensor be created in a dataset using the provided code snippet? What optional argument can be specified while creating a tag tensor?",
        "45f8272a-c435-434e-9e42-38075fc71a46": "Explain the process of appending tag samples to a dataset. Provide examples of appending a single tag and extending with a list of tags.",
        "45fe5942-c699-46d2-8daf-b141e8f3db7e": "What are the key dimensions for bounding boxes in the context of the document? How can a bbox tensor be created in a dataset, and what optional arguments can be specified during creation?",
        "79bef728-adaf-4525-883f-74113b7f8ccc": "Describe the significance of the \"coords\" key in the creation of a bbox tensor. What are the different values that can be assigned to the \"type\" and \"mode\" keys within the \"coords\" dictionary?",
        "fef84cc3-7ab5-4576-9cd8-3364cfb9b584": "How can the format of bounding box coordinates be specified when creating a bbox tensor in a dataset? Provide examples of different conventions for bounding box coordinates mentioned in the document.",
        "7e98f729-f222-4e60-aad5-86520a71f022": "How can segmentation masks be compressed to optimize storage space, and why is it recommended to use `lz4` compression specifically?",
        "8bc859ab-df40-4558-b744-b50622e873a8": "Explain how binary masks can be appended to a dataset using `np.ndarray` and provide an example with 5 objects.",
        "573269d8-f0f3-43b5-8b52-8eddea252439": "What is the structure of COCO keypoints and how are they represented in a tensor for keypoints_coco?",
        "d3c49d5b-575a-4bdf-a998-912384d15a12": "How can a keypoints_coco tensor be created in a dataset, and what are the optional arguments that can be specified during creation?",
        "81c29c67-4b67-4756-9dda-e46ab2b35656": "Describe the three possible visibility values for keypoints in COCO keypoints and their meanings.",
        "52fa5761-0e79-4152-9ef7-4aec5d40da8e": "What are the key features of Read the Docs as mentioned in the provided context?",
        "92bb8b7c-9a4b-4bb8-aadb-15981ac238df": "How can you upgrade your documentation with Read the Docs according to the instructions given?",
        "747a1720-b339-4541-aa52-d40b5d22f5f9": "What is Flask and what is its primary function as described in the context?",
        "286e8fff-9d40-47aa-8bd1-ff71ce39f5f6": "Describe the purpose of Jupyter as mentioned in the context.",
        "d106d927-b363-4fdb-8d1d-269c65dd35df": "How can you get your documentation online in 5 minutes based on the information provided?",
        "85a4ea80-e002-4eee-af9e-72df8a063eaa": "How can audio samples be appended to tensors in Deep Lake?",
        "b788d7f4-fef9-45c9-a7c1-863324a81d15": "What are the supported compressions for audio samples in Deep Lake?",
        "6007eb3e-dad1-4254-9d5c-f12caf5181f2": "How can a class label tensor be created in Deep Lake?",
        "3de45201-61e9-4565-9e75-f88eb7bd7a03": "What are the optional arguments that can be specified when creating a class label tensor?",
        "92f2417a-89dd-40eb-ab9d-1e47105b644c": "How can the class names be set for a class label tensor after tensor creation in Deep Lake?",
        "dc87ac1a-0394-47a6-a387-a53847256ce2": "How can a mesh tensor be created in the given context? What are the optional arguments that can be used during the creation of a mesh tensor?",
        "e6eb0b9c-4ce5-46fd-96b5-f130f931ab1d": "Explain the process of appending a ply file containing mesh data to a tensor. Provide an example scenario.",
        "bdb13fe3-0c76-4cb6-98ac-d197c5fa3b33": "What is the purpose of creating an embedding tensor in the context provided? What are the supported compressions for embedding tensors?",
        "a1eb009d-2ec8-4615-8225-3924c291cf10": "How can embedding samples be appended to a tensor in the context described? Provide examples of appending a Deep Lake embedding sample and extending with multiple Deep Lake embedding samples.",
        "596ec184-a8d7-4472-9111-d34f81c78186": "What is the significance of the Sequence htype in the context provided? How does it differ from other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.?",
        "bcf35a35-9f3c-48b9-b8ab-003c024787bf": "How can bounding boxes be appended in the dataset for object detection tasks?",
        "9c809218-9a60-4571-a356-54d815a08d2a": "What is the required format for 3D bounding boxes to be correctly displayed by the visualizer?",
        "e0612eed-61e5-436a-98b8-33977836235f": "What key should be specified in the coords dictionary when creating a 3D bbox tensor?",
        "072f3967-f372-4437-a66e-39dfde1c10d1": "Why is it important to have the intrinsics tensor or matrix specified when projecting 3D bounding boxes onto 2D data?",
        "1f0de180-3f5f-4dfe-96b1-17f9140cf4f5": "Can bounding boxes be appended as both np.ndarrays and lists of arrays in the dataset?",
        "9c20e800-04e6-427b-8084-b095379ecc97": "How can a tag tensor be created in a dataset using Python code?",
        "1a0c7a08-ee45-4d06-a493-232cb63308cc": "What are the supported compressions for chunk compression when creating a tag tensor?",
        "ba54bf03-baef-450a-8635-3f1b81079456": "Provide an example of how to append a tag sample to a dataset.",
        "edc9ceb1-b7b2-4bfc-8c4f-2e6577ef6ef9": "Explain the format of bounding boxes and why it is important to specify it in the coords key when creating a bbox tensor.",
        "8093d1b6-c0ac-4d74-96fa-206eadb5ceaf": "How can a bbox tensor be created in a dataset using Python code?",
        "4dacfcc3-d068-4ccb-8115-51f271d4da2c": "What are the keys required in the coords dictionary when creating a bbox tensor?",
        "26608b35-21c0-4c19-a8bd-cd0c6f346ef0": "Describe the difference between the \"pixel\" and \"fractional\" types for bounding box coordinates.",
        "3cddb0fd-460a-4374-a198-0c2a75a4c9e2": "What are the different modes available for specifying the convention of the 4 coordinates in a bbox tensor?",
        "e9a6a3be-3086-43e9-8b03-432bc329e576": "How can you set the class names after creating a tensor in a dataset?",
        "2d9b4bd7-470b-4b2f-a8ee-f05ac3a546f4": "Explain the difference between sample_compression and chunk_compression in the context of the provided information. How are they used in the dataset?",
        "cbb5c24f-f3ad-44f0-a6a0-66b830701a03": "How can 3D bounding boxes be appended to a dataset? Provide an example of appending one bounding box and another example of appending a sample with three bounding boxes.",
        "3b874128-76bb-4948-91e2-3d9127c7f663": "What is the purpose of the intrinsic matrix in the context of camera calibration? Explain the components of the intrinsic matrix and their significance in the transformation from 3D camera coordinates to 2D image coordinates.",
        "0b77c3a7-1768-481c-a677-7b10f297f337": "What are the supported values for the parameter when loading a view in the dataset?",
        "047f469a-72b0-4d19-8405-1719f61096fa": "How can you display the details of all past commits in the dataset?",
        "7aa8b8d1-2766-4fe1-9578-f75c8d46091a": "What does the property _max_len return in the dataset?",
        "abbf2c89-ec4e-40c4-8376-b59a0c7fc47d": "Explain the functionality of the property _max_view in the dataset.",
        "4531829a-679e-46bd-bff5-1b37a5fa1c65": "Describe the scenario in which the merge method in the dataset would be useful.",
        "33bd5d30-8b29-4446-9417-1981945e78e0": "Compare and contrast the features of Deep Lake with WebDatasets and Zarr based on the information provided in the context.",
        "b76c7a51-bb47-4f62-951a-e40515e79908": "How can you append 2 2-D points to a dataset using the provided code snippet?",
        "76848951-864f-421d-9c76-cbd120afdf8e": "What are the sample dimensions for the Polygon Htype?",
        "6cad9857-86c9-49f1-b269-5985b9f4bbe8": "How can you create a polygon tensor named \"polygons\" with no sample compression using the provided code snippet?",
        "5cdbd9b1-85ff-40e1-b62f-0b3e39eb2e3e": "What is the requirement for all points in a sample within a polygon tensor?",
        "ce2fc8ba-2450-49a3-b55a-29f926fe7d94": "How can polygons be appended to a dataset according to the context information provided?",
        "18b43156-a646-4297-a42e-0bb3d758aff8": "What happens if a tensor is renamed on both the target and current branch in the dataset?",
        "0ba10753-a19c-42d7-9243-de9732c8140c": "What exceptions can be raised when working with the dataset, according to the provided context information?",
        "67d8793f-9478-41d8-a5d9-95f5f2ebc10f": "How can you access the metadata of the dataset?",
        "bb30c5c3-e197-438a-b74c-dd7cc1a694d4": "How does the _min_len property help in dataset manipulation?",
        "a5c13958-0585-4d29-ae05-5612c8434136": "How does the _min_view property modify the dataset?",
        "5c6ae368-9c25-45b9-88dc-65b609140701": "Can you provide an example of using the min_view property on a dataset with images and labels?",
        "362aa129-1731-4a3d-8df7-c593a8ef5ced": "What does the _no_view_dataset property return?",
        "039d3b09-23e6-4106-97bc-04d1fff9932e": "How does the _num_samples property differ from the length of the tensors in the dataset?",
        "1fb10b5d-8980-4022-b0b3-22e16643584b": "How can you access the parent of a specific group within the dataset?",
        "67bbad3f-c821-4aa2-aef0-d52295d671fc": "What are the two types of units specified for bounding box coordinates in the given context information?",
        "26476eb8-c515-44e5-8f4a-0b8a9c21d700": "How can bounding boxes be appended in the dataset according to the examples provided?",
        "53880fa3-f43c-498f-9091-a7871608387c": "What is the default data type for bounding box coordinates mentioned in the context information?",
        "6e934b3a-75a8-4449-8d0b-7bdf7aaeafd5": "How should the format of 3D bounding boxes be specified for correct display in the visualizer, as per the given information?",
        "8339e242-a003-4454-b8bc-67a3e29f1f40": "What compression options are supported for bounding box data in the context provided?",
        "c518d8b3-9af3-4d76-a630-3b2ea81f4b1a": "Explain the process of creating a point cloud tensor using the `create_tensor` method in the given context. What are the optional arguments that can be used during the creation of a point cloud tensor?",
        "4547799f-f6ce-4223-9816-6d4ab0d92e9a": "How can point clouds be appended to a dataset using numpy arrays? Provide an example of appending two point clouds with different numbers of points and explain the resulting shape of the dataset.",
        "dc21fcab-e96c-4a3c-bcd5-46beed053f60": "Describe how point clouds can be added to a dataset using the `deeplake.read()` method. Provide an example of adding a sample point cloud with 100 points and explain the resulting shape of the dataset.",
        "e2663447-9d8c-4a8d-aaa4-790176899737": "What are the key characteristics of the `mesh` htype in the given context? How is the sample dimension defined for mesh samples?",
        "f776d7bc-c28c-4efd-8f22-19b472c04e22": "Compare and contrast the structure of point clouds and meshes in the context provided. How do they differ in terms of data representation and dimensions?",
        "2ea679b5-077a-45a9-953e-cb4120b76233": "Explain the different valid source directory structures for image classification in the context of the Deep Lake dataset.",
        "90acc0c3-bf08-49ad-b4dd-105271fcde69": "How can classes defined as sub-directories be accessed in the Deep Lake dataset?",
        "326c8c29-8a16-4ce3-b121-ebe8d3b1a3c3": "What is the purpose of the `deeplake.ingest_coco` function in the context of the document?",
        "7faa05d6-85fe-470f-896d-ecb85260e89b": "Describe the options available for mapping filenames to classes in the Deep Lake dataset.",
        "98dd5f9e-7181-4134-879d-54c9d8098f81": "How can images and annotations in COCO format be ingested into a Deep Lake dataset according to the provided information?",
        "f460b68b-39df-48ab-a15a-4eaea5e41c2b": "What is the purpose of the outer list and inner list in the given context?",
        "0a68a2f7-1bdf-4869-a6f5-f6339411499a": "Can you explain the significance of the doc_id and relevance_score in the inner list for each query?",
        "af858bf7-f62d-4fd3-8f66-4a17f670ab38": "Why is it mentioned that only values of 1 contribute to the training, and there is no reason to provide examples with relevance of 0?",
        "826ec81d-efbb-49d9-9bfc-61dbd981d28d": "What is the role of the embedding_function in the training process, and why is it required to be specified?",
        "50c02af3-36f9-44ef-a83a-1f423f113fed": "How does the API token for the DeepMemory managed service play a role in the context provided?",
        "6c10b720-a602-46f5-ab2c-2910567458cf": "What is the expected return type of the function described in the context?",
        "9f2bd508-e476-41e8-b9ff-a4b67e0a06da": "What exception is raised if the embedding_function is not specified during initialization or training?",
        "88b19f2f-f052-460c-9404-b1bace41c3fa": "What is the purpose of the `creds_key` parameter in the `ingest_huggingface` function?",
        "32f738a3-d788-4119-a8dd-0a74f1de90ef": "How can you enable or disable the ingestion progress bar in the `ingest_huggingface` function?",
        "02e38d43-cb67-4070-9636-9f02565b26cd": "What is the significance of the `token` parameter in the `ingest_huggingface` function?",
        "75f61eb5-2dca-40f0-a969-2e15e9956da3": "Explain the role of the `connect_kwargs` parameter in the `ingest_huggingface` function.",
        "e0918cb9-90ba-42ee-be27-1d6761b06d6f": "How can you create a new dataset from a dataframe using the `ingest_huggingface` function?",
        "92f79a3e-6c3d-4957-b9b6-a5658e8b8f46": "What type of exception will be raised if the `src` parameter is not a valid pandas dataframe object in the `ingest_huggingface` function?",
        "f4f19cb4-0e63-49ee-8b3d-bfccf538c8c0": "Describe the purpose of the `use_progressbar` parameter in the `ingest_huggingface` function.",
        "a883f6e1-dd70-44aa-8ad0-90c2100a277e": "How can you convert Hugging Face datasets to Deep Lake format using the `ingest_huggingface` function?",
        "d5b99bcf-a7e4-4639-b28a-cd41a2712bc0": "What is the role of the `dest` parameter in the `ingest_huggingface` function?",
        "a5fcd62d-7aee-4e34-a841-1c2961255db0": "Explain how the `dataset_kwargs` parameter is used in the `ingest_huggingface` function.",
        "7752aec3-401f-4ab1-835b-485af9f1c3b9": "How can you evaluate the performance of a trained model on a custom dataset using `db.deep_memory.evaluate`?",
        "af896b8e-964b-4500-8006-6b7a0b77bab9": "What is the structure of the `corpus` parameter required for evaluating the model performance in `db.deep_memory.evaluate`?",
        "7b4dc898-49a1-475e-96be-8b3e91f4b776": "What information does the `recalls` dictionary returned by `db.deep_memory.evaluate` contain?",
        "8270d65d-1b5f-4787-9761-0b7499c4bab7": "How can you enable the creation of a separate vectorstore for tracking evaluation queries and documents in `db.deep_memory.evaluate`?",
        "ad8010d6-e1cf-458c-a7a1-e07f7e1a6b88": "What is the purpose of the `embedding_function` parameter in the `db.deep_memory.evaluate` function?",
        "916f74b1-fe56-41cb-b5cf-6ea19c097d4a": "How does Deep Lake's Weights and Biases integration help improve reproducibility in machine learning experiments?",
        "72b14502-01bf-4373-877e-d6230b9b09ad": "What information does Deep Lake automatically push to Weights and Biases when tracking experiments?",
        "f15f612c-ecc8-4324-93cd-1e0022e11531": "How can you log the creation of a Deep Lake dataset on Weights and Biases?",
        "69435783-44c3-4b6b-b72f-4b9437809a3d": "What are some key concepts covered in the Deep Lake documentation?",
        "b3a85228-2fe3-496f-aa66-e312c2e11220": "How does Deep Lake's Dataloader contribute to high-performance features in the platform?",
        "6acd555d-63af-4f86-8350-00cf8c60232d": "How can you set the `connections` and `sample_compression` for `tensor.info.keypoints`?",
        "0e3821c3-da73-4a98-bcd9-0ac8efd46105": "What is the default data type for `dtype` in `tensor.info.keypoints`?",
        "2916ec23-7cd4-4e88-8c1e-378428935c72": "How can you append keypoints to a sample with multiple objects?",
        "48342f3c-d44e-4330-b0f8-83680265e6fb": "Why is it important for all objects in a sample to have the same number of keypoints in the same order?",
        "a13da49f-a24e-4df6-b4d2-e82abe796c76": "How can you update the keypoints and connections after tensor creation?",
        "b0d97432-6edd-48cc-937f-575e5d909306": "What is the purpose of the `tensors` parameter in the context provided?",
        "826557a0-304d-4d31-b6c7-9debc14025de": "How does the `overwrite` parameter affect the copying process in the context provided?",
        "df8da502-b54f-4e8d-a6b5-edb0452dc8f5": "Explain the significance of the `src_creds` parameter and provide an example of how it can be used.",
        "2dbc5271-a937-4fc1-ac70-a1d14d5c9a59": "What role does the `num_workers` parameter play in the copying process according to the context provided?",
        "26d69c6e-5135-4a1b-882d-4945c68a3e41": "How does the `public` parameter impact the accessibility of a dataset in the context provided?",
        "fea5f60a-d14a-4256-9012-b5d3a8e962ad": "How can a tag tensor be created in a dataset using Python code?",
        "2208692f-1d33-4332-98e8-85af4637e325": "What are the supported compressions for chunk compression when creating a tag tensor?",
        "211cf262-0757-40ae-96c3-2d9e06fb7f87": "Provide an example of how to append a tag sample to a dataset.",
        "ccbc7e26-b7c2-4cea-83a7-33ff58001f2f": "What are the sample dimensions for a bounding box in the Bounding Box Htype?",
        "e1339cc2-850d-4d7a-8da4-f6053b7e76f0": "How can a bbox tensor be created in a dataset with specified coordinates and mode?",
        "c51b0e4c-ca92-47e4-bb40-01b93e5c4922": "Explain the difference between the \"pixel\" and \"fractional\" types for bounding box coordinates.",
        "893a5499-c700-4742-8a7f-63d4729caff9": "What are the conventions for the 4 coordinates in the \"mode\" key when creating a bbox tensor?",
        "b7ef2e39-c8c2-45a8-b45e-8d066776146a": "How can you set the class names after creating a tensor in a dataset?",
        "f0e87075-6a0c-469c-8eb3-f9b2ef349d58": "What is the purpose of the `check_integrity` parameter in the dataset creation function?",
        "4fc3bf16-cfb3-40aa-85e2-e014e5528cd2": "When would you set the `lock_timeout` parameter to `None` in the dataset creation function?",
        "4e2a7846-9a4c-4101-89a4-aa146ef780ea": "What is the potential risk of setting `overwrite` to `True` in the dataset creation function?",
        "291b55ef-8872-4e3c-b427-b3f6182ca49e": "How can you handle concurrent access to a dataset if `lock_enabled` is set to `False`?",
        "b1e3a180-0dab-4c81-bf75-9d915b502eb9": "What exceptions might be raised if the dataset is corrupted and `reset` is not set to `True`?",
        "65df5cf9-4b07-47bd-b645-9aceb5af84e2": "Why should you be cautious when setting `access_method` to `download` in the dataset creation function?",
        "2039b6c4-5bfa-4b71-9454-f9cc947a7bec": "What is the significance of the `index_params` parameter in the dataset creation function?",
        "4daaa71e-e3bd-4f16-b292-e384c8fd594d": "Under what circumstances would an `AgreementError` be raised during dataset creation?",
        "e6562299-5391-4456-9a89-3a221dcd1a7e": "How can you avoid the `LockedException` when opening a dataset for writing?",
        "53e87812-c1b6-4e9c-9b7c-6c1a47839900": "What is the purpose of the `return` statement in the dataset creation function?",
        "75d30097-c8cd-40bb-a7ca-189131c68328": "Explain the difference between the \"point\" and \"polygon\" Htypes in the context of keypoint data storage.",
        "e5274884-bd65-4b45-b9fd-a7773388ff36": "How can dummy coordinates be used to store keypoints that are not present in an image?",
        "ee228351-d00d-4f06-a898-bcd7cbb9e76f": "What is the sample dimensions for points in a 2-D coordinate system?",
        "d9805202-40a3-4156-90d4-ebb489253c80": "How can a point tensor be created using the provided code snippet?",
        "5b92bfc2-497e-4848-9fc5-08649e15bb4d": "Can you provide an example of appending 3-D points to a dataset using the given code snippet?",
        "4674acfb-d2f5-4d1c-8820-213a17445f78": "What are the key considerations when working with the \"polygon\" Htype in terms of the number of coordinates per point and polygons per sample?",
        "fe630376-0b7a-4896-835d-c8fa254639f5": "How can different samples in a tensor of \"polygon\" Htype have varying numbers of polygons and points per polygon?",
        "e8027310-23ae-4386-8143-56e8072f7e5a": "How can you store your credentials on the Activeloop Platform for datasets?",
        "6aa0e5be-1b67-439d-acf1-80f1c1599bf2": "What is the purpose of using managed credentials in the context of adding keys to a dataset?",
        "40ee9bf8-08b6-4eea-ab5b-5aa0d504a82a": "How can you create a link tensor in the dataset?",
        "9597d104-203b-47d1-bfe2-f74230fab82d": "Provide examples of different types of links that can be populated in the tensor.",
        "413c25c6-3d6b-4344-ae4f-cb9cd2a6342a": "Why does a link with a cloud path always require a creds_key in the dataset?",
        "70849b4d-a4fd-4ea9-8a84-7b013d3a33fb": "How can you access the data stored in the dataset using Python code?",
        "eeb744b0-b7df-4a4c-94a5-762c36d5148c": "How can you update a sample in the dataset with a new link?",
        "775477cb-288b-494c-9a9c-44d8335b2653": "How can you set the `connections` attribute in `tensor.info.keypoints`?",
        "8334f2a4-0766-497a-820c-fea28c708a9c": "What is the default data type for `dtype` in `tensor.info.keypoints`?",
        "01b5aa50-9319-447b-846c-111e5f2b682e": "How can you append keypoints to a sample with multiple objects?",
        "ae38e16a-1cdc-4c11-978b-944f96c6a8c6": "Why is it important for all objects in a sample to have the same number of keypoints in the same order?",
        "d6cb310f-d33b-4a58-bcf3-f00d80e6b87c": "How can you update the `keypoints` and `connections` after tensor creation?",
        "0c4f69b5-b44f-4389-b8a8-c81363f34634": "Explain the purpose and functionality of the `enable_readonly()` method in the `StorageProvider` class of the `deeplake.core.storage` module.",
        "dce453b6-f8fa-45cc-abcc-52af246df805": "How does the `eval()` method in the `Pipeline` class of the `deeplake.core.transform` module differ from the `evaluate()` method in the `DeepMemory` class of the `deeplake.core.vectorstore.deep_memory.deep_memory` module?",
        "0807668e-118b-4a2c-ad56-ca2a36fff8fe": "What is the significance of the `exists()` static method in the `dataset` class of the `deeplake.api.dataset` module, and how is it used within the context of the document?",
        "29ab896f-ed68-4ab2-a672-b8028700926b": "Describe the relationship between the `extend()` method in the `Dataset` class and the `Tensor` method in the `deeplake.core.tensor` module.",
        "89b3e9db-1df0-44c7-9f63-04bc63e4a385": "How does the `flush()` method in the `Dataset` class interact with the `LRUCache` and `StorageProvider` methods within the `deeplake.core.storage` module?",
        "9db4973d-8f59-4445-bbb9-8fe268dd432a": "What are the two options for setting the `tensor.info.class_names` list?",
        "59facee4-07fb-4062-a2df-2a9f72aeec75": "How can you update the class names after tensor creation?",
        "88f52bad-872b-4189-8a40-7c53b1651cb1": "Why is `chunk_compression` recommended when the number of labels in one sample is low?",
        "e86f0ca8-a849-4bef-975b-2d1f70a0a1f9": "How can class labels be appended to a dataset?",
        "1471f70f-20fa-42ee-bab8-bbdcbb411fd8": "What are the different types of data formats that can be used to append class labels?",
        "9a459a7f-fb84-41d1-bd38-fb619369efe2": "How can a tag tensor be created in a dataset?",
        "33e306b9-d562-49f1-8215-1ca4acc6c986": "What are the supported compressions for creating a tag tensor?",
        "8d48d774-d253-4eb6-b51d-59e237bb8053": "How can tag samples be appended to a dataset?",
        "16e46be5-cf6e-428f-9088-28b2db656a96": "What is the purpose of the `tag` htype in the context of sample dimensions?",
        "f78762ee-6041-401b-9467-0b52c87901b9": "How can you extend a dataset with a list of indices for class labels?",
        "b99406b0-69f2-4cc7-9dc9-fbd9b3092715": "What is the purpose of the _ndim property in the Tensor class?",
        "4ebcf959-d269-4c70-8c9f-befd7ef63c07": "When using the numpy method to compute the contents of a tensor, what does the aslist parameter control?",
        "37b2e49c-7207-4b15-a92e-fbf8b89ec0e6": "In the path method, what does the fetch_chunks parameter determine when retrieving data from linked tensors?",
        "bf7cb4d7-3722-4cc7-9bb4-4c5f1be8dd26": "What error will be raised if a target id is passed to a tensor which is not an ancestor of the current commit?",
        "09f5d5c7-e849-47ea-a85c-f998268bd760": "When using the numpy method with fetch_chunks set to False, under what conditions will full chunks be retrieved from the storage?",
        "3873e561-9223-479f-8a70-e73bebd48183": "What are the supported values for the `scheduler` parameter when optimizing for optimization?",
        "bfdcfa37-f860-4611-a8fe-6ac29e770045": "What is the default value for the `verbose` parameter?",
        "73cf4775-c1ac-4044-9208-8a8ed42e6439": "When would the `ignore_errors` parameter be applicable and what is its default value?",
        "ec5268c1-bfe3-4e77-9124-0dda5df22e75": "What type of error would be raised if the user attempts to save a view inplace without write access?",
        "94df0a96-af49-48a5-bb36-92bc717ec3d9": "How can an external view be loaded if the `path` parameter is specified during saving?",
        "c9bac743-9787-4047-ab6d-8460bed75251": "What is the purpose of the `set_token` method in the context of the document?",
        "7b1a3479-61f4-432b-8901-59f6ab46909d": "How does the `size_approx` method estimate the size of the dataset?",
        "33490816-db34-463e-af1a-e81739dd3349": "When would the `summary` method take a long time to execute, and how can this be overridden?",
        "80018252-64b9-4089-a2fa-2018fb9d1674": "How can you determine if a dataset is in read-only mode or not?",
        "265dc50e-9077-4f5a-b759-4f3e9b907943": "What is the purpose of the `Dataset.commit` function in dataset version control?",
        "762f255f-21eb-41f2-8208-638dee70550a": "How can you view the differences between commits or branches in a dataset?",
        "67fd48f7-3c7b-463f-8d98-2d32bf15874f": "When can a dataset view be saved?",
        "e1e6325f-710f-4aec-84ff-fc0821ee4f56": "Explain the difference between creating a dataset view by indexing, filtering, querying, and sampling a dataset.",
        "795e0ef5-5f0d-4906-9db8-da5ecdd056f6": "Explain the process of creating a point cloud tensor using the `create_tensor` method in the given context. What are the optional arguments that can be used during the creation of a point cloud tensor?",
        "e81c126f-0795-448b-9934-305e9efb5805": "How can point clouds be appended to a dataset using numpy arrays? Provide an example of appending two point clouds with different numbers of points.",
        "05f300ad-9d83-4d22-b50c-4c758973066d": "Describe how point clouds can be added to a dataset using the `deeplake.read()` method. Provide an example of adding a sample point cloud with 100 points.",
        "373e69fb-de0a-4ff7-9b20-58ace5c5477a": "What are the key characteristics of the `mesh` htype samples in the given context? How are mesh samples represented in a tensor of `mesh` htype?",
        "c6779aa6-48d7-46eb-9dc5-a30d03a0caaf": "Compare and contrast the characteristics of point cloud samples and mesh samples in the context provided. How do they differ in terms of data representation and structure?",
        "eeff8f80-c0e7-422d-8629-0fecdd04ce4e": "What are the three options available for the `exec_option` parameter in the context of search execution?",
        "5c2a455f-d654-416d-9b6d-39fabe6cb188": "How does the `python` option differ from the `compute_engine` option in terms of implementation and potential issues?",
        "76bae9e4-12c8-40f6-a94b-7ebf28e5e647": "When creating a Deep Lake dataset, how can you specify that it should be stored in the Managed Tensor Database using the `runtime` parameter?",
        "c6ac3aa9-b1f6-4cfd-ab92-5f1c7378e9f6": "What is the purpose of the `embedding_tensor` parameter in the context of the query?",
        "e1f09775-ee01-4354-8c65-64f644669e58": "How does setting `return_view` to `True` affect the `return_tensors` parameter in the query?",
        "4e0ca481-b9ca-4c08-bfbb-2a0eaef93e3f": "How can dataset views be created in Deeplake? Provide examples of methods that can be used to create dataset views.",
        "c43eb2d1-fc88-430c-9f43-ea291af2d9a5": "What is the significance of saving a dataset view only when the dataset has been committed and has no changes on the HEAD node?",
        "4064b002-988d-4842-beb8-d763350829b5": "Explain the difference between filtering a dataset using a user-defined function and filtering with simplified expressions in Deeplake.",
        "d352f6ee-9205-4837-bacf-22435c1379fb": "How can you retrieve a dataset view in Deeplake using the `load_view` function? Provide an example scenario.",
        "27abb7c5-4875-4d28-b52a-8ed414358b08": "Why is it important to use `Dataset.save_view` when saving a dataset view as a virtual dataset (VDS) in Deeplake?",
        "cc757ff7-588b-41a1-8da0-db2f143a2ca2": "How can you set the `connections` attribute in `tensor.info.keypoints`?",
        "04efb53b-b26f-471c-a441-550c3f381a7c": "What is the default data type for `dtype` in `tensor.info.keypoints`?",
        "7b683a4a-f496-41ba-8b1f-16c77e4f39df": "How can you append keypoints to a sample in the dataset?",
        "83a39083-013f-4021-b347-09851fc4c37a": "Why is it important for all objects in every sample to have the same number of keypoints in the same order?",
        "ca28f1d4-e80c-470f-ac64-b9cf96d8871a": "How can you update the `keypoints` and `connections` after tensor creation in the dataset?",
        "706682f1-e6d2-45c6-bf2d-88266caa2b22": "Explain the purpose of the `deeplake.tiled` function and provide an example of how it can be used with the specified parameters.",
        "a75d00c5-9e20-4551-8aed-f76331e48158": "What is the significance of the `tile_shape` parameter in the `deeplake.tiled` function? How does it affect the storage of the sample data?",
        "27b4fb66-c55b-447a-a552-2dee1377302a": "How does the `dtype` parameter in the `deeplake.tiled` function impact the data type of the sample array? Provide an example scenario where specifying a different data type would be beneficial.",
        "6b23f301-cd4d-424d-b641-5938e5fd9f0d": "Describe the role of the `deeplake.compute` decorator in the context of the provided information. How does it modify the behavior of functions it decorates?",
        "f429758d-c36a-4a84-a17d-bab3628e5073": "Can you explain the requirements for functions that are decorated with `deeplake.compute`? What are the expected arguments and output for such functions?",
        "5b5a0696-b5fc-46ea-bca0-aa1144f25b4e": "Explain the difference between `deeplake.ingest_classification`, `deeplake.ingest_coco`, and `deeplake.ingest_yolo` in terms of the type of data they ingest into a Deep Lake Dataset.",
        "b56deb61-283f-4d03-9376-b3a10935db8f": "How can you create a new dataset by copying the structure of an existing dataset to a new location using the `deeplake.like` function?",
        "4d02f262-02e6-4ea2-a7d1-8b53845c6834": "Describe the process of loading an existing dataset using the `deeplake.load` function.",
        "6178e64c-d384-488a-96ea-1fcd646e0bbd": "What is the purpose of the `Dataset.append` function and how does it differ from the `Dataset.extend` function in Deep Lake?",
        "fd344550-9682-4251-9849-58793712ddd5": "How can you delete a dataset at a specific path using the `deeplake.delete` function?",
        "c39337dc-9ca2-4a96-bd76-a36e68ce9177": "What are the limitations of the Deep Lake Performant Dataloader in terms of supporting data formats?",
        "33b51a06-5e29-45d7-b5d6-08116c63b45c": "How can a nifti tensor be created in Deep Lake, and what are the supported compressions for nifti data?",
        "42c9a229-a622-4974-8f07-3a91e77d0e33": "Can raw nifti data be compressed when appending it to tensors in Deep Lake? If not, what is the alternative?",
        "1b11586e-0a93-452c-910b-bb8d766c3eb5": "What are the key characteristics of point cloud samples in Deep Lake, and how are point cloud tensors created?",
        "3728ec24-76d2-4891-b9fb-db4ad3d6668b": "What are the supported compressions for point cloud samples when creating a point cloud tensor in Deep Lake?",
        "4db4c28d-b645-4403-9640-b3a001c6e09c": "Explain the purpose of the `sequence` htype and provide an example of how it can be used in a dataset.",
        "d6540c77-335c-434a-a35c-38cfe582a050": "What is the `link` htype used for in a dataset? How does it differ from other htypes like `sequence` or `image`?",
        "edbf59eb-0baf-41ea-a2ea-9cae6c820ed9": "How can you extend a dataset with Deep Lake embedding samples? Provide an example code snippet.",
        "752395d3-d6c8-490a-a117-c9a2b62be227": "What are the exceptions to loading data when using the `link` htype in a dataset? Explain each exception in detail.",
        "d18214eb-adf0-48b3-9d67-56bdbd45428c": "How can you create a tensor with the `sequence[image]` htype in a dataset? Provide an example code snippet.",
        "378cda6b-4be5-4cc1-9b27-51a05da484e6": "What dependencies are installed when running the command `pip install \"deeplake[point_cloud]\"`?",
        "0f6a18a9-db0c-4285-8b16-78facd1fd5ef": "What is the purpose of installing the package `deeplake[visualizer]`?",
        "8e4f2271-46bd-490b-afbc-c4fd2e6e9cc9": "Which command should be used to install all available dependencies for Deep Lake?",
        "c3b55691-319f-4829-8a73-49f7bb85806f": "What support is provided by the package `deeplake[medical]`?",
        "1eed59cf-eabd-4633-8b83-602947215818": "How can Google Drive support be added to Deep Lake by using pip?",
        "88174f45-4904-494f-bbb1-3ef20224bac8": "What are the limitations of the Deep Lake Performant Dataloader in terms of supporting data formats?",
        "c3278bab-1793-4f3a-a289-3e0a0299be03": "How can a nifti tensor be created using Deep Lake? Provide an example of creating a nifti tensor.",
        "32a2f030-16b4-4c6f-9b8d-21d66d40c0c1": "How can nifti data be appended to a tensor in Deep Lake? Can raw nifti data be compressed?",
        "f82e88e1-9e7c-4e30-9b45-b585676e2ad2": "What is the point cloud Htype in Deep Lake? What are the sample dimensions for point cloud samples?",
        "f2da853b-dbc1-40b0-bc3e-4f16b2a25f8a": "How can a point cloud tensor be created in Deep Lake? What are the supported compressions for point cloud samples?",
        "6d5703dd-2d42-418b-8c10-83734132b63d": "How can point clouds be appended to a tensor in Deep Lake? Can point clouds be of type `Sample`?",
        "fb3bbce0-5a6c-4383-91cc-bee62effa461": "How can audio samples be appended to tensors in Deep Lake?",
        "996d8fa3-01fe-444f-ac96-96f26675b4e9": "What are the supported compressions for audio samples in Deep Lake?",
        "3dfe7d21-1fb9-4542-8947-4e04e8eaee7d": "How can a class label tensor be created in Deep Lake?",
        "89782e9b-d113-4114-93a0-0155e30c894c": "What are the optional arguments that can be specified when creating a class label tensor?",
        "46ff60ec-c3d5-4ba6-800f-318f1f407c84": "How can the class names be set for a class label tensor after tensor creation in Deep Lake?",
        "0c635133-5a20-43bf-bcaf-f5ec67162d2d": "What is the purpose of the `org_id` parameter in the function?",
        "13c2532b-afec-4c8a-a8f0-2fb46984737b": "What does the `verbose` parameter control in the function?",
        "ccc8dd11-8640-4eb2-915f-6e7ec920b314": "Explain the difference between the `access_method` values of 'stream', 'download', and 'local'.",
        "76591c96-748b-4213-bc79-f24addc4c0ac": "How does the `unlink` parameter affect the function when set to `True`?",
        "dc8bcf2d-5712-4cae-bfab-f32dff969b46": "Can you provide an example of modifying the 'download' access method to specify num_workers and scheduler?",
        "1b1e132c-1e4f-499e-b9c0-212dc9b30530": "Explain the key concepts of Datasets, Vector Store, Tensors, and Htypes as mentioned in the document.",
        "bce3cc68-091c-47db-8607-8b6d5e823030": "How can an image tensor be created according to the document?",
        "86dfdeeb-906b-442a-918d-38b8549cb960": "Describe the process of appending image samples as outlined in the document.",
        "9b446c22-6aa1-41b0-b12a-fc18944a9d3d": "What are the differences between image.rgb and image. as mentioned in the document?",
        "38b58eb7-5c12-46b1-956e-c3d3b4636ca2": "How can segmentation masks be compressed to optimize storage space? Why is it recommended to use `lz4` compression for segmentation masks?",
        "ef965b5d-56db-4e2c-8e12-1e2cbb9cb667": "Explain the format of COCO keypoints and the values that represent the visibility of a keypoint. Provide an example of a set of `K` keypoints for an object.",
        "e3d64f37-b58d-4191-af86-e4b37409c7c2": "How can a keypoints_coco tensor be created in the dataset? What are the optional arguments that can be specified when creating this tensor?",
        "4ec3b5c0-bf87-412a-83b1-e012a46718a4": "Describe the purpose of the `connections` parameter when creating a keypoints_coco tensor. How does it affect the visualization of keypoints in the dataset?",
        "74b1a91f-0b64-4e9c-b675-a8785c3d6c2f": "In what scenarios would it be beneficial to append binary masks as `np.ndarray` in a dataset? How does this process help in organizing and managing data efficiently?",
        "6ae3daef-46b3-4a49-9b8f-aacc94d64081": "Explain the process of creating a point cloud tensor using the provided code snippet. What are the optional arguments that can be used during the creation of a point cloud tensor?",
        "cf47bd80-7886-4369-8caa-c4a87b1d5847": "How can point clouds be appended to a dataset using numpy arrays? Provide an example using the given code snippet.",
        "b3b86d57-210a-4e76-8792-942d8bb00c7a": "Describe the Mesh Htype and the characteristics of mesh samples as mentioned in the context information. How is a mesh represented in a tensor of mesh Htype?",
        "f1a86d6a-0fbb-4d22-a7c5-f7ace8890ba3": "What are the key differences between point clouds and mesh samples in terms of their dimensions and data representation? How can different point clouds and meshes be handled within a dataset according to the provided information?",
        "ba75dabb-b820-4367-8bd5-56f95a7ab096": "Explain the process of creating a point cloud tensor using the `create_tensor` method in the given context. What are the optional arguments that can be used, and what are the supported compressions for sample data?",
        "45a047ec-0b43-44ec-8bef-27b8bdfee127": "How can point clouds be appended to a dataset using numpy arrays? Provide an example of appending two point clouds with different numbers of points and explain the resulting shape of the dataset after appending.",
        "dafc1bf5-ac23-4501-9e85-a602cbefca7f": "Describe how samples can be added to a dataset using the `deeplake.read()` method for point clouds. Provide an example of adding a sample with 100 points and explain the resulting shape of the dataset.",
        "00b02a2c-abc2-4c16-96c3-bccec8fde9b1": "What are the sample dimensions for the `mesh` htype in the given context? How are mesh samples represented in a tensor, and what is the structure of each mesh array in the context of the document?",
        "5133c554-92e7-4bed-ab02-0dc5b1d1f1fb": "Compare and contrast the creation and appending processes for point clouds and mesh samples in the context provided. Discuss any similarities and differences in handling these two types of data structures.",
        "99ddc11a-70d4-49ab-8db2-85c8d864df11": "What is the purpose of the `delete_branch` method in the dataset handler class?",
        "e13e9d9c-bb45-4551-ab34-7042d5731ae7": "Under what conditions can a branch be deleted using the `delete_branch` method?",
        "345aa517-a6f1-42ab-a3f0-114f2e387c54": "What exceptions may be raised when attempting to delete a branch using the `delete_branch` method?",
        "b86cb1c3-4914-48f8-a841-af586d4fa1d7": "How can you delete a tensor group from the dataset using the `delete_group` method?",
        "6fd6a736-6b95-4159-86fa-6839f9aeb7fc": "What is the significance of the `large_ok` parameter in the `delete_group` method?",
        "1857de34-8f1a-4fea-a77c-1b233a24330b": "What are the different types of destinations that can be specified when ingesting data from a DataFrame using the `deeplake.ingest_dataframe` function?",
        "e0d53105-6dd9-4e09-965c-1cadad4ed565": "How can you authenticate to Deep Lake when writing to Deep Lake cloud datasets?",
        "2cf64e64-c662-47c1-9a9f-7e1ca7e8f005": "What is the purpose of the `column_params` parameter in the `deeplake.ingest_dataframe` function?",
        "558efd44-2c77-4c34-b129-3f08a2436a4a": "When using a memory path as the destination, what is the behavior of the dataset that is created?",
        "59df631e-64d5-4c81-8120-1979f91581db": "How can you specify the filenames for linked data in the dataset when ingesting data from a DataFrame?",
        "42e204f4-52c6-4c50-bab2-a0cfd001fc75": "How can you append 2 2-D points to a dataset using the provided code snippet?",
        "f768e94e-43d9-44ae-9b8e-a110aa96a6d1": "What is the structure of a polygon tensor in the \"polygon\" htype?",
        "b6ae2a52-4cba-4701-86e5-269e875532ea": "What are the requirements for the points within a sample in a tensor of \"polygon\" htype?",
        "9376f7f1-b753-4d25-99d2-4619e965f916": "How can you create a polygon tensor using the provided code snippet?",
        "7a7054e1-b9eb-4344-8f57-7cbfa0ce23ac": "What are the optional arguments that can be used when creating a polygon tensor?",
        "1feb3509-7b1b-4d70-9f61-bd8ff01acbff": "What are the supported compressions for creating a polygon tensor?",
        "4a8fed0c-cac5-498a-ad4b-ccba2a6265b1": "How can polygons be appended to a dataset according to the context information provided?",
        "557344c7-3eaa-44b9-a127-1ab778c3c755": "Explain the purpose of the `sample_by` method in the `DeepLakeDataLoader` class and provide an example of how it can be used with different weights for sampling.",
        "66086c29-537c-4ec8-93fb-87a68cf69887": "How does the `shuffle` method in the `DeepLakeDataLoader` class work, and what parameters can be adjusted when using this method?",
        "6c1827ac-9c0a-46f9-b4c4-30b571e4adb7": "In the provided examples, how is the `sample_by` method used to sample the dataloader based on specific conditions or weights?",
        "84486d7c-c493-4ad3-b487-d9a6dc6eaad1": "What is the significance of the `replace` parameter in the `sample_by` method, and how does it affect the sampling process?",
        "263cab2a-13d8-40a1-b81a-7c1a846bbb42": "Can you explain the difference between using a list, tuple, or ndarray as weights in the `sample_by` method, and provide an example of how each can be utilized for sampling?",
        "4cb95bae-3ea1-4fa0-a161-9843f046e9f8": "What are the two options for storing images in Deep Lake, and why is it recommended to store compressed images?",
        "52c0e789-9423-45d9-a890-aabda865fde4": "How can an image tensor be created in Deep Lake, and what are the optional arguments that can be specified?",
        "1011bf85-9585-4085-836a-a86daaa2e58a": "How can image samples be appended to a Deep Lake dataset, and what are the two types of samples that can be used?",
        "574bd9be-adbb-4e38-aa74-e8ae165d18ed": "What happens if the compression format of the input sample does not match the sample_compression of the tensor in Deep Lake?",
        "9db3b503-543b-4395-a809-1ad309becf4a": "How can multiple image samples be appended at the same time in Deep Lake?",
        "228fdc6a-d403-4796-bab5-75674f2a8ff6": "What are the supported compressions for storing images in Deep Lake?",
        "009d02d3-72e1-403c-a805-f8ae92048da7": "How can the htypes `image.rgb` and `image.gray` be used in Deep Lake to specify the type of samples?",
        "310c410c-7b87-4994-b5ff-48e5fcc97752": "Explain the process of creating a polygon tensor using the provided code snippet. What are the optional arguments that can be used during the creation of a polygon tensor?",
        "46b6606c-4d33-4b70-b8da-a85e4e69d211": "How can polygons be appended to a dataset using a list of tuples or numpy arrays? Provide examples for both 2-D and 3-D points.",
        "7211b0e6-8e5d-464d-a768-673c0dc4a81e": "Describe the Nifti Htype mentioned in the context. What are the possible sample dimensions for Nifti data?",
        "6d5e2971-ee1e-4cfa-8fe3-6d20e3ba34a3": "Can you explain the significance of ensuring that all points in a sample have the same number of coordinates when working with polygons? How does this impact the data structure?",
        "0bd0ed3d-c259-46b8-b367-2149aedda753": "Discuss the importance of using supported compressions like \"lz4\" when creating a polygon tensor. How does compression affect the efficiency of handling polygon data?",
        "a77375db-6845-4357-b8ef-fc28ca543329": "What are the variations of the `link` type that can be used in the activeloop visualizer to correctly display data?",
        "5f3614d4-66de-4fa2-bc9a-5c7eb3950b7f": "When is data actually loaded from a dataset?",
        "1dce242d-be97-467c-a18f-65e443328a66": "What are the exceptions to the rule that no data is loaded until a sample is read from a dataset?",
        "d9a66704-8c81-4574-be54-75a22db5ef38": "How can credentials be added to a dataset?",
        "c2cb5a24-b050-4c45-bd2e-596eca2835b1": "What is the benefit of storing credentials on the Activeloop Platform as Managed Credentials?",
        "850f967a-5fa2-44c4-919f-90e89aba3124": "How can keypoints that are not present in an image be stored in a dataset?",
        "7aebf5c6-98b7-4b86-a3e7-0a9a9eaffb94": "What are the sample dimensions for points in a 2-D coordinate system?",
        "af291b84-497a-4a05-9365-275cf9bd4c5a": "How can a point tensor be created in a dataset?",
        "5558988f-7338-4107-8369-7763a80d883a": "What is the purpose of the COCO Keypoints Htype?",
        "14b2b3b3-2173-4cd1-a20d-22a26f2f7aff": "Can points in a sample have a different number of coordinates in a polygon htype tensor?",
        "c886e3ee-9f42-4168-af0a-29bfb1620d77": "What are the requirements for all points in a sample in a polygon htype tensor?",
        "ba7812fa-a502-4937-b806-953a85065e3b": "How can points be appended to a dataset for polygons?",
        "5e0a1f08-4094-40e4-933a-32befd08524d": "What are the different supported compressions for creating a point tensor?",
        "4387445f-e523-46c8-b79d-fb9a3ec33c62": "Can different samples in a polygon htype tensor have a different number of polygons?",
        "f5256953-dd7f-4286-9ce5-8126b101bff6": "How can different polygons have a different number of points in a polygon htype tensor?",
        "27ac3be3-222b-4e3e-a41d-e4a50ccb08d2": "How can a tag tensor be created in a dataset using Python code?",
        "f0e2080d-08c4-41c0-89a4-02133b1226fb": "What are the supported compressions for chunk compression when creating a tag tensor?",
        "245c4364-ed51-4e60-bc44-96473dc6f869": "Provide an example of how to append a tag sample to a dataset.",
        "f9c0722f-d934-4459-ba6d-d6f25b474bd0": "How can a bbox tensor be created in a dataset using Python code?",
        "d9cf1249-93f2-48ec-a1bd-a691e998c15a": "What are the keys required in the coords dictionary when creating a bbox tensor?",
        "80a12592-4610-41af-a868-cd6493fe41d6": "Explain the difference between the \"pixel\" and \"fractional\" types in bounding box coordinates.",
        "dbfa70e0-3f91-4a05-b538-449cf773f2ca": "What are the conventions for the 4 coordinates specified by the \"mode\" key in the coords dictionary for a bbox tensor?",
        "3668ba66-c76f-46c8-a405-dcc2e686a78e": "How can you specify the class names after creating a tensor in a dataset?",
        "4bc4e813-b87c-4d2c-82cf-aa47aea4f34d": "What are the variations of the `link` type that can be used in the activeloop visualizer to correctly display data?",
        "f50473d2-3882-4d4b-84cd-39bb28562cf2": "When is data actually loaded from a dataset?",
        "b2d57a55-dc77-4238-a4db-33db3eabaefd": "What are the exceptions to the rule that no data is loaded until a sample is read from a dataset?",
        "9fe9a568-d606-45d2-b587-a0bfd02843af": "How can credentials be added to a dataset?",
        "8edc2e19-b266-40fe-b84e-03cd7444b282": "What is the purpose of storing credentials on the Activeloop Platform as Managed Credentials?",
        "1bfd8c37-4177-4aa3-99af-1c6b2037524c": "How can managed credentials be used in a dataset without having to repopulate them every time the dataset is reloaded?",
        "ebb194f2-2346-4d86-8043-640da4d0b16b": "Explain the purpose of the `sequence` htype and provide an example of how it can be used in a dataset.",
        "2423e8e2-dd5d-447b-b431-61becbcbad2d": "How does the `link` htype differ from other htypes in terms of storing external data in a dataset?",
        "748a331a-697f-4131-abe7-d6b6d5578722": "What are the variations of the `link` htype that can be used in datasets, and how do they affect data visualization in the activeloop visualizer?",
        "87c17844-a8e3-40a7-b1ac-d2052bdf9910": "When is data actually loaded in a dataset with the `link` htype, and what are the exceptions to this rule?",
        "4a8163a7-8af0-42e3-8002-ad5b395c487a": "How can the `create_shape_tensor` and `create_sample_info_tensor` parameters impact the behavior of the `link` htype when adding data to a dataset?",
        "deb0e486-b95e-4ff7-be41-6a0d4f86d518": "What is the purpose of the `DEEPLAKE_DOWNLOAD_PATH` environment variable in the context of dataset access methods?",
        "349f329f-f04d-4672-ac6b-8eebc28938c5": "How can the \u2018download\u2019 access method be modified to specify the number of workers and scheduler to be used?",
        "42c46319-0054-426a-aa8e-b6a5264b5e9e": "What is the difference between the \u2018download\u2019 and \u2018local\u2019 access methods in terms of downloading datasets?",
        "c64f3558-4a06-4c94-8324-d25221d0d88c": "When using the \u2018local\u2019 access method, how can you specify the number of workers and scheduler to be used if the dataset needs to be downloaded?",
        "7b3fbbfd-cc72-435b-892b-ccc1b0e35288": "What does the `unlink` parameter do and when is it applicable?",
        "58fce4cd-e543-48aa-b104-c67986428cc1": "How can you handle a corrupted HEAD state of the branch being loaded when loading a dataset?",
        "50c05d1e-4f60-4ab4-8d68-e9e95a4976ee": "Under what conditions does the `check_integrity` parameter perform an integrity check on the dataset?",
        "0558e56b-8315-44e2-8e58-6ee6f5790600": "What is the purpose of the `lock_timeout` parameter in dataset management?",
        "a2dcf0ca-2759-405c-91a0-cc6d3fa709be": "How does the `lock_enabled` parameter affect the dataset management process?",
        "5186f875-f4ac-4b5f-89ca-474151327044": "What is the purpose of creating a keypoints_coco tensor in the given context?",
        "32c24cbb-3914-4f9e-b275-8044d396feee": "How can you specify the keypoints and connections when creating a keypoints_coco tensor?",
        "fe7e0da5-8ba3-4b41-a23d-b81374e363da": "What are the supported compressions for the keypoints_coco tensor?",
        "ee0dc645-917c-4f88-9163-1bf2beaccf55": "How can you update the keypoints and connections after creating a keypoints_coco tensor?",
        "149863fc-0dd4-4687-a5ee-a5cb4de59bb7": "How can keypoints be appended to the keypoints_coco tensor?",
        "d17d8301-8470-4ff3-84fc-c656350e1cd9": "What is the purpose of specifying an htype for a tensor in Deep Lake datasets?",
        "526fc34e-2e75-4587-a8c4-dff5a8908034": "How does specifying an htype contribute to the performance of datasets containing rich data like images and videos?",
        "a254a2a4-2eba-436c-8413-b0592342e3ba": "Can you provide an example of creating a tensor with a specified htype in Deep Lake?",
        "3a2b877d-7026-47d2-aaa6-65d4a6dbb456": "What are some of the supported htypes in Deep Lake and their respective defaults?",
        "a4e1f8f5-fcd7-4236-a5c1-79c9f75e30e2": "How are images stored in Deep Lake, and what are the options for storing them?",
        "4b37c448-5bef-44c0-a63d-20503cca7891": "Explain the difference between binary masks and segmentation masks in the context of object representation in an image.",
        "0e550725-291a-41f1-a368-4424c49e2140": "How can a binary_mask tensor be created using the provided code snippet? What are the optional arguments that can be specified?",
        "86a9031b-6e1a-437a-bcc4-9a25af27fbb5": "Why is it recommended to compress segmentation masks using `lz4` compression?",
        "eade2219-d3a4-422b-b136-30ef8bae4d61": "Provide an example of appending a binary mask with 5 objects to a dataset. Include the corresponding labels for each object.",
        "66cf36c3-5eab-419c-90a6-d98583bc4345": "What is the purpose of COCO keypoints in image processing? Describe the values that make up each keypoint in the COCO convention.",
        "07c750c4-bcc9-4c53-9a69-77870dab2b8c": "Explain the purpose of the `sequence` htype in the context of tensors and provide an example of how it can be used in a dataset.",
        "93260e6b-003d-445a-b8fc-952ca6f12c38": "How does the `link` htype differ from other htypes in terms of storing external data in a dataset? Provide examples of variations of the `link` htype and explain when data is actually loaded from external sources.",
        "e5a1c178-2d4b-44b5-89f2-1502aee56a89": "What is the default setting for the `shuffle` parameter in the `ingest_yolo` function?",
        "07294c62-49b1-43d8-9348-ac3c12ca3a17": "How can you enable or disable the ingestion progress bar in the `ingest_yolo` function?",
        "fcafa06f-6003-422d-a74d-e053fdcf02f4": "What is the purpose of the `num_workers` parameter in the `ingest_yolo` function?",
        "485d000d-5021-4a9d-bde2-52c613d63076": "How can you connect the dataset to Deep Lake using the `connect_kwargs` parameter in the `ingest_yolo` function?",
        "5d8dec49-e04a-4a5f-939c-2d5c091e06a8": "What error will be raised if `key_to_tensor_mapping` or `file_to_group_mapping` are not one-to-one in the `ingest_yolo` function?",
        "43d0e718-0c79-43fe-891c-61c468ffc299": "What is the main purpose of the `ingest_yolo` function?",
        "865701d5-deb8-42be-bc63-936bfb134fc1": "How can you specify the source data location in the `ingest_yolo` function?",
        "e356e508-a95c-4e02-8e78-3974c95e1def": "What is the significance of the `inspect_limit` parameter in the `ingest_yolo` function?",
        "31b36e2a-d678-4445-953d-5d3b6c1fcd0b": "How can you specify the number of workers to use for ingestion in the `ingest_yolo` function?",
        "9e8bbbf8-de9b-4e07-8f3a-446511228207": "How can you pass additional arguments to the dataset creator function in the `ingest_yolo` function?",
        "8932855c-73c4-4437-8a1d-eb470a25ecd7": "Explain the process of creating a polygon tensor using the provided code snippet. What are the optional arguments that can be used during the creation of a polygon tensor?",
        "2476ef0f-bf24-478e-9e1e-e1554197c37e": "How can polygons be appended to a dataset using a list of tuples or numpy arrays? Provide examples for both 2-D and 3-D points.",
        "9686c649-9495-4bfe-9530-2f489e89d46a": "Describe the Nifti Htype mentioned in the context. What are the possible sample dimensions for Nifti data?",
        "657d4398-d837-4d3f-97c3-015c3cff948a": "Can you explain the significance of ensuring that all points in a sample have the same number of coordinates when working with polygons? How does this impact the data structure?",
        "c9fac5bd-28da-40ba-b22f-b57fe37f7a6a": "Discuss the supported compressions for creating a polygon tensor. How can compression techniques like \"lz4\" be beneficial in handling large datasets?",
        "f5c1e524-8e29-45fd-a2bc-16ccf5176bfa": "How does Deep Lake handle the compression format of input samples that do not match the sample_compression of the tensor during the upload process?",
        "0180d39d-0727-40d1-82fd-39f1637ff472": "What happens if RGB images are appended to an image.gray tensor in Deep Lake?",
        "ea5df130-de5c-434d-ad8b-937fc3fc05c5": "What limitations are there for visualizing videos in the Deep Lake App?",
        "3e82336d-5e09-491d-a315-861faf8c7b32": "How can a video tensor be created in Deep Lake?",
        "b092c79a-5062-4876-ae07-c029eda88122": "What compressions are supported for video tensors in Deep Lake?",
        "43f5021b-8cf5-428f-8d8c-398196470394": "Can raw video frames be compressed in Deep Lake when appending samples to tensors?",
        "7a500ad1-cbba-4adc-a38d-e10c647a1bbc": "How can a mesh tensor be created in Deep Lake using the `create_tensor` function?",
        "88fe9351-c794-415b-a9c6-19519a6435b6": "What is the purpose of the `sample_compression` argument when creating a mesh tensor?",
        "b1f8c1cc-7872-4885-b5f9-c43ae064afd4": "How can a mesh data from a ply file be appended to a tensor in Deep Lake?",
        "0d2f8639-0654-4064-ba2d-e3ec71cac3a6": "What is the shape of a mesh tensor after appending a sample with 100 points and 200 faces?",
        "5cf9ce88-1391-43f9-8b03-5db80be21640": "How can an embedding tensor be created in Deep Lake using the `create_tensor` function?",
        "92c51da9-1e85-4587-9862-6ff709138d7d": "What are the supported compressions for an embedding tensor in Deep Lake?",
        "82a28a85-a386-4e33-9de1-fc050c905e88": "How can a Deep Lake embedding sample be appended to an embedding tensor?",
        "efa53420-80d4-47c1-9ed2-1df41d6fb234": "How can multiple Deep Lake embedding samples be extended in an embedding tensor?",
        "0058f434-75f0-4040-83a4-c65d22c423be": "What is the purpose of the Sequence htype in Deep Lake?",
        "8920eb3e-2702-4b54-8981-65ee658c3b5b": "Can you provide examples of other htypes that can be wrapped by the Sequence htype in Deep Lake?",
        "9de36219-5d6c-462a-a79f-391c255be81f": "How can a tag tensor be created in a dataset using Python code?",
        "1390ef85-8dd4-4382-b574-9a5d93ede0e6": "What are the supported compressions for chunk compression when creating a tag tensor?",
        "53f448d4-54f2-4c1c-a8ba-b0d4c1e42849": "Provide an example of how to append a tag sample to a dataset.",
        "2f37164c-c2f2-43ba-ab7d-60e30c5b9320": "Explain the format of bounding boxes in the context of the Bounding Box Htype.",
        "8c47c70c-87ba-4f9d-a023-920bff0c2a8d": "How can a bbox tensor be created in a dataset, and what are the optional arguments that can be specified?",
        "6cf0c224-a2d8-4c46-afd7-74fc7d426834": "Describe the different conventions for bounding box coordinates specified by the \"mode\" key in the coords dictionary.",
        "095d8323-e41e-4cc6-9977-e7c098294795": "What are the supported compressions for sample_compression or chunk_compression when creating a bbox tensor?",
        "f3f6bea3-79af-4592-a553-fca82f2a7130": "How can class names be set after creating a tensor in a dataset?",
        "1e9a9ccc-1921-4e48-8269-e44730bc278d": "Explain the purpose of the `checkout` method in the context of the provided information. How does the `create` parameter affect the behavior of this method?",
        "4bba743e-2b5b-4775-b219-a8d449e4fa39": "What are the possible exceptions that can be raised when using the `checkout` method? Provide a brief explanation of each exception.",
        "d1741e3e-2cf4-44d8-b1d6-71237ed1b739": "Walk through the example provided in the context information where the `checkout` method is used. Explain the outcome of each step in the example and how it demonstrates the functionality of the `checkout` method.",
        "573e61e1-7ed9-4b62-b8fb-7394b2fac0e5": "How does the `reset` parameter in the `checkout` method help in handling a corrupted HEAD state of a branch? Provide an example scenario where using the `reset` parameter would be beneficial.",
        "14dfc901-7a9b-481c-bbab-66938a386c77": "In what situation would an automatic commit occur before a checkout operation, as mentioned in the note section of the context information? How does this automatic commit impact the dataset?",
        "67fe1ac8-3296-4acc-aa56-af911cf08cc8": "Explain the difference between `Dataset.flush` and `Dataset.clear_cache` in the context of dataset management.",
        "e1a79b48-8316-467a-9e97-fc8fc4e334b2": "How can you estimate the size of a dataset using the `Dataset.size_approx` method?",
        "017e6e25-edf5-4223-8925-06ce190cad72": "Describe the functionality of `Dataset.random_split` and provide an example of how it can be used in a dataset.",
        "abeb7667-266a-46f2-bfe5-301ef58b26fc": "What is the purpose of `Dataset.add_creds_key` and how does it contribute to dataset credentials management?",
        "e0b70f3d-fe94-4684-8265-0fd528189b6f": "How can you retrieve information about the commits in a dataset using the `Dataset.log` method?",
        "0978fe7b-8c05-4e79-9974-0e0518e2215b": "How can you set the `connections` and `sample_compression` for `tensor.info.keypoints`?",
        "1308ba82-e58a-441a-991c-492b01539765": "What is the default data type for `dtype` in `tensor.info.keypoints`?",
        "2c5abfd7-53c6-461d-93fe-42efee88218c": "How can you append keypoints to a sample with 3 keypoints and 4 objects?",
        "6e208941-b4c5-4022-93ad-ecb7e28b8f68": "Why is it important for all objects in every sample to have the same number of keypoints in the same order?",
        "83dd2f88-b0f2-4060-83ee-7c9456c9daf2": "How can you prevent keypoints that are not present in an image from being drawn in the visualizer?",
        "e6531884-6a52-4b45-b129-85f35af15631": "Explain the difference between sample_compression and chunk_compression in the context of the provided information. How are they used in the dataset?",
        "950b8ab7-1a99-494d-bb07-d5bf41df1739": "How can 3D bounding boxes be appended to a dataset? Provide an example of appending one bounding box and another example of appending a sample with multiple bounding boxes.",
        "0b76d01d-de3e-4516-9acf-25f44feef26c": "What is the purpose of the intrinsic matrix in the context of camera calibration? Explain the components of the intrinsic matrix and their significance in the transformation from 3D camera coordinates to 2D image coordinates.",
        "67adf266-a50b-43d8-9910-06c59667fe7e": "What is the total number of commits in the history of the repository?",
        "4581fb08-20eb-483c-abc7-e549dde577d4": "What is the purpose of the .gitignore file in the repository?",
        "f35048b4-d945-49d3-b6fa-e8c54b45b563": "What is the significance of the CONTRIBUTING.md file in the repository?",
        "6416e092-4307-4800-9d49-5a76fc7ce095": "How many folders are present in the repository and what are their names?",
        "5b76581d-d58f-4811-a77e-36962605bf52": "What is the content of the README.zh-cn.md file in the repository?",
        "c2692541-b2a4-43a8-b8a9-003f8e3defb8": "Explain the process of creating a point cloud tensor using the provided code snippet. What are the optional arguments that can be used, and what are the supported compressions for sample compression?",
        "2ee309a1-202b-45fc-a0d1-c3f569303908": "How can point clouds be appended to a dataset using numpy arrays? Provide an example of appending two point clouds with different numbers of points and explain the resulting shape of the dataset.",
        "193f50a3-0ba5-46b2-9585-15fa90665a28": "Describe how samples can be added to a point cloud tensor using the `deeplake.read()` method. Provide an example of adding a sample from a file and explain the resulting shape of the point cloud tensor.",
        "a05e46e7-bc53-4445-a62b-3b685cbfc539": "What are the key characteristics of the Mesh Htype samples? How are mesh samples represented in a tensor of `mesh` htype, and what are the dimensions of each sample in this type?",
        "12cbe2a2-c952-4a39-ad87-747377d67af3": "Compare and contrast the characteristics of point cloud tensors and mesh tensors based on the information provided. How do the structures of point clouds and meshes differ in terms of data representation and dimensions?",
        "476d898e-d6cf-4358-a154-c0fda958507c": "What are the different ways in which you can reference a dataset using the `deeplake.dataset` function?",
        "0709bf9e-ac9c-4ba8-afaa-e12fffed4258": "How can you load a specific version of a dataset using the `deeplake.dataset` function?",
        "d09043f6-0600-4fdc-a35a-c4e05c6f3a80": "What parameters can be passed to the `deeplake.dataset` function to customize its behavior?",
        "000941ac-cba3-4ad1-ac2e-dd155299010b": "How can you authenticate to Deep Lake in order to write to Deep Lake cloud datasets?",
        "91ca96e3-36c9-4312-80f9-727854bfb50b": "Can you provide an example of how to create a `Dataset` object using the `deeplake.dataset` function?",
        "3d140bbc-dc3b-4095-9433-d0d3cdac336a": "How does Deep Lake handle the compression format of input samples that do not match the sample_compression of the tensor during the upload process?",
        "10078eae-6407-4697-8668-b8bd1e131a85": "What happens if RGB images are appended to an image.gray tensor in Deep Lake?",
        "ed059579-51e6-4498-8d2a-0b56ff2b6da5": "How can you create an image.rgb tensor in Deep Lake?",
        "57471475-1767-4177-9124-d80294c0dcbc": "What are the limitations of visualizing videos in the Deep Lake App?",
        "0560b20c-dfce-4788-a3d2-44be0fac845d": "How can you create a video tensor in Deep Lake?",
        "15b48e33-a9b8-4144-9409-a196839ebfb2": "What compressions are supported for video tensors in Deep Lake?",
        "1ce1e01f-ff06-4e85-8b6d-610d91c0e8b6": "Can raw video frames be compressed in Deep Lake? If not, which type of compression supports raw video frames?",
        "12d90b2d-0fd8-41da-9789-2250cc09ae55": "What is the purpose of the `num_workers` parameter in the `DeepLakeDataLoader` object?",
        "b35948af-c10b-4808-8378-f01774631aa6": "How does the `persistent_workers` parameter affect the behavior of the data loader?",
        "f211c1a4-0266-43b5-8280-599e394b7d24": "Can you explain the different decode methods supported by the `decode_method` parameter in the `DeepLakeDataLoader` object?",
        "163b2fc4-3a21-4244-be35-c4e02f036fea": "What does the `offset` method do in the `DeepLakeDataLoader` object?",
        "4f5d7dcf-d7bb-4c43-ad56-f06bc5c0a39f": "How does the `prefetch_factor` parameter impact the data loading process in the `DeepLakeDataLoader` object?",
        "4a34f49c-a449-42e6-a44d-d439286192e5": "What is the purpose of the `embedding_function` parameter in the given context?",
        "3a1171ff-50d3-4a8b-9ac9-4a89a5dade36": "How is the `embedding_data` parameter used in the context provided?",
        "d791444e-fcdf-47f8-be2f-35f9d7460c48": "Explain the significance of the `return_ids` parameter in the context of the document.",
        "3d9a3db0-0ff7-49ce-95e3-d530baae2035": "What is the role of the `rate_limiter` parameter in the context of the document?",
        "83f0763f-a195-48df-8ec8-10ab336ce514": "Describe the functionality of the `checkout` method in the context provided.",
        "fe280c0e-5107-48f4-a0cf-4b6abf870f7f": "How does the `commit` method work in the context of the document?",
        "930ce2ef-4d29-42eb-9bc6-3ec11a64e742": "Explain the components of the camera intrinsic matrix \\\\(K\\\\) and their significance in computer vision applications.",
        "fd5e0920-c0d7-48db-8e10-6cc51d448dd5": "How can an intrinsics tensor be created in a dataset using Python code?",
        "e22d6a10-60f4-4c34-a414-d7071a509e7a": "What are segmentation masks and how are they represented in computer vision tasks?",
        "044cd3a5-d585-4b6e-b52d-c036cec7ade0": "Describe the process of creating a segment_mask tensor in a dataset, including the required arguments and optional parameters.",
        "edb9edee-0469-472d-b3c5-5525f9f23cfd": "How can intrinsic parameters such as focal length and optical center be used to define the camera intrinsic matrix in computer vision?",
        "a6127e59-5424-41af-9486-fb7552290781": "What is the purpose of the `add_creds_key` method in the dataset class?",
        "d68faf66-528f-47dc-a207-4d6401a942b6": "How can you specify whether the credentials corresponding to a key should be fetched from the Activeloop platform when using the `add_creds_key` method?",
        "22fb0f92-3558-4637-b656-35da356852de": "What is the significance of the `managed` parameter in the `add_creds_key` method?",
        "d35227f9-cffa-4b8c-85bd-ae7d55a97dc4": "How can you determine if a dataset can be deleted from storage using the `_allow_delete` property?",
        "d441c08f-61b8-4b11-8978-3cb5cee1df29": "What is the functionality of the `append` method in the dataset class?",
        "8713f79c-abd2-4f3b-9193-ec10e5e6402e": "What exceptions may be raised when using the `append` method with multiple tensors at once?",
        "a7d490bf-762f-4958-b616-81ece9dfd18f": "In what scenario would the `NotImplementedError` be raised when using the `append` method?",
        "0aaa49de-6bf4-472e-959b-f50b104a980d": "How does Deep Lake handle the compression format of input samples that do not match the sample_compression of the tensor during the upload process?",
        "2d4fbe81-8da4-4386-9c45-7078a5e0ca6b": "What happens if RGB images are appended to an image.gray tensor in Deep Lake?",
        "1aa8eab8-2f6a-48ad-bb57-7ba9eee2e72d": "What limitations are there for visualizing videos in the Deep Lake App?",
        "fbe6c219-059e-441b-9c48-4885aabf84cb": "How can a video tensor be created in Deep Lake?",
        "e7f24045-706b-4d1b-9e9c-d115d250e5d7": "What compressions are supported for video tensors in Deep Lake?",
        "6fd6487d-5763-4585-ad51-d69e904d1a43": "Can raw video frames be compressed in Deep Lake? If so, under what conditions can they be compressed?",
        "d97f7af6-4bd0-45a4-ae48-dca16768b162": "How can image.rgb and image.gray tensors be created in Deep Lake?",
        "50e54c79-3f8c-4471-a36c-61be6caa443b": "What is the purpose of the sample_compression parameter when creating a tensor in Deep Lake?",
        "9d172c09-91b2-4b21-bdde-6c4c0d25b11d": "How does Deep Lake handle the conversion of grayscale images when they are appended to an image.rgb tensor?",
        "7d97bbdb-a4d0-46e2-9e44-5512e0b8ea3c": "What is the default data type for video tensors in Deep Lake?",
        "fe96928c-79f0-453d-acd5-282634c66401": "How can you change the logging level in Deep Lake using the \"deeplake\" logger? Provide an example code snippet.",
        "f17ece9f-9bd0-465d-bbff-9abfe827e729": "What are some of the key concepts covered in the Deep Lake documentation?",
        "ae4d7765-3da6-42bc-aaa6-3df09976eb5d": "How can you integrate Deep Lake with Weights and Biases and MMDetection?",
        "30a95646-0503-449a-ba66-7ad7b4eb1242": "What are some of the high-performance features available in Deep Lake, and how do they enhance data processing?",
        "535778d3-8d33-4fab-ac42-a91569335dfa": "Can you explain the purpose and usage of the deeplake.VectorStore module in Deep Lake?",
        "7c885f7b-dbf1-46d8-9701-4bc392e56136": "Explain the process of random splitting a dataset into training and validation sets based on the given lengths or fractions. What happens if there are remainders after computing the lengths?",
        "6016dbed-a95a-4167-a024-0150b14c352e": "How can you check if a dataset is in read-only mode? What implications does this have on the dataset?",
        "2545c666-890b-4443-a381-24551c75d4c4": "Describe the rechunk method provided in the context. What does it do and what parameters can be adjusted when using this method?",
        "bad03ef2-3180-456f-a62c-4ec2155b0120": "How can you append 2 2-D points to a dataset named `ds`?",
        "db646a67-86ff-407e-80db-b9081e127b04": "What is the structure of a sample in a tensor of `polygon` htype?",
        "1be1743a-ad26-4639-9e52-be233a12bd36": "Can you mix 2-D points with 3-D points in a sample of a `polygon` htype tensor? Why or why not?",
        "a7506f63-814c-4fde-b8cb-357a0340529d": "How can you create a polygon tensor named \"polygons\" in a dataset `ds`?",
        "4662a78c-e9e7-4fb1-a54b-9b895b2cf974": "What are the optional arguments that can be used when creating a polygon tensor?",
        "a07d3763-deef-4916-b979-9a0e3c9d9250": "What are the supported compressions for creating a polygon tensor?",
        "6cefa38a-9905-4061-9f4e-0c35a9b8c3b6": "How can polygons be appended to a dataset as per the context information provided?",
        "5976bf4a-bc2d-42b7-ae73-dbcf3ec17103": "How can a tag tensor be created in a dataset using Python code?",
        "be2e3140-19a0-44d6-9baa-8f565b8fec7b": "What are the supported compressions for chunk compression when creating a tag tensor?",
        "a4e21338-18c7-40f5-8a9e-e70a773e6d56": "How can tag samples be appended to a dataset, and what are the two ways to append tag samples?",
        "d817e598-f943-4010-a270-8b0805310796": "What are the sample dimensions for a bounding box in the Bounding Box Htype?",
        "d797d9a8-2be0-4816-b717-4cb72905bb94": "How can a bbox tensor be created in a dataset, and what are the key specifications required in the coords dictionary?",
        "c658fc12-a347-4a52-8003-8ee56f05f371": "What are the different conventions for bounding box coordinates specified in the \"mode\" key of the coords dictionary?",
        "f3688416-be30-4ebf-8f70-106c7d64c8d8": "What is the default data type for a bbox tensor if not specified during creation?",
        "3fa2a676-adc7-48cf-b34e-29bcf3306a52": "How can class names be set after creating a tensor in a dataset?",
        "c2032714-8dd8-4898-b60d-5e95cbffecaf": "Explain the importance of setting a seed in Deep Lake for controlling the flow of operations and ensuring reproducibility in random operations. How does setting a seed help in training models and running randomized operations consistently?",
        "d6412bac-4f1d-4bb5-b4e2-cfa9effc2e6d": "Describe the purpose of the `DeeplakeRandom` class in the Deep Lake API. What methods does this class provide, and how can they be used to manage random seed settings in Deep Lake?",
        "44099708-e8ce-475e-9e3a-b5e2a0d3c0fc": "How does the `seed()` method in the `DeeplakeRandom` class work in Deep Lake? Explain the parameters that can be passed to this method and the significance of setting the seed to `None` for resetting it.",
        "7d1c8d11-53f9-4d68-bd2e-1726b5d9e83a": "Discuss the role of random seed in Deep Lake's high-performance features such as Dataloader, Sampler, and Deep Memory. How does setting a seed impact the reproducibility and consistency of these operations?",
        "3a342b7a-2b61-4a80-a74d-dc35bc9a04cd": "How can the `get_seed()` method in the `DeeplakeRandom` class be utilized in Deep Lake? Explain the scenario in which retrieving the current seed value is beneficial for managing random operations in the platform.",
        "1657b468-aae6-4cf0-95d1-07910883a257": "How does the `create_shape_tensor` parameter impact the reading of sample shapes in a dataset?",
        "7c4ae66e-7aad-4311-b909-85379d300229": "What are the exceptions to the rule that no data is loaded until a sample is read from a dataset?",
        "99523279-8457-4bb9-9c4e-643cef3913dc": "How can credentials be added to a dataset for accessing external resources like S3 or GCS?",
        "4a625ecf-c738-409e-bdf7-207fdede60bf": "What is the purpose of populating credentials after adding their names to a dataset?",
        "a7474215-6bda-4948-9116-38d60658c1b6": "How can managed credentials on the Activeloop Platform be utilized in a dataset without the need for repopulating them?",
        "0de2e458-39fa-465f-9295-29a771fc1949": "How can segmentation masks be compressed in order to reduce the amount of data stored?",
        "5fbf876b-3581-4727-ae07-976ebf01e6e2": "How can binary masks be appended to a dataset using np.ndarray?",
        "de7eefcd-1a9b-4a35-8891-c365ff3f0fd9": "What are COCO keypoints and how are they represented in a tensor?",
        "948d83b1-9c7e-4fc9-b97d-c57a94cf5bae": "What are the three possible values for the visibility of a keypoint in a COCO keypoints tensor?",
        "48b1ab24-2b11-49f3-8f16-013d3ea19b91": "How can a keypoints_coco tensor be created in a dataset, and what are the optional arguments that can be specified?",
        "44ff0a13-0efd-4040-90b1-3e52d7e8b532": "What are the supported compressions for creating a keypoints_coco tensor?",
        "60779489-f813-4836-8f29-86a30ca69d9c": "How can the list of keypoints and connections be set after creating a keypoints_coco tensor?",
        "9a4b9912-5d1e-4020-9504-0e29f931213f": "How does Deep Lake handle the compression format of input samples that do not match the sample_compression of the tensor during the upload process?",
        "a854bd0d-e977-4cb5-ab2b-319c6f1db94a": "What happens when RGB images are appended to an image.gray tensor in Deep Lake?",
        "de6e4ca7-ba6a-4bf3-b0c7-4946b87bcb4e": "What limitations are there for visualizing videos in the Deep Lake App?",
        "949393ef-53b8-49d7-926f-2012146c2439": "How can a video tensor be created in Deep Lake?",
        "0f15c79c-1190-4cdc-930f-bc4536cf497e": "What type of compressions are supported for video tensors in Deep Lake?",
        "6a219116-f849-46f6-9ef5-0b68742de112": "What is the purpose of the `deeplake.read` function described in the context information?",
        "00e977a3-d852-4569-bd34-914b2a871e86": "Can you provide an example of how the `deeplake.read` function is used to read an image file with sample compression set to \"jpeg\"?",
        "4d824d24-b523-46d7-a849-5119cc8ce7c1": "What file types are supported by the `deeplake.read` function for reading raw data into Deep Lake format?",
        "928adc15-a512-47a3-9295-a852d25cfcd7": "What does the `deeplake.read` function return when a dataset exists at the given path?",
        "c6718e9b-35e8-4bc5-879a-01356422efdb": "In what scenarios does the `deeplake.read` function simply copy the data in the file instead of recompressing it?",
        "a1eea70a-124c-4fab-8857-afa100e73078": "How can you append a binary mask with 5 objects to a dataset using numpy arrays?",
        "7a12cc9c-0b26-4cfb-abf3-3382a058e697": "What are COCO keypoints and how are they represented in a tensor?",
        "7a2a5c77-5308-45d4-9866-6e48aedb66e5": "How can you create a keypoints_coco tensor in a dataset, and what are the optional arguments that can be specified?",
        "a7b8c1cc-359d-4b6f-9549-b775fa531b7e": "Why is it recommended to compress segmentation masks using `lz4`?",
        "29e5e45f-b168-4212-90bf-7bebe293ff69": "Can you explain the visibility values for keypoints in COCO keypoints convention?",
        "f0750cee-8ff8-41f2-8167-9fa87a976681": "Explain the process of creating a new tensor in a dataset using the `Dataset.create_tensor` function. What are the key steps involved in this process?",
        "5e20c0ce-d337-4e7c-a683-07866ba0c765": "How can you delete a tensor from a dataset using the `Dataset.delete_tensor` function? Provide a step-by-step explanation of how this operation is carried out.",
        "0c84f2b2-8d5f-4a74-a354-2d65191e2632": "Describe the functionality of the `Tensor.append` method in the context of adding samples to a tensor. How does this method differ from the `Tensor.extend` method?",
        "7e959a06-fe45-411d-8fe2-948171e5a228": "What is the purpose of the `Dataset.rename_tensor` function? How can you use this function to rename a specific tensor within a dataset?",
        "d0713dfc-6323-4a2a-a772-c143434eb879": "Discuss the significance of the `Dataset.create_group` function in the context of creating a tensor group. How does this function differ from creating a standalone tensor in a dataset?",
        "b75f3cd9-348c-4110-8bea-7c3ce4258b7a": "What is the purpose of specifying an htype for a tensor in Deep Lake datasets?",
        "3a60c89e-00a1-467d-a3d6-5358337ab481": "How does specifying an htype contribute to the performance of datasets containing rich data like images and videos?",
        "7ecdbdc2-1b96-4d5b-aa7e-f245129a7fb2": "Can you provide an example of creating a tensor with a specified htype in Deep Lake?",
        "13f74c75-73ae-4961-bc31-58fab63e6458": "What are some of the supported htypes in Deep Lake and their respective defaults?",
        "d889858d-3a33-4048-a7cd-03a68ac92b01": "How are images typically stored in Deep Lake datasets?",
        "89a46b34-fa23-4888-9a20-8d64075d5d98": "What is the purpose of the `verify` parameter in the `deeplake.link` function?",
        "f70c7d6b-4abf-468c-9cd6-010ad14710a0": "How can you specify the format of the file when using the `deeplake.link` function?",
        "71c9a143-803f-4326-895f-40cc5fe5bd14": "What is the significance of the `timeout` parameter in the `deeplake.link` function when dealing with http(s) urls?",
        "d0af72a0-0f52-42c0-aef8-469bc555007a": "What file types are supported by the `deeplake.link` function for linking raw data to a Deep Lake Dataset?",
        "f72359e1-82aa-4b49-bbbe-d0ab95bff926": "How does the `LinkedSample` object differ from other data storage methods in Deep Lake?",
        "117836e5-13c6-4e4e-b79c-c9817c25084a": "Explain the difference between `deeplake.ingest_classification`, `deeplake.ingest_coco`, `deeplake.ingest_yolo`, `deeplake.ingest_kaggle`, `deeplake.ingest_dataframe`, and `deeplake.ingest_huggingface` in terms of their functionalities and input formats.",
        "9e735e2d-218d-46eb-ab98-1b2ea071a5d3": "How can you load an existing dataset using the `deeplake.load` function? Provide a step-by-step explanation of the process.",
        "5ffe3705-1423-4f3f-bb77-e696cf4522b7": "Discuss the importance of dataset operations such as `Dataset.append`, `Dataset.extend`, `Dataset.update`, `Dataset.query`, `Dataset.copy`, and `Dataset.delete` in the context of managing and manipulating data within a dataset.",
        "a8a1a3b9-3b09-4dad-a41b-e9fc4ca91c1a": "Compare and contrast the functionalities of `deeplake.copy` and `deeplake.deepcopy` when it comes to copying datasets. Provide examples to illustrate their differences.",
        "47b78597-1153-4dc0-b512-939c3a1b6622": "How can you create a new dataset by copying the structure of an existing dataset to a new location using the `deeplake.like` function? Explain the steps involved in this process.",
        "7bfc4c09-9bd7-4c7f-9f39-68a1bb63b7e4": "What is the purpose of the `htype` parameter when creating a tensor in the deeplake dataset?",
        "73e336c4-ae8a-47ef-a93f-5093aac0bec9": "How can you override the default `dtype` for a tensor when creating it in the deeplake dataset?",
        "e51b5749-9b09-492a-b9c7-8c3bc31aca6c": "Explain the significance of the `sample_compression` parameter when creating a tensor in the deeplake dataset.",
        "d03dfd3c-28a9-47b9-aaf3-4d8ceeadc424": "When would you use the `hidden` parameter while creating a tensor in the deeplake dataset?",
        "c2c61740-8530-4ca7-9439-1735322c5c89": "What does the `create_sample_info_tensor` parameter do when creating a tensor in the deeplake dataset?",
        "fcabceb1-b971-4976-a43b-6c966a278185": "What is the default value for the parameter `ignore_one_group` in the function for creating a Dataset from images and COCO annotations?",
        "45af3936-3524-4790-831d-d61d62a1ef4e": "What is the purpose of the `ignore_keys` parameter in the function?",
        "11208efc-d417-405f-85f9-00b5d486b687": "How is the maximum number of samples to inspect in the annotations json determined in the function?",
        "88002e89-c497-4f29-b995-2707cc5e1a7d": "What is the significance of the `shuffle` parameter in the function for creating a Dataset?",
        "2510d2cd-40de-4752-9c90-a42ebfe44142": "How can credentials be provided to access the source data in the function?",
        "fa490ced-0d58-442d-96d4-ab5bcad2764b": "Compare and contrast the data storage formats of Deep Lake and MosaicML MDS format, highlighting how each system reads, writes, and organizes data differently.",
        "263fa17a-80b6-48bc-9a5f-6ad9cb362b70": "Explain the advantages of Deep Lake's compression scheme over traditional methods like zstd, and how it impacts CPU usage during data processing.",
        "6c0f1e60-01e5-493d-ad89-9959b0e0b17f": "Discuss the significance of Deep Lake's native version control and in-browser data visualization feature in managing and tracking different versions of data, in comparison to MosaicML data format.",
        "8487c4c0-e3e1-4164-b7c9-ace963147fb5": "How does Deep Lake differentiate itself from TensorFlow Datasets (TFDS) in terms of compatibility with ML frameworks, and what advantages does it offer in this regard?",
        "aca1c5d4-6cb1-4561-aa20-10280b8c8f81": "Analyze the impact of Deep Lake's API for connecting datasets to ML frameworks and other tools on the ease of use and integration of datasets in machine learning projects.",
        "3368044c-d085-4f96-84ec-ed1754c75702": "What are the arguments required for the transform to generate an output dataset?",
        "d7b4bced-eb20-4aea-9666-cee453de0fa2": "What is the purpose of the `ds_out` argument in the transform function?",
        "77d81e30-9cbc-4abe-b50e-4c9eddfbee48": "How does the `num_workers` argument impact the processing of the transform?",
        "ae44d192-dbfb-43e6-8f67-c3fb65205ce7": "What are the supported values for the `scheduler` argument in the transform function?",
        "673bf1c3-86a3-4886-92d4-a165dee988f9": "When would it be useful to set the `skip_ok` argument to `True` in the transform function?",
        "17d62603-089e-4fba-b5e5-0d945129177f": "What does the `check_lengths` argument do in the transform function?",
        "5dd98063-506a-4eb8-9f3d-ca44ea0d6597": "How does the `pad_data_in` argument affect the input data in the transform function?",
        "872e3635-0b7d-4118-b3e6-4b28d2f60abb": "In what scenario would you use the `ignore_errors` argument in the transform function?",
        "4c8b49b4-e727-4695-98ac-3555ac76c1d9": "What is the purpose of creating a keypoints_coco tensor in the given context?",
        "6a08e6f0-c51b-4e5b-b612-f8502bb09847": "How can you specify the keypoints and connections when creating a keypoints_coco tensor?",
        "c31065cc-094d-42a9-b8f5-d9c57ec9e79e": "What are the supported compressions for the keypoints_coco tensor?",
        "b235414d-ef95-4c9f-845d-4a3306d85ad9": "How can you update the keypoints and connections after creating a keypoints_coco tensor?",
        "a4c9291e-3ffa-47e8-8541-f45e8e332dfb": "How can keypoints be appended to the keypoints_coco tensor?",
        "d706a530-48e4-48a0-8b78-b373db10b292": "What is the purpose of the Read the Docs Sphinx Theme?",
        "1545e2e5-4e16-423f-b285-4d31f550e98c": "How is the Read the Docs Sphinx Theme designed to enhance the reader experience for documentation users?",
        "33166945-acaf-46db-be80-d24048e7195d": "Can the Read the Docs Sphinx Theme be used with any Sphinx project, or is it limited to Read the Docs only?",
        "3bb90531-4d3c-4ddb-a1cd-e8da42f8e466": "Name three specific files that are included in the repository for the Read the Docs Sphinx Theme.",
        "d285574d-5cb6-4dc5-ad57-d774f1e82ad8": "What type of license is used for the Read the Docs Sphinx Theme?",
        "6f793f22-3678-4869-bae1-eb79e2ebfe00": "Explain the key concepts in Deep Lake, including Datasets, Vector Store, Tensors, Htypes, Compressions, PyTorch and Tensorflow Support, and Utility Functions.",
        "f56dfac7-5533-45f7-a8c2-d04c761f03b4": "Describe the high-performance features of Deep Lake, such as Dataloader, Sampler, Tensor Query Language, Random Split, and Deep Memory.",
        "19f06acb-eb89-468a-8622-331e44cfdb60": "How can you interact with the VectorStore class in Deep Lake? Provide a brief overview of the methods available, such as add(), checkout(), commit(), delete(), search(), summary(), tensors(), and update_embedding().",
        "2aadb1b3-1ac9-4272-8105-63d21335148a": "What is the purpose of the deeplake.VectorStore class in the Deep Lake API?",
        "9badf5fa-61c7-4323-9e21-f2d8eef37c31": "How does the deeplake.VectorStore class utilize the dataset and tensor parameters in its initialization?",
        "043b64ba-5bfd-4b80-8827-a240a6cf18e6": "What is the purpose of the outer list and inner list in the given context?",
        "679420eb-c3e1-4678-8a97-0afceabf4119": "Explain the significance of the doc_id and relevance_score in the context of the queries.",
        "386e3cf2-1580-405c-ae25-3053472136d5": "Why is it mentioned that only values of 1 contribute to the training, and examples with relevance of 0 are not provided?",
        "15edfe5e-4a3d-4041-a385-d8c6e3756431": "What is the role of the embedding_function in the training process, and why is it important to specify it?",
        "9dbca9e2-8eed-48f0-b256-c27c549c4e6b": "How does the API token for the DeepMemory managed service play a role in the context provided?",
        "19b91dc9-133d-48ba-9b6b-e9852c3eae68": "Can you explain the significance of the job_id of the training job in this context?",
        "e90af592-7eb1-48fe-bc7d-ea902a1ded3f": "What would happen if the embedding_function is not specified during initialization or training, according to the context information?",
        "8d64c02c-76ae-45f0-b81f-630d4614dc85": "How does the context information ensure diversity in the questions generated for the quiz/examination?",
        "6dfa30b8-6228-46e7-925a-120233a4fe41": "What is the purpose of specifying an htype for a tensor in Deep Lake datasets?",
        "92427aeb-90b8-4544-86f6-8950a6e85f70": "How does specifying an htype contribute to the performance of Deep Lake datasets containing rich data like images and videos?",
        "057a9214-e8ed-475d-856c-3792857cc593": "Can you provide an example of creating a tensor with a specific htype in Deep Lake?",
        "34b45db1-0a15-4ded-95b7-54cf077a0a70": "What are some of the supported htypes in Deep Lake and their respective defaults?",
        "6f93bb61-8c4d-4402-b6b3-a0994cd2c3c3": "How are images typically stored in Deep Lake, and what are the options for storing them?",
        "ab8ea251-e94b-41b5-9503-805e66050e2c": "What is the default value for the parameter `large_ok` in the function `get_managed_creds_keys()`?",
        "e32c1b1c-12c1-4496-add7-0661ec3ca890": "What exception will be raised if a dataset is larger than 1 GB and `large_ok` is set to `False`?",
        "62706362-d128-4a54-8e4f-0dff7411bdde": "Explain the purpose of the property `_is_actually_cloud` in the context of datasets connected to Deep Lake cloud.",
        "25d64099-0005-4255-ae04-1d5ea166a4c6": "Provide an example of how the `rename()` function can be used to rename a dataset.",
        "442f109e-ad1b-4c3e-82da-a712637d3e08": "What is the purpose of the `update_creds_key()` function and what parameters does it take?",
        "a6f4ee85-fc8b-46a8-a33f-afa9475cac16": "What are the limitations of the Deep Lake Performant Dataloader in terms of supporting data formats?",
        "63156551-9347-4e56-a8c5-1aab2d48ffe4": "How can a nifti tensor be created using the Deep Lake library?",
        "ce83a617-5243-44d8-ba11-b34abbcb7edf": "What are the supported compressions for nifti data in Deep Lake?",
        "f9256a57-6617-4855-9091-a1c043b17115": "How can nifti data be appended to tensors in Deep Lake?",
        "6b79077c-f035-46c7-b39d-5df477e252cc": "What is the point cloud Htype in Deep Lake and what are the sample dimensions for point cloud samples?",
        "4ff9d4b8-35c7-4b53-9e3f-301ccf1d7b1d": "How can a point cloud tensor be created in Deep Lake and what are the supported compressions for point cloud samples?",
        "2968152f-4a7f-4d44-83c0-6bb55d6b0d41": "How can point clouds be appended to tensors in Deep Lake?",
        "8dddfceb-2a0d-46fc-acba-5c6b3dda8eef": "Compare and contrast the data storage formats used by Deep Lake, DVC, and MosaicML MDS format. How does the choice of storage format impact data organization and access in each system?",
        "6c8b1f84-52ff-4634-9250-23914229a6cc": "How does the `create_shape_tensor` parameter impact the loading of data from a dataset in the activeloop visualizer?",
        "d6fd5491-e4c1-49fb-b013-fee4215f759b": "What are the exceptions to the rule that no data is loaded until a sample is read from a dataset?",
        "e0503c46-ac03-4c02-bd79-dbd6837caa3f": "How can credentials be added to a dataset in order to access specific resources?",
        "56f15cb4-63ee-4ef1-91bf-d9bb5fe0a93c": "What is the purpose of populating credentials after adding their names to a dataset?",
        "3bb2616a-9fc3-44f2-84e8-a04ad701b224": "How can managed credentials on the Activeloop Platform be utilized in relation to dataset access?",
        "b4d9b378-c087-4ae0-8f07-408488b611f5": "What are the two options available for performing computations in Deep Lake, and why is it discouraged to use one of them with big datasets?",
        "289b29de-254d-482a-a2d2-e2bb7f1d8a9e": "How can you store datasets in the Managed Tensor Database in Deep Lake?",
        "92cef9c7-48bc-4329-b4d5-22bff7c958d3": "What is the purpose of the `embedding_function` parameter in the Deep Lake Compute Engine?",
        "f6fb3ba1-d15e-48f7-a5c1-96e60ab9cc91": "When creating a dataset, how can you specify that it should be stored in the Managed Tensor Database?",
        "ed30451e-d2ff-4818-9bb5-8c0e13c2757e": "What is the default value for the `embedding_source_tensor` parameter in the Deep Lake Compute Engine?",
        "3dd68a7e-efba-4227-a7ed-a6070d026cb3": "Explain the key concepts of Datasets, Vector Store, Tensors, and Htypes as mentioned in the document.",
        "0bc9d297-a7d5-4657-8c6f-980c4049e0f5": "How can an image tensor be created according to the document?",
        "b5d41443-5699-418d-b864-8b999f54ffb9": "Describe the process of appending image samples as outlined in the document.",
        "30c4a548-f333-4af7-bb01-077c55f3de25": "What are the differences between image.rgb and image. as discussed in the document?",
        "bc3ab1a6-5273-4a63-a255-44d4ad4b3baf": "What is the purpose of creating a keypoints_coco tensor in the given context?",
        "064ca626-672f-46fc-93ae-9958176f1d39": "How can you specify the keypoints and connections when creating a keypoints_coco tensor?",
        "e451cc32-d392-4960-970c-07be2b8eaa52": "What are the supported compressions for the keypoints_coco tensor?",
        "dd8c29ce-0087-458e-973f-58cf08995343": "How can you update the keypoints and connections after creating a keypoints_coco tensor?",
        "8fc674a1-b2e2-4629-ba8c-5733d3f2ef7b": "How can keypoints be appended to the keypoints_coco tensor?",
        "4158ccc9-48f8-4fce-bbcb-d783c319989e": "What is the default htype for a tensor if not specified during creation in Deep Lake?",
        "3c24d394-d246-41ac-9431-8f30c7364a9f": "How does specifying an htype for a tensor in Deep Lake contribute to dataset performance?",
        "64978e0e-f295-4274-9bcc-fc8aa9b28ba9": "Can you provide an example of creating a tensor with a specified htype in Deep Lake?",
        "c6e128a7-2338-48e0-a6dc-6478b10c5989": "What are some of the supported htypes in Deep Lake and their respective defaults?",
        "3e20f6c8-cb25-42b0-b38d-4556482872f9": "How are images stored in Deep Lake, and what are the options for storing them?",
        "3c3e4ce7-933c-421b-a632-a49ea6adb0cc": "How can you specify the htype of a tensor at its creation in Deep Lake?",
        "f3c54998-6817-4b21-ae31-caf37a342abb": "Why is specifying an htype important for increasing the performance of Deep Lake datasets containing rich data such as images and videos?",
        "b3b16557-7fb8-4033-8886-3d272cfd8841": "What is the default htype of a tensor in Deep Lake if not specified during creation?",
        "53714882-a4e4-454c-926a-1ecced3ce1a1": "How can strict settings and error handling be achieved by specifying an htype for a tensor in Deep Lake?",
        "53d3ec9e-5121-4a29-9f35-3ff86398e8a0": "Can you provide an example of creating a tensor named \"my_tensor\" with a specified htype in Deep Lake?",
        "c1368749-2066-4eac-b1bb-ab3aa9dd15d7": "What is the purpose of the deeplake.VectorStore class in the Deep Lake framework?",
        "ef4dcc80-0e7f-46c4-a2b5-c248c2bdb4c1": "What parameters can be passed to the __init__ method of the VectorStore class?",
        "d2b786f6-513c-4711-9b82-4697dae73a37": "How does the VectorStore class handle embedding data?",
        "2c45032c-cd7a-486a-80ac-a25c74f8fc88": "What is the significance of the token parameter in the VectorStore class?",
        "54800526-543e-4aa1-9133-1cecf5f63f1e": "How does the VectorStore class handle data ingestion batch size?",
        "0b14cbe3-9681-4859-b43e-89396546ca4b": "Can the VectorStore class be set to read-only mode? If so, how?",
        "64265bde-1e4e-4836-8e98-24413ddf4cb2": "What is the default value for the verbose parameter in the VectorStore class?",
        "fce2823f-a62a-4c5f-8819-af5b70a70e83": "How does the VectorStore class handle credentials for accessing data?",
        "c2009fa0-d905-4ef8-a566-cc4f0b546b6d": "What is the role of the exec_option parameter in the VectorStore class?",
        "0ee4b410-bb3a-424f-9041-d224abc6000f": "How does the VectorStore class handle overwriting existing data?",
        "ba5fef3c-62b7-45d8-a2dd-7a8991023c32": "What are the different types of paths that can be specified for the 'dest' parameter in the dataset configuration?",
        "6dd8d241-6324-4868-9540-14f57eb30826": "What is the purpose of the 'class_names_file' parameter in the dataset configuration?",
        "ee83c264-7317-40bc-a0e6-a323cfc3d7f3": "How can missing annotations files be handled in the dataset configuration?",
        "cc56bd2c-cb12-4760-99f8-d35991e6229b": "Explain the use of the 'image_params', 'label_params', and 'coordinates_params' parameters in the dataset configuration.",
        "380c8fde-2100-4a78-98c9-1b1e42659053": "When would you use the 'src_creds' parameter in the dataset configuration, and what information can be provided in it?",
        "59b3904c-cee4-4958-abf0-fd3db02b71ca": "What is the purpose of the \".circleci\" folder in the repository?",
        "e840e7fa-0a16-4939-b2a9-45fa1e5ecfbf": "How many commits have been made in the history of the project?",
        "032e6bd5-658e-4a4b-9cd2-dd261e529762": "What is the content of the \"README.rst\" file?",
        "052d5fb0-bf32-41e1-a336-10dbb8999efc": "What licenses are included in the repository?",
        "d763305a-da8c-4121-96a7-5ceaefe8f508": "What is the significance of the \"docker-compose.yaml\" file in the project?",
        "179441b4-0707-4756-82b1-e7af8cf48e1e": "What is the default mode datasets stored on Deep Lake cloud open in if your account does not have write access?",
        "b8efca98-ff55-4b93-a6a1-4d13d4574fc5": "How can you specify credentials to access a dataset at a specific path, and what keys are supported in the credentials dictionary?",
        "751b80db-0713-470b-9dc5-de7d7be688ab": "What is the purpose of the `token` parameter in the dataset configuration?",
        "3e518faf-692e-44b5-82f4-e248b186190a": "What is the significance of the `access_method` parameter in the dataset configuration, and what are the available options for this parameter?",
        "869cc6ee-e7b2-4ac5-80b6-be8f5e663a0b": "How does the `memory_cache_size` parameter impact the dataset storage and retrieval process?",
        "fde17296-b6d1-4212-b45f-0273e0a6aa16": "What is the purpose of the `optimize` parameter in the function described in the context information?",
        "dbababcf-5814-4c31-b4b1-236bb288ea6b": "How can you specify the path for saving a VDS in the function?",
        "25d175a4-8f10-4632-9cfd-aff1c5b60f83": "What are the different values supported for the `scheduler` parameter when optimizing a dataset view?",
        "2d4bfdc6-0737-4bd5-be6b-1f1aa3782cbe": "When will a `ReadOnlyModeError` be raised in the function?",
        "c1953bd0-2119-4e96-9c75-fc7a04c3933e": "Explain the significance of the `num_workers` parameter in the optimization process of a dataset view."
    },
    "corpus": {
        "node_683": "* Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.\n\n    * If `verify=True` was specified during `create_tensor` of the tensor to which this is being added, some metadata is read from them to verify the integrity of the link samples. This is `True` by default.\n\n    * If you do not want to verify your links, all three of `verify`, `create_shape_tensor` and `create_sample_info_tensor` have to be set to `False`.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.dataset(\"......\")\n    \n\nAdding credentials to the dataset\n\nYou can add the names of the credentials you want to use (not needed for\nhttp/local urls)\n\n    \n    \n    >>> ds.add_creds_key(\"MY_S3_KEY\")\n    >>> ds.add_creds_key(\"GCS_KEY\")\n    \n\nand populate the added names with credentials dictionaries\n\n    \n    \n    >>> ds.populate_creds(\"MY_S3_KEY\", {})   # add creds here\n    >>> ds.populate_creds(\"GCS_KEY\", {})    # add creds here\n    \n\nThese creds are only present temporarily and will have to be repopulated on\nevery reload.\n\nFor datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.",
        "node_682": "Examples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.\n\nExamples\n\n    \n    \n    >>> ds.create_tensor(\"seq\", htype=\"sequence\")\n    >>> ds.seq.append([1, 2, 3])\n    >>> ds.seq.append([4, 5, 6])\n    >>> ds.seq.numpy()\n    array([[[1],\n            [2],\n            [3]],\n           [[4],\n            [5],\n            [6]]])\n    \n    \n    \n    >>> ds.create_tensor(\"image_seq\", htype=\"sequence[image]\", sample_compression=\"jpg\")\n    >>> ds.image_seq.append([deeplake.read(\"img01.jpg\"), deeplake.read(\"img02.jpg\")])\n    \n\n## Link htype\uf0c1\n\n  * Link htype is a special meta htype that allows linking of external data (files) to the dataset, without storing the data in the dataset itself.\n\n  * Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read.",
        "node_620": "### Limitations\uf0c1\n\n  * The Deep Lake Performant Dataloader does not support Nifti data.\n\n### Creating a nifti tensor\uf0c1\n\nA nifti tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"patients\", htype=\"nifti\", sample_compression=\"nii.gz\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"nii.gz\", \"nii\", None]\n    \n\n### Appending nifti data\uf0c1\n\n  * Nifti samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw nifti data. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\nExamples\n\n    \n    \n    >>> ds.patients.append(deeplake.read(\"data/patient0.nii.gz\"))\n    \n    \n    \n    >>> ds.patients.extend([deeplake.read(f\"data/patient{i}.nii.gz\") for i in range(10)])\n    \n\n## Point Cloud Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Point cloud samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.",
        "node_487": "* Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\n  * Recompression of samples read with `deeplake.read` is also not supported.\n\nExamples\n\nAppending Deep Lake video sample\n\n    \n    \n    >>> ds.videos.append(deeplake.read(\"videos/0012.mp4\"))\n    \n\nExtending with multiple videos\n\n    \n    \n    >>> ds.videos.extend([deeplake.read(f\"videos/00{i}.mp4\") for i in range(10)])\n    \n\n## Audio Htype\uf0c1\n\n  * Sample dimensions: `(# samples in audio, # channels)` or `(# samples in audio,)`\n\n### Creating an audio tensor\uf0c1\n\nAn audio tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"audios\", htype=\"audio\", sample_compression=\"mp3\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `float64`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.",
        "node_944": "* Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.\n\n    * If `verify=True` was specified during `create_tensor` of the tensor to which this is being added, some metadata is read from them to verify the integrity of the link samples. This is `True` by default.\n\n    * If you do not want to verify your links, all three of `verify`, `create_shape_tensor` and `create_sample_info_tensor` have to be set to `False`.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.dataset(\"......\")\n    \n\nAdding credentials to the dataset\n\nYou can add the names of the credentials you want to use (not needed for\nhttp/local urls)\n\n    \n    \n    >>> ds.add_creds_key(\"MY_S3_KEY\")\n    >>> ds.add_creds_key(\"GCS_KEY\")\n    \n\nand populate the added names with credentials dictionaries\n\n    \n    \n    >>> ds.populate_creds(\"MY_S3_KEY\", {})   # add creds here\n    >>> ds.populate_creds(\"GCS_KEY\", {})    # add creds here\n    \n\nThese creds are only present temporarily and will have to be repopulated on\nevery reload.\n\nFor datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.",
        "node_1136": "Examples\n\n    \n    \n    >>> # Search using an embedding\n    >>> data = vector_store.search(\n    ...        embedding = [1, 2, 3],\n    ...        exec_option = \"python\",\n    ... )\n    >>> # Search using an embedding function and data for embedding\n    >>> data = vector_store.search(\n    ...        embedding_data = \"What does this chatbot do?\",\n    ...        embedding_function = query_embedding_fn,\n    ...        exec_option = \"compute_engine\",\n    ... )\n    >>> # Add a filter to your search\n    >>> data = vector_store.search(\n    ...        embedding = np.ones(3),\n    ...        exec_option = \"python\",\n    ...        filter = {\"json_tensor_name\": {\"key: value\"}, \"json_tensor_name_2\": {\"key_2: value_2\"},...}, # Only valid for exec_option = \"python\"\n    ... )\n    >>> # Search using TQL\n    >>> data = vector_store.search(\n    ...        query = \"select * where ..... <add TQL syntax>\",\n    ...        exec_option = \"tensor_db\", # Only valid for exec_option = \"compute_engine\" or \"tensor_db\"\n    ... )\n    \n\nParameters\n\n    \n\n  * **embedding** (_Union_ _[__np.ndarray_ _,__List_ _[__float_ _]__]__,__optional_) \u2013 Embedding representation for performing the search. Defaults to None. The `embedding_data` and `embedding` cannot both be specified.\n\n  * **embedding_data** (_List_ _[__str_ _]_) \u2013 Data against which the search will be performed by embedding it using the embedding_function. Defaults to None. The embedding_data and embedding cannot both be specified.\n\n  * **embedding_function** (_Optional_ _[__Callable_ _]__,__optional_) \u2013 function for converting embedding_data into embedding. Only valid if embedding_data is specified. Input to embedding_function is a list of data and output is a list of embeddings.\n\n  * **k** (_int_) \u2013 Number of elements to return after running query. Defaults to 4.\n\n  * **distance_metric** (_str_) \u2013 Distance metric to use for sorting the data.",
        "node_461": "### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.\n\nExamples\n\nAppending a tag\n\n    \n    \n    >>> ds.tags.append(\"verified\")\n    \n\nExtending with list of tags\n\n    \n    \n    >>> ds.tags.extend([\"verified\", \"unverified\"])\n    \n\n## Bounding Box Htype\uf0c1\n\n  * Sample dimensions: `(# bounding boxes, 4)`\n\nBounding boxes have a variety of conventions such as those used in YOLO, COCO,\nPascal-VOC and others. In order for bounding boxes to be correctly displayed\nby the visualizer, the format of the bounding box must be specified in the\ncoords key in tensor meta information mentioned below.\n\n### Creating a bbox tensor\uf0c1\n\nA bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"boxes\", htype=\"bbox\", coords={\"type\": \"fractional\", \"mode\": \"CCWH\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with keys \u201ctype\u201d and \u201cmode\u201d.\n    \n      * **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.",
        "node_489": "`tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.\n\n### Appending class labels\uf0c1\n\n  * Class labels can be appended as `int`, `str`, `np.ndarray` or `list` of `int` or `str`.\n\n  * In case of strings, `tensor.info.class_names` is updated automatically.\n\nExamples\n\nAppending index\n\n    \n    \n    >>> ds.labels.append(0)\n    >>> ds.labels.append(np.zeros((5,), dtype=np.uint32))\n    \n\nExtending with list of indices\n\n    \n    \n    >>> ds.labels.extend([[0, 1, 2], [1, 3]])\n    \n\nAppending text labels\n\n    \n    \n    >>> ds.labels.append([\"cars\", \"airplanes\"])\n    \n\n## Tag Htype\uf0c1\n\n  * Sample dimensions: `(# tags,)`\n\nThis htype can be used to tag samples with one or more string values.\n\n### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.",
        "node_799": "* Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.\n\n    * If `verify=True` was specified during `create_tensor` of the tensor to which this is being added, some metadata is read from them to verify the integrity of the link samples. This is `True` by default.\n\n    * If you do not want to verify your links, all three of `verify`, `create_shape_tensor` and `create_sample_info_tensor` have to be set to `False`.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.dataset(\"......\")\n    \n\nAdding credentials to the dataset\n\nYou can add the names of the credentials you want to use (not needed for\nhttp/local urls)\n\n    \n    \n    >>> ds.add_creds_key(\"MY_S3_KEY\")\n    >>> ds.add_creds_key(\"GCS_KEY\")\n    \n\nand populate the added names with credentials dictionaries\n\n    \n    \n    >>> ds.populate_creds(\"MY_S3_KEY\", {})   # add creds here\n    >>> ds.populate_creds(\"GCS_KEY\", {})    # add creds here\n    \n\nThese creds are only present temporarily and will have to be repopulated on\nevery reload.\n\nFor datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.",
        "node_582": "The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.\n\n  * \\\\(f_x = F / p_x\\\\)\n\n  * \\\\(f_y = F / p_y\\\\)\n\n  * \\\\(F\\\\) \\- Focal length in world units, typically expressed in millimeters.\n\n  * \\\\((p_x, p_y)\\\\) \\- Size of the pixel in world units.\n\n### Creating an intrinsics tensor\uf0c1\n\nAn intrinsics tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"intrinsics\", htype=\"intrinsics\")\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending intrinsics matrices\uf0c1\n\n    \n    \n    >>> intrinsic_params = np.zeros((3, 3))\n    >>> ds.intrinsics.append(intrinsic_params)\n    \n\n## Segmentation Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width)`\n\nSegmentation masks are 2D representations of class labels where the numerical\nlabel data is encoded in an array of same shape as the image. The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**.",
        "node_572": "Images can be stored in Deep Lake as compressed bytes or as raw arrays. Due to\nthe high compression ratio for most image formats, it is highly recommended to\nstore compressed images using the `sample_compression` input to the\ncreate_tensor method.\n\n### Creating an image tensor\uf0c1\n\nAn image tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\")\n    \n\nOR\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", chunk_compression=\"jpg\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"bmp\", \"dib\", \"gif\", \"ico\", \"jpeg\", \"jpeg2000\", \"pcx\", \"png\", \"ppm\", \"sgi\", \"tga\", \"tiff\",\n    ... \"webp\", \"wmf\", \"xbm\", \"eps\", \"fli\", \"im\", \"msp\", \"mpo\"]\n    \n\n### Appending image samples\uf0c1\n\n  * Image samples can be of type `np.ndarray` or Deep Lake `Sample` which can be created using `deeplake.read()`.\n\nExamples\n\nAppending pixel data with array\n\n    \n    \n    >>> ds.images.append(np.zeros((5, 5, 3), dtype=np.uint8))\n    \n\nAppening Deep Lake image sample\n\n    \n    \n    >>> ds.images.append(deeplake.read(\"images/0001.jpg\"))\n    \n\nYou can append multiple samples at the same time using `extend()`.\n\n    \n    \n    >>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type.",
        "node_1123": "It can be:\n\n    * a Deep Lake cloud path of the form `hub://org_id/dataset_name`. Requires registration with Deep Lake.\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.\n\n  * **tensor_params** (_List_ _[__Dict_ _[__str_ _,__dict_ _]__]__,__optional_) \u2013 List of dictionaries that contains information about tensors that user wants to create. See `create_tensor` in Deep Lake API docs for more information. Defaults to `DEFAULT_VECTORSTORE_TENSORS`.\n\n  * **embedding_function** (_Optional_ _[__Any_ _]__,__optional_) \u2013 Function or class that converts the embeddable data into embeddings. Input to embedding_function is a list of data and output is a list of embeddings. Defaults to None.\n\n  * **read_only** (_bool_ _,__optional_) \u2013 Opens dataset in read-only mode if True. Defaults to False.\n\n  * **ingestion_batch_size** (_int_) \u2013 Batch size to use for parallel ingestion.\n\n  * **index_params** (_Dict_ _[__str_ _,__Union_ _[__int_ _,__str_ _]__]_) \u2013 \n\nDictionary containing information about vector index that will be created.\nDefaults to `None`, which will utilize `DEFAULT_VECTORSTORE_INDEX_PARAMS` from\n`deeplake.constants`. The specified key-values override the default ones:\n\n    * \u2019threshold\u2019: The threshold for the dataset size above which an index will be created for the embedding tensor. When the threshold value is set to -1, index creation is turned off. Defaults to -1, which turns off the index.\n\n    * \u2019distance_metric\u2019: This key specifies the method of calculating the distance between vectors when creating the vector database (VDB) index.",
        "node_115": "* ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function. See `deeplake.empty()`.\n\nReturns\n\n    \n\nThe destination Deep Lake dataset.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**ValueError** \u2013 If `dest` is not a path or a Deep Lake `Dataset`.\n\nNote\n\n  * if DatasetDict looks like:\n    \n        >>> {\n    ...    train: Dataset({\n    ...        features: ['data']\n    ...    }),\n    ...    validation: Dataset({\n    ...        features: ['data']\n    ...    }),\n    ...    test: Dataset({\n    ...        features: ['data']\n    ...    }),\n    ... }\n    \n\nit will be converted to a Deep Lake `Dataset` with tensors `['train/data',\n'validation/data', 'test/data']`.\n\nFeatures of the type `Sequence(feature=Value(dtype='string'))` are not\nsupported. Columns of such type are skipped.\n\ndeeplake.load(_path : Union[str, Path]_, _read_only : Optional[bool] = None_,\n_memory_cache_size : int = 2000_, _local_cache_size : int = 0_, _creds :\nOptional[Union[dict, str]] = None_, _token : Optional[str] = None_, _org_id :\nOptional[str] = None_, _verbose : bool = True_, _access_method : str =\n'stream'_, _unlink : bool = False_, _reset : bool = False_, _check_integrity :\nOptional[bool] = None_, _lock_timeout : Optional[int] = 0_, _lock_enabled :\nOptional[bool] = True_, _index_params : Optional[Dict[str, Union[int, str]]] =\nNone_) -> Dataset\uf0c1\n\n    \n\nLoads an existing dataset\n\nExamples\n\n    \n    \n    >>> ds = deeplake.load(\"hub://username/dataset\")\n    >>> ds = deeplake.load(\"s3://mybucket/my_dataset\")\n    >>> ds = deeplake.load(\"./datasets/my_dataset\", overwrite=True)\n    \n\nLoading to a specfic version:\n\n    \n    \n    >>> ds = deeplake.load(\"hub://username/dataset@new_branch\")\n    >>> ds = deeplake.load(\"hub://username/dataset@3e49cded62b6b335c74ff07e97f8451a37aca7b2)\n    \n    \n    \n    >>> my_commit_id = \"3e49cded62b6b335c74ff07e97f8451a37aca7b2\"\n    >>> ds = deeplake.load(f\"hub://username/dataset@{my_commit_id}\")\n    \n\nParameters\n\n    \n\n  * **path** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset.",
        "node_400": "---|---  \n`Dataset.create_group` | Creates a tensor group.  \n`Dataset.create_tensor_like` | Copies the `source` tensor's meta information and creates a new tensor with it.  \n  \n## Deleting and Renaming Tensors\uf0c1\n\n`Dataset.delete_tensor` | Delete a tensor from the dataset.  \n---|---  \n`Dataset.delete_group` | Delete a tensor group from the dataset.  \n`Dataset.rename_tensor` | Renames tensor with name `name` to `new_name`  \n`Dataset.rename_group` | Renames group with name `name` to `new_name`  \n  \n## Adding and deleting samples\uf0c1\n\n`Tensor.append` | Appends a single sample to the end of the tensor.  \n---|---  \n`Tensor.extend` | Extends the end of the tensor by appending multiple elements from a sequence.  \n`Tensor.pop` | Removes element(s) at the given index / indices.  \n`Tensor.clear` | Deletes all samples from the tensor  \n`Tensor.__setitem__` | Update samples with new values.  \n  \n## Retrieving samples\uf0c1\n\n`Tensor.numpy` | Computes the contents of the tensor in numpy format.  \n---|---  \n`Tensor.data` | Returns data in the tensor in a format based on the tensor's base htype.  \n`Tensor.tobytes` | Returns the bytes of the tensor.  \n`Tensor.text` | Return text data.  \n`Tensor.dict` | Return json data.  \n`Tensor.list` | Return list data.  \n`Tensor._linked_sample` | Returns the linked sample at the given index.  \n  \n## Tensor Properties\uf0c1\n\n`Tensor.htype` | Htype of the tensor.  \n---|---  \n`Tensor.base_htype` | Base htype of the tensor.  \n`Tensor.dtype` | Dtype of the tensor.  \n`Tensor.shape` | Get the shape of this tensor.  \n`Tensor.shape_interval` | Returns a `ShapeInterval` object that describes this tensor's shape more accurately.  \n`Tensor.ndim` | Number of dimensions of the tensor.  \n`Tensor.num_samples` | Returns the length of the primary axis of the tensor.  \n`Tensor.__len__` | Returns the length of the primary axis of the tensor.",
        "node_192": "Examples\n\n    \n    \n    >>> ds.delete_group(\"images/dogs\")\n    \n\nParameters\n\n    \n\n  * **name** (_str_) \u2013 The name of tensor group to be deleted.\n\n  * **large_ok** (_bool_) \u2013 Delete tensor groups larger than 1 GB. Disabled by default.\n\nReturns\n\n    \n\nNone\n\nRaises\n\n    \n\n**TensorGroupDoesNotExistError** \u2013 If tensor group of name `name` does not\nexist in the dataset.\n\ndelete_tensor(_name : str_, _large_ok : bool = False_)\uf0c1\n\n    \n\nDelete a tensor from the dataset.\n\nExamples\n\n    \n    \n    >>> ds.delete_tensor(\"images/cats\")\n    \n\nParameters\n\n    \n\n  * **name** (_str_) \u2013 The name of tensor to be deleted.\n\n  * **large_ok** (_bool_) \u2013 Delete tensors larger than 1 GB. Disabled by default.\n\nReturns\n\n    \n\nNone\n\nRaises\n\n    \n\n  * **TensorDoesNotExistError** \u2013 If tensor of name `name` does not exist in the dataset.\n\n  * **TensorTooLargeToDelete** \u2013 If the tensor is larger than 1 GB and `large_ok` is `False`.\n\ndelete_view(_id : str_)\uf0c1\n\n    \n\nDeletes the view with given view id.\n\nParameters\n\n    \n\n**id** (_str_) \u2013 Id of the view to delete.\n\nRaises\n\n    \n\n**KeyError** \u2013 if view with given id does not exist.\n\ndiff(_id_1 : Optional[str] = None_, _id_2 : Optional[str] = None_, _as_dict\n=False_) -> Optional[Dict]\uf0c1\n\n    \n\nReturns/displays the differences between commits/branches.\n\nFor each tensor this contains information about the sample indexes that were\nadded/modified as well as whether the tensor was created.\n\nParameters\n\n    \n\n  * **id_1** (_str_ _,__Optional_) \u2013 The first commit_id or branch name.\n\n  * **id_2** (_str_ _,__Optional_) \u2013 The second commit_id or branch name.\n\n  * **as_dict** (_bool_ _,__Optional_) \u2013 If `True`, returns the diff as lists of commit wise dictionaries.\n\nReturns\n\n    \n\nOptional[Dict]\n\nRaises\n\n    \n\n**ValueError** \u2013 If `id_1` is None and `id_2` is not None.",
        "node_94": "* **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\n  * **org_id** (_str_ _,__Optional_) \u2013 Organization id to be used for enabling high-performance features. Only applicable for local datasets.\n\n  * **public** (_bool_) \u2013 Defines if the dataset will have public access. Applicable only if Deep Lake cloud storage is used and a new Dataset is being created. Defaults to False.\n\n  * **verbose** (_bool_) \u2013 If True, logs will be printed. Defaults to `True`.\n\nReturns\n\n    \n\nNew dataset object.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**ValueError** \u2013 If `org_id` is specified for a non-local dataset.\n\ndeeplake.ingest_classification(_src : Union[str, Path]_, _dest : Union[str,\nPath]_, _image_params : Optional[Dict] = None_, _label_params : Optional[Dict]\n= None_, _dest_creds : Optional[Union[Dict, str]] = None_, _progressbar : bool\n= True_, _summary : bool = True_, _num_workers : int = 0_, _shuffle : bool =\nTrue_, _token : Optional[str] = None_, _connect_kwargs : Optional[Dict] =\nNone_, _** dataset_kwargs_) -> Dataset\uf0c1\n\n    \n\nIngest a dataset of images from a local folder to a Deep Lake Dataset. Images\nshould be stored in subfolders by class name.\n\nParameters\n\n    \n\n  * **src** (_str_ _,__pathlib.Path_) \u2013 Local path to where the unstructured dataset of images is stored or path to csv file.\n\n  * **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://org_id/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`.",
        "node_1139": "Store datasets in this database by specifying runtime = {\u201ctensor_db\u201d: True} during dataset creation.\n\n  * **embedding_tensor** (_str_) \u2013 Name of tensor with embeddings. Defaults to \u201cembedding\u201d.\n\n  * **return_tensors** (_Optional_ _[__List_ _[__str_ _]__]_) \u2013 List of tensors to return data for. Defaults to None, which returns data for all tensors except the embedding tensor (in order to minimize payload). To return data for all tensors, specify return_tensors = \u201c*\u201d.\n\n  * **return_view** (_bool_) \u2013 Return a Deep Lake dataset view that satisfied the search parameters, instead of a dictionary with data. Defaults to False. If `True` return_tensors is set to \u201c*\u201d beucase data is lazy-loaded and there is no cost to including all tensors in the view.\n\n  * **deep_memory** (_bool_) \u2013 Whether to use the Deep Memory model for improving search results. Defaults to False if deep_memory is not specified in the Vector Store initialization. If True, the distance metric is set to \u201cdeepmemory_distance\u201d, which represents the metric with which the model was trained. The search is performed using the Deep Memory model. If False, the distance metric is set to \u201cCOS\u201d or whatever distance metric user specifies.\n\n  * **return_tql** (_bool_) \u2013 Whether to return the TQL query string used for the search. Defaults to False.\n\nRaises\n\n    \n\n  * **ValueError** \u2013 When invalid parameters are specified.\n\n  * **ValueError** \u2013 when deep_memory is True. Deep Memory is only available for datasets stored in the Deep Lake Managed Database for paid accounts.\n\n  * **DeepMemoryAccessError** \u2013 if user does not have access to deep_memory.",
        "node_63": "Parameters\n\n    \n\n  * **shuffle** (_bool_) \u2013 shows wheter we need to shuffle elements or not. Defaults to True.\n\n  * **buffer_size** (_int_) \u2013 The size of the buffer used to shuffle the data in MBs. Defaults to 2048 MB. Increasing the buffer_size will increase the extent of shuffling.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n  * **ValueError** \u2013 If .shuffle() has already been called.\n\n  * **ValueError** \u2013 If dataset is view and shuffle is True\n\ntensorflow(_num_workers : int = 0_, _collate_fn : Optional[Callable] = None_,\n_tensors : Optional[List[str]] = None_, _num_threads : Optional[int] = None_,\n_prefetch_factor : int = 2_, _return_index : bool = True_, _decode_method :\nOptional[Dict[str, str]] = None_, _persistent_workers : bool = False_)\uf0c1\n\n    \n\nReturns a `DeepLakeDataLoader` object.\n\nParameters\n\n    \n\n  * **num_workers** (_int_) \u2013 Number of workers to use for transforming and processing the data. Defaults to 0.\n\n  * **collate_fn** (_Callable_ _,__Optional_) \u2013 merges a list of samples to form a mini-batch of Tensor(s).\n\n  * **tensors** (_List_ _[__str_ _]__,__Optional_) \u2013 List of tensors to load. If None, all tensors are loaded. Defaults to `None`.\n\n  * **num_threads** (_int_ _,__Optional_) \u2013 Number of threads to use for fetching and decompressing the data. If `None`, the number of threads is automatically determined. Defaults to `None`.\n\n  * **prefetch_factor** (_int_) \u2013 Number of batches to transform and collate in advance per worker. Defaults to 2.\n\n  * **return_index** (_bool_) \u2013 Used to idnetify where loader needs to retur sample index or not. Defaults to `True`.\n\n  * **persistent_workers** (_bool_) \u2013 If `True`, the data loader will not shutdown the worker processes after a dataset has been consumed once. Defaults to `False`.",
        "node_848": "1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.",
        "node_1048": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Random Split\n  * Edit on GitHub\n\n* * *\n\n# Random Split\uf0c1\n\nSplits the dataset into non overlapping new datasets of given lengths. The\nresulting datasets are generated in such a way that when creating a dataloader\nfrom the view and training on it, the performance impact is minimal. Using the\noutputs of this function with .pytorch method of dataset (instead of\n.dataloader) may result in poor performance. See the `random_split` method on\nhow to use this feature:\n\n`Dataset.random_split` | Splits the dataset into non-overlapping `Dataset` objects of given lengths.  \n---|---  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_467": "The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"])\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending segmentation masks\uf0c1\n\n  * Segmentation masks can be appended as `np.ndarray`.\n\nExamples\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512)))\n    \n\nNote\n\nSince each pixel can only be labeled once, segmentation masks are not\nappropriate for datasets where objects might overlap, or where multiple\nobjects within the same class must be distinguished. For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.",
        "node_217": ">>> import deeplake\n    >>> ds = deeplake.load('hub://activeloop/fashion-mnist-train')\n    >>> sampled_ds = ds.sample_by(\"max_weight(labels == 5: 10, labels == 6: 5\"))\n    \n\nSample the dataset with the given weights;\n\n    \n    \n    >>> ds = deeplake.load('hub://activeloop/coco-train')\n    >>> weights = list()\n    >>> for i in range(len(ds)):\n    ...     weights.append(i % 5)\n    ...\n    >>> sampled_ds = ds.sample_by(weights, replace=False)\n    \n\n_property _sample_indices\uf0c1\n\n    \n\nReturns all the indices pointed to by this dataset view.\n\nsave_view(_message : Optional[str] = None_, _path : Optional[Union[str, Path]]\n= None_, _id : Optional[str] = None_, _optimize : bool = False_, _tensors :\nOptional[List[str]] = None_, _num_workers : int = 0_, _scheduler : str =\n'threaded'_, _verbose : bool = True_, _ignore_errors : bool = False_, _**\nds_args_) -> str\uf0c1\n\n    \n\nSaves a dataset view as a virtual dataset (VDS)\n\nExamples\n\n    \n    \n    >>> # Save to specified path\n    >>> vds_path = ds[:10].save_view(path=\"views/first_10\", id=\"first_10\")\n    >>> vds_path\n    views/first_10\n    \n    \n    \n    >>> # Path unspecified\n    >>> vds_path = ds[:100].save_view(id=\"first_100\", message=\"first 100 samples\")\n    >>> # vds_path = path/to/dataset\n    \n    \n    \n    >>> # Random id\n    >>> vds_path = ds[:100].save_view()\n    >>> # vds_path = path/to/dataset/.queries/92f41922ed0471ec2d27690b7351fc96bea060e6c5ee22b14f7ffa5f291aa068\n    \n\nSee `Dataset.get_view()` to learn how to load views by id. These virtual\ndatasets can also be loaded from their path like normal datasets.\n\nParameters\n\n    \n\n  * **message** (_Optional_ _,__str_) \u2013 Custom user message.",
        "node_804": "core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.\n\nSupported htypes and their respective defaults are:\n\nHtype configs\uf0c1 HTYPE | DTYPE | COMPRESSION  \n---|---|---  \ngeneric | None | None  \nimage | uint8 | Required arg  \nimage.rgb | uint8 | Required arg  \nimage.gray | uint8 | Required arg  \nvideo | uint8 | Required arg  \naudio | float64 | Required arg  \nclass_label | uint32 | None  \ntag | str | None  \nbbox | float32 | None  \nbbox.3d | float32 | None  \nintrinsics | float32 | None  \nsegment_mask | uint32 | None  \nbinary_mask | bool | None  \nkeypoints_coco | int32 | None  \npoint | int32 | None  \npolygon | float32 | None  \ntext | str | None  \njson | Any | None  \nlist | List | None  \ndicom | None | dcm  \nnifti | None | Required arg  \npoint_cloud | None | las  \nmesh | None | ply  \ninstance_label | uint32 | None  \nembedding | None | None  \nlink | str | None  \nsequence | None | None  \n  \n## Image Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # channels)` or `(height, width)`.\n\nImages can be stored in Deep Lake as compressed bytes or as raw arrays.",
        "node_651": "* Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.\n\n### Creating a mesh tensor\uf0c1\n\nA mesh tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"mesh\", htype=\"mesh\", sample_compression=\"ply\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"ply\"]\n    \n\n### Appending meshes\uf0c1\n\nExamples\n\nAppending a ply file containing a mesh data to tensor\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.ply\")  # mesh with 100 points and 200 faces\n    >>> ds.mesh.append(sample)\n    \n    \n    \n    >>> ds.mesh.shape\n    >>> (1, 100, 3)\n    \n\n## Embedding Htype\uf0c1\n\n  * Sample dimensions: `(# elements in the embedding,)`\n\n### Creating an embedding tensor\uf0c1\n\nAn embedding tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"embedding\", htype=\"embedding\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\", None]\n    \n\n### Appending embedding samples\uf0c1\n\n  * Embedding samples can be of type `np.ndarray`.\n\nExamples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.",
        "node_425": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_482": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.gray htypes\n    * Video Htype\n      * Limitations\n      * Creating a video tensor\n      * Appending video samples\n    * Audio Htype\n      * Creating an audio tensor\n      * Appending audio samples\n    * Class Label Htype\n      * Creating a class label tensor\n      * Appending class labels\n    * Tag Htype\n      * Creating a tag tensor\n      * Appending tag samples\n    * Bounding Box Htype\n      * Creating a bbox tensor\n      * Appending bounding boxes\n    * 3D Bounding Box Htype\n      * Creating a 3d bbox tensor\n      * Appending 3d bounding boxes\n    * Intrinsics Htype\n      * Creating an intrinsics tensor\n      * Appending intrinsics matrices\n    * Segmentation Mask Htype\n      * Creating a segment_mask tensor\n      * Appending segmentation masks\n    * Binary Mask Htype\n      * Creating a binary_mask tensor\n      * Appending binary masks\n    * COCO Keypoints Htype\n      * Creating a keypoints_coco tensor\n      * Appending keypoints\n    * Point Htype\n      * Creating a point tensor\n      * Appending point samples\n    * Polygon Htype\n      * Creating a polygon tensor\n      * Appending polygons\n    * Nifti Htype\n      * Limitations\n      * Creating a nifti tensor\n      * Appending nifti data\n    * Point Cloud Htype\n      * Creating a point cloud tensor\n      * Appending point clouds\n    * Mesh Htype\n      * Creating a mesh tensor\n      * Appending meshes\n    * Embedding Htype\n      * Creating an embedding tensor\n      * Appending embedding samples\n    * Sequence htype\n    * Link htype\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.",
        "node_1233": "* **skip_ok** (_bool_) \u2013 If `True`, skips the check for output tensors generated. This allows the user to skip certain tensors in the function definition. This is especially useful for inplace transformations in which certain tensors are not modified. Defaults to `False`.\n\n  * **check_lengths** (_bool_) \u2013 If `True`, checks whether `ds_out` has tensors of same lengths initially.\n\n  * **pad_data_in** (_bool_) \u2013 If `True`, pads tensors of `data_in` to match the length of the largest tensor in `data_in`. Defaults to `False`.\n\n  * **read_only_ok** (_bool_) \u2013 If `True` and output dataset is same as input dataset, the read-only check is skipped. Defaults to False.\n\n  * **cache_size** (_int_) \u2013 Cache size to be used by transform per worker.\n\n  * **checkpoint_interval** (_int_) \u2013 If > 0, the transform will be checkpointed with a commit every `checkpoint_interval` input samples to avoid restarting full transform due to intermitten failures. If the transform is interrupted, the intermediate data is deleted and the dataset is reset to the last commit. If <= 0, no checkpointing is done. Checkpoint interval should be a multiple of num_workers if num_workers > 0\\. Defaults to 0.\n\n  * **ignore_errors** (_bool_) \u2013 If `True`, input samples that causes transform to fail will be skipped and the errors will be ignored **if possible**.\n\n  * **verbose** (_bool_) \u2013 If `True`, prints additional information about the transform.\n\n  * ****kwargs** \u2013 Additional arguments.\n\nRaises\n\n    \n\n  * **InvalidInputDataError** \u2013 If `data_in` passed to transform is invalid. It should support __getitem__ and __len__ operations. Using scheduler other than \u201cthreaded\u201d with deeplake dataset having base storage as memory as `data_in` will also raise this.\n\n  * **InvalidOutputDatasetError** \u2013 If all the tensors of `ds_out` passed to transform don\u2019t have the same length. Using scheduler other than \u201cthreaded\u201d with deeplake dataset having base storage as memory as `ds_out` will also raise this.",
        "node_369": "---|---  \n`Dataset.sample_by` | Returns a sliced `Dataset` with given weighted sampler applied.  \n`Dataset.filter` | Filters the dataset in accordance of filter function `f(x: sample) -> bool`  \n`Dataset.save_view` | Saves a dataset view as a virtual dataset (VDS)  \n`Dataset.get_view` | Returns the dataset view corresponding to `id`.  \n`Dataset.load_view` | Loads the view and returns the `Dataset` by id.  \n`Dataset.delete_view` | Deletes the view with given view id.  \n`Dataset.get_views` | Returns list of views stored in this Dataset.  \n`Dataset.is_view` | Returns `True` if this dataset is a view and `False` otherwise.  \n`Dataset.min_view` | Returns a view of the dataset in which all tensors are sliced to have the same length as the shortest tensor.  \n`Dataset.max_view` | Returns a view of the dataset in which shorter tensors are padded with `None` s to have the same length as the longest tensor.  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_755": "### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.\n    \n        * \u201ccenter\u201d: [center_x, center_y, center_z, size_x, size_y, size_z, rot_x, rot_y, rot_z]\n    \n          * Sample dimensions: `(# bounding boxes, 9)`\n\n          * `size_x` \\- is the length of the bounding box along x direction\n\n          * `size_y` \\- is the width of the bounding box along y direction\n\n          * `size_z` \\- is the height of the bounding box along z direction\n\n          * `rot_x` \\- rotation angle along x axis, given in degrees\n\n          * `rot_y` \\- rotation angle along y axis, given in degrees\n\n          * `rot_z` \\- rotation angle along z axis, given in degrees\n\n        * \u201cvertex\u201d: 8 3D vertices - [[x0, y0, z0], [x1, y1, z1], [x2, y2, z2], \u2026.., [x7, y7, z7]]\n    \n          * Sample dimensions: `(# bounding boxes, 8, 3)`\n\nThe vertex order is of the following form:\n\n                \n                                      4_____________________ 5\n                     /|                    /|\n                    / |                   / |\n                   /  |                  /  |\n                  /___|_________________/   |\n                0|    |                 | 1 |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |_________________|___|\n                 |   /  7               |   / 6\n                 |  /                   |  /\n                 | /                    | /\n                 |/_____________________|/\n                  3                      2\n                \n\n    * **dtype** : Defaults to `float32`.",
        "node_1065": "This is optional, tokens are normally autogenerated.\n\n  * **org_id** (_str_ _,__Optional_) \u2013 Organization id to be used for enabling high-performance features. Only applicable for local datasets.\n\n  * **verbose** (_bool_) \u2013 If True, logs will be printed. Defaults to True.\n\n  * **lock_timeout** (_int_) \u2013 Number of seconds to wait before throwing a LockException. If None, wait indefinitely\n\n  * **lock_enabled** (_bool_) \u2013 If true, the dataset manages a write lock. NOTE: Only set to False if you are managing concurrent access externally.\n\n  * **index_params** \u2013 Optional[Dict[str, Union[int, str]]]: Index parameters used while creating vector store, passed down to dataset.\n\nReturns\n\n    \n\nDataset created using the arguments provided.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **DatasetHandlerError** \u2013 If a Dataset already exists at the given path and overwrite is False.\n\n  * **UserNotLoggedInException** \u2013 When user is not authenticated\n\n  * **InvalidTokenException** \u2013 If the specified toke is invalid\n\n  * **TokenPermissionError** \u2013 When there are permission or other errors related to token\n\n  * **ValueError** \u2013 If version is specified in the path\n\nDanger\n\nSetting `overwrite` to `True` will delete all of your data if it exists! Be\nvery careful when setting this parameter.\n\ndeeplake.like(_dest : Union[str, Path]_, _src : Union[str, Dataset, Path]_,\n_runtime : Optional[Dict] = None_, _tensors : Optional[List[str]] = None_,\n_overwrite : bool = False_, _creds : Optional[Union[dict, str]] = None_,\n_token : Optional[str] = None_, _org_id : Optional[str] = None_, _public :\nbool = False_, _verbose : bool = True_) -> Dataset\uf0c1\n\n    \n\nCreates a new dataset by copying the `source` dataset\u2019s structure to a new\nlocation. No samples are copied, only the meta/info for the dataset and it\u2019s\ntensors.\n\nParameters\n\n    \n\n  * **dest** \u2013 Empty Dataset or Path where the new dataset will be created.",
        "node_1188": "Defaults to 0. When set to 0, it will always use serial processing, irrespective of the scheduler.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for rechunking. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Defaults to \u2018threaded\u2019.\n\n  * **progressbar** (_bool_) \u2013 Displays a progress bar If `True` (default).\n\nrename(_path : Union[str, Path]_)\uf0c1\n\n    \n\nRenames the dataset to path.\n\nExample\n\n    \n    \n    >>> ds = deeplake.load(\"hub://username/dataset\")\n    >>> ds.rename(\"hub://username/renamed_dataset\")\n    \n\nParameters\n\n    \n\n**path** (_str_ _,__pathlib.Path_) \u2013 New path to the dataset.\n\nRaises\n\n    \n\n**RenameError** \u2013 If `path` points to a different directory.\n\nrename_group(_name : str_, _new_name : str_) -> None\uf0c1\n\n    \n\nRenames group with name `name` to `new_name`\n\nParameters\n\n    \n\n  * **name** (_str_) \u2013 Name of group to be renamed.\n\n  * **new_name** (_str_) \u2013 New name of group.\n\nRaises\n\n    \n\n  * **TensorGroupDoesNotExistError** \u2013 If tensor group of name `name` does not exist in the dataset.\n\n  * **TensorAlreadyExistsError** \u2013 Duplicate tensors are not allowed.\n\n  * **TensorGroupAlreadyExistsError** \u2013 Duplicate tensor groups are not allowed.\n\n  * **InvalidTensorGroupNameError** \u2013 If `name` is in dataset attributes.\n\n  * **RenameError** \u2013 If `new_name` points to a group different from `name`.\n\nrename_tensor(_name : str_, _new_name : str_) -> Tensor\uf0c1\n\n    \n\nRenames tensor with name `name` to `new_name`\n\nParameters\n\n    \n\n  * **name** (_str_) \u2013 Name of tensor to be renamed.\n\n  * **new_name** (_str_) \u2013 New name of tensor.\n\nReturns\n\n    \n\nRenamed tensor.\n\nReturn type\n\n    \n\nTensor\n\nRaises\n\n    \n\n  * **TensorDoesNotExistError** \u2013 If tensor of name `name` does not exist in the dataset.\n\n  * **TensorAlreadyExistsError** \u2013 Duplicate tensors are not allowed.",
        "node_70": "In addition it can also be json,\nwhich contains number or string.\n\n`ORDER BY` statement optionally accepts `ASC/DESC` keywords specifying whether\nthe ordering should be ascending or descending. It is ascending by default.\n\n### LIMIT OFFSET\uf0c1\n\n`LIMIT` and `OFFSET` expressions are used to limit the output of the query by\nindex, as in SQL.\n\n### Expressions\uf0c1\n\nTQL supports any comparison operator (`==, !=, <, <=, >=`) where the left side\nis a tensor and the right side is a known value.\n\nThe value can be numeric scalar or array as well as string value.\n\nString literal should be provided within single quotes (`'`) and can be used\non `class_label`, `json` and `text` tensors.\n\nFor class labels it will get corresponding numeric value from the\n**class_names** list and do numeric comparison.\n\nFor json and text it will do string comparison. The left side of the\nexpression can be indexed (subscripted) if the tensor is multidimensional\narray or json. Jsons support indexing by string, e.g. `index_meta['id'] ==\n'some_id'`. Jsons can also be indexed by number if the underlying data is\narray.\n\nNumeric multidimensional tensors can be indexed by numbers, e.g.\n`categories[0] == 1` as well as Python style slicing and multidimensional\nindexing, such as `boxes[:2]`. This last expression returns array containing\nthe third elements of the initial two dimensional array boxes.\n\nTQL supports logical operators - `AND`, `OR` and `NOT`. These operators can be\nused to combine boolean expressions.",
        "node_45": "For datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.\n\n    \n    \n    >>> ds.add_creds_key(\"my_s3_creds\", managed=True)\n    >>> ds.add_creds_key(\"my_gcs_creds\", managed=True)\n    \n\nCreate a link tensor\n\n    \n    \n    >>> ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")\n    \n\nPopulate the tensor with links\n\n    \n    \n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\", creds_key=\"my_s3_key\"))\n    >>> ds.img.append(deeplake.link(\"gcs://ghi/jkl.png\", creds_key=\"GCS_KEY\"))\n    >>> ds.img.append(deeplake.link(\"https://picsum.photos/200/300\")) # http path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"./path/to/cat.jpeg\")) # local path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))  # this will throw an exception as cloud paths always need creds_key\n    :bluebold:`Accessing the data`\n    \n    \n    \n    >>> for i in range(5):\n    ...     ds.img[i].numpy()\n    ...\n    \n\nUpdating a sample\n\n    \n    \n    >>> ds.img[0] = deeplake.link(\"./data/cat.jpeg\")\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_953": "* Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.\n\nExamples\n\nAppending Deep Lake audio sample\n\n    \n    \n    >>> ds.audios.append(deeplake.read(\"audios/001.mp3\"))\n    \n\nExtending with Deep Lake audio samples\n\n    \n    \n    >>> ds.audios.extend([deeplake.read(f\"videos/00{i}.mp3\") for i in range(10)])\n    \n\n## Class Label Htype\uf0c1\n\n  * Sample dimensions: `(# labels,)`\n\nClass labels are stored as numerical values in tensors, which are indices of\nthe list `tensor.info.class_names`.\n\n### Creating a class label tensor\uf0c1\n\nA class label tensor can be created using\n\n    \n    \n    >>> classes = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"]\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\", class_names=classes, chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.",
        "node_1279": "VectorStore method)\n  * TensorUnsupportedSampleType (class in deeplake.util.exceptions)\n  * text() (deeplake.core.tensor.Tensor method)\n  * tiled() (in module deeplake)\n    * (in module deeplake.api.tiled)\n  * timestamps (deeplake.core.tensor.Tensor property)\n  * tobytes() (deeplake.core.tensor.Tensor method)\n  * token (deeplake.core.dataset.Dataset property)\n    * (deeplake.core.dataset.DeepLakeCloudDataset property)\n  * TokenPermissionError (class in deeplake.util.exceptions)\n  * train() (deeplake.core.vectorstore.deep_memory.deep_memory.DeepMemory method)\n  * transform() (deeplake.enterprise.DeepLakeDataLoader method)\n  * TransformError (class in deeplake.util.exceptions)\n\n  \n---|---  \n  \n## U\n\n  * UnableToReadFromUrlError (class in deeplake.util.exceptions)\n  * uncompressed_bytes() (deeplake.core.sample.Sample method)\n  * UnexpectedStatusCodeException (class in deeplake.util.exceptions)\n  * UnstructuredDataset (class in deeplake.auto.unstructured.base)\n  * UnsupportedCompressionError (class in deeplake.util.exceptions)\n  * UnsupportedSchedulerError (class in deeplake.util.exceptions)\n\n|\n\n  * UnsupportedTensorTypeError (class in deeplake.util.exceptions)\n  * update() (deeplake.api.info.Info method)\n    * (deeplake.core.dataset.Dataset method)\n  * update_creds_key() (deeplake.core.dataset.Dataset method)\n    * (deeplake.core.dataset.DeepLakeCloudDataset method)\n  * update_embedding() (deeplake.core.vectorstore.deeplake_vectorstore.VectorStore method)\n  * UserNotLoggedInException (class in deeplake.util.exceptions)\n\n  \n---|---  \n  \n## V\n\n  * validate() (deeplake.core.index.Index method)\n    * (deeplake.core.index.",
        "node_76": "`DeepMemory.__init__` | Base Deep Memory class to train and evaluate models on DeepMemory managed service.  \n---|---  \n  \n## Deep Memory Operations\uf0c1\n\n`DeepMemory.train` | Train a model on DeepMemory managed service.  \n---|---  \n`DeepMemory.cancel` | Cancel a training job on DeepMemory managed service.  \n`DeepMemory.delete` | Delete a training job on DeepMemory managed service.  \n  \n## Deep Memory Properties\uf0c1\n\n`DeepMemory.status` | Get the status of a training job on DeepMemory managed service.  \n---|---  \n`DeepMemory.list_jobs` | List all training jobs on DeepMemory managed service.  \n  \n## Syntax\uf0c1\n\nThis page describes `ds.query`. DeepMemory is a deep learning model that is\ntrained on the dataset to improve the search results, by aligning queries with\nthe corpus dataset. It gives up to +22% of recall improvement on an eval\ndataset. To use deep_memory, please subscribe to our waitlist.\n\n### Training\uf0c1\n\nTo start training you should first create a vectostore object, and then\npreprocess the data and use deep memory with it:\n\n    \n    \n    >>> from deeplake import VectorStore\n    >>> db = VectorStore(\n    ...     path=\"hub://{$ORG_ID}/{$DATASET_ID}\",\n    ...     token=token, # or you can be signed in with CLI\n    ...     runtime={\"tensor_db\": True},\n    ...     embedding_function=embedding_function, # function that takes converts texts into embeddings, it is optional and can be provided later\n    ... )\n    \n\nTo train a deepmemory model you need to preprocess the dataset so that,\n`corpus`, will become a list of list of tuples, where outer list corresponds\nto the query and inner list to the relevant documents. Each tuple should\ncontain the document id (`id` tensor from the corpus dataset) and the\nrelevance score (range is 0-1, where 0 represents unrelated document and 1\nrelated). `queries` should be a list of strings.",
        "node_1175": "Defaults to 0.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for optimization. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Only applicable if optimize=True. Defaults to \u2018threaded\u2019.\n\n  * **progressbar** (_bool_) \u2013 Whether to use progressbar for optimization. Only applicable if optimize=True. Defaults to True.\n\nReturns\n\n    \n\nThe loaded view.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**KeyError** \u2013 if view with given id does not exist.\n\nlog()\uf0c1\n\n    \n\nDisplays the details of all the past commits.\n\n_property _max_len\uf0c1\n\n    \n\nReturn the maximum length of the tensor.\n\n_property _max_view\uf0c1\n\n    \n\nReturns a view of the dataset in which shorter tensors are padded with `None`\ns to have the same length as the longest tensor.\n\nExample\n\nCreating a dataset with 5 images and 4 labels. `ds.max_view` will return a\nview with `labels` tensor padded to have 5 samples.",
        "node_441": "1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.",
        "node_372": "## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.  \n`Dataset.rename` | Renames the dataset to path.  \n`Dataset.connect` | Connect a Deep Lake cloud dataset through a deeplake path.  \n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n`Dataset.pop` | Removes a sample from all the tensors of the dataset.  \n`Dataset.rechunk` | Rewrites the underlying chunks to make their sizes optimal.  \n`Dataset.flush` | Necessary operation after writes if caches are being used.  \n`Dataset.clear_cache` | \n\n  * Flushes (see `Dataset.flush()`) the contents of the cache layers (if any) and then deletes contents of all the layers of it.\n\n  \n`Dataset.size_approx` | Estimates the size in bytes of the dataset.  \n`Dataset.random_split` | Splits the dataset into non-overlapping `Dataset` objects of given lengths.  \n  \n## Dataset Visualization\uf0c1\n\n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n---|---  \n  \n## Dataset Credentials\uf0c1\n\n`Dataset.add_creds_key` | Adds a new creds key to the dataset.  \n---|---  \n`Dataset.populate_creds` | Populates the creds key added in add_creds_key with the given creds.  \n`Dataset.update_creds_key` | Updates the name and/or management status of a creds key.",
        "node_47": "| `lz4`  \n  \n## Sample Compression\uf0c1\n\nIf sample compression is specified when `creating tensors`, samples will be\ncompressed to the given format if possible. If given data is already\ncompressed and matches the provided `sample_compression`, it will be stored as\nis. If left as `None`, given samples are uncompressed.\n\nNote\n\nFor audio and video, we don\u2019t support compressing raw frames but only reading\ncompressed audio and video data.\n\nExamples:\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\")\n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\nStructure of sample-wise compressed tensor.\uf0c1\n\n## Chunk Compression\uf0c1\n\nIf chunk compression is specified when `creating tensors`, added samples will\nbe clubbed together and compressed to the given format chunk-wise. If given\ndata is already compressed, it will be uncompressed and then recompressed\nchunk-wise.\n\nNote\n\nChunk-wise compression is not supported for audio, video and point_cloud\nhtypes.\n\nExamples:\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", chunk_compression=\"jpg\")\n    \n    >>> ds.create_tensor(\"boxes\", htype=\"bbox\", chunk_compression=\"lz4\")\n    \n\nStructure of chunk-wise compressed tensor.\uf0c1\n\nNote\n\nSee `deeplake.read()` to learn how to read data from files and populate these\ntensors.\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_80": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n    * `dataset()`\n    * `empty()`\n    * `like()`\n    * `ingest_classification()`\n    * `ingest_coco()`\n    * `ingest_yolo()`\n    * `ingest_kaggle()`\n    * `ingest_dataframe()`\n    * `ingest_huggingface()`\n    * `load()`\n    * `delete()`\n    * `rename()`\n    * `copy()`\n    * `deepcopy()`\n    * `connect()`\n    * `exists()`\n    * `read()`\n    * `link()`\n    * `link_tiled()`\n    * `tiled()`\n    * `compute()`\n    * `compose()`\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * deeplake\n  * Edit on GitHub\n\n* * *\n\n# deeplake\uf0c1\n\nThe deeplake package provides a database which stores data as compressed\nchunked arrays that can be stored anywhere and later streamed to deep learning\nmodels.",
        "node_358": "## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.  \n`Dataset.rename` | Renames the dataset to path.  \n`Dataset.connect` | Connect a Deep Lake cloud dataset through a deeplake path.  \n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n`Dataset.pop` | Removes a sample from all the tensors of the dataset.  \n`Dataset.rechunk` | Rewrites the underlying chunks to make their sizes optimal.  \n`Dataset.flush` | Necessary operation after writes if caches are being used.  \n`Dataset.clear_cache` | \n\n  * Flushes (see `Dataset.flush()`) the contents of the cache layers (if any) and then deletes contents of all the layers of it.\n\n  \n`Dataset.size_approx` | Estimates the size in bytes of the dataset.  \n`Dataset.random_split` | Splits the dataset into non-overlapping `Dataset` objects of given lengths.  \n  \n## Dataset Visualization\uf0c1\n\n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n---|---  \n  \n## Dataset Credentials\uf0c1\n\n`Dataset.add_creds_key` | Adds a new creds key to the dataset.  \n---|---  \n`Dataset.populate_creds` | Populates the creds key added in add_creds_key with the given creds.  \n`Dataset.update_creds_key` | Updates the name and/or management status of a creds key.",
        "node_243": "Plays video in Jupyter notebook or plays in web browser.\nVideo is streamed directly from storage. This method will fail for\nincompatible htypes.\n\nExample\n\n    \n    \n    >>> ds = deeplake.load(\"./test/my_video_ds\")\n    >>> # play second sample\n    >>> ds.videos[2].play()\n    \n\nNote\n\nVideo streaming is not yet supported on colab.\n\npop(_index : Optional[Union[int, List[int]]] = None_)\uf0c1\n\n    \n\nRemoves element(s) at the given index / indices.\n\n_property _sample_indices\uf0c1\n\n    \n\nReturns all the indices pointed to by this tensor in the dataset view.\n\n_property _sample_info _: Union[Dict, List[Dict]]_\uf0c1\n\n    \n\nReturns info about particular samples in a tensor. Returns dict in case of\nsingle sample, otherwise list of dicts. Data in returned dict would depend on\nthe tensor\u2019s htype and the sample itself.\n\nExample\n\n    \n    \n    >>> ds.videos[0].sample_info\n    {'duration': 400400, 'fps': 29.97002997002997, 'timebase': 3.3333333333333335e-05, 'shape': [400, 360, 640, 3], 'format': 'mp4', 'filename': '../deeplake/tests/dummy_data/video/samplemp4.mp4', 'modified': False}\n    >>> ds.images[:2].sample_info\n    [{'exif': {'Software': 'Google'}, 'shape': [900, 900, 3], 'format': 'jpeg', 'filename': '../deeplake/tests/dummy_data/images/cat.jpeg', 'modified': False}, {'exif': {}, 'shape': [495, 750, 3], 'format': 'jpeg', 'filename': '../deeplake/tests/dummy_data/images/car.jpg', 'modified': False}]\n    \n\n_property _shape _: Tuple[Optional[int], ...]_\uf0c1\n\n    \n\nGet the shape of this tensor. Length is included.",
        "node_1226": "* `DynamicTensorNumpyError`\n    * `InvalidShapeIntervalError`\n    * `InvalidKeyTypeError`\n    * `UnsupportedTensorTypeError`\n    * `InvalidBytesRequestedError`\n    * `ProviderListEmptyError`\n    * `DirectoryAtPathException`\n    * `FileAtPathException`\n    * `ProviderSizeListMismatch`\n    * `ModuleNotInstalledException`\n    * `LoginException`\n    * `UserNotLoggedInException`\n    * `InvalidHubPathException`\n    * `PathNotEmptyException`\n    * `AuthenticationException`\n    * `AuthorizationException`\n    * `InvalidPasswordException`\n    * `CouldNotCreateNewDatasetException`\n    * `ResourceNotFoundException`\n    * `BadRequestException`\n    * `OverLimitException`\n    * `ServerException`\n    * `BadGatewayException`\n    * `GatewayTimeoutException`\n    * `WaitTimeoutException`\n    * `LockedException`\n    * `UnexpectedStatusCodeException`\n    * `EmptyTokenException`\n    * `S3Error`\n    * `S3GetError`\n    * `S3SetError`\n    * `S3DeletionError`\n    * `S3ListError`\n    * `UnsupportedCompressionError`\n    * `SampleCompressionError`\n    * `SampleDecompressionError`\n    * `InvalidImageDimensions`\n    * `TensorUnsupportedSampleType`\n    * `MetaError`\n    * `MetaDoesNotExistError`\n    * `MetaAlreadyExistsError`\n    * `MetaInvalidKey`\n    * `MetaInvalidRequiredMetaKey`\n    * `TensorMetaInvalidHtype`\n    * `TensorMetaInvalidHtypeOverwriteValue`\n    * `TensorMetaMissingRequiredValue`\n    * `TensorMetaInvalidHtypeOverwriteKey`\n    * `TensorDtypeMismatchError`\n    *",
        "node_1173": "Examples\n\n    \n    \n    >>> # save view\n    >>> ds[:100].save_view(id=\"first_100\")\n    >>> # load view\n    >>> first_100 = ds.get_view(\"first_100\").load()\n    >>> # 100\n    >>> print(len(first_100))\n    \n\nSee `Dataset.save_view()` to learn more about saving views.\n\nParameters\n\n    \n\n**id** (_str_) \u2013 id of required view.\n\nReturns\n\n    \n\nViewEntry\n\nRaises\n\n    \n\n**KeyError** \u2013 If no such view exists.\n\nget_views(_commit_id : Optional[str] = None_) -> List[ViewEntry]\uf0c1\n\n    \n\nReturns list of views stored in this Dataset.\n\nParameters\n\n    \n\n**commit_id** (_str_ _,__optional_) \u2013\n\n  * Commit from which views should be returned.\n\n  * If not specified, views from all commits are returned.\n\nReturns\n\n    \n\nList of `ViewEntry` instances.\n\nReturn type\n\n    \n\nList[ViewEntry]\n\n_property _groups _: Dict[str, Dataset]_\uf0c1\n\n    \n\nAll sub groups in this group\n\n_property _has_head_changes\uf0c1\n\n    \n\nReturns True if currently at head node and uncommitted changes are present.\n\n_property _info\uf0c1\n\n    \n\nReturns the information about the dataset.\n\n_property _is_head_node\uf0c1\n\n    \n\nReturns True if the current commit is the head node of the branch and False\notherwise.\n\n_property _is_view _: bool_\uf0c1\n\n    \n\nReturns `True` if this dataset is a view and `False` otherwise.\n\nload_view(_id : str_, _optimize : Optional[bool] = False_, _tensors :\nOptional[List[str]] = None_, _num_workers : int = 0_, _scheduler : str =\n'threaded'_, _progressbar : Optional[bool] = True_)\uf0c1\n\n    \n\nLoads the view and returns the `Dataset` by id. Equivalent to\nds.get_view(id).load().\n\nParameters\n\n    \n\n  * **id** (_str_) \u2013 id of the view to be loaded.\n\n  * **optimize** (_bool_) \u2013 If `True`, the dataset view is optimized by copying and rechunking the required data before loading. This is necessary to achieve fast streaming speeds when training models using the dataset view.",
        "node_255": "* `TensorModifiedError`\n    * `GCSDefaultCredsNotFoundError`\n    * `InvalidOperationError`\n    * `AgreementError`\n    * `AgreementNotAcceptedError`\n    * `RenameError`\n    * `BufferError`\n    * `InfoError`\n    * `OutOfChunkCountError`\n    * `OutOfSampleCountError`\n    * `SampleHtypeMismatchError`\n    * `EmptyTensorError`\n    * `DatasetViewSavingError`\n    * `ManagedCredentialsNotFoundError`\n    * `UnableToReadFromUrlError`\n    * `InvalidTokenException`\n    * `TokenPermissionError`\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_558": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_112": "* **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * A Dataset or The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://username/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.\n\n  * **column_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the tensors corresponding to the dataframe columns.\n\n  * **src_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 Credentials to access the source data. If not provided, will be inferred from the environment.\n\n  * **dest_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 The string `ENV` or a dictionary containing credentials used to access the destination path of the dataset.\n\n  * **creds_key** (_Optional_ _[__str_ _]_) \u2013 creds_key for linked tensors, applicable if the htype any tensor is specified as \u2018link[\u2026]\u2019 in the \u2018column_params\u2019 input.\n\n  * **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Set to `True` by default.\n\n  * **token** (_Optional_ _[__str_ _]_) \u2013 The token to use for accessing the dataset.\n\n  * **connect_kwargs** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing arguments to be passed to the dataset connect method. See `Dataset.connect()`.\n\n  * ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function. See `deeplake.empty()`.",
        "node_1037": "Parameters\n\n    \n\n  * **shuffle** (_bool_) \u2013 shows wheter we need to shuffle elements or not. Defaults to True.\n\n  * **buffer_size** (_int_) \u2013 The size of the buffer used to shuffle the data in MBs. Defaults to 2048 MB. Increasing the buffer_size will increase the extent of shuffling.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n  * **ValueError** \u2013 If .shuffle() has already been called.\n\n  * **ValueError** \u2013 If dataset is view and shuffle is True\n\ntensorflow(_num_workers : int = 0_, _collate_fn : Optional[Callable] = None_,\n_tensors : Optional[List[str]] = None_, _num_threads : Optional[int] = None_,\n_prefetch_factor : int = 2_, _return_index : bool = True_, _decode_method :\nOptional[Dict[str, str]] = None_, _persistent_workers : bool = False_)\uf0c1\n\n    \n\nReturns a `DeepLakeDataLoader` object.\n\nParameters\n\n    \n\n  * **num_workers** (_int_) \u2013 Number of workers to use for transforming and processing the data. Defaults to 0.\n\n  * **collate_fn** (_Callable_ _,__Optional_) \u2013 merges a list of samples to form a mini-batch of Tensor(s).\n\n  * **tensors** (_List_ _[__str_ _]__,__Optional_) \u2013 List of tensors to load. If None, all tensors are loaded. Defaults to `None`.\n\n  * **num_threads** (_int_ _,__Optional_) \u2013 Number of threads to use for fetching and decompressing the data. If `None`, the number of threads is automatically determined. Defaults to `None`.\n\n  * **prefetch_factor** (_int_) \u2013 Number of batches to transform and collate in advance per worker. Defaults to 2.\n\n  * **return_index** (_bool_) \u2013 Used to idnetify where loader needs to retur sample index or not. Defaults to `True`.\n\n  * **persistent_workers** (_bool_) \u2013 If `True`, the data loader will not shutdown the worker processes after a dataset has been consumed once. Defaults to `False`.",
        "node_566": "* Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.\n\n    * If `verify=True` was specified during `create_tensor` of the tensor to which this is being added, some metadata is read from them to verify the integrity of the link samples. This is `True` by default.\n\n    * If you do not want to verify your links, all three of `verify`, `create_shape_tensor` and `create_sample_info_tensor` have to be set to `False`.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.dataset(\"......\")\n    \n\nAdding credentials to the dataset\n\nYou can add the names of the credentials you want to use (not needed for\nhttp/local urls)\n\n    \n    \n    >>> ds.add_creds_key(\"MY_S3_KEY\")\n    >>> ds.add_creds_key(\"GCS_KEY\")\n    \n\nand populate the added names with credentials dictionaries\n\n    \n    \n    >>> ds.populate_creds(\"MY_S3_KEY\", {})   # add creds here\n    >>> ds.populate_creds(\"GCS_KEY\", {})    # add creds here\n    \n\nThese creds are only present temporarily and will have to be repopulated on\nevery reload.\n\nFor datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.",
        "node_576": "`tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.\n\n### Appending class labels\uf0c1\n\n  * Class labels can be appended as `int`, `str`, `np.ndarray` or `list` of `int` or `str`.\n\n  * In case of strings, `tensor.info.class_names` is updated automatically.\n\nExamples\n\nAppending index\n\n    \n    \n    >>> ds.labels.append(0)\n    >>> ds.labels.append(np.zeros((5,), dtype=np.uint32))\n    \n\nExtending with list of indices\n\n    \n    \n    >>> ds.labels.extend([[0, 1, 2], [1, 3]])\n    \n\nAppending text labels\n\n    \n    \n    >>> ds.labels.append([\"cars\", \"airplanes\"])\n    \n\n## Tag Htype\uf0c1\n\n  * Sample dimensions: `(# tags,)`\n\nThis htype can be used to tag samples with one or more string values.\n\n### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.",
        "node_1299": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Deep Lake API Reference\n  * Edit on GitHub\n\n* * *\n\n# Deep Lake API Reference\uf0c1\n\nDeep Lake is an open-source database for AI.",
        "node_713": "For datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.\n\n    \n    \n    >>> ds.add_creds_key(\"my_s3_creds\", managed=True)\n    >>> ds.add_creds_key(\"my_gcs_creds\", managed=True)\n    \n\nCreate a link tensor\n\n    \n    \n    >>> ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")\n    \n\nPopulate the tensor with links\n\n    \n    \n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\", creds_key=\"my_s3_key\"))\n    >>> ds.img.append(deeplake.link(\"gcs://ghi/jkl.png\", creds_key=\"GCS_KEY\"))\n    >>> ds.img.append(deeplake.link(\"https://picsum.photos/200/300\")) # http path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"./path/to/cat.jpeg\")) # local path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))  # this will throw an exception as cloud paths always need creds_key\n    :bluebold:`Accessing the data`\n    \n    \n    \n    >>> for i in range(5):\n    ...     ds.img[i].numpy()\n    ...\n    \n\nUpdating a sample\n\n    \n    \n    >>> ds.img[0] = deeplake.link(\"./data/cat.jpeg\")\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_408": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n    * Creating Tensors\n    * Deleting and Renaming Tensors\n    * Adding and deleting samples\n    * Retrieving samples\n    * Tensor Properties\n    * Info\n    * Video features\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Tensors\n  * Edit on GitHub\n\n* * *\n\n# Tensors\uf0c1\n\n## Creating Tensors\uf0c1\n\n`Dataset.create_tensor` | Creates a new tensor in the dataset.  \n---|---  \n`Dataset.create_group` | Creates a tensor group.  \n`Dataset.create_tensor_like` | Copies the `source` tensor's meta information and creates a new tensor with it.  \n  \n## Deleting and Renaming Tensors\uf0c1\n\n`Dataset.delete_tensor` | Delete a tensor from the dataset.  \n---|---  \n`Dataset.delete_group` | Delete a tensor group from the dataset.  \n`Dataset.rename_tensor` | Renames tensor with name `name` to `new_name`  \n`Dataset.rename_group` | Renames group with name `name` to `new_name`  \n  \n## Adding and deleting samples\uf0c1\n\n`Tensor.append` | Appends a single sample to the end of the tensor.  \n---|---  \n`Tensor.extend` | Extends the end of the tensor by appending multiple elements from a sequence.",
        "node_37": "For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.\n\n## Point Htype\uf0c1\n\n  * Sample dimensions: `(# points, 2)` in case of 2-D (X, Y) co-ordinates or `(# points, 3)` in case of 3-D (X, Y, Z) co-ordinates of the point.\n\nPoints does not contain a fixed mapping across samples between the point order\nand real-world objects (i.e., point 0 is an elbow, point 1 is a knee, etc.).\nIf you require such a mapping, use COCO Keypoints Htype.\n\n### Creating a point tensor\uf0c1\n\nA point tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"points\", htype=\"point\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending point samples\uf0c1\n\n  * Points can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.",
        "node_1128": "Tensor names are specified as parameters, and data for each tensor is\nspecified as parameter values. All data must of equal length.\n\nExamples\n\n    \n    \n    >>> # Dummy data\n    >>> texts = [\"Hello\", \"World\"]\n    >>> embeddings = [[1, 2, 3], [4, 5, 6]]\n    >>> metadatas = [{\"timestamp\": \"01:20\"}, {\"timestamp\": \"01:22\"}]\n    >>> emebdding_fn = lambda x: [[1, 2, 3]] * len(x)\n    >>> embedding_fn_2 = lambda x: [[4, 5]] * len(x)\n    >>> # Directly upload embeddings\n    >>> deeplake_vector_store.add(\n    .     text = texts,\n    .     embedding = embeddings,\n    .     metadata = metadatas,\n    . )\n    >>> # Upload embedding via embedding function\n    >>> deeplake_vector_store.add(\n    .     text = texts,\n    .     metadata = metadatas,\n    .     embedding_function = embedding_fn,\n    .     embedding_data = texts,\n    . )\n    >>> # Upload embedding via embedding function to a user-defined embedding tensor\n    >>> deeplake_vector_store.add(\n    .     text = texts,\n    .     metadata = metadatas,\n    .     embedding_function = embedding_fn,\n    .     embedding_data = texts,\n    .     embedding_tensor = \"embedding_1\",\n    . )\n    >>> # Multiple embedding functions (user defined embedding tensors must be specified)\n    >>> deeplake_vector_store.add(\n    .     embedding_tensor = [\"embedding_1\", \"embedding_2\"]\n    .     embedding_function = [embedding_fn, embedding_fn_2],\n    .     embedding_data = [texts, texts],\n    . )\n    >>> # Alternative syntax for multiple embedding functions\n    >>> deeplake_vector_store.add(\n    .     text = texts,\n    .     metadata = metadatas,\n    .     embedding_tensor_1 = (embedding_fn, texts),\n    .     embedding_tensor_2 = (embedding_fn_2, texts),\n    .",
        "node_285": "cfg\n\n|\n\n### setup.cfg\n\n|  |   \n  \n### setup.py\n\n|\n\n### setup.py\n\n|  |   \n  \n### sonar-project.properties\n\n|\n\n### sonar-project.properties\n\n|  |   \nView all files  \n  \n## Repository files navigation\n\n  * README\n  * MPL-2.0 license\n  * Security\n\n  \n\n# Deep Lake: Database for AI\n\n###  **Docs** \u2022 **Get Started** \u2022 **API Reference** \u2022 **LangChain & VectorDBs\nCourse** \u2022 **Blog** \u2022 **Whitepaper** \u2022 **Slack** \u2022 **Twitter**\n\n_Read this in other languages:\u7b80\u4f53\u4e2d\u6587_\n\n## What is Deep Lake?\n\nDeep Lake is a Database for AI powered by a storage format optimized for deep-\nlearning applications. Deep Lake can be used for:\n\n  1. Storing data and vectors while building LLM applications\n  2. Managing datasets while training deep learning models\n\nDeep Lake simplifies the deployment of enterprise-grade LLM-based products by\noffering storage for all data types (embeddings, audio, text, videos, images,\npdfs, annotations, etc.), querying and vector search, data streaming while\ntraining models at scale, data versioning and lineage, and integrations with\npopular tools such as LangChain, LlamaIndex, Weights & Biases, and many more.\nDeep Lake works with data of any size, it is serverless, and it enables you to\nstore all of your data in your own cloud and in one place. Deep Lake is used\nby Intel, Airbus, Matterport, ZERO Systems, Red Cross, Yale, & Oxford.",
        "node_12": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n    * Creating a Deep Lake Vector Store\n    * Vector Store Operations\n    * Vector Store Properties\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Vector Store\n  * Edit on GitHub\n\n* * *\n\n# Vector Store\uf0c1\n\n## Creating a Deep Lake Vector Store\uf0c1\n\n`VectorStore.__init__` | Creates an empty VectorStore or loads an existing one if it exists at the specified `path`.  \n---|---  \n  \n## Vector Store Operations\uf0c1\n\n`VectorStore.add` | Adding elements to deeplake vector store.  \n---|---  \n`VectorStore.search` | VectorStore search method that combines embedding search, metadata search, and custom TQL search.  \n`VectorStore.delete` | Delete the data in the Vector Store.  \n`VectorStore.delete_by_path` | Deleted the Vector Store at the specified path.  \n`VectorStore.update_embedding` | Recompute existing embeddings of the VectorStore, that match either query, filter, ids or row_ids.  \n  \n## Vector Store Properties\uf0c1\n\n`VectorStore.summary` | Prints a summary of the dataset  \n---|---  \n`VectorStore.tensors` | Returns the list of tensors present in the dataset  \n`VectorStore.__len__` | Length of the dataset  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop.",
        "node_587": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_760": "* Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`. A set of `K` keypoints of an object is represented as:\n\n[x1, y1, v1, x2, y2, v2, \u2026, xk, yk, vk]\n\nThe visibility `v` can be one of three values:\n\n0\n\n    \n\nkeypoint not in image.\n\n1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.",
        "node_413": "`Tensor.tobytes` | Returns the bytes of the tensor.  \n`Tensor.text` | Return text data.  \n`Tensor.dict` | Return json data.  \n`Tensor.list` | Return list data.  \n`Tensor._linked_sample` | Returns the linked sample at the given index.  \n  \n## Tensor Properties\uf0c1\n\n`Tensor.htype` | Htype of the tensor.  \n---|---  \n`Tensor.base_htype` | Base htype of the tensor.  \n`Tensor.dtype` | Dtype of the tensor.  \n`Tensor.shape` | Get the shape of this tensor.  \n`Tensor.shape_interval` | Returns a `ShapeInterval` object that describes this tensor's shape more accurately.  \n`Tensor.ndim` | Number of dimensions of the tensor.  \n`Tensor.num_samples` | Returns the length of the primary axis of the tensor.  \n`Tensor.__len__` | Returns the length of the primary axis of the tensor.  \n`Tensor.is_dynamic` | Will return `True` if samples in this tensor have shapes that are unequal.  \n`Tensor.is_sequence` | Whether this tensor is a sequence tensor.  \n`Tensor.is_link` | Whether this tensor is a link tensor.  \n`Tensor.verify` | Whether linked data will be verified when samples are added.  \n  \n## Info\uf0c1\n\n`Tensor.info` | Returns the information about the tensor.  \n---|---  \n`Tensor.sample_info` | Returns info about particular samples in a tensor.  \n  \n## Video features\uf0c1\n\n`Tensor.play` | Play video sample.  \n---|---  \n`Tensor.timestamps` | Returns timestamps (in seconds) for video sample as numpy array.  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_69": "## Syntax\uf0c1\n\n### SELECT\uf0c1\n\nTQL supports only `SELECT` statement. Every TQL expression starts with `SELECT\n*`. TQL supports only `*` which means to select all tensors. The common syntax\nfor select statement is the following:\n\n    \n    \n    SELECT * [FROM string] [WHERE expression] [LIMIT number [OFFSET number]] [ORDER BY expression [ASC/DESC]]\n    \n\nEach part of the `SELECT` statement can be omitted.\n\n`FROM` expression is allowed, but it does not have any effect on the query,\nbecause for now TQL queries are run on a specific dataset, so the `FROM` is\nknown from the context\n\n### WHERE\uf0c1\n\n`WHERE` expression is used to filter the samples in the dataset by conditions.\nThe conditions should be convertible to boolean. Any expression which outputs\na number will be converted to boolean with non-zero values taken as `True`. If\nthe expression is not convertible to boolean, such as **strings** , **json**\nobjects and **arrays** , the query will print the corresponding error.\n\n### ORDER BY\uf0c1\n\n`ORDER BY` expression orders the output of the query by the given criteria.\nThe criteria can be any expression output of which can be ordered. The ordered\noutputs are either scalar numbers or strings. In addition it can also be json,\nwhich contains number or string.\n\n`ORDER BY` statement optionally accepts `ASC/DESC` keywords specifying whether\nthe ordering should be ascending or descending. It is ascending by default.\n\n### LIMIT OFFSET\uf0c1\n\n`LIMIT` and `OFFSET` expressions are used to limit the output of the query by\nindex, as in SQL.\n\n### Expressions\uf0c1\n\nTQL supports any comparison operator (`==, !=, <, <=, >=`) where the left side\nis a tensor and the right side is a known value.\n\nThe value can be numeric scalar or array as well as string value.\n\nString literal should be provided within single quotes (`'`) and can be used\non `class_label`, `json` and `text` tensors.\n\nFor class labels it will get corresponding numeric value from the\n**class_names** list and do numeric comparison.\n\nFor json and text it will do string comparison.",
        "node_129": "* **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for copying. Defaults to 0. When set to 0, it will always use serial processing, irrespective of the scheduler.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for copying. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Defaults to \u2018threaded\u2019.\n\n  * **progressbar** (_bool_) \u2013 Displays a progress bar if True (default).\n\n  * **public** (_bool_) \u2013 Defines if the dataset will have public access. Applicable only if Deep Lake cloud storage is used and a new Dataset is being created. Defaults to `False`.\n\n  * **verbose** (_bool_) \u2013 If True, logs will be printed. Defaults to `True`.\n\n  * ****kwargs** \u2013 Additional keyword arguments\n\nReturns\n\n    \n\nNew dataset object.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **DatasetHandlerError** \u2013 If a dataset already exists at destination path and overwrite is False.\n\n  * **TypeError** \u2013 If source is not a dataset.\n\n  * **UnsupportedParameterException** \u2013 If parameter that is no longer supported is beeing called.\n\n  * **DatasetCorruptError** \u2013 If loading source dataset fails with DatasetCorruptedError\n\ndeeplake.connect(_src_path : str_, _creds_key : str_, _dest_path :\nOptional[str] = None_, _org_id : Optional[str] = None_, _ds_name :\nOptional[str] = None_, _token : Optional[str] = None_) -> Dataset\uf0c1\n\n    \n\nConnects dataset at `src_path` to Deep Lake via the provided path.",
        "node_771": "For datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.\n\n    \n    \n    >>> ds.add_creds_key(\"my_s3_creds\", managed=True)\n    >>> ds.add_creds_key(\"my_gcs_creds\", managed=True)\n    \n\nCreate a link tensor\n\n    \n    \n    >>> ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")\n    \n\nPopulate the tensor with links\n\n    \n    \n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\", creds_key=\"my_s3_key\"))\n    >>> ds.img.append(deeplake.link(\"gcs://ghi/jkl.png\", creds_key=\"GCS_KEY\"))\n    >>> ds.img.append(deeplake.link(\"https://picsum.photos/200/300\")) # http path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"./path/to/cat.jpeg\")) # local path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))  # this will throw an exception as cloud paths always need creds_key\n    :bluebold:`Accessing the data`\n    \n    \n    \n    >>> for i in range(5):\n    ...     ds.img[i].numpy()\n    ...\n    \n\nUpdating a sample\n\n    \n    \n    >>> ds.img[0] = deeplake.link(\"./data/cat.jpeg\")\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_1219": "Return type\n\n    \n\nShapeInterval\n\nNote\n\nIf you are expecting a tuple, use `shape` instead.\n\nshapes()\uf0c1\n\n    \n\nGet the shapes of all the samples in the tensor.\n\nReturns\n\n    \n\nList of shapes of all the samples in the tensor.\n\nReturn type\n\n    \n\nnp.ndarray\n\nsummary()\uf0c1\n\n    \n\nPrints a summary of the tensor.\n\ntext(_fetch_chunks : bool = False_)\uf0c1\n\n    \n\nReturn text data. Only applicable for tensors with \u2018text\u2019 base htype.\n\n_property _timestamps _: ndarray_\uf0c1\n\n    \n\nReturns timestamps (in seconds) for video sample as numpy array.\n\nExample\n\n    \n    \n    >>> # Return timestamps for all frames of first video sample\n    >>> ds.videos[0].timestamps.shape\n    (400,)\n    >>> # Return timestamps for 5th to 10th frame of first video sample\n    >>> ds.videos[0, 5:10].timestamps\n    array([0.2002    , 0.23356667, 0.26693332, 0.33366665, 0.4004    ],\n    dtype=float32)\n    \n\ntobytes() -> bytes\uf0c1\n\n    \n\nReturns the bytes of the tensor.\n\n  * Only works for a single sample of tensor.\n\n  * If the tensor is uncompressed, this returns the bytes of the numpy array.\n\n  * If the tensor is sample compressed, this returns the compressed bytes of the sample.\n\n  * If the tensor is chunk compressed, this raises an error.\n\nReturns\n\n    \n\nThe bytes of the tensor.\n\nReturn type\n\n    \n\nbytes\n\nRaises\n\n    \n\n**ValueError** \u2013 If the tensor has multiple samples.\n\n_property _verify\uf0c1\n\n    \n\nWhether linked data will be verified when samples are added. Applicable only\nto tensors with htype `link[htype]`.\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.",
        "node_375": "`Dataset.commits` | Lists all the commits leading to the current dataset state.  \n`Dataset.branches` | Lists all the branches of the dataset.  \n  \n## Dataset Views\uf0c1\n\nA dataset view is a subset of a dataset that points to specific samples\n(indices) in an existing dataset. Dataset views can be created by indexing a\ndataset, filtering a dataset with `Dataset.filter()`, querying a dataset with\n`Dataset.query()` or by sampling a dataset with `Dataset.sample_by()`.\nFiltering is done with user-defined functions or simplified expressions\nwhereas query can perform SQL-like queries with our Tensor Query Language. See\nthe full TQL spec here.\n\nDataset views can only be saved when a dataset has been committed and has no\nchanges on the HEAD node, in order to preserve data lineage and prevent the\nunderlying data from changing after the query or filter conditions have been\nevaluated.\n\n**Example**\n\n    \n    \n    >>> import deeplake\n    >>> # load dataset\n    >>> ds = deeplake.load(\"hub://activeloop/mnist-train\")\n    >>> # filter dataset\n    >>> zeros = ds.filter(\"labels == 0\")\n    >>> # save view\n    >>> zeros.save_view(id=\"zeros\")\n    >>> # load_view\n    >>> zeros = ds.load_view(id=\"zeros\")\n    >>> len(zeros)\n    5923\n    \n\n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n---|---  \n`Dataset.sample_by` | Returns a sliced `Dataset` with given weighted sampler applied.  \n`Dataset.filter` | Filters the dataset in accordance of filter function `f(x: sample) -> bool`  \n`Dataset.save_view` | Saves a dataset view as a virtual dataset (VDS)  \n`Dataset.get_view` | Returns the dataset view corresponding to `id`.  \n`Dataset.load_view` | Loads the view and returns the `Dataset` by id.  \n`Dataset.delete_view` | Deletes the view with given view id.  \n`Dataset.get_views` | Returns list of views stored in this Dataset.  \n`Dataset.is_view` | Returns `True` if this dataset is a view and `False` otherwise.",
        "node_472": "For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.\n\n## Point Htype\uf0c1\n\n  * Sample dimensions: `(# points, 2)` in case of 2-D (X, Y) co-ordinates or `(# points, 3)` in case of 3-D (X, Y, Z) co-ordinates of the point.\n\nPoints does not contain a fixed mapping across samples between the point order\nand real-world objects (i.e., point 0 is an elbow, point 1 is a knee, etc.).\nIf you require such a mapping, use COCO Keypoints Htype.\n\n### Creating a point tensor\uf0c1\n\nA point tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"points\", htype=\"point\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending point samples\uf0c1\n\n  * Points can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.",
        "node_435": "### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.\n    \n        * \u201ccenter\u201d: [center_x, center_y, center_z, size_x, size_y, size_z, rot_x, rot_y, rot_z]\n    \n          * Sample dimensions: `(# bounding boxes, 9)`\n\n          * `size_x` \\- is the length of the bounding box along x direction\n\n          * `size_y` \\- is the width of the bounding box along y direction\n\n          * `size_z` \\- is the height of the bounding box along z direction\n\n          * `rot_x` \\- rotation angle along x axis, given in degrees\n\n          * `rot_y` \\- rotation angle along y axis, given in degrees\n\n          * `rot_z` \\- rotation angle along z axis, given in degrees\n\n        * \u201cvertex\u201d: 8 3D vertices - [[x0, y0, z0], [x1, y1, z1], [x2, y2, z2], \u2026.., [x7, y7, z7]]\n    \n          * Sample dimensions: `(# bounding boxes, 8, 3)`\n\nThe vertex order is of the following form:\n\n                \n                                      4_____________________ 5\n                     /|                    /|\n                    / |                   / |\n                   /  |                  /  |\n                  /___|_________________/   |\n                0|    |                 | 1 |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |_________________|___|\n                 |   /  7               |   / 6\n                 |  /                   |  /\n                 | /                    | /\n                 |/_____________________|/\n                  3                      2\n                \n\n    * **dtype** : Defaults to `float32`.",
        "node_1252": "LRUCache method)\n    * (deeplake.core.storage.MemoryProvider method)\n  * __init__() (deeplake.core.index.Index method)\n    * (deeplake.core.index.IndexEntry method)\n    * (deeplake.core.sample.Sample method)\n    * (deeplake.core.storage.GCSProvider method)\n    * (deeplake.core.storage.GDriveProvider method)\n    * (deeplake.core.storage.LocalProvider method)\n    * (deeplake.core.storage.LRUCache method)\n    * (deeplake.core.storage.MemoryProvider method)\n    * (deeplake.core.storage.S3Provider method)\n    * (deeplake.core.vectorstore.deep_memory.deep_memory.DeepMemory method)\n    * (deeplake.core.vectorstore.deeplake_vectorstore.VectorStore method)\n    * (deeplake.util.shape_interval.ShapeInterval method)\n  * __iter__() (deeplake.core.storage.GCSProvider method)\n    * (deeplake.core.storage.GDriveProvider method)\n    * (deeplake.core.storage.LocalProvider method)\n    * (deeplake.core.storage.LRUCache method)\n    * (deeplake.core.storage.MemoryProvider method)\n    * (deeplake.core.storage.S3Provider method)\n    * (deeplake.core.storage.StorageProvider method)\n  * __len__() (deeplake.core.storage.GCSProvider method)\n    * (deeplake.core.storage.GDriveProvider method)\n    * (deeplake.core.storage.LocalProvider method)\n    * (deeplake.core.storage.LRUCache method)\n    * (deeplake.core.storage.MemoryProvider method)\n    * (deeplake.core.storage.S3Provider method)\n    * (deeplake.core.storage.StorageProvider method)\n    * (deeplake.core.tensor.Tensor method)\n\n|\n\n  * __repr__() (deeplake.core.index.",
        "node_117": "Defaults to `False`. Datasets stored on Deep Lake cloud that your account does not have write access to will automatically open in read mode.\n\n  * **memory_cache_size** (_int_) \u2013 The size of the memory cache to be used in MB.\n\n  * **local_cache_size** (_int_) \u2013 The size of the local filesystem cache to be used in MB.\n\n  * **creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\n  * **org_id** (_str_ _,__Optional_) \u2013 Organization id to be used for enabling high-performance features. Only applicable for local datasets.\n\n  * **verbose** (_bool_) \u2013 If `True`, logs will be printed. Defaults to `True`.\n\n  * **access_method** (_str_) \u2013 \n\nThe access method to use for the dataset. Can be:\n\n    * \u2019stream\u2019\n\n>       * Streams the data from the dataset i.e. only fetches data when\n> required. This is the default value.\n\n    * \u2019download\u2019\n\n>       * Downloads the data to the local filesystem to the path specified in\n> environment variable `DEEPLAKE_DOWNLOAD_PATH`. This will overwrite\n> `DEEPLAKE_DOWNLOAD_PATH`.",
        "node_815": "The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.\n\n  * \\\\(f_x = F / p_x\\\\)\n\n  * \\\\(f_y = F / p_y\\\\)\n\n  * \\\\(F\\\\) \\- Focal length in world units, typically expressed in millimeters.\n\n  * \\\\((p_x, p_y)\\\\) \\- Size of the pixel in world units.\n\n### Creating an intrinsics tensor\uf0c1\n\nAn intrinsics tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"intrinsics\", htype=\"intrinsics\")\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending intrinsics matrices\uf0c1\n\n    \n    \n    >>> intrinsic_params = np.zeros((3, 3))\n    >>> ds.intrinsics.append(intrinsic_params)\n    \n\n## Segmentation Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width)`\n\nSegmentation masks are 2D representations of class labels where the numerical\nlabel data is encoded in an array of same shape as the image. The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**.",
        "node_1286": "* **Themes:** modify the look and feel of outputs via creating themes, and reuse many third-party themes.\n\n  * **Contributed extensions:** dozens of extensions contributed by users; most of them installable from PyPI.\n\nSphinx uses the reStructuredText markup language by default, and can read MyST\nmarkdown via third-party extensions. Both of these are powerful and\nstraightforward to use, and have functionality for complex documentation and\npublishing workflows. They both build upon Docutils to parse and write\ndocuments.\n\nSee below for how to navigate Sphinx\u2019s documentation.\n\nSee also\n\nThe Sphinx documentation Table of Contents has a full list of this site\u2019s\npages.\n\n## Get started\u00b6\n\nThese sections cover the basics of getting started with Sphinx, including\ncreating and building your own documentation from scratch.\n\nGet started\n\n  * Getting Started\n    * Setting up the documentation sources\n    * Defining document structure\n    * Adding content\n    * Running the build\n    * Documenting objects\n    * Basic configuration\n    * Autodoc\n    * Intersphinx\n    * More topics to be covered\n  * Installing Sphinx\n    * Overview\n    * Linux\n    * macOS\n    * Windows\n    * Installation from PyPI\n    * Docker\n    * Installation from source\n  * Tutorial: Build your first project\n    * Getting started\n    * First steps to document your project using Sphinx\n    * More Sphinx customization\n    * Narrative documentation in Sphinx\n    * Describing code in Sphinx\n    * Automatic documentation generation from code\n    * Appendix: Deploying a Sphinx project online\n    * Where to go from here\n\n## User Guides\u00b6\n\nThese sections cover various topics in using and extending Sphinx for various\nuse-cases. They are a comprehensive guide to using Sphinx in many contexts and\nassume more knowledge of Sphinx. If you are new to Sphinx, we recommend\nstarting with Get started.",
        "node_1282": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Search\n  * \n\n* * *\n\nPlease activate JavaScript to enable the search functionality.\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_1029": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n    * DeepLakeDataLoader\n      * `DeepLakeDataLoader`\n        * `DeepLakeDataLoader.batch()`\n        * `DeepLakeDataLoader.close()`\n        * `DeepLakeDataLoader.numpy()`\n        * `DeepLakeDataLoader.offset()`\n        * `DeepLakeDataLoader.pytorch()`\n        * `DeepLakeDataLoader.query()`\n        * `DeepLakeDataLoader.sample_by()`\n        * `DeepLakeDataLoader.shuffle()`\n        * `DeepLakeDataLoader.tensorflow()`\n        * `DeepLakeDataLoader.transform()`\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Dataloader\n  * Edit on GitHub\n\n* * *\n\n# Dataloader\uf0c1\n\nTrain your models using the new high performance C++ dataloader. See the\n`dataloader` method on how to create dataloaders from your datasets:\n\n`Dataset.dataloader` | Returns a `DeepLakeDataLoader` object.  \n---|---  \n  \n## DeepLakeDataLoader\uf0c1\n\n_class _deeplake.enterprise.DeepLakeDataLoader\uf0c1\n\n    \n\nbatch(_batch_size : int_, _drop_last : bool = False_)\uf0c1\n\n    \n\nReturns a batched `DeepLakeDataLoader` object.\n\nParameters\n\n    \n\n  * **batch_size** (_int_) \u2013 Number of samples in each batch.",
        "node_1199": "These keys are used for tensors that are\nlinked to external data.\n\nExamples\n\n    \n    \n    >>> # create/load a dataset\n    >>> ds = deeplake.dataset(\"hub://username/dataset\")\n    >>> # add a new creds key\n    >>> ds.add_creds_key(\"my_s3_key\")\n    \n\nParameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The key to be added.\n\n  * **managed** (_bool_) \u2013 If `True`, the creds corresponding to the key will be fetched from activeloop platform. Note, this is only applicable for datasets that are connected to activeloop platform. Defaults to `False`.\n\n_property _client\uf0c1\n\n    \n\nReturns the client of the dataset.\n\nconnect(_* args_, _** kwargs_)\uf0c1\n\n    \n\nConnect a Deep Lake cloud dataset through a deeplake path.\n\nExamples\n\n    \n    \n    >>> # create/load an s3 dataset\n    >>> s3_ds = deeplake.dataset(\"s3://bucket/dataset\")\n    >>> ds = s3_ds.connect(dest_path=\"hub://my_org/dataset\", creds_key=\"my_managed_credentials_key\", token=\"my_activeloop_token)\n    >>> # or\n    >>> ds = s3_ds.connect(org_id=\"my_org\", creds_key=\"my_managed_credentials_key\", token=\"my_activeloop_token\")\n    \n\nParameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The managed credentials to be used for accessing the source path.\n\n  * **dest_path** (_str_ _,__optional_) \u2013 The full path to where the connected Deep Lake dataset will reside. Can be: a Deep Lake path like `hub://organization/dataset`\n\n  * **org_id** (_str_ _,__optional_) \u2013 The organization to where the connected Deep Lake dataset will be added.\n\n  * **ds_name** (_str_ _,__optional_) \u2013 The name of the connected Deep Lake dataset. Will be infered from `dest_path` or `src_path` if not provided.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token used to fetch the managed credentials.\n\nRaises\n\n    \n\n  * **InvalidSourcePathError** \u2013 If the dataset\u2019s path is not a valid s3, gcs or azure path.",
        "node_1081": "Returns\n\n    \n\nThe Dataset created from the images and YOLO annotations.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**IngestionError** \u2013 If annotations are not found for all the images and\n\u2018allow_no_annotation\u2019 is False\n\ndeeplake.ingest_kaggle(_tag : str_, _src : Union[str, Path]_, _dest :\nUnion[str, Path]_, _exist_ok : bool = False_, _images_compression : str =\n'auto'_, _dest_creds : Optional[Union[Dict, str]] = None_, _kaggle_credentials\n: Optional[dict] = None_, _progressbar : bool = True_, _summary : bool =\nTrue_, _shuffle : bool = True_, _** dataset_kwargs_) -> Dataset\uf0c1\n\n    \n\nDownload and ingest a kaggle dataset and store it as a structured dataset to\ndestination.\n\nParameters\n\n    \n\n  * **tag** (_str_) \u2013 Kaggle dataset tag. Example: `\"coloradokb/dandelionimages\"` points to https://www.kaggle.com/coloradokb/dandelionimages\n\n  * **src** (_str_ _,__pathlib.Path_) \u2013 Local path to where the raw kaggle dataset will be downlaoded to.\n\n  * **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://username/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.",
        "node_1238": "Parameters\n\n    \n\n  * **dataset** (_Dataset_) \u2013 deeplake dataset object or path.\n\n  * **path** (_Union_ _[__str_ _,__pathlib.Path_ _]_) \u2013 Path to the dataset.\n\n  * **logger** (_logging.Logger_) \u2013 Logger object.\n\n  * **embedding_function** (_Optional_ _[__Any_ _]__,__optional_) \u2013 Embedding funtion class used to convert queries/documents to embeddings. Defaults to None.\n\n  * **token** (_Optional_ _[__str_ _]__,__optional_) \u2013 API token for the DeepMemory managed service. Defaults to None.\n\n  * **creds** (_Optional_ _[__Dict_ _[__str_ _,__Any_ _]__]__,__optional_) \u2013 Credentials to access the dataset. Defaults to None.\n\nRaises\n\n    \n\n**ImportError** \u2013 if indra is not installed\n\ncancel(_job_id : str_)\uf0c1\n\n    \n\nCancel a training job on DeepMemory managed service.\n\nExamples\n\n    \n    \n    >>> cancelled: bool = vectorstore.deep_memory.cancel(job_id)\n    \n\nParameters\n\n    \n\n**job_id** (_str_) \u2013 job_id of the training job.\n\nReturns\n\n    \n\nTrue if job was cancelled successfully, False otherwise.\n\nReturn type\n\n    \n\nbool\n\ndelete(_job_id : str_)\uf0c1\n\n    \n\nDelete a training job on DeepMemory managed service.\n\nExamples\n\n    \n    \n    >>> deleted: bool = vectorstore.deep_memory.delete(job_id)\n    \n\nParameters\n\n    \n\n**job_id** (_str_) \u2013 job_id of the training job.\n\nReturns\n\n    \n\nTrue if job was deleted successfully, False otherwise.\n\nReturn type\n\n    \n\nbool\n\nevaluate(_relevance : List[List[Tuple[str, int]]]_, _queries : List[str]_,\n_embedding_function : Optional[Callable[[...], List[ndarray]]] = None_,\n_embedding : Optional[Union[List[ndarray], List[List[float]]]] = None_, _top_k\n: List[int] = [1, 3, 5, 10, 50, 100]_, _qvs_params : Optional[Dict[str, Any]]\n= None_) -> Dict[str, Dict[str, float]]\uf0c1\n\n    \n\nEvaluate a model using the DeepMemory managed service.",
        "node_762": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_608": "### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.\n\n### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.",
        "node_798": "Examples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.\n\nExamples\n\n    \n    \n    >>> ds.create_tensor(\"seq\", htype=\"sequence\")\n    >>> ds.seq.append([1, 2, 3])\n    >>> ds.seq.append([4, 5, 6])\n    >>> ds.seq.numpy()\n    array([[[1],\n            [2],\n            [3]],\n           [[4],\n            [5],\n            [6]]])\n    \n    \n    \n    >>> ds.create_tensor(\"image_seq\", htype=\"sequence[image]\", sample_compression=\"jpg\")\n    >>> ds.image_seq.append([deeplake.read(\"img01.jpg\"), deeplake.read(\"img02.jpg\")])\n    \n\n## Link htype\uf0c1\n\n  * Link htype is a special meta htype that allows linking of external data (files) to the dataset, without storing the data in the dataset itself.\n\n  * Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.",
        "node_131": "Can be: an s3 path like `s3://bucket/path/to/dataset`. a gcs path like `gcs://bucket/path/to/dataset`. an azure path like `az://account_name/container/path/to/dataset`.\n\n  * **creds_key** (_str_) \u2013 The managed credentials to be used for accessing the source path.\n\n  * **dest_path** (_str_ _,__optional_) \u2013 The full path to where the connected Deep Lake dataset will reside. Can be: a Deep Lake path like `hub://organization/dataset`\n\n  * **org_id** (_str_ _,__optional_) \u2013 The organization to where the connected Deep Lake dataset will be added.\n\n  * **ds_name** (_str_ _,__optional_) \u2013 The name of the connected Deep Lake dataset. Will be infered from `dest_path` or `src_path` if not provided.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token used to fetch the managed credentials.\n\nReturns\n\n    \n\nThe connected Deep Lake dataset.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **InvalidSourcePathError** \u2013 If the `src_path` is not a valid s3, gcs or azure path.\n\n  * **InvalidDestinationPathError** \u2013 If `dest_path`, or `org_id` and `ds_name` do not form a valid Deep Lake path.\n\n  * **TokenPermissionError** \u2013 If the user does not have permission to create a dataset in the specified organization.\n\ndeeplake.exists(_path : Union[str, Path]_, _creds : Optional[Union[Dict, str]]\n= None_, _token : Optional[str] = None_) -> bool\uf0c1\n\n    \n\nChecks if a dataset exists at the given `path`.\n\nParameters\n\n    \n\n  * **path** (_str_ _,__pathlib.Path_) \u2013 the path which needs to be checked.\n\n  * **creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths.",
        "node_1001": "Examples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.\n\nExamples\n\n    \n    \n    >>> ds.create_tensor(\"seq\", htype=\"sequence\")\n    >>> ds.seq.append([1, 2, 3])\n    >>> ds.seq.append([4, 5, 6])\n    >>> ds.seq.numpy()\n    array([[[1],\n            [2],\n            [3]],\n           [[4],\n            [5],\n            [6]]])\n    \n    \n    \n    >>> ds.create_tensor(\"image_seq\", htype=\"sequence[image]\", sample_compression=\"jpg\")\n    >>> ds.image_seq.append([deeplake.read(\"img01.jpg\"), deeplake.read(\"img02.jpg\")])\n    \n\n## Link htype\uf0c1\n\n  * Link htype is a special meta htype that allows linking of external data (files) to the dataset, without storing the data in the dataset itself.\n\n  * Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.",
        "node_639": "* sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nrotation angles are specified in degrees, not radians\n\n### Appending 3d bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98, 22, 36, 44, 18, 0, 36, 0]])\n    >>> ds.3d_boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77, 22, 36, 44, 18, 0, 28, 0],\n           [462, 123, 238,  98, 26, 34, 24, 19, 0, -50, 0],\n           [688, 108, 279, 116, 12, 32, 14, 38, 0, 30, 0]])\n    >>> boxes.shape\n    (9, 4)\n    >>> ds.3d_boxes.append(boxes)\n    \n\n## Intrinsics Htype\uf0c1\n\n  * Sample dimensions: `(# intrinsics matrices, 3, 3)`\n\nThe intrinsic matrix represents a projective transformation from the 3-D\ncamera\u2019s coordinates into the 2-D image coordinates. The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.",
        "node_95": "Images\nshould be stored in subfolders by class name.\n\nParameters\n\n    \n\n  * **src** (_str_ _,__pathlib.Path_) \u2013 Local path to where the unstructured dataset of images is stored or path to csv file.\n\n  * **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://org_id/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.\n\n  * **image_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the images tensor.\n\n  * **label_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the labels tensor.\n\n  * **dest_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 The string `ENV` or a dictionary containing credentials used to access the destination path of the dataset.\n\n  * **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Defaults to `True`.\n\n  * **summary** (_bool_) \u2013 If `True`, a summary of skipped files will be printed after completion. Defaults to `True`.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for ingestion. Set to `0` by default.\n\n  * **shuffle** (_bool_) \u2013 Shuffles the input data prior to ingestion. Since data arranged in folders by class is highly non-random, shuffling is important in order to produce optimal results when training. Defaults to `True`.",
        "node_1003": "For datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.\n\n    \n    \n    >>> ds.add_creds_key(\"my_s3_creds\", managed=True)\n    >>> ds.add_creds_key(\"my_gcs_creds\", managed=True)\n    \n\nCreate a link tensor\n\n    \n    \n    >>> ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")\n    \n\nPopulate the tensor with links\n\n    \n    \n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\", creds_key=\"my_s3_key\"))\n    >>> ds.img.append(deeplake.link(\"gcs://ghi/jkl.png\", creds_key=\"GCS_KEY\"))\n    >>> ds.img.append(deeplake.link(\"https://picsum.photos/200/300\")) # http path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"./path/to/cat.jpeg\")) # local path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))  # this will throw an exception as cloud paths always need creds_key\n    :bluebold:`Accessing the data`\n    \n    \n    \n    >>> for i in range(5):\n    ...     ds.img[i].numpy()\n    ...\n    \n\nUpdating a sample\n\n    \n    \n    >>> ds.img[0] = deeplake.link(\"./data/cat.jpeg\")\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_543": "Images can be stored in Deep Lake as compressed bytes or as raw arrays. Due to\nthe high compression ratio for most image formats, it is highly recommended to\nstore compressed images using the `sample_compression` input to the\ncreate_tensor method.\n\n### Creating an image tensor\uf0c1\n\nAn image tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\")\n    \n\nOR\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", chunk_compression=\"jpg\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"bmp\", \"dib\", \"gif\", \"ico\", \"jpeg\", \"jpeg2000\", \"pcx\", \"png\", \"ppm\", \"sgi\", \"tga\", \"tiff\",\n    ... \"webp\", \"wmf\", \"xbm\", \"eps\", \"fli\", \"im\", \"msp\", \"mpo\"]\n    \n\n### Appending image samples\uf0c1\n\n  * Image samples can be of type `np.ndarray` or Deep Lake `Sample` which can be created using `deeplake.read()`.\n\nExamples\n\nAppending pixel data with array\n\n    \n    \n    >>> ds.images.append(np.zeros((5, 5, 3), dtype=np.uint8))\n    \n\nAppening Deep Lake image sample\n\n    \n    \n    >>> ds.images.append(deeplake.read(\"images/0001.jpg\"))\n    \n\nYou can append multiple samples at the same time using `extend()`.\n\n    \n    \n    >>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type.",
        "node_941": "* Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.\n\nExamples\n\nAppending point clouds with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> point_cloud1 = np.random.randint(0, 10, (5, 3))\n    >>> ds.point_clouds.append(point_cloud1)\n    >>> point_cloud2 = np.random.randint(0, 10, (15, 3))\n    >>> ds.point_clouds.append(point_cloud2)\n    >>> ds.point_clouds.shape\n    >>> (2, None, 3)\n    \n\nOr we can use `deeplake.read()` method to add samples\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.las\") # point cloud with 100 points\n    >>> ds.point_cloud.append(sample)\n    >>> ds.point_cloud.shape\n    >>> (1, 100, 3)\n    \n\n## Mesh Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Mesh samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.",
        "node_19": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_778": "* Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\n  * Recompression of samples read with `deeplake.read` is also not supported.\n\nExamples\n\nAppending Deep Lake video sample\n\n    \n    \n    >>> ds.videos.append(deeplake.read(\"videos/0012.mp4\"))\n    \n\nExtending with multiple videos\n\n    \n    \n    >>> ds.videos.extend([deeplake.read(f\"videos/00{i}.mp4\") for i in range(10)])\n    \n\n## Audio Htype\uf0c1\n\n  * Sample dimensions: `(# samples in audio, # channels)` or `(# samples in audio,)`\n\n### Creating an audio tensor\uf0c1\n\nAn audio tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"audios\", htype=\"audio\", sample_compression=\"mp3\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `float64`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.",
        "node_1273": "Sample property)\n  * Pipeline (class in deeplake.core.transform)\n  * play() (deeplake.core.tensor.Tensor method)\n\n|\n\n  * pop() (deeplake.api.info.Info method)\n    * (deeplake.core.dataset.Dataset method)\n    * (deeplake.core.tensor.Tensor method)\n  * popitem() (deeplake.api.info.Info method)\n  * populate_creds() (deeplake.core.dataset.Dataset method)\n  * ProviderListEmptyError (class in deeplake.util.exceptions)\n  * ProviderSizeListMismatch (class in deeplake.util.exceptions)\n  * pytorch() (deeplake.core.dataset.Dataset method)\n    * (deeplake.enterprise.DeepLakeDataLoader method)\n\n  \n---|---  \n  \n## Q\n\n  * query() (deeplake.core.dataset.Dataset method)\n    * (deeplake.enterprise.DeepLakeDataLoader method)\n\n  \n---  \n  \n## R\n\n  * random_split() (deeplake.core.dataset.Dataset method)\n  * read() (in module deeplake)\n    * (in module deeplake.api.read)\n  * read_only (deeplake.core.dataset.Dataset property)\n  * ReadOnlyModeError (class in deeplake.util.exceptions)\n  * rechunk() (deeplake.core.dataset.Dataset method)\n  * register_deeplake_object() (deeplake.core.storage.LRUCache method)\n  * remove_deeplake_object() (deeplake.core.storage.LRUCache method)\n  * remove_memory_cache() (in module deeplake.util.remove_cache)\n  * rename() (deeplake.api.dataset.dataset static method)\n    * (deeplake.core.dataset.Dataset method)\n    * (deeplake.core.dataset.DeepLakeCloudDataset method)\n    * (deeplake.core.storage.GCSProvider method)\n    * (deeplake.core.storage.LocalProvider method)\n    * (deeplake.core.storage.",
        "node_1313": "Revision `88b8ba89`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: v3.0.15\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_643": "* Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`. A set of `K` keypoints of an object is represented as:\n\n[x1, y1, v1, x2, y2, v2, \u2026, xk, yk, vk]\n\nThe visibility `v` can be one of three values:\n\n0\n\n    \n\nkeypoint not in image.\n\n1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.",
        "node_88": "Be\nvery careful when setting this parameter.\n\nWarning\n\nSetting `access_method` to download will overwrite the local copy of the\ndataset if it was previously downloaded.\n\nNote\n\nAny changes made to the dataset in download / local mode will only be made to\nthe local copy and will not be reflected in the original dataset.\n\ndeeplake.empty(_path : Union[str, Path]_, _runtime : Optional[dict] = None_,\n_overwrite : bool = False_, _public : bool = False_, _memory_cache_size : int\n= 2000_, _local_cache_size : int = 0_, _creds : Optional[Union[Dict, str]] =\nNone_, _token : Optional[str] = None_, _org_id : Optional[str] = None_,\n_lock_enabled : Optional[bool] = True_, _lock_timeout : Optional[int] = 0_,\n_verbose : bool = True_, _index_params : Optional[Dict[str, Union[int, str]]]\n= None_) -> Dataset\uf0c1\n\n    \n\nCreates an empty dataset\n\nParameters\n\n    \n\n  * **path** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset. It can be:\n\n    * a Deep Lake cloud path of the form `hub://org_id/dataset_name`. Requires registration with Deep Lake.\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.\n\n  * **runtime** (_dict_) \u2013 Parameters for creating a dataset in the Deep Lake Tensor Database. Only applicable for paths of the form `hub://org_id/dataset_name` and runtime must be `{\"tensor_db\": True}`.\n\n  * **overwrite** (_bool_) \u2013 If set to `True` this overwrites the dataset if it already exists. Defaults to `False`.",
        "node_670": "The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.\n\n  * \\\\(f_x = F / p_x\\\\)\n\n  * \\\\(f_y = F / p_y\\\\)\n\n  * \\\\(F\\\\) \\- Focal length in world units, typically expressed in millimeters.\n\n  * \\\\((p_x, p_y)\\\\) \\- Size of the pixel in world units.\n\n### Creating an intrinsics tensor\uf0c1\n\nAn intrinsics tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"intrinsics\", htype=\"intrinsics\")\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending intrinsics matrices\uf0c1\n\n    \n    \n    >>> intrinsic_params = np.zeros((3, 3))\n    >>> ds.intrinsics.append(intrinsic_params)\n    \n\n## Segmentation Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width)`\n\nSegmentation masks are 2D representations of class labels where the numerical\nlabel data is encoded in an array of same shape as the image. The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**.",
        "node_673": "* Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`. A set of `K` keypoints of an object is represented as:\n\n[x1, y1, v1, x2, y2, v2, \u2026, xk, yk, vk]\n\nThe visibility `v` can be one of three values:\n\n0\n\n    \n\nkeypoint not in image.\n\n1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.",
        "node_511": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.gray htypes\n    * Video Htype\n      * Limitations\n      * Creating a video tensor\n      * Appending video samples\n    * Audio Htype\n      * Creating an audio tensor\n      * Appending audio samples\n    * Class Label Htype\n      * Creating a class label tensor\n      * Appending class labels\n    * Tag Htype\n      * Creating a tag tensor\n      * Appending tag samples\n    * Bounding Box Htype\n      * Creating a bbox tensor\n      * Appending bounding boxes\n    * 3D Bounding Box Htype\n      * Creating a 3d bbox tensor\n      * Appending 3d bounding boxes\n    * Intrinsics Htype\n      * Creating an intrinsics tensor\n      * Appending intrinsics matrices\n    * Segmentation Mask Htype\n      * Creating a segment_mask tensor\n      * Appending segmentation masks\n    * Binary Mask Htype\n      * Creating a binary_mask tensor\n      * Appending binary masks\n    * COCO Keypoints Htype\n      * Creating a keypoints_coco tensor\n      * Appending keypoints\n    * Point Htype\n      * Creating a point tensor\n      * Appending point samples\n    * Polygon Htype\n      * Creating a polygon tensor\n      * Appending polygons\n    * Nifti Htype\n      * Limitations\n      * Creating a nifti tensor\n      * Appending nifti data\n    * Point Cloud Htype\n      * Creating a point cloud tensor\n      * Appending point clouds\n    * Mesh Htype\n      * Creating a mesh tensor\n      * Appending meshes\n    * Embedding Htype\n      * Creating an embedding tensor\n      * Appending embedding samples\n    * Sequence htype\n    * Link htype\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.",
        "node_666": "* **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.boxes.info.update(coords = {\"type\": \"pixel\", \"mode\": \"LTRB\"})\n    \n\nNote\n\nIf the bounding box format is not specified, the visualizer will assume a YOLO\nformat (`fractional` \\+ `CCWH`) if the box coordinates are < 1 on average.\nOtherwise, it will assume the COCO format (`pixel` \\+ `LTWH`).\n\n### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.",
        "node_1240": "\", \"What is the capital of France?\"]\n    >>> embedding_function = openai_embedding.embed_documents\n    >>> vectorstore.deep_memory.evaluate(\n    ...     relevance=relevance,\n    ...     queries=queries,\n    ...     embedding_function=embedding_function,\n    ... )\n    \n    \n    \n    >>> # 2. Evaluate a model with precomputed embeddings:\n    >>> embeddings = [[-1.2, 12, ...], ...]\n    >>> vectorstore.deep_memory.evaluate(\n    ...     relevance=relevance,\n    ...     queries=queries,\n    ...     embedding=embeddings,\n    >>> )\n    \n    \n    \n    >>> # 3. Evaluate a model with precomputed embeddings and log queries:\n    >>> vectorstore.deep_memory.evaluate(\n    ...     relevance=relevance,\n    ...     queries=queries,\n    ...     embedding=embeddings,\n    ...     qvs_params={\"log_queries\": True},\n    ... )\n    \n    \n    \n    >>> # 4. Evaluate with precomputed embeddings, log queries, and a custom branch:\n    >>> vectorstore.deep_memory.evaluate(\n    ...     relevance=relevance,\n    ...     queries=queries,\n    ...     embedding=embeddings,\n    ...     qvs_params={\n    ...         \"log_queries\": True,\n    ...         \"branch\": \"queries\",\n    ...     }\n    ... )\n    \n\nParameters\n\n    \n\n  * **queries** (_List_ _[__str_ _]_) \u2013 Queries for model evaluation.\n\n  * **relevance** (_List_ _[__List_ _[__Tuple_ _[__str_ _,__int_ _]__]__]_) \u2013 Relevant documents and scores for each query. \\- Outer list: matches the queries. \\- Inner list: pairs of doc_id and relevance score. \\- doc_id: Document ID from the corpus dataset, found in the id tensor. \\- relevance_score: Between 0 (not relevant) and 1 (relevant).\n\n  * **embedding** (_Optional_ _[__np.ndarray_ _]__,__optional_) \u2013 Query embeddings. Defaults to None.\n\n  * **embedding_function** (_Optional_ _[__Callable_ _[__...__,__List_ _[__np.ndarray_ _]__]__]__,__optional_) \u2013 Function to convert queries into embeddings.",
        "node_1253": "core.storage.LRUCache method)\n    * (deeplake.core.storage.MemoryProvider method)\n    * (deeplake.core.storage.S3Provider method)\n    * (deeplake.core.storage.StorageProvider method)\n  * __len__() (deeplake.core.storage.GCSProvider method)\n    * (deeplake.core.storage.GDriveProvider method)\n    * (deeplake.core.storage.LocalProvider method)\n    * (deeplake.core.storage.LRUCache method)\n    * (deeplake.core.storage.MemoryProvider method)\n    * (deeplake.core.storage.S3Provider method)\n    * (deeplake.core.storage.StorageProvider method)\n    * (deeplake.core.tensor.Tensor method)\n\n|\n\n  * __repr__() (deeplake.core.index.Index method)\n  * __setitem__() (deeplake.core.storage.GCSProvider method)\n    * (deeplake.core.storage.GDriveProvider method)\n    * (deeplake.core.storage.LocalProvider method)\n    * (deeplake.core.storage.LRUCache method)\n    * (deeplake.core.storage.MemoryProvider method)\n    * (deeplake.core.storage.S3Provider method)\n    * (deeplake.core.storage.StorageProvider method)\n    * (deeplake.core.tensor.Tensor method)\n  * __setstate__() (deeplake.core.storage.LRUCache method)\n  * __str__() (deeplake.core.index.Index method)\n    * (deeplake.core.index.IndexEntry method)\n  * __weakref__ (deeplake.core.index.Index attribute)\n    * (deeplake.core.index.IndexEntry attribute)\n    * (deeplake.core.storage.StorageProvider attribute)\n  * _all_keys() (deeplake.core.storage.GCSProvider method)\n    * (deeplake.core.storage.GDriveProvider method)\n    * (deeplake.core.storage.",
        "node_406": "---|---  \n`Dataset.create_group` | Creates a tensor group.  \n`Dataset.create_tensor_like` | Copies the `source` tensor's meta information and creates a new tensor with it.  \n  \n## Deleting and Renaming Tensors\uf0c1\n\n`Dataset.delete_tensor` | Delete a tensor from the dataset.  \n---|---  \n`Dataset.delete_group` | Delete a tensor group from the dataset.  \n`Dataset.rename_tensor` | Renames tensor with name `name` to `new_name`  \n`Dataset.rename_group` | Renames group with name `name` to `new_name`  \n  \n## Adding and deleting samples\uf0c1\n\n`Tensor.append` | Appends a single sample to the end of the tensor.  \n---|---  \n`Tensor.extend` | Extends the end of the tensor by appending multiple elements from a sequence.  \n`Tensor.pop` | Removes element(s) at the given index / indices.  \n`Tensor.clear` | Deletes all samples from the tensor  \n`Tensor.__setitem__` | Update samples with new values.  \n  \n## Retrieving samples\uf0c1\n\n`Tensor.numpy` | Computes the contents of the tensor in numpy format.  \n---|---  \n`Tensor.data` | Returns data in the tensor in a format based on the tensor's base htype.  \n`Tensor.tobytes` | Returns the bytes of the tensor.  \n`Tensor.text` | Return text data.  \n`Tensor.dict` | Return json data.  \n`Tensor.list` | Return list data.  \n`Tensor._linked_sample` | Returns the linked sample at the given index.  \n  \n## Tensor Properties\uf0c1\n\n`Tensor.htype` | Htype of the tensor.  \n---|---  \n`Tensor.base_htype` | Base htype of the tensor.  \n`Tensor.dtype` | Dtype of the tensor.  \n`Tensor.shape` | Get the shape of this tensor.  \n`Tensor.shape_interval` | Returns a `ShapeInterval` object that describes this tensor's shape more accurately.  \n`Tensor.ndim` | Number of dimensions of the tensor.  \n`Tensor.num_samples` | Returns the length of the primary axis of the tensor.  \n`Tensor.__len__` | Returns the length of the primary axis of the tensor.",
        "node_523": "* sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nrotation angles are specified in degrees, not radians\n\n### Appending 3d bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98, 22, 36, 44, 18, 0, 36, 0]])\n    >>> ds.3d_boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77, 22, 36, 44, 18, 0, 28, 0],\n           [462, 123, 238,  98, 26, 34, 24, 19, 0, -50, 0],\n           [688, 108, 279, 116, 12, 32, 14, 38, 0, 30, 0]])\n    >>> boxes.shape\n    (9, 4)\n    >>> ds.3d_boxes.append(boxes)\n    \n\n## Intrinsics Htype\uf0c1\n\n  * Sample dimensions: `(# intrinsics matrices, 3, 3)`\n\nThe intrinsic matrix represents a projective transformation from the 3-D\ncamera\u2019s coordinates into the 2-D image coordinates. The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.",
        "node_486": ">>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type. i.e., if RGB images are appended to an `image.gray`\ntensor, Deep Lake will convert them to grayscale and if grayscale images are\nappended to an `image.rgb` tensor, Deep Lake will convert them to RGB format.\n\nimage.rgb and image.gray tensors can be created using\n\n    \n    \n    >>> ds.create_tensor(\"rgb_images\", htype=\"image.rgb\", sample_compression=\"...\")\n    \n    \n    \n    >>> ds.create_tensor(\"gray_images\", htype=\"image.gray\", sample_compression=\"...\")\n    \n\n## Video Htype\uf0c1\n\n  * Sample dimensions: `(# frames, height, width, # channels)` or `(# frames, height, width)`\n\n### Limitations\uf0c1\n\n  * Visualization of videos in the Deep Lake App is limited by the video coded support for various browsers.\n    \n    * Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.",
        "node_811": "* **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.boxes.info.update(coords = {\"type\": \"pixel\", \"mode\": \"LTRB\"})\n    \n\nNote\n\nIf the bounding box format is not specified, the visualizer will assume a YOLO\nformat (`fractional` \\+ `CCWH`) if the box coordinates are < 1 on average.\nOtherwise, it will assume the COCO format (`pixel` \\+ `LTWH`).\n\n### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.",
        "node_1197": "If `True`, the creds corresponding to the key will be fetched from activeloop platform.\n\nRaises\n\n    \n\n  * **ValueError** \u2013 If the dataset is not connected to activeloop platform.\n\n  * **ValueError** \u2013 If both `new_creds_key` and `managed` are `None`.\n\n  * **KeyError** \u2013 If the creds key is not present in the dataset.\n\nExamples\n\n    \n    \n    >>> # create/load a dataset\n    >>> ds = deeplake.dataset(\"path/to/dataset\")\n    >>> # add a new creds key\n    >>> ds.add_creds_key(\"my_s3_key\")\n    >>> # Populate the name added with creds dictionary\n    >>> # These creds are only present temporarily and will have to be repopulated on every reload\n    >>> ds.populate_creds(\"my_s3_key\", {})\n    >>> # Rename the key and change the management status of the key to True. Before doing this, ensure that the creds have been created on activeloop platform\n    >>> # Now, this key will no longer use the credentials populated in the previous step but will instead fetch them from activeloop platform\n    >>> # These creds don't have to be populated again on every reload and will be fetched every time the dataset is loaded\n    >>> ds.update_creds_key(\"my_s3_key\", \"my_managed_key\", True)\n    \n\nvisualize(_width : Optional[Union[int, str]] = None_, _height :\nOptional[Union[int, str]] = None_)\uf0c1\n\n    \n\nVisualizes the dataset in the Jupyter notebook.\n\nParameters\n\n    \n\n  * **width** \u2013 Union[int, str, None] Optional width of the visualizer canvas.\n\n  * **height** \u2013 Union[int, str, None] Optional height of the visualizer canvas.\n\nRaises\n\n    \n\n**Exception** \u2013 If the dataset is not a Deep Lake cloud dataset and the\nvisualization is attempted in colab.\n\n## DeepLakeCloudDataset\uf0c1\n\n_class _deeplake.core.dataset.DeepLakeCloudDataset\uf0c1\n\n    \n\nBases: `Dataset`\n\nSubclass of `Dataset`. Deep Lake cloud datasets are those datasets which are\nstored in or connected to Activeloop servers, their paths look like:\n`hub://username/dataset_name`.",
        "node_402": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n    * Creating Tensors\n    * Deleting and Renaming Tensors\n    * Adding and deleting samples\n    * Retrieving samples\n    * Tensor Properties\n    * Info\n    * Video features\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Tensors\n  * Edit on GitHub\n\n* * *\n\n# Tensors\uf0c1\n\n## Creating Tensors\uf0c1\n\n`Dataset.create_tensor` | Creates a new tensor in the dataset.  \n---|---  \n`Dataset.create_group` | Creates a tensor group.  \n`Dataset.create_tensor_like` | Copies the `source` tensor's meta information and creates a new tensor with it.  \n  \n## Deleting and Renaming Tensors\uf0c1\n\n`Dataset.delete_tensor` | Delete a tensor from the dataset.  \n---|---  \n`Dataset.delete_group` | Delete a tensor group from the dataset.  \n`Dataset.rename_tensor` | Renames tensor with name `name` to `new_name`  \n`Dataset.rename_group` | Renames group with name `name` to `new_name`  \n  \n## Adding and deleting samples\uf0c1\n\n`Tensor.append` | Appends a single sample to the end of the tensor.  \n---|---  \n`Tensor.extend` | Extends the end of the tensor by appending multiple elements from a sequence.",
        "node_541": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_16": "`Tensor.tobytes` | Returns the bytes of the tensor.  \n`Tensor.text` | Return text data.  \n`Tensor.dict` | Return json data.  \n`Tensor.list` | Return list data.  \n`Tensor._linked_sample` | Returns the linked sample at the given index.  \n  \n## Tensor Properties\uf0c1\n\n`Tensor.htype` | Htype of the tensor.  \n---|---  \n`Tensor.base_htype` | Base htype of the tensor.  \n`Tensor.dtype` | Dtype of the tensor.  \n`Tensor.shape` | Get the shape of this tensor.  \n`Tensor.shape_interval` | Returns a `ShapeInterval` object that describes this tensor's shape more accurately.  \n`Tensor.ndim` | Number of dimensions of the tensor.  \n`Tensor.num_samples` | Returns the length of the primary axis of the tensor.  \n`Tensor.__len__` | Returns the length of the primary axis of the tensor.  \n`Tensor.is_dynamic` | Will return `True` if samples in this tensor have shapes that are unequal.  \n`Tensor.is_sequence` | Whether this tensor is a sequence tensor.  \n`Tensor.is_link` | Whether this tensor is a link tensor.  \n`Tensor.verify` | Whether linked data will be verified when samples are added.  \n  \n## Info\uf0c1\n\n`Tensor.info` | Returns the information about the tensor.  \n---|---  \n`Tensor.sample_info` | Returns info about particular samples in a tensor.  \n  \n## Video features\uf0c1\n\n`Tensor.play` | Play video sample.  \n---|---  \n`Tensor.timestamps` | Returns timestamps (in seconds) for video sample as numpy array.  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_361": "`Dataset.commits` | Lists all the commits leading to the current dataset state.  \n`Dataset.branches` | Lists all the branches of the dataset.  \n  \n## Dataset Views\uf0c1\n\nA dataset view is a subset of a dataset that points to specific samples\n(indices) in an existing dataset. Dataset views can be created by indexing a\ndataset, filtering a dataset with `Dataset.filter()`, querying a dataset with\n`Dataset.query()` or by sampling a dataset with `Dataset.sample_by()`.\nFiltering is done with user-defined functions or simplified expressions\nwhereas query can perform SQL-like queries with our Tensor Query Language. See\nthe full TQL spec here.\n\nDataset views can only be saved when a dataset has been committed and has no\nchanges on the HEAD node, in order to preserve data lineage and prevent the\nunderlying data from changing after the query or filter conditions have been\nevaluated.\n\n**Example**\n\n    \n    \n    >>> import deeplake\n    >>> # load dataset\n    >>> ds = deeplake.load(\"hub://activeloop/mnist-train\")\n    >>> # filter dataset\n    >>> zeros = ds.filter(\"labels == 0\")\n    >>> # save view\n    >>> zeros.save_view(id=\"zeros\")\n    >>> # load_view\n    >>> zeros = ds.load_view(id=\"zeros\")\n    >>> len(zeros)\n    5923\n    \n\n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n---|---  \n`Dataset.sample_by` | Returns a sliced `Dataset` with given weighted sampler applied.  \n`Dataset.filter` | Filters the dataset in accordance of filter function `f(x: sample) -> bool`  \n`Dataset.save_view` | Saves a dataset view as a virtual dataset (VDS)  \n`Dataset.get_view` | Returns the dataset view corresponding to `id`.  \n`Dataset.load_view` | Loads the view and returns the `Dataset` by id.  \n`Dataset.delete_view` | Deletes the view with given view id.  \n`Dataset.get_views` | Returns list of views stored in this Dataset.  \n`Dataset.is_view` | Returns `True` if this dataset is a view and `False` otherwise.",
        "node_592": "* Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.\n\nExamples\n\nAppending point clouds with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> point_cloud1 = np.random.randint(0, 10, (5, 3))\n    >>> ds.point_clouds.append(point_cloud1)\n    >>> point_cloud2 = np.random.randint(0, 10, (15, 3))\n    >>> ds.point_clouds.append(point_cloud2)\n    >>> ds.point_clouds.shape\n    >>> (2, None, 3)\n    \n\nOr we can use `deeplake.read()` method to add samples\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.las\") # point cloud with 100 points\n    >>> ds.point_cloud.append(sample)\n    >>> ds.point_cloud.shape\n    >>> (1, 100, 3)\n    \n\n## Mesh Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Mesh samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.",
        "node_1126": "This is Optional, tokens are normally autogenerated. Defaults to None.\n\n  * **overwrite** (_bool_) \u2013 If set to True this overwrites the Vector Store if it already exists. Defaults to False.\n\n  * **verbose** (_bool_) \u2013 Whether to print summary of the dataset created. Defaults to True.\n\n  * **creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **runtime** (_Dict_ _,__optional_) \u2013 Parameters for creating the Vector Store in Deep Lake\u2019s Managed Tensor Database. Not applicable when loading an existing Vector Store. To create a Vector Store in the Managed Tensor Database, set runtime = {\u201ctensor_db\u201d: True}.\n\n  * **branch** (_str_) \u2013 Branch name to use for the Vector Store. Defaults to \u201cmain\u201d.\n\n  * ****kwargs** (_dict_) \u2013 Additional keyword arguments.\n\nDanger\n\nSetting `overwrite` to `True` will delete all of your data if the Vector Store\nexists! Be very careful when setting this parameter.",
        "node_31": "The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.\n\n  * \\\\(f_x = F / p_x\\\\)\n\n  * \\\\(f_y = F / p_y\\\\)\n\n  * \\\\(F\\\\) \\- Focal length in world units, typically expressed in millimeters.\n\n  * \\\\((p_x, p_y)\\\\) \\- Size of the pixel in world units.\n\n### Creating an intrinsics tensor\uf0c1\n\nAn intrinsics tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"intrinsics\", htype=\"intrinsics\")\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending intrinsics matrices\uf0c1\n\n    \n    \n    >>> intrinsic_params = np.zeros((3, 3))\n    >>> ds.intrinsics.append(intrinsic_params)\n    \n\n## Segmentation Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width)`\n\nSegmentation masks are 2D representations of class labels where the numerical\nlabel data is encoded in an array of same shape as the image. The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**.",
        "node_647": "Examples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.",
        "node_1045": "For class labels it will get corresponding numeric value from the\n**class_names** list and do numeric comparison.\n\nFor json and text it will do string comparison. The left side of the\nexpression can be indexed (subscripted) if the tensor is multidimensional\narray or json. Jsons support indexing by string, e.g. `index_meta['id'] ==\n'some_id'`. Jsons can also be indexed by number if the underlying data is\narray.\n\nNumeric multidimensional tensors can be indexed by numbers, e.g.\n`categories[0] == 1` as well as Python style slicing and multidimensional\nindexing, such as `boxes[:2]`. This last expression returns array containing\nthe third elements of the initial two dimensional array boxes.\n\nTQL supports logical operators - `AND`, `OR` and `NOT`. These operators can be\nused to combine boolean expressions. For example,\n\n    \n    \n    labels == 0 OR labels == 1\n    \n\nFrom SQL we also support the following two keywords:\n\n  * `BETWEEN`\n\n    \n    \n    labels BETWEEN 0 and 5\n    \n\n  * `IN`\n\n    \n    \n    labels in ARRAY[0, 2, 4, 6, 8]\n    \n\n### Functions\uf0c1\n\nThere are predefined functions which can be used in `WHERE` expression as well\nas in `ORDER BY` expressions:\n\n  * `CONTAINS` \\- checks if the given tensor contains given value - `CONTAINS(categories, 'person')`\n\n  * `RANDOM` \\- returns random number. May be used in `ORDER BY` to shuffle the output - `ORDER BY RANDOM()`\n\n  * `SHAPE` \\- returns the shape array of the given tensor - `SHAPE(boxes)`\n\n  * `ALL` \\- takes an array of booleans and returns single boolean, `True` if all elements of the input array are `True`\n\n  * `ALL_STRICT` \\- same as `ALL` with one difference.",
        "node_1275": "core.dataset.Dataset method)\n  * ResourceNotFoundException (class in deeplake.util.exceptions)\n  * root (deeplake.core.dataset.Dataset property)\n\n  \n---|---  \n  \n## S\n\n  * S3DeletionError (class in deeplake.util.exceptions)\n  * S3Error (class in deeplake.util.exceptions)\n  * S3GetError (class in deeplake.util.exceptions)\n  * S3ListError (class in deeplake.util.exceptions)\n  * S3Provider (class in deeplake.core.storage)\n  * S3SetError (class in deeplake.util.exceptions)\n  * SamePathException (class in deeplake.util.exceptions)\n  * Sample (class in deeplake.core.sample)\n  * sample_by() (deeplake.core.dataset.Dataset method)\n    * (deeplake.enterprise.DeepLakeDataLoader method)\n  * sample_indices (deeplake.core.dataset.Dataset property)\n    * (deeplake.core.tensor.Tensor property)\n  * sample_info (deeplake.core.tensor.Tensor property)\n  * SampleCompressionError (class in deeplake.util.exceptions)\n  * SampleDecompressionError (class in deeplake.util.exceptions)\n  * SampleHtypeMismatchError (class in deeplake.util.exceptions)\n  * save_view() (deeplake.core.dataset.Dataset method)\n  * search() (deeplake.core.vectorstore.deeplake_vectorstore.VectorStore method)\n  * seed() (deeplake.core.seed.DeeplakeRandom method)\n  * ServerException (class in deeplake.util.exceptions)\n\n|\n\n  * set_bytes() (deeplake.core.storage.StorageProvider method)\n  * set_model() (deeplake.core.vectorstore.deep_memory.deep_memory.DeepMemory method)\n  * set_token() (deeplake.core.dataset.Dataset method)\n  * setdefault() (deeplake.api.info.Info method)\n  * shape (deeplake.core.tensor.",
        "node_130": "* **verbose** (_bool_) \u2013 If True, logs will be printed. Defaults to `True`.\n\n  * ****kwargs** \u2013 Additional keyword arguments\n\nReturns\n\n    \n\nNew dataset object.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **DatasetHandlerError** \u2013 If a dataset already exists at destination path and overwrite is False.\n\n  * **TypeError** \u2013 If source is not a dataset.\n\n  * **UnsupportedParameterException** \u2013 If parameter that is no longer supported is beeing called.\n\n  * **DatasetCorruptError** \u2013 If loading source dataset fails with DatasetCorruptedError\n\ndeeplake.connect(_src_path : str_, _creds_key : str_, _dest_path :\nOptional[str] = None_, _org_id : Optional[str] = None_, _ds_name :\nOptional[str] = None_, _token : Optional[str] = None_) -> Dataset\uf0c1\n\n    \n\nConnects dataset at `src_path` to Deep Lake via the provided path.\n\nExamples\n\n    \n    \n    >>> # Connect an s3 dataset\n    >>> ds = deeplake.connect(src_path=\"s3://bucket/dataset\", dest_path=\"hub://my_org/dataset\", creds_key=\"my_managed_credentials_key\", token=\"my_activeloop_token\")\n    >>> # or\n    >>> ds = deeplake.connect(src_path=\"s3://bucket/dataset\", org_id=\"my_org\", creds_key=\"my_managed_credentials_key\", token=\"my_activeloop_token\")\n    \n\nParameters\n\n    \n\n  * **src_path** (_str_) \u2013 Cloud path to the source dataset. Can be: an s3 path like `s3://bucket/path/to/dataset`. a gcs path like `gcs://bucket/path/to/dataset`. an azure path like `az://account_name/container/path/to/dataset`.\n\n  * **creds_key** (_str_) \u2013 The managed credentials to be used for accessing the source path.\n\n  * **dest_path** (_str_ _,__optional_) \u2013 The full path to where the connected Deep Lake dataset will reside. Can be: a Deep Lake path like `hub://organization/dataset`\n\n  * **org_id** (_str_ _,__optional_) \u2013 The organization to where the connected Deep Lake dataset will be added.",
        "node_972": "Examples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.\n\nExamples\n\n    \n    \n    >>> ds.create_tensor(\"seq\", htype=\"sequence\")\n    >>> ds.seq.append([1, 2, 3])\n    >>> ds.seq.append([4, 5, 6])\n    >>> ds.seq.numpy()\n    array([[[1],\n            [2],\n            [3]],\n           [[4],\n            [5],\n            [6]]])\n    \n    \n    \n    >>> ds.create_tensor(\"image_seq\", htype=\"sequence[image]\", sample_compression=\"jpg\")\n    >>> ds.image_seq.append([deeplake.read(\"img01.jpg\"), deeplake.read(\"img02.jpg\")])\n    \n\n## Link htype\uf0c1\n\n  * Link htype is a special meta htype that allows linking of external data (files) to the dataset, without storing the data in the dataset itself.\n\n  * Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.",
        "node_356": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n    * Creating Datasets\n    * Loading Datasets\n    * Deleting and Renaming Datasets\n    * Copying Datasets\n    * Dataset Operations\n    * Dataset Visualization\n    * Dataset Credentials\n    * Dataset Properties\n    * Dataset Version Control\n    * Dataset Views\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Datasets\n  * Edit on GitHub\n\n* * *\n\n# Datasets\uf0c1\n\n## Creating Datasets\uf0c1\n\n`deeplake.dataset` | Returns a `Dataset` object referencing either a new or existing dataset.  \n---|---  \n`deeplake.empty` | Creates an empty dataset  \n`deeplake.like` | Creates a new dataset by copying the `source` dataset's structure to a new location.  \n`deeplake.ingest_classification` | Ingest a dataset of images from a local folder to a Deep Lake Dataset.  \n`deeplake.ingest_coco` | Ingest images and annotations in COCO format to a Deep Lake Dataset.  \n`deeplake.ingest_yolo` | Ingest images and annotations (bounding boxes or polygons) in YOLO format to a Deep Lake Dataset.  \n`deeplake.ingest_kaggle` | Download and ingest a kaggle dataset and store it as a structured dataset to destination.",
        "node_40": "### Limitations\uf0c1\n\n  * The Deep Lake Performant Dataloader does not support Nifti data.\n\n### Creating a nifti tensor\uf0c1\n\nA nifti tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"patients\", htype=\"nifti\", sample_compression=\"nii.gz\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"nii.gz\", \"nii\", None]\n    \n\n### Appending nifti data\uf0c1\n\n  * Nifti samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw nifti data. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\nExamples\n\n    \n    \n    >>> ds.patients.append(deeplake.read(\"data/patient0.nii.gz\"))\n    \n    \n    \n    >>> ds.patients.extend([deeplake.read(f\"data/patient{i}.nii.gz\") for i in range(10)])\n    \n\n## Point Cloud Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Point cloud samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.",
        "node_219": "Applicable only if `optimize=True`. Defaults to 0.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for optimization. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Only applicable if `optimize=True`. Defaults to \u2018threaded\u2019.\n\n  * **verbose** (_bool_) \u2013 If `True`, logs will be printed. Defaults to `True`.\n\n  * **ignore_errors** (_bool_) \u2013 Skip samples that cause errors while saving views. Only applicable if `optimize=True`. Defaults to `False`.\n\n  * **ds_args** (_dict_) \u2013 Additional args for creating VDS when path is specified. (See documentation for `deeplake.dataset()`)\n\nReturns\n\n    \n\nPath to the saved VDS.\n\nReturn type\n\n    \n\nstr\n\nRaises\n\n    \n\n  * **ReadOnlyModeError** \u2013 When attempting to save a view inplace and the user doesn\u2019t have write access.\n\n  * **DatasetViewSavingError** \u2013 If HEAD node has uncommitted changes.\n\n  * **TypeError** \u2013 If `id` is not of type `str`.\n\nNote\n\nSpecifying `path` makes the view external. External views cannot be accessed\nusing the parent dataset\u2019s `Dataset.get_view()`, `Dataset.load_view()`,\n`Dataset.delete_view()` methods. They have to be loaded using\n`deeplake.load()`.\n\nset_token(_new_token : str_)\uf0c1\n\n    \n\nMethod to set a new token\n\nsize_approx()\uf0c1\n\n    \n\nEstimates the size in bytes of the dataset. Includes only content, so will\ngenerally return an under-estimate.\n\nsummary(_force : bool = False_)\uf0c1\n\n    \n\nPrints a summary of the dataset.\n\nParameters\n\n    \n\n**force** (_bool_) \u2013 Dataset views with more than 10000 samples might take a\nlong time to summarize. If force=True, the summary will be printed regardless.\nAn error will be raised otherwise.",
        "node_1303": "Deep Lake\n\nv3.1.5\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n\nEnterprise Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n\nAPI Reference\n\n  * deeplake\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n\n__Deep Lake\n\n  * \u00bb\n  * Deep Lake API Reference\n  * Edit on GitHub\n\n* * *\n\n# Deep Lake API Reference\u00b6\n\nDeep Lake is an open-source database for AI.\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n    * Creating Datasets\n    * Loading Datasets\n    * Deleting and Renaming Datasets\n    * Copying Datasets\n    * Dataset Operations\n    * Dataset Visualization\n    * Dataset Credentials\n    * Dataset Properties\n    * Dataset Version Control\n    * Dataset Views\n  * Tensors\n    * Creating Tensors\n    * Deleting and Renaming Tensors\n    * Adding and deleting samples\n    * Retrieving samples\n    * Tensor Properties\n    * Info\n    * Video features\n  * Htypes\n    * Image Htype\n    * Video Htype\n    * Audio Htype\n    * Class Label Htype\n    * Bounding Box Htype\n    * Segmentation Mask Htype\n    * Binary Mask Htype\n    * COCO Keypoints Htype\n    * Point Htype\n    * Polygon Htype\n    * Point Cloud Htype\n    * Mesh Htype\n    * Sequence htype\n    * Link htype\n  * Compressions\n    * Sample Compression\n    * Chunk Compression\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n    * General Functions\n    * Making Deep Lake Samples\n    * Parallelism\n\nIntegrations\n\n  * Weights and Biases\n    * Logging Dataset Creation\n    * Logging Dataset Read\n\nEnterprise Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n\nAPI Reference\n\n  * deeplake\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n\n# Indices and tables\u00b6\n\n  * Index\n\n  * Module Index\n\n  * Search Page\n\nNext\n\n* * *\n\n(C) Copyright 2022, Activeloop.",
        "node_788": "For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.\n\n### Creating a binary_mask tensor\uf0c1\n\nA binary_mask tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"masks\", htype=\"binary_mask\", sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * ref:sample_compression <sample_compression> or chunk_compression\n\n    * dtype: Defaults to `bool`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`.",
        "node_222": "Raises\n\n    \n\n  * **ValueError** \u2013 If partial update of a sample is attempted.\n\n  * **Exception** \u2013 Error while attempting to rollback updates.\n\nupdate_creds_key(_creds_key : str_, _new_creds_key : Optional[str] = None_,\n_managed : Optional[bool] = None_)\uf0c1\n\n    \n\nUpdates the name and/or management status of a creds key.\n\nParameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The key whose name and/or management status is to be changed.\n\n  * **new_creds_key** (_str_ _,__optional_) \u2013 The new key to replace the old key. If not provided, the old key will be used.\n\n  * **managed** (_bool_) \u2013 The target management status. If `True`, the creds corresponding to the key will be fetched from activeloop platform.\n\nRaises\n\n    \n\n  * **ValueError** \u2013 If the dataset is not connected to activeloop platform.\n\n  * **ValueError** \u2013 If both `new_creds_key` and `managed` are `None`.\n\n  * **KeyError** \u2013 If the creds key is not present in the dataset.\n\nExamples\n\n    \n    \n    >>> # create/load a dataset\n    >>> ds = deeplake.dataset(\"path/to/dataset\")\n    >>> # add a new creds key\n    >>> ds.add_creds_key(\"my_s3_key\")\n    >>> # Populate the name added with creds dictionary\n    >>> # These creds are only present temporarily and will have to be repopulated on every reload\n    >>> ds.populate_creds(\"my_s3_key\", {})\n    >>> # Rename the key and change the management status of the key to True.",
        "node_176": "_managed : bool = False_)\uf0c1\n\n    \n\nAdds a new creds key to the dataset. These keys are used for tensors that are\nlinked to external data.\n\nExamples\n\n    \n    \n    >>> # create/load a dataset\n    >>> ds = deeplake.empty(\"path/to/dataset\")\n    >>> # add a new creds key\n    >>> ds.add_creds_key(\"my_s3_key\")\n    \n\nParameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The key to be added.\n\n  * **managed** (_bool_) \u2013 \n    * If `True`, the creds corresponding to the key will be fetched from Activeloop platform.\n\n    * Defaults to `False`.\n\nRaises\n\n    \n\n**ValueError** \u2013 If the dataset is not connected to Activeloop platform and\n`managed` is `True`.\n\nNote\n\n`managed` parameter is applicable only for datasets that are connected to\nActiveloop platform.\n\n_property _allow_delete _: bool_\uf0c1\n\n    \n\nReturns True if dataset can be deleted from storage. Whether it can be deleted\nor not is stored in the database_meta.json and can be changed with\nallow_delete = True|False\n\nappend(_sample : Dict[str, Any]_, _skip_ok : bool = False_, _append_empty :\nbool = False_)\uf0c1\n\n    \n\nAppend samples to mutliple tensors at once. This method expects all tensors\nbeing updated to be of the same length.\n\nParameters\n\n    \n\n  * **sample** (_dict_) \u2013 Dictionary with tensor names as keys and samples as values.\n\n  * **skip_ok** (_bool_) \u2013 Skip tensors not in `sample` if set to `True`.\n\n  * **append_empty** (_bool_) \u2013 Append empty samples to tensors not specified in `sample` if set to `True`. If True, `skip_ok` is ignored.\n\nRaises\n\n    \n\n  * **KeyError** \u2013 If any tensor in the dataset is not a key in `sample` and `skip_ok` is `False`.\n\n  * **TensorDoesNotExistError** \u2013 If tensor in `sample` does not exist.\n\n  * **ValueError** \u2013 If all tensors being updated are not of the same length.\n\n  * **NotImplementedError** \u2013 If an error occurs while writing tiles.",
        "node_503": "* Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.\n\nExamples\n\nAppending polygons with 2-D points\n\n    \n    \n    >>> poly1 = [(1, 2), (2, 3), (3, 4)]\n    >>> poly2 = [(10, 12), (14, 19)]\n    >>> poly3 = [(33, 32), (54, 67), (67, 43), (56, 98)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with 3-D points\n\n    \n    \n    >>> poly1 = [(10, 2, 9), (12, 3, 8), (12, 10, 4)]\n    >>> poly2 = [(10, 1, 8), (5, 17, 11)]\n    >>> poly3 = [(33, 33, 31), (45, 76, 13), (60, 24, 17), (67, 87, 83)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> sample = np.random.randint(0, 10, (5, 7, 2))  # 5 polygons with 7 points\n    >>> ds.polygons.append(sample)\n    \n    \n    \n    >>> import numpy as np\n    >>> poly1 = np.random.randint(0, 10, (5, 2))\n    >>> poly2 = np.random.randint(0, 10, (8, 2))\n    >>> poly3 = np.random.randint(0, 10, (3, 2))\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\n## Nifti Htype\uf0c1\n\n  * Sample dimensions: `(# height, # width, # slices)` or `(# height, # width, # slices, # time unit)` in case of time-series data.",
        "node_546": "* Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.\n\nExamples\n\nAppending Deep Lake audio sample\n\n    \n    \n    >>> ds.audios.append(deeplake.read(\"audios/001.mp3\"))\n    \n\nExtending with Deep Lake audio samples\n\n    \n    \n    >>> ds.audios.extend([deeplake.read(f\"videos/00{i}.mp3\") for i in range(10)])\n    \n\n## Class Label Htype\uf0c1\n\n  * Sample dimensions: `(# labels,)`\n\nClass labels are stored as numerical values in tensors, which are indices of\nthe list `tensor.info.class_names`.\n\n### Creating a class label tensor\uf0c1\n\nA class label tensor can be created using\n\n    \n    \n    >>> classes = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"]\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\", class_names=classes, chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.",
        "node_284": "readthedocs.yaml\n\n|  |   \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n|  |   \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n|  |   \n  \n### MANIFEST.in\n\n|\n\n### MANIFEST.in\n\n|  |   \n  \n### README.md\n\n|\n\n### README.md\n\n|  |   \n  \n### README.zh-cn.md\n\n|\n\n### README.zh-cn.md\n\n|  |   \n  \n### SECURITY.md\n\n|\n\n### SECURITY.md\n\n|  |   \n  \n### conftest.py\n\n|\n\n### conftest.py\n\n|  |   \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n|  |   \n  \n### setup.cfg\n\n|\n\n### setup.cfg\n\n|  |   \n  \n### setup.py\n\n|\n\n### setup.py\n\n|  |   \n  \n### sonar-project.properties\n\n|\n\n### sonar-project.properties\n\n|  |   \nView all files  \n  \n## Repository files navigation\n\n  * README\n  * MPL-2.0 license\n  * Security\n\n  \n\n# Deep Lake: Database for AI\n\n###  **Docs** \u2022 **Get Started** \u2022 **API Reference** \u2022 **LangChain & VectorDBs\nCourse** \u2022 **Blog** \u2022 **Whitepaper** \u2022 **Slack** \u2022 **Twitter**\n\n_Read this in other languages:\u7b80\u4f53\u4e2d\u6587_\n\n## What is Deep Lake?\n\nDeep Lake is a Database for AI powered by a storage format optimized for deep-\nlearning applications. Deep Lake can be used for:\n\n  1. Storing data and vectors while building LLM applications\n  2.",
        "node_930": "* sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nrotation angles are specified in degrees, not radians\n\n### Appending 3d bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98, 22, 36, 44, 18, 0, 36, 0]])\n    >>> ds.3d_boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77, 22, 36, 44, 18, 0, 28, 0],\n           [462, 123, 238,  98, 26, 34, 24, 19, 0, -50, 0],\n           [688, 108, 279, 116, 12, 32, 14, 38, 0, 30, 0]])\n    >>> boxes.shape\n    (9, 4)\n    >>> ds.3d_boxes.append(boxes)\n    \n\n## Intrinsics Htype\uf0c1\n\n  * Sample dimensions: `(# intrinsics matrices, 3, 3)`\n\nThe intrinsic matrix represents a projective transformation from the 3-D\ncamera\u2019s coordinates into the 2-D image coordinates. The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.",
        "node_6": "---|---  \n`deeplake.empty` | Creates an empty dataset  \n`deeplake.like` | Creates a new dataset by copying the `source` dataset's structure to a new location.  \n`deeplake.ingest_classification` | Ingest a dataset of images from a local folder to a Deep Lake Dataset.  \n`deeplake.ingest_coco` | Ingest images and annotations in COCO format to a Deep Lake Dataset.  \n`deeplake.ingest_yolo` | Ingest images and annotations (bounding boxes or polygons) in YOLO format to a Deep Lake Dataset.  \n`deeplake.ingest_kaggle` | Download and ingest a kaggle dataset and store it as a structured dataset to destination.  \n`deeplake.ingest_dataframe` | Convert pandas dataframe to a Deep Lake Dataset.  \n`deeplake.ingest_huggingface` | Converts Hugging Face datasets to Deep Lake format.  \n  \n## Loading Datasets\uf0c1\n\n`deeplake.load` | Loads an existing dataset  \n---|---  \n  \n## Deleting and Renaming Datasets\uf0c1\n\n`deeplake.delete` | Deletes a dataset at a given path.  \n---|---  \n`deeplake.rename` | Renames dataset at `old_path` to `new_path`.  \n  \n## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.  \n`Dataset.rename` | Renames the dataset to path.",
        "node_1117": "It has the following arguments:\n\n  * `data_in`: Input passed to the transform to generate output dataset.\n\n>     * It should support `__getitem__` and `__len__`. This can be a Deep Lake\n> dataset.\n\n  * `ds_out (Dataset, optional)`: The dataset object to which the transform will get written.\n\n>     * If this is not provided, data_in will be overwritten if it is a Deep\n> Lake dataset, otherwise error will be raised.\n>\n>     * It should have all keys being generated in output already present as\n> tensors.\n>\n>     * It\u2019s initial state should be either:\n>\n\n>>       * Empty i.e. all tensors have no samples. In this case all samples\nare added to the dataset.\n\n>>\n\n>>       * All tensors are populated and have same length. In this case new\nsamples are appended to the dataset.\n\n  * `num_workers (int)`: The number of workers to use for performing the transform.\n\n>     * Defaults to 0. When set to 0, it will always use serial processing,\n> irrespective of the scheduler.\n\n  * `scheduler (str)`: The scheduler to be used to compute the transformation.\n\n>     * Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019.\n> Defaults to \u2018threaded\u2019.\n\n  * `progressbar (bool)`: Displays a progress bar if True (default).\n\n  * `skip_ok (bool)`: If True, skips the check for output tensors generated.\n\n>     * This allows the user to skip certain tensors in the function\n> definition.\n>\n>     * This is especially useful for inplace transformations in which certain\n> tensors are not modified. Defaults to `False`.\n\n  * `ignore_errors (bool)`: If `True`, input samples that causes transform to fail will be skipped and the errors will be ignored **if possible**.\n\nIt raises the following errors:\n\n  * `InvalidInputDataError`: If data_in passed to transform is invalid. It should support `__getitem__` and `__len__` operations. Using scheduler other than \u201cthreaded\u201d with deeplake dataset having base storage as memory as data_in will also raise this.",
        "node_1212": "* For all else, returns dict with key \u201cvalue\u201d with value same as `numpy()`.\n\ndict(_fetch_chunks : bool = False_)\uf0c1\n\n    \n\nReturn json data. Only applicable for tensors with \u2018json\u2019 base htype.\n\n_property _dtype _: Optional[dtype]_\uf0c1\n\n    \n\nDtype of the tensor.\n\nextend(_samples : Union[ndarray, Sequence[Union[Sample, ndarray, int, float,\nbool, dict, list, str, integer, floating, bool_]], Tensor]_, _progressbar :\nbool = False_, _ignore_errors : bool = False_)\uf0c1\n\n    \n\nExtends the end of the tensor by appending multiple elements from a sequence.\nAccepts a sequence, a single batched numpy array, or a sequence of\n`deeplake.read()` outputs, which can be used to load files. See examples down\nbelow.\n\nExample\n\nNumpy input:\n\n    \n    \n    >>> len(tensor)\n    0\n    >>> tensor.extend(np.zeros((100, 28, 28, 1)))\n    >>> len(tensor)\n    100\n    \n\nFile input:\n\n    \n    \n    >>> len(tensor)\n    0\n    >>> tensor.extend([\n            deeplake.read(\"path/to/image1\"),\n            deeplake.read(\"path/to/image2\"),\n        ])\n    >>> len(tensor)\n    2\n    \n\nParameters\n\n    \n\n  * **samples** (_np.ndarray_ _,__Sequence_ _,__Sequence_ _[__Sample_ _]_) \u2013 The data to add to the tensor. The length should be equal to the number of samples to add.\n\n  * **progressbar** (_bool_) \u2013 Specifies whether a progressbar should be displayed while extending.\n\n  * **ignore_errors** (_bool_) \u2013 Skip samples that cause errors while extending, if set to `True`.\n\nRaises\n\n    \n\n**TensorDtypeMismatchError** \u2013 Dtype for array must be equal to or castable to\nthis tensor\u2019s dtype.\n\n_property _hidden _: bool_\uf0c1\n\n    \n\nWhether this tensor is a hidden tensor.\n\n_property _htype\uf0c1\n\n    \n\nHtype of the tensor.\n\n_property _info _: Info_\uf0c1\n\n    \n\nReturns the information about the tensor. User can set info of tensor.\n\nReturns\n\n    \n\nInformation about the tensor.",
        "node_1248": "Getting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n    * Creating Datasets\n    * Loading Datasets\n    * Deleting and Renaming Datasets\n    * Copying Datasets\n    * Dataset Operations\n    * Dataset Visualization\n    * Dataset Credentials\n    * Dataset Properties\n    * Dataset Version Control\n    * Dataset Views\n  * Vector Store\n    * Creating a Deep Lake Vector Store\n    * Vector Store Operations\n    * Vector Store Properties\n  * Tensors\n    * Creating Tensors\n    * Deleting and Renaming Tensors\n    * Adding and deleting samples\n    * Retrieving samples\n    * Tensor Properties\n    * Info\n    * Video features\n  * Htypes\n    * Image Htype\n    * Video Htype\n    * Audio Htype\n    * Class Label Htype\n    * Tag Htype\n    * Bounding Box Htype\n    * 3D Bounding Box Htype\n    * Intrinsics Htype\n    * Segmentation Mask Htype\n    * Binary Mask Htype\n    * COCO Keypoints Htype\n    * Point Htype\n    * Polygon Htype\n    * Nifti Htype\n    * Point Cloud Htype\n    * Mesh Htype\n    * Embedding Htype\n    * Sequence htype\n    * Link htype\n  * Compressions\n    * Sample Compression\n    * Chunk Compression\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n    * General Functions\n    * Making Deep Lake Samples\n    * Parallelism\n\nIntegrations\n\n  * Weights and Biases\n    * Logging Dataset Creation\n    * Logging Dataset Read\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.",
        "node_1125": "* \u2019additional_params\u2019: Additional parameters for fine-tuning the index.\n\n  * **exec_option** (_str_) \u2013 Default method for search execution. It could be either `\"auto\"`, `\"python\"`, `\"compute_engine\"` or `\"tensor_db\"`. Defaults to `\"auto\"`. If None, it\u2019s set to \u201cauto\u201d. \\- `auto`\\- Selects the best execution method based on the storage location of the Vector Store. It is the default option. \\- `python` \\- Pure-python implementation that runs on the client and can be used for data stored anywhere. WARNING: using this option with big datasets is discouraged because it can lead to memory issues. \\- `compute_engine` \\- Performant C++ implementation of the Deep Lake Compute Engine that runs on the client and can be used for any data stored in or connected to Deep Lake. It cannot be used with in-memory or local datasets. \\- `tensor_db` \\- Performant and fully-hosted Managed Tensor Database that is responsible for storage and query execution. Only available for data stored in the Deep Lake Managed Database. Store datasets in this database by specifying runtime = {\u201ctensor_db\u201d: True} during dataset creation.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching user credentials. This is Optional, tokens are normally autogenerated. Defaults to None.\n\n  * **overwrite** (_bool_) \u2013 If set to True this overwrites the Vector Store if it already exists. Defaults to False.\n\n  * **verbose** (_bool_) \u2013 Whether to print summary of the dataset created. Defaults to True.\n\n  * **creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys.",
        "node_797": "* Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.\n\n### Creating a mesh tensor\uf0c1\n\nA mesh tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"mesh\", htype=\"mesh\", sample_compression=\"ply\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"ply\"]\n    \n\n### Appending meshes\uf0c1\n\nExamples\n\nAppending a ply file containing a mesh data to tensor\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.ply\")  # mesh with 100 points and 200 faces\n    >>> ds.mesh.append(sample)\n    \n    \n    \n    >>> ds.mesh.shape\n    >>> (1, 100, 3)\n    \n\n## Embedding Htype\uf0c1\n\n  * Sample dimensions: `(# elements in the embedding,)`\n\n### Creating an embedding tensor\uf0c1\n\nAn embedding tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"embedding\", htype=\"embedding\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\", None]\n    \n\n### Appending embedding samples\uf0c1\n\n  * Embedding samples can be of type `np.ndarray`.\n\nExamples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.",
        "node_705": "For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.\n\n## Point Htype\uf0c1\n\n  * Sample dimensions: `(# points, 2)` in case of 2-D (X, Y) co-ordinates or `(# points, 3)` in case of 3-D (X, Y, Z) co-ordinates of the point.\n\nPoints does not contain a fixed mapping across samples between the point order\nand real-world objects (i.e., point 0 is an elbow, point 1 is a knee, etc.).\nIf you require such a mapping, use COCO Keypoints Htype.\n\n### Creating a point tensor\uf0c1\n\nA point tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"points\", htype=\"point\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending point samples\uf0c1\n\n  * Points can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.",
        "node_787": "The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"])\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending segmentation masks\uf0c1\n\n  * Segmentation masks can be appended as `np.ndarray`.\n\nExamples\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512)))\n    \n\nNote\n\nSince each pixel can only be labeled once, segmentation masks are not\nappropriate for datasets where objects might overlap, or where multiple\nobjects within the same class must be distinguished. For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.",
        "node_626": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.",
        "node_258": "Parameters\n\n    \n\n  * **data_in** \u2013 Input passed to the transform to generate output dataset. Should support __getitem__ and __len__. Can be a Deep Lake dataset.\n\n  * **ds_out** (_Dataset_ _,__optional_) \u2013 \n    * The dataset object to which the transform will get written. If this is not provided, `data_in` will be overwritten if it is a Deep Lake dataset, otherwise error will be raised.\n\n    * It should have all keys being generated in output already present as tensors. It\u2019s initial state should be either:\n\n    * **Empty** , i.e., all tensors have no samples. In this case all samples are added to the dataset.\n\n    * **All tensors are populated and have same length.** In this case new samples are appended to the dataset.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for performing the transform. Defaults to 0. When set to 0, it will always use serial processing, irrespective of the scheduler.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used to compute the transformation. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Defaults to \u2018threaded\u2019.\n\n  * **progressbar** (_bool_) \u2013 Displays a progress bar if `True` (default).\n\n  * **skip_ok** (_bool_) \u2013 If `True`, skips the check for output tensors generated. This allows the user to skip certain tensors in the function definition. This is especially useful for inplace transformations in which certain tensors are not modified. Defaults to `False`.\n\n  * **check_lengths** (_bool_) \u2013 If `True`, checks whether `ds_out` has tensors of same lengths initially.\n\n  * **pad_data_in** (_bool_) \u2013 If `True`, pads tensors of `data_in` to match the length of the largest tensor in `data_in`. Defaults to `False`.\n\n  * **read_only_ok** (_bool_) \u2013 If `True` and output dataset is same as input dataset, the read-only check is skipped. Defaults to False.\n\n  * **cache_size** (_int_) \u2013 Cache size to be used by transform per worker.",
        "node_201": "Defaults to 0.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for optimization. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Only applicable if optimize=True. Defaults to \u2018threaded\u2019.\n\n  * **progressbar** (_bool_) \u2013 Whether to use progressbar for optimization. Only applicable if optimize=True. Defaults to True.\n\nReturns\n\n    \n\nThe loaded view.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**KeyError** \u2013 if view with given id does not exist.\n\nlog()\uf0c1\n\n    \n\nDisplays the details of all the past commits.\n\n_property _max_len\uf0c1\n\n    \n\nReturn the maximum length of the tensor.\n\n_property _max_view\uf0c1\n\n    \n\nReturns a view of the dataset in which shorter tensors are padded with `None`\ns to have the same length as the longest tensor.\n\nExample\n\nCreating a dataset with 5 images and 4 labels. `ds.max_view` will return a\nview with `labels` tensor padded to have 5 samples.",
        "node_152": "This is Optional, tokens are normally autogenerated. Defaults to None.\n\n  * **overwrite** (_bool_) \u2013 If set to True this overwrites the Vector Store if it already exists. Defaults to False.\n\n  * **verbose** (_bool_) \u2013 Whether to print summary of the dataset created. Defaults to True.\n\n  * **creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **runtime** (_Dict_ _,__optional_) \u2013 Parameters for creating the Vector Store in Deep Lake\u2019s Managed Tensor Database. Not applicable when loading an existing Vector Store. To create a Vector Store in the Managed Tensor Database, set runtime = {\u201ctensor_db\u201d: True}.\n\n  * **branch** (_str_) \u2013 Branch name to use for the Vector Store. Defaults to \u201cmain\u201d.\n\n  * ****kwargs** (_dict_) \u2013 Additional keyword arguments.\n\nDanger\n\nSetting `overwrite` to `True` will delete all of your data if the Vector Store\nexists! Be very careful when setting this parameter.",
        "node_495": "The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.\n\n  * \\\\(f_x = F / p_x\\\\)\n\n  * \\\\(f_y = F / p_y\\\\)\n\n  * \\\\(F\\\\) \\- Focal length in world units, typically expressed in millimeters.\n\n  * \\\\((p_x, p_y)\\\\) \\- Size of the pixel in world units.\n\n### Creating an intrinsics tensor\uf0c1\n\nAn intrinsics tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"intrinsics\", htype=\"intrinsics\")\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending intrinsics matrices\uf0c1\n\n    \n    \n    >>> intrinsic_params = np.zeros((3, 3))\n    >>> ds.intrinsics.append(intrinsic_params)\n    \n\n## Segmentation Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width)`\n\nSegmentation masks are 2D representations of class labels where the numerical\nlabel data is encoded in an array of same shape as the image. The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**.",
        "node_1182": "* **collate_fn** (_Callable_ _,__Optional_) \u2013 merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset. Read torch.utils.data.DataLoader docs for more details.\n\n  * **pin_memory** (_bool_) \u2013 If `True`, the data loader will copy Tensors into CUDA pinned memory before returning them. Default value is `False`. Read torch.utils.data.DataLoader docs for more details.\n\n  * **shuffle** (_bool_) \u2013 If `True`, the data loader will shuffle the data indices. Default value is False. Details about how Deep Lake shuffles data can be found at Shuffling in ds.pytorch()\n\n  * **buffer_size** (_int_) \u2013 The size of the buffer used to shuffle the data in MBs. Defaults to 2048 MB. Increasing the buffer_size will increase the extent of shuffling.\n\n  * **use_local_cache** (_bool_) \u2013 If `True`, the data loader will use a local cache to store data. The default cache location is ~/.activeloop/cache, but it can be changed by setting the `LOCAL_CACHE_PREFIX` environment variable. This is useful when the dataset can fit on the machine and we don\u2019t want to fetch the data multiple times for each iteration. Default value is `False`\n\n  * **progressbar** (_bool_) \u2013 If `True`, tqdm will be wrapped around the returned dataloader. Default value is True.\n\n  * **return_index** (_bool_) \u2013 If `True`, the returned dataloader will have a key \u201cindex\u201d that contains the index of the sample(s) in the original dataset. Default value is True.\n\n  * **pad_tensors** (_bool_) \u2013 If `True`, shorter tensors will be padded to the length of the longest tensor. Default value is False.\n\n  * **transform_kwargs** (_optional_ _,__Dict_ _[__str_ _,__Any_ _]_) \u2013 Additional kwargs to be passed to `transform`.\n\n  * **decode_method** (_Dict_ _[__str_ _,__str_ _]__,__Optional_) \u2013 \n\nA dictionary of decode methods for each tensor. Defaults to `None`.",
        "node_379": "## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.  \n`Dataset.rename` | Renames the dataset to path.  \n`Dataset.connect` | Connect a Deep Lake cloud dataset through a deeplake path.  \n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n`Dataset.pop` | Removes a sample from all the tensors of the dataset.  \n`Dataset.rechunk` | Rewrites the underlying chunks to make their sizes optimal.  \n`Dataset.flush` | Necessary operation after writes if caches are being used.  \n`Dataset.clear_cache` | \n\n  * Flushes (see `Dataset.flush()`) the contents of the cache layers (if any) and then deletes contents of all the layers of it.\n\n  \n`Dataset.size_approx` | Estimates the size in bytes of the dataset.  \n`Dataset.random_split` | Splits the dataset into non-overlapping `Dataset` objects of given lengths.  \n  \n## Dataset Visualization\uf0c1\n\n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n---|---  \n  \n## Dataset Credentials\uf0c1\n\n`Dataset.add_creds_key` | Adds a new creds key to the dataset.  \n---|---  \n`Dataset.populate_creds` | Populates the creds key added in add_creds_key with the given creds.  \n`Dataset.update_creds_key` | Updates the name and/or management status of a creds key.",
        "node_1018": "---|---  \n`link` | Utility that stores a link to raw data.  \n`link_tiled` | Utility that stores links to multiple images that act as tiles and together form a big image.  \n  \n## Parallelism\uf0c1\n\n`compute` | Compute is a decorator for functions.  \n---|---  \n`compose` | Takes a list of functions decorated using `deeplake.compute()` and creates a pipeline that can be evaluated using .eval  \n  \nTransform pipelines returned by `compute()` and `compose()` are evaluated\nusing `eval`:\n\n`eval` | Evaluates the pipeline on `data_in` to produce an output dataset `ds_out`.  \n---|---  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_142": "It should support `__getitem__` and `__len__` operations. Using scheduler other than \u201cthreaded\u201d with deeplake dataset having base storage as memory as `data_in` will also raise this.\n\n  * `InvalidOutputDatasetError`: If all the tensors of `ds_out` passed to transform don\u2019t have the same length. Using scheduler other than \u201cthreaded\u201d with deeplake dataset having base storage as memory as `ds_out` will also raise this.\n\n  * `TensorMismatchError`: If one or more of the outputs generated during transform contain different tensors than the ones present in `ds_out` provided to transform.\n\n  * `UnsupportedSchedulerError`: If the scheduler passed is not recognized. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019.\n\n  * `TransformError`: All other exceptions raised if there are problems while running the pipeline.\n\ndeeplake.compose(_functions : List[ComputeFunction]_)\uf0c1\n\n    \n\nTakes a list of functions decorated using `deeplake.compute()` and creates a\npipeline that can be evaluated using .eval\n\nExample:\n\n    \n    \n    pipeline = deeplake.compose([my_fn(a=3), another_function(b=2)])\n    pipeline.eval(data_in, ds_out, scheduler=\"processed\", num_workers=2)\n    \n\nThe `eval` method evaluates the pipeline/transform function.\n\nIt has the following arguments:\n\n  * `data_in`: Input passed to the transform to generate output dataset.\n\n>     * It should support `__getitem__` and `__len__`. This can be a Deep Lake\n> dataset.\n\n  * `ds_out (Dataset, optional)`: The dataset object to which the transform will get written.\n\n>     * If this is not provided, data_in will be overwritten if it is a Deep\n> Lake dataset, otherwise error will be raised.\n>\n>     * It should have all keys being generated in output already present as\n> tensors.\n>\n>     * It\u2019s initial state should be either:\n>\n\n>>       * Empty i.e. all tensors have no samples. In this case all samples\nare added to the dataset.\n\n>>\n\n>>       * All tensors are populated and have same length. In this case new\nsamples are appended to the dataset.",
        "node_108": "* **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://username/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.\n\n  * **exist_ok** (_bool_) \u2013 If the kaggle dataset was already downloaded and `exist_ok` is `True`, ingestion will proceed without error.\n\n  * **images_compression** (_str_) \u2013 For image classification datasets, this compression will be used for the `images` tensor. If `images_compression` is \u201cauto\u201d, compression will be automatically determined by the most common extension in the directory.\n\n  * **dest_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 The string `ENV` or a dictionary containing credentials used to access the destination path of the dataset.\n\n  * **kaggle_credentials** (_dict_) \u2013 A dictionary containing kaggle credentials {\u201cusername\u201d:\u201dYOUR_USERNAME\u201d, \u201ckey\u201d: \u201cYOUR_KEY\u201d}. If `None`, environment variables/the kaggle.json file will be used if available.\n\n  * **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Set to `True` by default.\n\n  * **summary** (_bool_) \u2013 Generates ingestion summary. Set to `True` by default.\n\n  * **shuffle** (_bool_) \u2013 Shuffles the input data prior to ingestion. Since data arranged in folders by class is highly non-random, shuffling is important in order to produce optimal results when training. Defaults to `True`.",
        "node_919": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_1000": "* Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.\n\n### Creating a mesh tensor\uf0c1\n\nA mesh tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"mesh\", htype=\"mesh\", sample_compression=\"ply\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"ply\"]\n    \n\n### Appending meshes\uf0c1\n\nExamples\n\nAppending a ply file containing a mesh data to tensor\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.ply\")  # mesh with 100 points and 200 faces\n    >>> ds.mesh.append(sample)\n    \n    \n    \n    >>> ds.mesh.shape\n    >>> (1, 100, 3)\n    \n\n## Embedding Htype\uf0c1\n\n  * Sample dimensions: `(# elements in the embedding,)`\n\n### Creating an embedding tensor\uf0c1\n\nAn embedding tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"embedding\", htype=\"embedding\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\", None]\n    \n\n### Appending embedding samples\uf0c1\n\n  * Embedding samples can be of type `np.ndarray`.\n\nExamples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.",
        "node_967": "Examples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.",
        "node_1014": "---|---  \n`link` | Utility that stores a link to raw data.  \n`link_tiled` | Utility that stores links to multiple images that act as tiles and together form a big image.  \n  \n## Parallelism\uf0c1\n\n`compute` | Compute is a decorator for functions.  \n---|---  \n`compose` | Takes a list of functions decorated using `deeplake.compute()` and creates a pipeline that can be evaluated using .eval  \n  \nTransform pipelines returned by `compute()` and `compose()` are evaluated\nusing `eval`:\n\n`eval` | Evaluates the pipeline on `data_in` to produce an output dataset `ds_out`.  \n---|---  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_104": "* **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://org_id/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.\n\n  * **class_names_file** \u2013 Path to the file containing the class names on separate lines. This is typically a file titled classes.names.\n\n  * **annotations_directory** (_Optional_ _[__Union_ _[__str_ _,__pathlib.Path_ _]__]_) \u2013 Path to directory containing the annotations. If specified, the \u2018data_directory\u2019 will not be examined for annotations.\n\n  * **allow_no_annotation** (_bool_) \u2013 Flag to determine whether missing annotations files corresponding to an image should be treated as empty annoations. Set to `False` by default.\n\n  * **image_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the images tensor.\n\n  * **label_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the labels tensor.\n\n  * **coordinates_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the ccoordinates tensor. This tensor either contains bounding boxes or polygons.\n\n  * **src_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 Credentials to access the source data. If not provided, will be inferred from the environment.",
        "node_154": "Tensor names are specified as parameters, and data for each tensor is\nspecified as parameter values. All data must of equal length.\n\nExamples\n\n    \n    \n    >>> # Dummy data\n    >>> texts = [\"Hello\", \"World\"]\n    >>> embeddings = [[1, 2, 3], [4, 5, 6]]\n    >>> metadatas = [{\"timestamp\": \"01:20\"}, {\"timestamp\": \"01:22\"}]\n    >>> emebdding_fn = lambda x: [[1, 2, 3]] * len(x)\n    >>> embedding_fn_2 = lambda x: [[4, 5]] * len(x)\n    >>> # Directly upload embeddings\n    >>> deeplake_vector_store.add(\n    .     text = texts,\n    .     embedding = embeddings,\n    .     metadata = metadatas,\n    . )\n    >>> # Upload embedding via embedding function\n    >>> deeplake_vector_store.add(\n    .     text = texts,\n    .     metadata = metadatas,\n    .     embedding_function = embedding_fn,\n    .     embedding_data = texts,\n    . )\n    >>> # Upload embedding via embedding function to a user-defined embedding tensor\n    >>> deeplake_vector_store.add(\n    .     text = texts,\n    .     metadata = metadatas,\n    .     embedding_function = embedding_fn,\n    .     embedding_data = texts,\n    .     embedding_tensor = \"embedding_1\",\n    . )\n    >>> # Multiple embedding functions (user defined embedding tensors must be specified)\n    >>> deeplake_vector_store.add(\n    .     embedding_tensor = [\"embedding_1\", \"embedding_2\"]\n    .     embedding_function = [embedding_fn, embedding_fn_2],\n    .     embedding_data = [texts, texts],\n    . )\n    >>> # Alternative syntax for multiple embedding functions\n    >>> deeplake_vector_store.add(\n    .     text = texts,\n    .     metadata = metadatas,\n    .     embedding_tensor_1 = (embedding_fn, texts),\n    .     embedding_tensor_2 = (embedding_fn_2, texts),\n    .",
        "node_913": "* Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.\n\n### Creating a mesh tensor\uf0c1\n\nA mesh tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"mesh\", htype=\"mesh\", sample_compression=\"ply\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"ply\"]\n    \n\n### Appending meshes\uf0c1\n\nExamples\n\nAppending a ply file containing a mesh data to tensor\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.ply\")  # mesh with 100 points and 200 faces\n    >>> ds.mesh.append(sample)\n    \n    \n    \n    >>> ds.mesh.shape\n    >>> (1, 100, 3)\n    \n\n## Embedding Htype\uf0c1\n\n  * Sample dimensions: `(# elements in the embedding,)`\n\n### Creating an embedding tensor\uf0c1\n\nAn embedding tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"embedding\", htype=\"embedding\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\", None]\n    \n\n### Appending embedding samples\uf0c1\n\n  * Embedding samples can be of type `np.ndarray`.\n\nExamples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.",
        "node_1046": "May be used in `ORDER BY` to shuffle the output - `ORDER BY RANDOM()`\n\n  * `SHAPE` \\- returns the shape array of the given tensor - `SHAPE(boxes)`\n\n  * `ALL` \\- takes an array of booleans and returns single boolean, `True` if all elements of the input array are `True`\n\n  * `ALL_STRICT` \\- same as `ALL` with one difference. `ALL` returns `True` on empty array, while `ALL_STRICT` return `False`\n\n  * `ANY` \\- takes an array of booleans and returns single boolean, `True` if any of the elements int the input array is `True`\n\n  * `LOGICAL_AND` \\- takes two boolean arrays, does element wise **logical and** , returns the result array. This will return `False` if the input arrays have different sizes.\n\n  * `LOGICAL_OR` \\- takes two boolean arrays, does element wise **logical or** , returns the result array. This will return `False` if the input arrays have different sizes.\n\n### UNION, INTERSECT, EXCEPT\uf0c1\n\nQuery can contain multiple `SELECT` statements, combined by one of the set\noperations - `UNION`, `INTERSECT` and `EXCEPT`.\n\n## Examples\uf0c1\n\nQuerying for images containing 0 in MNIST Train Dataset with `ds.query`.\n\n    \n    \n    >>> import deeplake\n    >>> ds = deeplake.load(\"hub://activeloop/mnist-train\")\n    >>> result = ds.query(\"select * where labels == 0\")\n    >>> len(result)\n    5923\n    \n\nQuerying for samples with `car` or `motorcycle` in `categories` of COCO Train\nDataset.\n\n    \n    \n    >>> import deeplake\n    >>> ds = deeplake.load(\"hub://activeloop/coco-train\")\n    >>> result = ds.query(\"(select * where contains(categories, 'car')) union (select * where contains(categories, 'motorcycle'))\")\n    >>> len(result)\n    14376\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.",
        "node_1076": "* **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Set to `True` by default.\n\n  * **shuffle** (_bool_) \u2013 Shuffles the input data prior to ingestion. Set to `False` by default.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for ingestion. Set to `0` by default.\n\n  * **token** (_Optional_ _[__str_ _]_) \u2013 The token to use for accessing the dataset and/or connecting it to Deep Lake.\n\n  * **connect_kwargs** (_Optional_ _[__Dict_ _]_) \u2013 If specified, the dataset will be connected to Deep Lake, and connect_kwargs will be passed to `Dataset.connect`.\n\n  * ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function. See `deeplake.empty()`.\n\nReturns\n\n    \n\nThe Dataset created from images and COCO annotations.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**IngestionError** \u2013 If either `key_to_tensor_mapping` or\n`file_to_group_mapping` are not one-to-one.\n\ndeeplake.ingest_yolo(_data_directory : Union[str, Path]_, _dest : Union[str,\nPath]_, _class_names_file : Optional[Union[str, Path]] = None_,\n_annotations_directory : Optional[Union[str, Path]] = None_,\n_allow_no_annotation : bool = False_, _image_params : Optional[Dict] = None_,\n_label_params : Optional[Dict] = None_, _coordinates_params : Optional[Dict] =\nNone_, _src_creds : Optional[Union[Dict, str]] = None_, _dest_creds :\nOptional[Union[Dict, str]] = None_, _image_creds_key : Optional[str] = None_,\n_inspect_limit : int = 1000_, _progressbar : bool = True_, _shuffle : bool =\nFalse_, _num_workers : int = 0_, _token : Optional[str] = None_,\n_connect_kwargs : Optional[Dict] = None_, _** dataset_kwargs_) -> Dataset\uf0c1\n\n    \n\nIngest images and annotations (bounding boxes or polygons) in YOLO format to a\nDeep Lake Dataset. The source data can be stored locally or in the cloud.",
        "node_533": "### Limitations\uf0c1\n\n  * The Deep Lake Performant Dataloader does not support Nifti data.\n\n### Creating a nifti tensor\uf0c1\n\nA nifti tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"patients\", htype=\"nifti\", sample_compression=\"nii.gz\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"nii.gz\", \"nii\", None]\n    \n\n### Appending nifti data\uf0c1\n\n  * Nifti samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw nifti data. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\nExamples\n\n    \n    \n    >>> ds.patients.append(deeplake.read(\"data/patient0.nii.gz\"))\n    \n    \n    \n    >>> ds.patients.extend([deeplake.read(f\"data/patient{i}.nii.gz\") for i in range(10)])\n    \n\n## Point Cloud Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Point cloud samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.",
        "node_99": "The\nsource data can be stored locally or in the cloud.\n\nExamples\n\n    \n    \n    >>> # Ingest local data in COCO format to a Deep Lake dataset stored in Deep Lake storage.\n    >>> ds = deeplake.ingest_coco(\n    >>>     \"<path/to/images/directory>\",\n    >>>     [\"path/to/annotation/file1.json\", \"path/to/annotation/file2.json\"],\n    >>>     dest=\"hub://org_id/dataset\",\n    >>>     key_to_tensor_mapping={\"category_id\": \"labels\", \"bbox\": \"boxes\"},\n    >>>     file_to_group_mapping={\"file1.json\": \"group1\", \"file2.json\": \"group2\"},\n    >>>     ignore_keys=[\"area\", \"image_id\", \"id\"],\n    >>>     num_workers=4,\n    >>> )\n    >>> # Ingest data from your cloud into another Deep Lake dataset in your cloud, and connect that dataset to the Deep Lake backend.\n    >>> ds = deeplake.ingest_coco(\n    >>>     \"s3://bucket/images/directory\",\n    >>>     \"s3://bucket/annotation/file1.json\",\n    >>>     dest=\"s3://bucket/dataset_name\",\n    >>>     ignore_one_group=True,\n    >>>     ignore_keys=[\"area\", \"image_id\", \"id\"],\n    >>>     image_settings={\"name\": \"images\", \"htype\": \"link[image]\", \"sample_compression\": \"jpeg\"},\n    >>>     image_creds_key=\"my_s3_managed_credentials\",\n    >>>     src_creds=aws_creds, # Can also be inferred from environment\n    >>>     dest_creds=aws_creds, # Can also be inferred from environment\n    >>>     connect_kwargs={\"creds_key\": \"my_s3_managed_credentials\", \"org_id\": \"org_id\"},\n    >>>     num_workers=4,\n    >>> )\n    \n\nParameters\n\n    \n\n  * **images_directory** (_str_ _,__pathlib.Path_) \u2013 The path to the directory containing images.\n\n  * **annotation_files** (_str_ _,__pathlib.Path_ _,__List_ _[__str_ _]_) \u2013 Path to JSON annotation files in COCO format.\n\n  * **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset.",
        "node_159": "* **query** (_Optional_ _[__str_ _]_) \u2013 TQL Query string for direct evaluation for finding samples for deletion, without application of additional filters.\n\n  * **exec_option** (_Optional_ _[__str_ _]_) \u2013 Method for search execution. It could be either `\"python\"`, `\"compute_engine\"` or `\"tensor_db\"`. Defaults to `None`, which inherits the option from the Vector Store initialization. \\- `python` \\- Pure-python implementation that runs on the client and can be used for data stored anywhere. WARNING: using this option with big datasets is discouraged because it can lead to memory issues. \\- `compute_engine` \\- Performant C++ implementation of the Deep Lake Compute Engine that runs on the client and can be used for any data stored in or connected to Deep Lake. It cannot be used with in-memory or local datasets. \\- `tensor_db` \\- Performant and fully-hosted Managed Tensor Database that is responsible for storage and query execution. Only available for data stored in the Deep Lake Managed Database. Store datasets in this database by specifying runtime = {\u201ctensor_db\u201d: True} during dataset creation.\n\n  * **delete_all** (_Optional_ _[__bool_ _]_) \u2013 Whether to delete all the samples and version history of the dataset. Defaults to None.\n\nReturns\n\n    \n\nReturns True if deletion was successful, otherwise it raises a ValueError.\n\nReturn type\n\n    \n\nbool\n\nRaises\n\n    \n\n**ValueError** \u2013 If neither `ids`, `filter`, `query`, nor `delete_all` are\nspecified, or if an invalid `exec_option` is provided.\n\n_static _delete_by_path(_path : Union[str, Path]_, _token : Optional[str] =\nNone_, _force : bool = False_, _creds : Optional[Union[Dict, str]] = None_) ->\nNone\uf0c1\n\n    \n\nDeleted the Vector Store at the specified path.\n\nParameters\n\n    \n\n  * **path** (_str_ _,__pathlib.Path_) \u2013 The full path to the Deep Lake Vector Store.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching user credentials. This is optional, as tokens are normally autogenerated. Defaults to `None`.",
        "node_539": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.",
        "node_1043": "## Syntax\uf0c1\n\n### SELECT\uf0c1\n\nTQL supports only `SELECT` statement. Every TQL expression starts with `SELECT\n*`. TQL supports only `*` which means to select all tensors. The common syntax\nfor select statement is the following:\n\n    \n    \n    SELECT * [FROM string] [WHERE expression] [LIMIT number [OFFSET number]] [ORDER BY expression [ASC/DESC]]\n    \n\nEach part of the `SELECT` statement can be omitted.\n\n`FROM` expression is allowed, but it does not have any effect on the query,\nbecause for now TQL queries are run on a specific dataset, so the `FROM` is\nknown from the context\n\n### WHERE\uf0c1\n\n`WHERE` expression is used to filter the samples in the dataset by conditions.\nThe conditions should be convertible to boolean. Any expression which outputs\na number will be converted to boolean with non-zero values taken as `True`. If\nthe expression is not convertible to boolean, such as **strings** , **json**\nobjects and **arrays** , the query will print the corresponding error.\n\n### ORDER BY\uf0c1\n\n`ORDER BY` expression orders the output of the query by the given criteria.\nThe criteria can be any expression output of which can be ordered. The ordered\noutputs are either scalar numbers or strings. In addition it can also be json,\nwhich contains number or string.\n\n`ORDER BY` statement optionally accepts `ASC/DESC` keywords specifying whether\nthe ordering should be ascending or descending. It is ascending by default.\n\n### LIMIT OFFSET\uf0c1\n\n`LIMIT` and `OFFSET` expressions are used to limit the output of the query by\nindex, as in SQL.\n\n### Expressions\uf0c1\n\nTQL supports any comparison operator (`==, !=, <, <=, >=`) where the left side\nis a tensor and the right side is a known value.\n\nThe value can be numeric scalar or array as well as string value.\n\nString literal should be provided within single quotes (`'`) and can be used\non `class_label`, `json` and `text` tensors.\n\nFor class labels it will get corresponding numeric value from the\n**class_names** list and do numeric comparison.\n\nFor json and text it will do string comparison.",
        "node_410": "`Tensor.tobytes` | Returns the bytes of the tensor.  \n`Tensor.text` | Return text data.  \n`Tensor.dict` | Return json data.  \n`Tensor.list` | Return list data.  \n`Tensor._linked_sample` | Returns the linked sample at the given index.  \n  \n## Tensor Properties\uf0c1\n\n`Tensor.htype` | Htype of the tensor.  \n---|---  \n`Tensor.base_htype` | Base htype of the tensor.  \n`Tensor.dtype` | Dtype of the tensor.  \n`Tensor.shape` | Get the shape of this tensor.  \n`Tensor.shape_interval` | Returns a `ShapeInterval` object that describes this tensor's shape more accurately.  \n`Tensor.ndim` | Number of dimensions of the tensor.  \n`Tensor.num_samples` | Returns the length of the primary axis of the tensor.  \n`Tensor.__len__` | Returns the length of the primary axis of the tensor.  \n`Tensor.is_dynamic` | Will return `True` if samples in this tensor have shapes that are unequal.  \n`Tensor.is_sequence` | Whether this tensor is a sequence tensor.  \n`Tensor.is_link` | Whether this tensor is a link tensor.  \n`Tensor.verify` | Whether linked data will be verified when samples are added.  \n  \n## Info\uf0c1\n\n`Tensor.info` | Returns the information about the tensor.  \n---|---  \n`Tensor.sample_info` | Returns info about particular samples in a tensor.  \n  \n## Video features\uf0c1\n\n`Tensor.play` | Play video sample.  \n---|---  \n`Tensor.timestamps` | Returns timestamps (in seconds) for video sample as numpy array.  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_20": "core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.\n\nSupported htypes and their respective defaults are:\n\nHtype configs\uf0c1 HTYPE | DTYPE | COMPRESSION  \n---|---|---  \ngeneric | None | None  \nimage | uint8 | Required arg  \nimage.rgb | uint8 | Required arg  \nimage.gray | uint8 | Required arg  \nvideo | uint8 | Required arg  \naudio | float64 | Required arg  \nclass_label | uint32 | None  \ntag | str | None  \nbbox | float32 | None  \nbbox.3d | float32 | None  \nintrinsics | float32 | None  \nsegment_mask | uint32 | None  \nbinary_mask | bool | None  \nkeypoints_coco | int32 | None  \npoint | int32 | None  \npolygon | float32 | None  \ntext | str | None  \njson | Any | None  \nlist | List | None  \ndicom | None | dcm  \nnifti | None | Required arg  \npoint_cloud | None | las  \nmesh | None | ply  \ninstance_label | uint32 | None  \nembedding | None | None  \nlink | str | None  \nsequence | None | None  \n  \n## Image Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # channels)` or `(height, width)`.\n\nImages can be stored in Deep Lake as compressed bytes or as raw arrays.",
        "node_346": "`Dataset.read_only` | Returns True if dataset is in read-only mode and False otherwise.  \n`Dataset.info` | Returns the information about the dataset.  \n`Dataset.max_len` | Return the maximum length of the tensor.  \n`Dataset.min_len` | Return the minimum length of the tensor.  \n  \n## Dataset Version Control\uf0c1\n\n`Dataset.commit` | Stores a snapshot of the current state of the dataset.  \n---|---  \n`Dataset.diff` | Returns/displays the differences between commits/branches.  \n`Dataset.checkout` | Checks out to a specific commit_id or branch.  \n`Dataset.merge` | Merges the target_id into the current dataset.  \n`Dataset.log` | Displays the details of all the past commits.  \n`Dataset.reset` | Resets the uncommitted changes present in the branch.  \n`Dataset.get_commit_details` | Get details of a particular commit.  \n`Dataset.commit_id` | The lasted committed commit id of the dataset.  \n`Dataset.branch` | The current branch of the dataset  \n`Dataset.pending_commit_id` | The commit_id of the next commit that will be made to the dataset.  \n`Dataset.has_head_changes` | Returns True if currently at head node and uncommitted changes are present.  \n`Dataset.commits` | Lists all the commits leading to the current dataset state.  \n`Dataset.branches` | Lists all the branches of the dataset.  \n  \n## Dataset Views\uf0c1\n\nA dataset view is a subset of a dataset that points to specific samples\n(indices) in an existing dataset. Dataset views can be created by indexing a\ndataset, filtering a dataset with `Dataset.filter()`, querying a dataset with\n`Dataset.query()` or by sampling a dataset with `Dataset.sample_by()`.\nFiltering is done with user-defined functions or simplified expressions\nwhereas query can perform SQL-like queries with our Tensor Query Language. See\nthe full TQL spec here.\n\nDataset views can only be saved when a dataset has been committed and has no\nchanges on the HEAD node, in order to preserve data lineage and prevent the\nunderlying data from changing after the query or filter conditions have been\nevaluated.",
        "node_1178": "* If tensor is renamed on both target and current branch, tensor on target will be registered as a new tensor on current branch.\n\n      * If tensor is renamed on target and a new tensor of the new name was created on the current branch, they will be merged.\n\nRaises\n\n    \n\n  * **Exception** \u2013 if dataset is a filtered view.\n\n  * **ValueError** \u2013 if the conflict resolution strategy is not one of the None, \u201cours\u201d, or \u201ctheirs\u201d.\n\n_property _meta _: DatasetMeta_\uf0c1\n\n    \n\nReturns the metadata of the dataset.\n\n_property _min_len\uf0c1\n\n    \n\nReturn the minimum length of the tensor.\n\n_property _min_view\uf0c1\n\n    \n\nReturns a view of the dataset in which all tensors are sliced to have the same\nlength as the shortest tensor.\n\nExample\n\nCreating a dataset with 5 images and 4 labels. `ds.min_view` will return a\nview in which tensors are sliced to have 4 samples.\n\n    \n    \n    >>> import deeplake\n    >>> ds = deeplake.dataset(\"../test/test_ds\", overwrite=True)\n    >>> ds.create_tensor(\"images\", htype=\"link[image]\", sample_compression=\"jpg\")\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\")\n    >>> ds.images.extend([deeplake.link(\"https://picsum.photos/20/20\") for _ in range(5)])\n    >>> ds.labels.extend([0, 1, 2, 1])\n    >>> len(ds.images)\n    5\n    >>> len(ds.labels)\n    4\n    >>> for i, sample in enumerate(ds.max_view):\n    ...     print(sample[\"images\"].shape, sample[\"labels\"].numpy())\n    ...\n    (20, 20, 3) [0]\n    (20, 20, 3) [1]\n    (20, 20, 3) [2]\n    (20, 20, 3) [1]\n    \n\n_property _no_view_dataset\uf0c1\n\n    \n\nReturns the same dataset without slicing.\n\n_property _num_samples _: int_\uf0c1\n\n    \n\nReturns the length of the smallest tensor. Ignores any applied indexing and\nreturns the total length.\n\n_property _parent\uf0c1\n\n    \n\nReturns the parent of this group.",
        "node_1145": "Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_589": "Examples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.",
        "node_1227": "* `S3GetError`\n    * `S3SetError`\n    * `S3DeletionError`\n    * `S3ListError`\n    * `UnsupportedCompressionError`\n    * `SampleCompressionError`\n    * `SampleDecompressionError`\n    * `InvalidImageDimensions`\n    * `TensorUnsupportedSampleType`\n    * `MetaError`\n    * `MetaDoesNotExistError`\n    * `MetaAlreadyExistsError`\n    * `MetaInvalidKey`\n    * `MetaInvalidRequiredMetaKey`\n    * `TensorMetaInvalidHtype`\n    * `TensorMetaInvalidHtypeOverwriteValue`\n    * `TensorMetaMissingRequiredValue`\n    * `TensorMetaInvalidHtypeOverwriteKey`\n    * `TensorDtypeMismatchError`\n    * `InvalidTensorLinkError`\n    * `TensorMetaMutuallyExclusiveKeysError`\n    * `ReadOnlyModeError`\n    * `TransformError`\n    * `FilterError`\n    * `InvalidInputDataError`\n    * `UnsupportedSchedulerError`\n    * `TensorMismatchError`\n    * `InvalidOutputDatasetError`\n    * `InvalidTransformDataset`\n    * `HubComposeEmptyListError`\n    * `HubComposeIncompatibleFunction`\n    * `DatasetUnsupportedPytorch`\n    * `CorruptedMetaError`\n    * `ChunkEngineError`\n    * `FullChunkError`\n    * `ChunkIdEncoderError`\n    * `ChunkSizeTooSmallError`\n    * `DatasetHandlerError`\n    * `MemoryDatasetCanNotBePickledError`\n    * `CorruptedSampleError`\n    * `VersionControlError`\n    * `MergeError`\n    * `MergeNotSupportedError`\n    * `MergeMismatchError`\n    * `MergeConflictError`\n    * `CheckoutError`\n    * `CommitError`\n    *",
        "node_814": "* sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nrotation angles are specified in degrees, not radians\n\n### Appending 3d bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98, 22, 36, 44, 18, 0, 36, 0]])\n    >>> ds.3d_boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77, 22, 36, 44, 18, 0, 28, 0],\n           [462, 123, 238,  98, 26, 34, 24, 19, 0, -50, 0],\n           [688, 108, 279, 116, 12, 32, 14, 38, 0, 30, 0]])\n    >>> boxes.shape\n    (9, 4)\n    >>> ds.3d_boxes.append(boxes)\n    \n\n## Intrinsics Htype\uf0c1\n\n  * Sample dimensions: `(# intrinsics matrices, 3, 3)`\n\nThe intrinsic matrix represents a projective transformation from the 3-D\ncamera\u2019s coordinates into the 2-D image coordinates. The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.",
        "node_749": "* Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\n  * Recompression of samples read with `deeplake.read` is also not supported.\n\nExamples\n\nAppending Deep Lake video sample\n\n    \n    \n    >>> ds.videos.append(deeplake.read(\"videos/0012.mp4\"))\n    \n\nExtending with multiple videos\n\n    \n    \n    >>> ds.videos.extend([deeplake.read(f\"videos/00{i}.mp4\") for i in range(10)])\n    \n\n## Audio Htype\uf0c1\n\n  * Sample dimensions: `(# samples in audio, # channels)` or `(# samples in audio,)`\n\n### Creating an audio tensor\uf0c1\n\nAn audio tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"audios\", htype=\"audio\", sample_compression=\"mp3\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `float64`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.",
        "node_949": "core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.\n\nSupported htypes and their respective defaults are:\n\nHtype configs\uf0c1 HTYPE | DTYPE | COMPRESSION  \n---|---|---  \ngeneric | None | None  \nimage | uint8 | Required arg  \nimage.rgb | uint8 | Required arg  \nimage.gray | uint8 | Required arg  \nvideo | uint8 | Required arg  \naudio | float64 | Required arg  \nclass_label | uint32 | None  \ntag | str | None  \nbbox | float32 | None  \nbbox.3d | float32 | None  \nintrinsics | float32 | None  \nsegment_mask | uint32 | None  \nbinary_mask | bool | None  \nkeypoints_coco | int32 | None  \npoint | int32 | None  \npolygon | float32 | None  \ntext | str | None  \njson | Any | None  \nlist | List | None  \ndicom | None | dcm  \nnifti | None | Required arg  \npoint_cloud | None | las  \nmesh | None | ply  \ninstance_label | uint32 | None  \nembedding | None | None  \nlink | str | None  \nsequence | None | None  \n  \n## Image Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # channels)` or `(height, width)`.\n\nImages can be stored in Deep Lake as compressed bytes or as raw arrays.",
        "node_561": "* Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.\n\nExamples\n\nAppending polygons with 2-D points\n\n    \n    \n    >>> poly1 = [(1, 2), (2, 3), (3, 4)]\n    >>> poly2 = [(10, 12), (14, 19)]\n    >>> poly3 = [(33, 32), (54, 67), (67, 43), (56, 98)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with 3-D points\n\n    \n    \n    >>> poly1 = [(10, 2, 9), (12, 3, 8), (12, 10, 4)]\n    >>> poly2 = [(10, 1, 8), (5, 17, 11)]\n    >>> poly3 = [(33, 33, 31), (45, 76, 13), (60, 24, 17), (67, 87, 83)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> sample = np.random.randint(0, 10, (5, 7, 2))  # 5 polygons with 7 points\n    >>> ds.polygons.append(sample)\n    \n    \n    \n    >>> import numpy as np\n    >>> poly1 = np.random.randint(0, 10, (5, 2))\n    >>> poly2 = np.random.randint(0, 10, (8, 2))\n    >>> poly3 = np.random.randint(0, 10, (3, 2))\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\n## Nifti Htype\uf0c1\n\n  * Sample dimensions: `(# height, # width, # slices)` or `(# height, # width, # slices, # time unit)` in case of time-series data.",
        "node_1154": "Note\n\n  * Commiting from a non-head node in any branch, will lead to an automatic checkout to a new branch.\n\n  * This same behaviour will happen if new samples are added or existing samples are updated from a non-head node.\n\n_property _commit_id _: Optional[str]_\uf0c1\n\n    \n\nThe lasted committed commit id of the dataset. If there are no commits, this\nreturns `None`.\n\n_property _commits _: List[Dict]_\uf0c1\n\n    \n\nLists all the commits leading to the current dataset state.\n\nReturns\n\n    \n\nList of dictionaries containing commit information.\n\nconnect(_creds_key : str_, _dest_path : Optional[str] = None_, _org_id :\nOptional[str] = None_, _ds_name : Optional[str] = None_, _token :\nOptional[str] = None_)\uf0c1\n\n    \n\nConnect a Deep Lake cloud dataset through a deeplake path.\n\nExamples\n\n    \n    \n    >>> # create/load an s3 dataset\n    >>> s3_ds = deeplake.dataset(\"s3://bucket/dataset\")\n    >>> ds = s3_ds.connect(dest_path=\"hub://my_org/dataset\", creds_key=\"my_managed_credentials_key\", token=\"my_activeloop_token)\n    >>> # or\n    >>> ds = s3_ds.connect(org_id=\"my_org\", creds_key=\"my_managed_credentials_key\", token=\"my_activeloop_token\")\n    \n\nParameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The managed credentials to be used for accessing the source path.\n\n  * **dest_path** (_str_ _,__optional_) \u2013 The full path to where the connected Deep Lake dataset will reside. Can be: a Deep Lake path like `hub://organization/dataset`\n\n  * **org_id** (_str_ _,__optional_) \u2013 The organization to where the connected Deep Lake dataset will be added.\n\n  * **ds_name** (_str_ _,__optional_) \u2013 The name of the connected Deep Lake dataset. Will be infered from `dest_path` or `src_path` if not provided.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token used to fetch the managed credentials.",
        "node_1124": "Defaults to False.\n\n  * **ingestion_batch_size** (_int_) \u2013 Batch size to use for parallel ingestion.\n\n  * **index_params** (_Dict_ _[__str_ _,__Union_ _[__int_ _,__str_ _]__]_) \u2013 \n\nDictionary containing information about vector index that will be created.\nDefaults to `None`, which will utilize `DEFAULT_VECTORSTORE_INDEX_PARAMS` from\n`deeplake.constants`. The specified key-values override the default ones:\n\n    * \u2019threshold\u2019: The threshold for the dataset size above which an index will be created for the embedding tensor. When the threshold value is set to -1, index creation is turned off. Defaults to -1, which turns off the index.\n\n    * \u2019distance_metric\u2019: This key specifies the method of calculating the distance between vectors when creating the vector database (VDB) index. It can either be a string that corresponds to a member of the DistanceType enumeration, or the string value itself.\n\n>       * If no value is provided, it defaults to \u201cL2\u201d.\n>\n>       * \u201dL2\u201d corresponds to DistanceType.L2_NORM.\n>\n>       * \u201dCOS\u201d corresponds to DistanceType.COSINE_SIMILARITY.\n\n    * \u2019additional_params\u2019: Additional parameters for fine-tuning the index.\n\n  * **exec_option** (_str_) \u2013 Default method for search execution. It could be either `\"auto\"`, `\"python\"`, `\"compute_engine\"` or `\"tensor_db\"`. Defaults to `\"auto\"`. If None, it\u2019s set to \u201cauto\u201d. \\- `auto`\\- Selects the best execution method based on the storage location of the Vector Store. It is the default option. \\- `python` \\- Pure-python implementation that runs on the client and can be used for data stored anywhere. WARNING: using this option with big datasets is discouraged because it can lead to memory issues. \\- `compute_engine` \\- Performant C++ implementation of the Deep Lake Compute Engine that runs on the client and can be used for any data stored in or connected to Deep Lake. It cannot be used with in-memory or local datasets.",
        "node_1270": "util.exceptions)\n  * log() (deeplake.core.dataset.Dataset method)\n  * LoginException (class in deeplake.util.exceptions)\n  * LRUCache (class in deeplake.core.storage)\n\n  \n---|---  \n  \n## M\n\n  * ManagedCredentialsNotFoundError (class in deeplake.util.exceptions)\n  * max_len (deeplake.core.dataset.Dataset property)\n  * max_view (deeplake.core.dataset.Dataset property)\n  * maybe_flush() (deeplake.core.storage.StorageProvider method)\n  * MemoryDatasetCanNotBePickledError (class in deeplake.util.exceptions)\n  * MemoryProvider (class in deeplake.core.storage)\n  * merge() (deeplake.core.dataset.Dataset method)\n  * merge_slices() (in module deeplake.core.index)\n  * MergeConflictError (class in deeplake.util.exceptions)\n  * MergeError (class in deeplake.util.exceptions)\n  * MergeMismatchError (class in deeplake.util.exceptions)\n  * MergeNotSupportedError (class in deeplake.util.exceptions)\n  * message (deeplake.core.dataset.ViewEntry property)\n  * meta (deeplake.core.dataset.Dataset property)\n    * (deeplake.core.tensor.Tensor property)\n\n|\n\n  * MetaAlreadyExistsError (class in deeplake.util.exceptions)\n  * MetaDoesNotExistError (class in deeplake.util.exceptions)\n  * MetaError (class in deeplake.util.exceptions)\n  * MetaInvalidKey (class in deeplake.util.exceptions)\n  * MetaInvalidRequiredMetaKey (class in deeplake.util.exceptions)\n  * min_len (deeplake.core.dataset.Dataset property)\n  * min_view (deeplake.core.dataset.Dataset property)\n  * modified_samples() (deeplake.core.tensor.Tensor method)\n  * module \n    * deeplake\n    * deeplake.api.info\n    * deeplake.integrations.wandb.",
        "node_524": "The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.\n\n  * \\\\(f_x = F / p_x\\\\)\n\n  * \\\\(f_y = F / p_y\\\\)\n\n  * \\\\(F\\\\) \\- Focal length in world units, typically expressed in millimeters.\n\n  * \\\\((p_x, p_y)\\\\) \\- Size of the pixel in world units.\n\n### Creating an intrinsics tensor\uf0c1\n\nAn intrinsics tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"intrinsics\", htype=\"intrinsics\")\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending intrinsics matrices\uf0c1\n\n    \n    \n    >>> intrinsic_params = np.zeros((3, 3))\n    >>> ds.intrinsics.append(intrinsic_params)\n    \n\n## Segmentation Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width)`\n\nSegmentation masks are 2D representations of class labels where the numerical\nlabel data is encoded in an array of same shape as the image. The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**.",
        "node_1153": "clear_cache()\uf0c1\n\n    \n\n  * Flushes (see `Dataset.flush()`) the contents of the cache layers (if any) and then deletes contents of all the layers of it.\n\n  * This doesn\u2019t delete data from the actual storage.\n\n  * This is useful if you have multiple datasets with memory caches open, taking up too much RAM.\n\n  * Also useful when local cache is no longer needed for certain datasets and is taking up storage space.\n\n_property _client\uf0c1\n\n    \n\nReturns the client of the dataset.\n\ncommit(_message : Optional[str] = None_, _allow_empty =False_) -> str\uf0c1\n\n    \n\nStores a snapshot of the current state of the dataset.\n\nParameters\n\n    \n\n  * **message** (_str_ _,__Optional_) \u2013 Used to describe the commit.\n\n  * **allow_empty** (_bool_) \u2013 If `True`, commit even if there are no changes.\n\nReturns\n\n    \n\nthe commit id of the saved commit that can be used to access the snapshot.\n\nReturn type\n\n    \n\nstr\n\nRaises\n\n    \n\n  * **Exception** \u2013 If dataset is a filtered view.\n\n  * **EmptyCommitError** \u2013 if there are no changes and user does not forced to commit unchanged data.\n\nNote\n\n  * Commiting from a non-head node in any branch, will lead to an automatic checkout to a new branch.\n\n  * This same behaviour will happen if new samples are added or existing samples are updated from a non-head node.\n\n_property _commit_id _: Optional[str]_\uf0c1\n\n    \n\nThe lasted committed commit id of the dataset. If there are no commits, this\nreturns `None`.\n\n_property _commits _: List[Dict]_\uf0c1\n\n    \n\nLists all the commits leading to the current dataset state.\n\nReturns\n\n    \n\nList of dictionaries containing commit information.\n\nconnect(_creds_key : str_, _dest_path : Optional[str] = None_, _org_id :\nOptional[str] = None_, _ds_name : Optional[str] = None_, _token :\nOptional[str] = None_)\uf0c1\n\n    \n\nConnect a Deep Lake cloud dataset through a deeplake path.",
        "node_829": "For datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.\n\n    \n    \n    >>> ds.add_creds_key(\"my_s3_creds\", managed=True)\n    >>> ds.add_creds_key(\"my_gcs_creds\", managed=True)\n    \n\nCreate a link tensor\n\n    \n    \n    >>> ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")\n    \n\nPopulate the tensor with links\n\n    \n    \n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\", creds_key=\"my_s3_key\"))\n    >>> ds.img.append(deeplake.link(\"gcs://ghi/jkl.png\", creds_key=\"GCS_KEY\"))\n    >>> ds.img.append(deeplake.link(\"https://picsum.photos/200/300\")) # http path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"./path/to/cat.jpeg\")) # local path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))  # this will throw an exception as cloud paths always need creds_key\n    :bluebold:`Accessing the data`\n    \n    \n    \n    >>> for i in range(5):\n    ...     ds.img[i].numpy()\n    ...\n    \n\nUpdating a sample\n\n    \n    \n    >>> ds.img[0] = deeplake.link(\"./data/cat.jpeg\")\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_938": "Examples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.",
        "node_540": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.gray htypes\n    * Video Htype\n      * Limitations\n      * Creating a video tensor\n      * Appending video samples\n    * Audio Htype\n      * Creating an audio tensor\n      * Appending audio samples\n    * Class Label Htype\n      * Creating a class label tensor\n      * Appending class labels\n    * Tag Htype\n      * Creating a tag tensor\n      * Appending tag samples\n    * Bounding Box Htype\n      * Creating a bbox tensor\n      * Appending bounding boxes\n    * 3D Bounding Box Htype\n      * Creating a 3d bbox tensor\n      * Appending 3d bounding boxes\n    * Intrinsics Htype\n      * Creating an intrinsics tensor\n      * Appending intrinsics matrices\n    * Segmentation Mask Htype\n      * Creating a segment_mask tensor\n      * Appending segmentation masks\n    * Binary Mask Htype\n      * Creating a binary_mask tensor\n      * Appending binary masks\n    * COCO Keypoints Htype\n      * Creating a keypoints_coco tensor\n      * Appending keypoints\n    * Point Htype\n      * Creating a point tensor\n      * Appending point samples\n    * Polygon Htype\n      * Creating a polygon tensor\n      * Appending polygons\n    * Nifti Htype\n      * Limitations\n      * Creating a nifti tensor\n      * Appending nifti data\n    * Point Cloud Htype\n      * Creating a point cloud tensor\n      * Appending point clouds\n    * Mesh Htype\n      * Creating a mesh tensor\n      * Appending meshes\n    * Embedding Htype\n      * Creating an embedding tensor\n      * Appending embedding samples\n    * Sequence htype\n    * Link htype\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.",
        "node_857": "* Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.\n\n    * If `verify=True` was specified during `create_tensor` of the tensor to which this is being added, some metadata is read from them to verify the integrity of the link samples. This is `True` by default.\n\n    * If you do not want to verify your links, all three of `verify`, `create_shape_tensor` and `create_sample_info_tensor` have to be set to `False`.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.dataset(\"......\")\n    \n\nAdding credentials to the dataset\n\nYou can add the names of the credentials you want to use (not needed for\nhttp/local urls)\n\n    \n    \n    >>> ds.add_creds_key(\"MY_S3_KEY\")\n    >>> ds.add_creds_key(\"GCS_KEY\")\n    \n\nand populate the added names with credentials dictionaries\n\n    \n    \n    >>> ds.populate_creds(\"MY_S3_KEY\", {})   # add creds here\n    >>> ds.populate_creds(\"GCS_KEY\", {})    # add creds here\n    \n\nThese creds are only present temporarily and will have to be repopulated on\nevery reload.\n\nFor datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.",
        "node_416": "`Tensor.tobytes` | Returns the bytes of the tensor.  \n`Tensor.text` | Return text data.  \n`Tensor.dict` | Return json data.  \n`Tensor.list` | Return list data.  \n`Tensor._linked_sample` | Returns the linked sample at the given index.  \n  \n## Tensor Properties\uf0c1\n\n`Tensor.htype` | Htype of the tensor.  \n---|---  \n`Tensor.base_htype` | Base htype of the tensor.  \n`Tensor.dtype` | Dtype of the tensor.  \n`Tensor.shape` | Get the shape of this tensor.  \n`Tensor.shape_interval` | Returns a `ShapeInterval` object that describes this tensor's shape more accurately.  \n`Tensor.ndim` | Number of dimensions of the tensor.  \n`Tensor.num_samples` | Returns the length of the primary axis of the tensor.  \n`Tensor.__len__` | Returns the length of the primary axis of the tensor.  \n`Tensor.is_dynamic` | Will return `True` if samples in this tensor have shapes that are unequal.  \n`Tensor.is_sequence` | Whether this tensor is a sequence tensor.  \n`Tensor.is_link` | Whether this tensor is a link tensor.  \n`Tensor.verify` | Whether linked data will be verified when samples are added.  \n  \n## Info\uf0c1\n\n`Tensor.info` | Returns the information about the tensor.  \n---|---  \n`Tensor.sample_info` | Returns info about particular samples in a tensor.  \n  \n## Video features\uf0c1\n\n`Tensor.play` | Play video sample.  \n---|---  \n`Tensor.timestamps` | Returns timestamps (in seconds) for video sample as numpy array.  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_1165": "Parameters\n\n    \n\n**large_ok** (_bool_) \u2013 Delete datasets larger than 1 GB. Defaults to `False`.\n\nRaises\n\n    \n\n  * **DatasetTooLargeToDelete** \u2013 If the dataset is larger than 1 GB and `large_ok` is `False`.\n\n  * **DatasetHandlerError** \u2013 If the dataset is marked as allow_delete=False.\n\ndelete_branch(_name : str_) -> None\uf0c1\n\n    \n\nDeletes the branch and cleans up any unneeded data. Branches can only be\ndeleted if there are no sub-branches and if it has never been merged into\nanother branch.\n\nParameters\n\n    \n\n**name** (_str_) \u2013 The branch to delete.\n\nRaises\n\n    \n\n  * **CommitError** \u2013 If `branch` could not be found.\n\n  * **ReadOnlyModeError** \u2013 If branch deletion is attempted in read-only mode.\n\n  * **Exception** \u2013 If you have the given branch currently checked out.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.empty(\"../test/test_ds\")\n    >>> ds.create_tensor(\"abc\")\n    Tensor(key='abc')\n    >>> ds.abc.append([1, 2, 3])\n    >>> first_commit = ds.commit()\n    >>> ds.checkout(\"alt\", create=True)\n    'firstdbf9474d461a19e9333c2fd19b46115348f'\n    >>> ds.abc.append([4, 5, 6])\n    >>> ds.abc.numpy()\n    array([[1, 2, 3],\n           [4, 5, 6]])\n    >>> ds.checkout(first_commit)\n    'firstdbf9474d461a19e9333c2fd19b46115348f'\n    >>> ds.delete_branch(\"alt\")\n    \n\ndelete_group(_name : str_, _large_ok : bool = False_)\uf0c1\n\n    \n\nDelete a tensor group from the dataset.\n\nExamples\n\n    \n    \n    >>> ds.delete_group(\"images/dogs\")\n    \n\nParameters\n\n    \n\n  * **name** (_str_) \u2013 The name of tensor group to be deleted.\n\n  * **large_ok** (_bool_) \u2013 Delete tensor groups larger than 1 GB. Disabled by default.",
        "node_521": "### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.\n\n### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.",
        "node_38": "Examples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.",
        "node_1246": "Set to `None` to reset the seed. Defaults to `None`.\n\nRaises\n\n    \n\n**TypeError** \u2013 If the provided value type is not supported.\n\n## Background\uf0c1\n\nSpecify a seed to train models and run randomized Deep Lake operations\nreproducibly. Features affected are:\n\n>   * Dataloader shuffling\n>\n>   * Sampling and random operations in Tensor Query Language (TQL)\n>\n>   * `Dataset.random_split`\n>\n>\n\nThe random seed can be specified using `deeplake.random.seed`:\n\n    \n    \n    >>> import deeplake\n    >>> deeplake.random.seed(0)\n    \n\n## Random number generators in other libraries\uf0c1\n\nThe Deep Lake random seed does not affect random number generators in other\nlibraries such as `numpy`.\n\nHowever, seeds in other libraries will affect code where Deep Lake uses those\nlibraries, but it will not impact the methods above where Deep Lake uses its\ninternal seed.\n\nPrevious\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_160": "Defaults to None.\n\nReturns\n\n    \n\nReturns True if deletion was successful, otherwise it raises a ValueError.\n\nReturn type\n\n    \n\nbool\n\nRaises\n\n    \n\n**ValueError** \u2013 If neither `ids`, `filter`, `query`, nor `delete_all` are\nspecified, or if an invalid `exec_option` is provided.\n\n_static _delete_by_path(_path : Union[str, Path]_, _token : Optional[str] =\nNone_, _force : bool = False_, _creds : Optional[Union[Dict, str]] = None_) ->\nNone\uf0c1\n\n    \n\nDeleted the Vector Store at the specified path.\n\nParameters\n\n    \n\n  * **path** (_str_ _,__pathlib.Path_) \u2013 The full path to the Deep Lake Vector Store.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching user credentials. This is optional, as tokens are normally autogenerated. Defaults to `None`.\n\n  * **creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **force** (_bool_) \u2013 delete the path in a forced manner without rising an exception. Defaults to `True`.\n\nDanger\n\nThis method permanently deletes all of your data if the Vector Store exists!\nBe very careful when using this method.",
        "node_380": "`Dataset.flush` | Necessary operation after writes if caches are being used.  \n`Dataset.clear_cache` | \n\n  * Flushes (see `Dataset.flush()`) the contents of the cache layers (if any) and then deletes contents of all the layers of it.\n\n  \n`Dataset.size_approx` | Estimates the size in bytes of the dataset.  \n`Dataset.random_split` | Splits the dataset into non-overlapping `Dataset` objects of given lengths.  \n  \n## Dataset Visualization\uf0c1\n\n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n---|---  \n  \n## Dataset Credentials\uf0c1\n\n`Dataset.add_creds_key` | Adds a new creds key to the dataset.  \n---|---  \n`Dataset.populate_creds` | Populates the creds key added in add_creds_key with the given creds.  \n`Dataset.update_creds_key` | Updates the name and/or management status of a creds key.  \n`Dataset.get_creds_keys` | Returns the set of creds keys added to the dataset.  \n  \n## Dataset Properties\uf0c1\n\n`Dataset.tensors` | All tensors belonging to this group, including those within sub groups.  \n---|---  \n`Dataset.groups` | All sub groups in this group  \n`Dataset.num_samples` | Returns the length of the smallest tensor.  \n`Dataset.read_only` | Returns True if dataset is in read-only mode and False otherwise.  \n`Dataset.info` | Returns the information about the dataset.  \n`Dataset.max_len` | Return the maximum length of the tensor.  \n`Dataset.min_len` | Return the minimum length of the tensor.  \n  \n## Dataset Version Control\uf0c1\n\n`Dataset.commit` | Stores a snapshot of the current state of the dataset.  \n---|---  \n`Dataset.diff` | Returns/displays the differences between commits/branches.  \n`Dataset.checkout` | Checks out to a specific commit_id or branch.  \n`Dataset.merge` | Merges the target_id into the current dataset.  \n`Dataset.log` | Displays the details of all the past commits.  \n`Dataset.reset` | Resets the uncommitted changes present in the branch.  \n`Dataset.get_commit_details` | Get details of a particular commit.",
        "node_36": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_215": "* **TensorAlreadyExistsError** \u2013 Duplicate tensors are not allowed.\n\n  * **TensorGroupAlreadyExistsError** \u2013 Duplicate tensor groups are not allowed.\n\n  * **InvalidTensorGroupNameError** \u2013 If `name` is in dataset attributes.\n\n  * **RenameError** \u2013 If `new_name` points to a group different from `name`.\n\nrename_tensor(_name : str_, _new_name : str_) -> Tensor\uf0c1\n\n    \n\nRenames tensor with name `name` to `new_name`\n\nParameters\n\n    \n\n  * **name** (_str_) \u2013 Name of tensor to be renamed.\n\n  * **new_name** (_str_) \u2013 New name of tensor.\n\nReturns\n\n    \n\nRenamed tensor.\n\nReturn type\n\n    \n\nTensor\n\nRaises\n\n    \n\n  * **TensorDoesNotExistError** \u2013 If tensor of name `name` does not exist in the dataset.\n\n  * **TensorAlreadyExistsError** \u2013 Duplicate tensors are not allowed.\n\n  * **TensorGroupAlreadyExistsError** \u2013 Duplicate tensor groups are not allowed.\n\n  * **InvalidTensorNameError** \u2013 If `new_name` is in dataset attributes.\n\n  * **RenameError** \u2013 If `new_name` points to a group different from `name`.\n\nreset(_force : bool = False_)\uf0c1\n\n    \n\nResets the uncommitted changes present in the branch.\n\nNote\n\nThe uncommitted data is deleted from underlying storage, this is not a\nreversible operation.\n\n_property _root\uf0c1\n\n    \n\nReturns the root dataset of a group.\n\nsample_by(_weights : Union[str, list, tuple]_, _replace : Optional[bool] =\nTrue_, _size : Optional[int] = None_)\uf0c1\n\n    \n\nReturns a sliced `Dataset` with given weighted sampler applied.\n\nParameters\n\n    \n\n  * **weights** \u2013 (Union[str, list, tuple]): If it\u2019s string then tql will be run to calculate the weights based on the expression. list and tuple will be treated as the list of the weights per sample.\n\n  * **replace** \u2013 Optional[bool] If true the samples can be repeated in the result view. Defaults to `True`\n\n  * **size** \u2013 Optional[int] The length of the result view. Defaults to length of the dataset.\n\nReturns\n\n    \n\nA deeplake.Dataset object.",
        "node_1036": "list, tuple and ndarray will be treated as the list of the weights per sample\n\n  * **replace** \u2013 Optional[bool] If true the samples can be repeated in the result view. (default: `True`).\n\n  * **size** \u2013 Optional[int] The length of the result view. (default: `len(dataset)`)\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nExamples\n\nSample the dataloader with `labels == 5` twice more than `labels == 6`\n\n    \n    \n    >>> ds = deeplake.load('hub://activeloop/fashion-mnist-train')\n    >>> sampled_ds = ds.dataloader().sample_by(\"max_weight(labels == 5: 10, labels == 6: 5)\")\n    \n\nSample the dataloader treating labels tensor as weights.\n\n    \n    \n    >>> ds = deeplake.load('hub://activeloop/fashion-mnist-train')\n    >>> sampled_ds = ds.dataloader().sample_by(\"labels\")\n    \n\nSample the dataloader with the given weights;\n\n    \n    \n    >>> ds_train = deeplake.load('hub://activeloop/coco-train')\n    >>> weights = list()\n    >>> for i in range(0, len(ds_train)):\n    ...     weights.append(i % 5)\n    ...\n    >>> sampled_ds = ds.dataloader().sample_by(weights, replace=False)\n    \n\nshuffle(_shuffle : bool = True_, _buffer_size : int = 2048_)\uf0c1\n\n    \n\nReturns a shuffled `DeepLakeDataLoader` object.\n\nParameters\n\n    \n\n  * **shuffle** (_bool_) \u2013 shows wheter we need to shuffle elements or not. Defaults to True.\n\n  * **buffer_size** (_int_) \u2013 The size of the buffer used to shuffle the data in MBs. Defaults to 2048 MB. Increasing the buffer_size will increase the extent of shuffling.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n  * **ValueError** \u2013 If .shuffle() has already been called.",
        "node_704": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_876": "* Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`. A set of `K` keypoints of an object is represented as:\n\n[x1, y1, v1, x2, y2, v2, \u2026, xk, yk, vk]\n\nThe visibility `v` can be one of three values:\n\n0\n\n    \n\nkeypoint not in image.\n\n1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.",
        "node_247": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n    * deeplake.api.dataset\n    * deeplake.api.info\n    * deeplake.api.link\n    * deeplake.api.read\n    * deeplake.api.tiled\n    * deeplake.api.link_tiled\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * deeplake.api\n  * Edit on GitHub\n\n* * *\n\n# deeplake.api\uf0c1\n\n  * deeplake.api.dataset\n    * `dataset`\n  * deeplake.api.info\n    * `Info`\n  * deeplake.api.link\n    * `link()`\n  * deeplake.api.read\n    * `read()`\n  * deeplake.api.tiled\n    * `tiled()`\n  * deeplake.api.link_tiled\n    * `link_tiled()`\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.",
        "node_1071": "* ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function see `deeplake.empty()`.\n\nReturns\n\n    \n\nNew dataset object with structured dataset.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **InvalidPathException** \u2013 If the source directory does not exist.\n\n  * **SamePathException** \u2013 If the source and destination path are same.\n\n  * **AutoCompressionError** \u2013 If the source director is empty or does not contain a valid extension.\n\n  * **InvalidFileExtension** \u2013 If the most frequent file extension is found to be \u2018None\u2019 during auto-compression.\n\nNote\n\n  * Currently only local source paths and image classification datasets / csv files are supported for automatic ingestion.\n\n  * Supported filetypes: png/jpeg/jpg/csv.\n\n  * All files and sub-directories with unsupported filetypes are ignored.\n\n  * Valid source directory structures for image classification look like:\n    \n        data/\n        img0.jpg\n        img1.jpg\n        ...\n    \n\n  * or:\n    \n        data/\n        class0/\n            cat0.jpg\n            ...\n        class1/\n            dog0.jpg\n            ...\n        ...\n    \n\n  * or:\n    \n        data/\n        train/\n            class0/\n                img0.jpg\n                ...\n            ...\n        val/\n            class0/\n                img0.jpg\n                ...\n            ...\n        ...\n    \n\n  * Classes defined as sub-directories can be accessed at `ds[\"test/labels\"].info.class_names`.\n\n  * Support for train and test sub directories is present under `ds[\"train/images\"]`, `ds[\"train/labels\"]` and `ds[\"test/images\"]`, `ds[\"test/labels\"]`.\n\n  * Mapping filenames to classes from an external file is currently not supported.",
        "node_1031": "Parameters\n\n    \n\n  * **num_workers** (_int_) \u2013 Number of workers to use for transforming and processing the data. Defaults to 0.\n\n  * **tensors** (_List_ _[__str_ _]__,__Optional_) \u2013 List of tensors to load. If None, all tensors are loaded. Defaults to None.\n\n  * **num_threads** (_int_ _,__Optional_) \u2013 Number of threads to use for fetching and decompressing the data. If None, the number of threads is automatically determined. Defaults to None.\n\n  * **prefetch_factor** (_int_) \u2013 Number of batches to transform and collate in advance per worker. Defaults to 2.\n\n  * **persistent_workers** (_bool_) \u2013 If `True`, the data loader will not shutdown the worker processes after a dataset has been consumed once. Defaults to `False`.\n\n  * **decode_method** (_Dict_ _[__str_ _,__str_ _]__,__Optional_) \u2013 \n\nA dictionary of decode methods for each tensor. Defaults to None.\n\n    * Supported decode methods are:-\n\n> \u2018numpy\u2019\n>  \n>\n> Default behaviour. Returns samples as numpy arrays.\n>\n> \u2019tobytes\u2019\n>  \n>\n> Returns raw bytes of the samples.\n>\n> \u2019pil\u2019\n>  \n>\n> Returns samples as PIL images. Especially useful when transformation use\n> torchvision transforms, that require PIL images as input. Only supported for\n> tensors with sample_compression=\u2019jpeg\u2019 or \u2018png\u2019.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n**ValueError** \u2013 If .pytorch() or .tensorflow() or .numpy() has already been\ncalled.\n\noffset(_off : int = 0_)\uf0c1\n\n    \n\nReturns a shifted `DeepLakeDataLoader` object.\n\nParameters\n\n    \n\n**off** (_int_) \u2013 index that the dataloadee will start to iterate.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n**ValueError** \u2013 If .offset() has already been called.",
        "node_637": "### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.\n\n### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.",
        "node_53": "Note\n\nIf you make changes to an existing dataset, commit the changes with an active\nWeights and Biases run to log it\u2019s state.\n\n## Logging Dataset Read\uf0c1\n\nA dataset read will be logged if you iterate over a dataset or call\n`Dataset.pytorch()` or `Tensor.numpy()` on its tensors.\n\n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"torch dataloader\")\n    >>> train_loader = ds.pytorch()\n    >>> run.finish()\n    \n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"iteration\")\n    >>> for sample in ds:\n    >>>     print(sample[\"images\"].shape)\n    >>> run.finish()\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_742": "For datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.\n\n    \n    \n    >>> ds.add_creds_key(\"my_s3_creds\", managed=True)\n    >>> ds.add_creds_key(\"my_gcs_creds\", managed=True)\n    \n\nCreate a link tensor\n\n    \n    \n    >>> ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")\n    \n\nPopulate the tensor with links\n\n    \n    \n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\", creds_key=\"my_s3_key\"))\n    >>> ds.img.append(deeplake.link(\"gcs://ghi/jkl.png\", creds_key=\"GCS_KEY\"))\n    >>> ds.img.append(deeplake.link(\"https://picsum.photos/200/300\")) # http path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"./path/to/cat.jpeg\")) # local path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))  # this will throw an exception as cloud paths always need creds_key\n    :bluebold:`Accessing the data`\n    \n    \n    \n    >>> for i in range(5):\n    ...     ds.img[i].numpy()\n    ...\n    \n\nUpdating a sample\n\n    \n    \n    >>> ds.img[0] = deeplake.link(\"./data/cat.jpeg\")\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_736": "* Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.\n\nExamples\n\nAppending polygons with 2-D points\n\n    \n    \n    >>> poly1 = [(1, 2), (2, 3), (3, 4)]\n    >>> poly2 = [(10, 12), (14, 19)]\n    >>> poly3 = [(33, 32), (54, 67), (67, 43), (56, 98)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with 3-D points\n\n    \n    \n    >>> poly1 = [(10, 2, 9), (12, 3, 8), (12, 10, 4)]\n    >>> poly2 = [(10, 1, 8), (5, 17, 11)]\n    >>> poly3 = [(33, 33, 31), (45, 76, 13), (60, 24, 17), (67, 87, 83)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> sample = np.random.randint(0, 10, (5, 7, 2))  # 5 polygons with 7 points\n    >>> ds.polygons.append(sample)\n    \n    \n    \n    >>> import numpy as np\n    >>> poly1 = np.random.randint(0, 10, (5, 2))\n    >>> poly2 = np.random.randint(0, 10, (8, 2))\n    >>> poly3 = np.random.randint(0, 10, (3, 2))\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\n## Nifti Htype\uf0c1\n\n  * Sample dimensions: `(# height, # width, # slices)` or `(# height, # width, # slices, # time unit)` in case of time-series data.",
        "node_1005": "| `lz4`  \n  \n## Sample Compression\uf0c1\n\nIf sample compression is specified when `creating tensors`, samples will be\ncompressed to the given format if possible. If given data is already\ncompressed and matches the provided `sample_compression`, it will be stored as\nis. If left as `None`, given samples are uncompressed.\n\nNote\n\nFor audio and video, we don\u2019t support compressing raw frames but only reading\ncompressed audio and video data.\n\nExamples:\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\")\n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\nStructure of sample-wise compressed tensor.\uf0c1\n\n## Chunk Compression\uf0c1\n\nIf chunk compression is specified when `creating tensors`, added samples will\nbe clubbed together and compressed to the given format chunk-wise. If given\ndata is already compressed, it will be uncompressed and then recompressed\nchunk-wise.\n\nNote\n\nChunk-wise compression is not supported for audio, video and point_cloud\nhtypes.\n\nExamples:\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", chunk_compression=\"jpg\")\n    \n    >>> ds.create_tensor(\"boxes\", htype=\"bbox\", chunk_compression=\"lz4\")\n    \n\nStructure of chunk-wise compressed tensor.\uf0c1\n\nNote\n\nSee `deeplake.read()` to learn how to read data from files and populate these\ntensors.\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_980": ">>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type. i.e., if RGB images are appended to an `image.gray`\ntensor, Deep Lake will convert them to grayscale and if grayscale images are\nappended to an `image.rgb` tensor, Deep Lake will convert them to RGB format.\n\nimage.rgb and image.gray tensors can be created using\n\n    \n    \n    >>> ds.create_tensor(\"rgb_images\", htype=\"image.rgb\", sample_compression=\"...\")\n    \n    \n    \n    >>> ds.create_tensor(\"gray_images\", htype=\"image.gray\", sample_compression=\"...\")\n    \n\n## Video Htype\uf0c1\n\n  * Sample dimensions: `(# frames, height, width, # channels)` or `(# frames, height, width)`\n\n### Limitations\uf0c1\n\n  * Visualization of videos in the Deep Lake App is limited by the video coded support for various browsers.\n    \n    * Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.",
        "node_64": "* **tensors** (_List_ _[__str_ _]__,__Optional_) \u2013 List of tensors to load. If None, all tensors are loaded. Defaults to `None`.\n\n  * **num_threads** (_int_ _,__Optional_) \u2013 Number of threads to use for fetching and decompressing the data. If `None`, the number of threads is automatically determined. Defaults to `None`.\n\n  * **prefetch_factor** (_int_) \u2013 Number of batches to transform and collate in advance per worker. Defaults to 2.\n\n  * **return_index** (_bool_) \u2013 Used to idnetify where loader needs to retur sample index or not. Defaults to `True`.\n\n  * **persistent_workers** (_bool_) \u2013 If `True`, the data loader will not shutdown the worker processes after a dataset has been consumed once. Defaults to `False`.\n\n  * **decode_method** (_Dict_ _[__str_ _,__str_ _]__,__Optional_) \u2013 \n\nA dictionary of decode methods for each tensor. Defaults to `None`.\n\n    * Supported decode methods are:\n\n> \u2019numpy\u2019\n>  \n>\n> Default behaviour. Returns samples as numpy arrays.\n>\n> \u2019tobytes\u2019\n>  \n>\n> Returns raw bytes of the samples.\n>\n> \u2019pil\u2019\n>  \n>\n> Returns samples as PIL images. Especially useful when transformation use\n> torchvision transforms, that require PIL images as input. Only supported for\n> tensors with `sample_compression='jpeg'` or `'png'`.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n**ValueError** \u2013 If .pytorch() or .tensorflow() or .numpy() has already been\ncalled.",
        "node_1305": "Deep Lake\n\nv3.1.0\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n\nEnterprise Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n\nAPI Reference\n\n  * deeplake\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n\n__Deep Lake\n\n  * \u00bb\n  * Deep Lake API Reference\n  * Edit on GitHub\n\n* * *\n\n# Deep Lake API Reference\u00b6\n\nDeep Lake is an open-source database for AI.",
        "node_289": "**100+ most-popular image, video, and audio datasets\navailable in seconds** Deep Lake community has uploaded 100+ image, video and\naudio datasets like MNIST, COCO, ImageNet, CIFAR, GTZAN and others.  **Instant\nVisualization Support in theDeep Lake App** Deep Lake datasets are instantly\nvisualized with bounding boxes, masks, annotations, etc. in Deep Lake\nVisualizer (see below).\n\n## \ud83d\ude80 Performance\n\nDeep Lake's performant dataloader built in C++ speeds up data streaming by >2x\ncompared to Hub 2.x (Ofeidis et al. 2022, Hambardzumyan et al. 2023)\n\n## \ud83d\ude80 How to install Deep Lake\n\nDeep Lake can be installed using pip:\n\n    \n    \n    pip3 install deeplake\n\n**By default, Deep Lake does not install dependencies for audio, video,\ngoogle-cloud, and other features. Details on all installation options\nareavailable here.**\n\n### To access all of Deep Lake's features, please register in the Deep Lake\nApp.",
        "node_894": "* Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\n  * Recompression of samples read with `deeplake.read` is also not supported.\n\nExamples\n\nAppending Deep Lake video sample\n\n    \n    \n    >>> ds.videos.append(deeplake.read(\"videos/0012.mp4\"))\n    \n\nExtending with multiple videos\n\n    \n    \n    >>> ds.videos.extend([deeplake.read(f\"videos/00{i}.mp4\") for i in range(10)])\n    \n\n## Audio Htype\uf0c1\n\n  * Sample dimensions: `(# samples in audio, # channels)` or `(# samples in audio,)`\n\n### Creating an audio tensor\uf0c1\n\nAn audio tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"audios\", htype=\"audio\", sample_compression=\"mp3\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `float64`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.",
        "node_532": "* Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.\n\nExamples\n\nAppending polygons with 2-D points\n\n    \n    \n    >>> poly1 = [(1, 2), (2, 3), (3, 4)]\n    >>> poly2 = [(10, 12), (14, 19)]\n    >>> poly3 = [(33, 32), (54, 67), (67, 43), (56, 98)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with 3-D points\n\n    \n    \n    >>> poly1 = [(10, 2, 9), (12, 3, 8), (12, 10, 4)]\n    >>> poly2 = [(10, 1, 8), (5, 17, 11)]\n    >>> poly3 = [(33, 33, 31), (45, 76, 13), (60, 24, 17), (67, 87, 83)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> sample = np.random.randint(0, 10, (5, 7, 2))  # 5 polygons with 7 points\n    >>> ds.polygons.append(sample)\n    \n    \n    \n    >>> import numpy as np\n    >>> poly1 = np.random.randint(0, 10, (5, 2))\n    >>> poly2 = np.random.randint(0, 10, (8, 2))\n    >>> poly3 = np.random.randint(0, 10, (3, 2))\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\n## Nifti Htype\uf0c1\n\n  * Sample dimensions: `(# height, # width, # slices)` or `(# height, # width, # slices, # time unit)` in case of time-series data.",
        "node_835": ">>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type. i.e., if RGB images are appended to an `image.gray`\ntensor, Deep Lake will convert them to grayscale and if grayscale images are\nappended to an `image.rgb` tensor, Deep Lake will convert them to RGB format.\n\nimage.rgb and image.gray tensors can be created using\n\n    \n    \n    >>> ds.create_tensor(\"rgb_images\", htype=\"image.rgb\", sample_compression=\"...\")\n    \n    \n    \n    >>> ds.create_tensor(\"gray_images\", htype=\"image.gray\", sample_compression=\"...\")\n    \n\n## Video Htype\uf0c1\n\n  * Sample dimensions: `(# frames, height, width, # channels)` or `(# frames, height, width)`\n\n### Limitations\uf0c1\n\n  * Visualization of videos in the Deep Lake App is limited by the video coded support for various browsers.\n    \n    * Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.",
        "node_140": "It has the following arguments:\n\n  * `data_in`: Input passed to the transform to generate output dataset.\n\n>     * It should support `__getitem__` and `__len__`. This can be a Deep Lake\n> dataset.\n\n  * `ds_out (Dataset, optional)`: The dataset object to which the transform will get written.\n\n>     * If this is not provided, data_in will be overwritten if it is a Deep\n> Lake dataset, otherwise error will be raised.\n>\n>     * It should have all keys being generated in output already present as\n> tensors.\n>\n>     * It\u2019s initial state should be either:\n>\n\n>>       * Empty i.e. all tensors have no samples. In this case all samples\nare added to the dataset.\n\n>>\n\n>>       * All tensors are populated and have same length. In this case new\nsamples are appended to the dataset.\n\n  * `num_workers (int)`: The number of workers to use for performing the transform.\n\n>     * Defaults to 0. When set to 0, it will always use serial processing,\n> irrespective of the scheduler.\n\n  * `scheduler (str)`: The scheduler to be used to compute the transformation.\n\n>     * Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019.\n> Defaults to \u2018threaded\u2019.\n\n  * `progressbar (bool)`: Displays a progress bar if `True` (default).\n\n  * `skip_ok (bool)`: If `True`, skips the check for output tensors generated.\n\n>     * This allows the user to skip certain tensors in the function\n> definition.\n>\n>     * This is especially useful for inplace transformations in which certain\n> tensors are not modified. Defaults to `False`.\n\n  * `check_lengths (bool)`: If `True`, checks whether `ds_out` has tensors of same lengths initially.\n\n  * `pad_data_in (bool)`: If `True`, pads tensors of `data_in` to match the length of the largest tensor in `data_in`. Defaults to `False`.\n\n  * `ignore_errors (bool)`: If `True`, input samples that causes transform to fail will be skipped and the errors will be ignored **if possible**.",
        "node_877": "1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.",
        "node_54": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * MMDetection\n  * Edit on GitHub\n\n* * *\n\n# MMDetection\uf0c1\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_1213": "The length should be equal to the number of samples to add.\n\n  * **progressbar** (_bool_) \u2013 Specifies whether a progressbar should be displayed while extending.\n\n  * **ignore_errors** (_bool_) \u2013 Skip samples that cause errors while extending, if set to `True`.\n\nRaises\n\n    \n\n**TensorDtypeMismatchError** \u2013 Dtype for array must be equal to or castable to\nthis tensor\u2019s dtype.\n\n_property _hidden _: bool_\uf0c1\n\n    \n\nWhether this tensor is a hidden tensor.\n\n_property _htype\uf0c1\n\n    \n\nHtype of the tensor.\n\n_property _info _: Info_\uf0c1\n\n    \n\nReturns the information about the tensor. User can set info of tensor.\n\nReturns\n\n    \n\nInformation about the tensor.\n\nReturn type\n\n    \n\nInfo\n\nExample\n\n    \n    \n    >>> # update info\n    >>> ds.images.info.update(large=True, gray=False)\n    >>> # get info\n    >>> ds.images.info\n    {'large': True, 'gray': False}\n    \n    \n    \n    >>> ds.images.info = {\"complete\": True}\n    >>> ds.images.info\n    {'complete': True}\n    \n\ninvalidate_libdeeplake_dataset()\uf0c1\n\n    \n\nInvalidates the libdeeplake dataset object.\n\n_property _is_dynamic _: bool_\uf0c1\n\n    \n\nWill return `True` if samples in this tensor have shapes that are unequal.\n\n_property _is_link\uf0c1\n\n    \n\nWhether this tensor is a link tensor.\n\n_property _is_sequence\uf0c1\n\n    \n\nWhether this tensor is a sequence tensor.\n\nlist(_fetch_chunks : bool = False_)\uf0c1\n\n    \n\nReturn list data. Only applicable for tensors with \u2018list\u2019 or \u2018tag\u2019 base htype.\n\n_property _meta\uf0c1\n\n    \n\nMetadata of the tensor.\n\nmodified_samples(_target_id : Optional[str] = None_, _return_indexes :\nOptional[bool] = False_)\uf0c1\n\n    \n\nReturns a slice of the tensor with only those elements that were\nmodified/added. By default the modifications are calculated relative to the\nprevious commit made, but this can be changed by providing a `target id`.\n\nParameters\n\n    \n\n  * **target_id** (_str_ _,__optional_) \u2013 The commit id or branch name to calculate the modifications relative to. Defaults to `None`.",
        "node_611": "The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.\n\n  * \\\\(f_x = F / p_x\\\\)\n\n  * \\\\(f_y = F / p_y\\\\)\n\n  * \\\\(F\\\\) \\- Focal length in world units, typically expressed in millimeters.\n\n  * \\\\((p_x, p_y)\\\\) \\- Size of the pixel in world units.\n\n### Creating an intrinsics tensor\uf0c1\n\nAn intrinsics tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"intrinsics\", htype=\"intrinsics\")\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending intrinsics matrices\uf0c1\n\n    \n    \n    >>> intrinsic_params = np.zeros((3, 3))\n    >>> ds.intrinsics.append(intrinsic_params)\n    \n\n## Segmentation Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width)`\n\nSegmentation masks are 2D representations of class labels where the numerical\nlabel data is encoded in an array of same shape as the image. The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**.",
        "node_419": "`Tensor.tobytes` | Returns the bytes of the tensor.  \n`Tensor.text` | Return text data.  \n`Tensor.dict` | Return json data.  \n`Tensor.list` | Return list data.  \n`Tensor._linked_sample` | Returns the linked sample at the given index.  \n  \n## Tensor Properties\uf0c1\n\n`Tensor.htype` | Htype of the tensor.  \n---|---  \n`Tensor.base_htype` | Base htype of the tensor.  \n`Tensor.dtype` | Dtype of the tensor.  \n`Tensor.shape` | Get the shape of this tensor.  \n`Tensor.shape_interval` | Returns a `ShapeInterval` object that describes this tensor's shape more accurately.  \n`Tensor.ndim` | Number of dimensions of the tensor.  \n`Tensor.num_samples` | Returns the length of the primary axis of the tensor.  \n`Tensor.__len__` | Returns the length of the primary axis of the tensor.  \n`Tensor.is_dynamic` | Will return `True` if samples in this tensor have shapes that are unequal.  \n`Tensor.is_sequence` | Whether this tensor is a sequence tensor.  \n`Tensor.is_link` | Whether this tensor is a link tensor.  \n`Tensor.verify` | Whether linked data will be verified when samples are added.  \n  \n## Info\uf0c1\n\n`Tensor.info` | Returns the information about the tensor.  \n---|---  \n`Tensor.sample_info` | Returns info about particular samples in a tensor.  \n  \n## Video features\uf0c1\n\n`Tensor.play` | Play video sample.  \n---|---  \n`Tensor.timestamps` | Returns timestamps (in seconds) for video sample as numpy array.  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_376": "---|---  \n`Dataset.sample_by` | Returns a sliced `Dataset` with given weighted sampler applied.  \n`Dataset.filter` | Filters the dataset in accordance of filter function `f(x: sample) -> bool`  \n`Dataset.save_view` | Saves a dataset view as a virtual dataset (VDS)  \n`Dataset.get_view` | Returns the dataset view corresponding to `id`.  \n`Dataset.load_view` | Loads the view and returns the `Dataset` by id.  \n`Dataset.delete_view` | Deletes the view with given view id.  \n`Dataset.get_views` | Returns list of views stored in this Dataset.  \n`Dataset.is_view` | Returns `True` if this dataset is a view and `False` otherwise.  \n`Dataset.min_view` | Returns a view of the dataset in which all tensors are sliced to have the same length as the shortest tensor.  \n`Dataset.max_view` | Returns a view of the dataset in which shorter tensors are padded with `None` s to have the same length as the longest tensor.  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_614": "* Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`. A set of `K` keypoints of an object is represented as:\n\n[x1, y1, v1, x2, y2, v2, \u2026, xk, yk, vk]\n\nThe visibility `v` can be one of three values:\n\n0\n\n    \n\nkeypoint not in image.\n\n1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.",
        "node_1261": "api.info \n    * module\n  * deeplake.integrations.wandb.wandb \n    * module\n  * DeepLakeCloudDataset (class in deeplake.core.dataset)\n  * DeepLakeDataLoader (class in deeplake.enterprise)\n  * DeeplakeRandom (class in deeplake.core.seed)\n\n|\n\n  * DeepMemory (class in deeplake.core.vectorstore.deep_memory.deep_memory)\n  * delete() (deeplake.api.dataset.dataset static method)\n    * (deeplake.core.dataset.Dataset method)\n    * (deeplake.core.dataset.DeepLakeCloudDataset method)\n    * (deeplake.core.dataset.ViewEntry method)\n    * (deeplake.core.vectorstore.deep_memory.deep_memory.DeepMemory method)\n    * (deeplake.core.vectorstore.deeplake_vectorstore.VectorStore method)\n    * (in module deeplake)\n  * delete_branch() (deeplake.core.dataset.Dataset method)\n  * delete_by_path() (deeplake.core.vectorstore.deeplake_vectorstore.VectorStore static method)\n  * delete_group() (deeplake.core.dataset.Dataset method)\n  * delete_tensor() (deeplake.core.dataset.Dataset method)\n  * delete_view() (deeplake.core.dataset.Dataset method)\n  * dict() (deeplake.core.tensor.Tensor method)\n  * diff() (deeplake.core.dataset.Dataset method)\n  * DirectoryAtPathException (class in deeplake.util.exceptions)\n  * disable_readonly() (deeplake.core.storage.StorageProvider method)\n  * download_kaggle_dataset() (in module deeplake.auto.unstructured.kaggle)\n  * downsample() (deeplake.core.index.Index method)\n    * (deeplake.core.index.IndexEntry method)\n  * dtype (deeplake.core.tensor.Tensor property)\n  * DynamicTensorNumpyError (class in deeplake.util.",
        "node_1040": "Parameters\n\n    \n\n  * **transform** (_Callable_ _or_ _Dict_ _[__Callable_ _]_) \u2013 A function or dictionary of functions to apply to the data.\n\n  * **kwargs** \u2013 Additional arguments to be passed to transform. Only applicable if transform is a callable. Ignored if transform is a dictionary.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n**ValueError** \u2013 If .transform() has already been called.\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_1210": "`Sample` is\ngenerated by `deeplake.read()`. See the above examples.\n\n_property _base_htype\uf0c1\n\n    \n\nBase htype of the tensor.\n\nExample\n\n    \n    \n    >>> ds.create_tensor(\"video_seq\", htype=\"sequence[video]\", sample_compression=\"mp4\")\n    >>> ds.video_seq.htype\n    sequence[video]\n    >>> ds.video_seq.base_htype\n    video\n    \n\nclear()\uf0c1\n\n    \n\nDeletes all samples from the tensor\n\ncreds_key()\uf0c1\n\n    \n\nReturn path data. Only applicable for linked tensors\n\ndata(_aslist : bool = False_, _fetch_chunks : bool = False_) -> Any\uf0c1\n\n    \n\nReturns data in the tensor in a format based on the tensor\u2019s base htype.\n\n  * If tensor has `text` base htype\n    \n    * Returns dict with dict[\u201cvalue\u201d] = `Tensor.text()`\n\n  * If tensor has `json` base htype\n    \n    * Returns dict with dict[\u201cvalue\u201d] = `Tensor.dict()`\n\n  * If tensor has `list` base htype\n    \n    * Returns dict with dict[\u201cvalue\u201d] = `Tensor.list()`\n\n  * For `video` tensors, returns a dict with keys \u201cframes\u201d, \u201ctimestamps\u201d and \u201csample_info\u201d:\n\n>     * Value of dict[\u201cframes\u201d] will be same as `numpy()`.\n>\n>     * Value of dict[\u201ctimestamps\u201d] will be same as `timestamps` corresponding\n> to the frames.\n>\n>     * Value of dict[\u201csample_info\u201d] will be same as `sample_info`.\n\n  * For `class_label` tensors, returns a dict with keys \u201cvalue\u201d and \u201ctext\u201d.\n\n>     * Value of dict[\u201cvalue\u201d] will be same as `numpy()`.\n>\n>     * Value of dict[\u201ctext\u201d] will be list of class labels as strings.\n\n  * For `image` or `dicom` tensors, returns dict with keys \u201cvalue\u201d and \u201csample_info\u201d.\n\n>     * Value of dict[\u201cvalue\u201d] will be same as `numpy()`.\n>\n>     * Value of dict[\u201csample_info\u201d] will be same as `sample_info`.",
        "node_1146": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n    * Dataset\n      * `Dataset`\n        * `Dataset.add_creds_key()`\n        * `Dataset.allow_delete`\n        * `Dataset.append()`\n        * `Dataset.branch`\n        * `Dataset.branches`\n        * `Dataset.checkout()`\n        * `Dataset.clear_cache()`\n        * `Dataset.client`\n        * `Dataset.commit()`\n        * `Dataset.commit_id`\n        * `Dataset.commits`\n        * `Dataset.connect()`\n        * `Dataset.copy()`\n        * `Dataset.create_group()`\n        * `Dataset.create_tensor()`\n        * `Dataset.create_tensor_like()`\n        * `Dataset.dataloader()`\n        * `Dataset.delete()`\n        * `Dataset.delete_branch()`\n        * `Dataset.delete_group()`\n        * `Dataset.delete_tensor()`\n        * `Dataset.delete_view()`\n        * `Dataset.diff()`\n        * `Dataset.extend()`\n        * `Dataset.filter()`\n        * `Dataset.fix_vc()`\n        * `Dataset.flush()`\n        * `Dataset.get_commit_details()`\n        * `Dataset.get_creds_keys()`\n        * `Dataset.get_managed_creds_keys()`\n        * `Dataset.get_view()`\n        * `Dataset.get_views()`\n        * `Dataset.groups`\n        * `Dataset.has_head_changes`\n        * `Dataset.info`\n        * `Dataset.is_head_node`\n        * `Dataset.is_view`\n        * `Dataset.",
        "node_1294": "ini\n\n|\n\n### pytest.ini\n\n|  |   \n  \n### setup.cfg\n\n|\n\n### setup.cfg\n\n|  |   \n  \n### setup.py\n\n|\n\n### setup.py\n\n|  |   \n  \n### tox.ini\n\n|\n\n### tox.ini\n\n|  |   \n  \n### webpack.common.js\n\n|\n\n### webpack.common.js\n\n|  |   \n  \n### webpack.dev.js\n\n|\n\n### webpack.dev.js\n\n|  |   \n  \n### webpack.prod.js\n\n|\n\n### webpack.prod.js\n\n|  |   \nView all files  \n  \n## Repository files navigation\n\n  * README\n  * Code of conduct\n  * MIT license\n\n# Read the Docs Sphinx Theme\n\nThis Sphinx theme was designed to provide a great reader experience for\ndocumentation users on both desktop and mobile devices. This theme is used\nprimarily on Read the Docs but can work with any Sphinx project. You can find\na working demo of the theme in the theme documentation\n\n## Installation\n\nThis theme is distributed on PyPI and can be installed with `pip`:\n\n    \n    \n    $ pip install sphinx-rtd-theme\n\nTo use the theme in your Sphinx project, you will need to edit your `conf.py`\nfile's `html_theme` setting:\n\n    \n    \n    html_theme = \"sphinx_rtd_theme\"\n\nSee also:\n\nSupported browsers\n\n    \n\nOfficially supported and tested browser/operating system combinations\n\nSupported dependencies\n\n    \n\nSupported versions of Python, Sphinx, and other dependencies.\n\nExample documentation\n\n    \n\nA full example of this theme output, with localized strings enabled.\n\n## Configuration\n\nThis theme is highly customizable on both the page level and on a global\nlevel. To see all the possible configuration options, read the documentation\non configuring the theme.\n\n## Contributing\n\nIf you would like to help modify or translate the theme, you'll find more\ninformation on contributing in our contributing guide.",
        "node_1017": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n    * General Functions\n    * Making Deep Lake Samples\n    * Parallelism\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Utility Functions\n  * Edit on GitHub\n\n* * *\n\n# Utility Functions\uf0c1\n\n## General Functions\uf0c1\n\n`exists` | Checks if a dataset exists at the given `path`.  \n---|---  \n  \n## Making Deep Lake Samples\uf0c1\n\n`read` | Utility that reads raw data from supported files into Deep Lake format.  \n---|---  \n`link` | Utility that stores a link to raw data.  \n`link_tiled` | Utility that stores links to multiple images that act as tiles and together form a big image.  \n  \n## Parallelism\uf0c1\n\n`compute` | Compute is a decorator for functions.  \n---|---  \n`compose` | Takes a list of functions decorated using `deeplake.compute()` and creates a pipeline that can be evaluated using .eval  \n  \nTransform pipelines returned by `compute()` and `compose()` are evaluated\nusing `eval`:\n\n`eval` | Evaluates the pipeline on `data_in` to produce an output dataset `ds_out`.  \n---|---  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.",
        "node_233": "extend()`\n        * `Tensor.hidden`\n        * `Tensor.htype`\n        * `Tensor.info`\n        * `Tensor.invalidate_libdeeplake_dataset()`\n        * `Tensor.is_dynamic`\n        * `Tensor.is_link`\n        * `Tensor.is_sequence`\n        * `Tensor.list()`\n        * `Tensor.meta`\n        * `Tensor.modified_samples()`\n        * `Tensor.ndim`\n        * `Tensor.num_samples`\n        * `Tensor.numpy()`\n        * `Tensor.path()`\n        * `Tensor.play()`\n        * `Tensor.pop()`\n        * `Tensor.sample_indices`\n        * `Tensor.sample_info`\n        * `Tensor.shape`\n        * `Tensor.shape_interval`\n        * `Tensor.shapes()`\n        * `Tensor.summary()`\n        * `Tensor.text()`\n        * `Tensor.timestamps`\n        * `Tensor.tobytes()`\n        * `Tensor.verify`\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * deeplake.core.tensor\n  * Edit on GitHub\n\n* * *\n\n# deeplake.core.tensor\uf0c1\n\n## Tensor\uf0c1\n\n_class _deeplake.core.tensor.Tensor\uf0c1\n\n    \n\n__len__()\uf0c1\n\n    \n\nReturns the length of the primary axis of the tensor. Accounts for indexing\ninto the tensor object.\n\nExamples\n\n    \n    \n    >>> len(tensor)\n    0\n    >>> tensor.extend(np.zeros((100, 10, 10)))\n    >>> len(tensor)\n    100\n    >>> len(tensor[5:10])\n    5\n    \n\nReturns\n\n    \n\nThe current length of this tensor.\n\nReturn type\n\n    \n\nint\n\n__setitem__(_item : Union[int, slice]_, _value : Any_)\uf0c1\n\n    \n\nUpdate samples with new values.",
        "node_1314": "v2.8.5\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Tensors\n  * Htypes\n  * Sample Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n\nExperimental API\n\n  * Dataloader & Query\n\nAPI Reference\n\n  * hub\n  * hub.core\n  * hub.core.dataset\n  * hub.core.tensor\n  * hub.api\n  * hub.auto\n  * hub.util\n  * hub.client.log\n  * hub.experimental\n  * hub.experimental.dataloader\n\n__Hub\n\n  * \u00bb\n  * Hub API Reference\n  * Edit on GitHub\n\n* * *\n\n# Hub API Reference\uf0c1\n\nHub is an open-source database for AI.\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n    * Creating Datasets\n    * Loading Datasets\n    * Deleting and Renaming Datasets\n    * Copying Datasets\n    * Dataset Operations\n    * Dataset Visualization\n    * Dataset Credentials\n    * Dataset Properties\n    * Dataset Version Control\n    * Dataset Views\n  * Tensors\n    * Creating Tensors\n    * Deleting and Renaming Tensors\n    * Adding and deleting samples\n    * Retrieving samples\n    * Tensor Properties\n    * Info\n    * Video features\n  * Htypes\n    * Sequence htype\n    * Link htype\n  * Sample Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n    * General Functions\n    * Making Hub Samples\n    * Parallelism\n\nIntegrations\n\n  * Weights and Biases\n    * Logging Dataset Creation\n    * Logging Dataset Read\n\nExperimental API\n\n  * Dataloader & Query\n\nAPI Reference\n\n  * hub\n  * hub.core\n  * hub.core.dataset\n  * hub.core.tensor\n  * hub.api\n  * hub.auto\n  * hub.util\n  * hub.client.log\n  * hub.experimental\n  * hub.experimental.dataloader\n\n# Indices and tables\uf0c1\n\n  * Index\n\n  * Module Index\n\n  * Search Page\n\nNext\n\n* * *\n\n(C) Copyright 2022, Activeloop.",
        "node_1302": "Deep Lake\n\nv3.1.5\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n\nEnterprise Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n\nAPI Reference\n\n  * deeplake\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n\n__Deep Lake\n\n  * \u00bb\n  * Deep Lake API Reference\n  * Edit on GitHub\n\n* * *\n\n# Deep Lake API Reference\u00b6\n\nDeep Lake is an open-source database for AI.",
        "node_235": "Raises an error if\nnot compatible.\n\n_property __config\uf0c1\n\n    \n\nReturns a summary of the configuration of the tensor.\n\n_linked_sample()\uf0c1\n\n    \n\nReturns the linked sample at the given index. This is only applicable for\ntensors of `link[]` htype and can only be used for exactly one sample.\n\n    \n    \n    >>> linked_sample = ds.abc[0]._linked_sample().path\n    'https://picsum.photos/200/300'\n    \n\n_pop(_index : List[int]_)\uf0c1\n\n    \n\nRemoves elements at the given indices. `index` must be sorted in descending\norder.\n\nappend(_sample : Union[Sample, ndarray, int, float, bool, dict, list, str,\ninteger, floating, bool_]_)\uf0c1\n\n    \n\nAppends a single sample to the end of the tensor. Can be an array, scalar\nvalue, or the return value from `deeplake.read()`, which can be used to load\nfiles. See examples down below.\n\nExamples\n\nNumpy input:\n\n    \n    \n    >>> len(tensor)\n    0\n    >>> tensor.append(np.zeros((28, 28, 1)))\n    >>> len(tensor)\n    1\n    \n\nFile input:\n\n    \n    \n    >>> len(tensor)\n    0\n    >>> tensor.append(deeplake.read(\"path/to/file\"))\n    >>> len(tensor)\n    1\n    \n\nParameters\n\n    \n\n**sample** (_InputSample_) \u2013 The data to append to the tensor. `Sample` is\ngenerated by `deeplake.read()`. See the above examples.\n\n_property _base_htype\uf0c1\n\n    \n\nBase htype of the tensor.\n\nExample\n\n    \n    \n    >>> ds.create_tensor(\"video_seq\", htype=\"sequence[video]\", sample_compression=\"mp4\")\n    >>> ds.video_seq.htype\n    sequence[video]\n    >>> ds.video_seq.base_htype\n    video\n    \n\nclear()\uf0c1\n\n    \n\nDeletes all samples from the tensor\n\ncreds_key()\uf0c1\n\n    \n\nReturn path data. Only applicable for linked tensors\n\ndata(_aslist : bool = False_, _fetch_chunks : bool = False_) -> Any\uf0c1\n\n    \n\nReturns data in the tensor in a format based on the tensor\u2019s base htype.",
        "node_1111": "These images must all have the exact same dimensions. Used\nto add data to a Deep Lake Dataset without copying it. See Link htype.\n\nSupported file types:\n\n    \n    \n    Image: \"bmp\", \"dib\", \"gif\", \"ico\", \"jpeg\", \"jpeg2000\", \"pcx\", \"png\", \"ppm\", \"sgi\", \"tga\", \"tiff\", \"webp\", \"wmf\", \"xbm\"\n    \n\nParameters\n\n    \n\n  * **path_array** (_np.ndarray_) \u2013 N dimensional array of paths to the data, with paths corresponding to respective tiles. The array must have dtype=object and have string values. Each string must point to an image file with the same dimensions.\n\n  * **creds_key** (_optional_ _,__str_) \u2013 The credential key to use to read data for this sample. The actual credentials are fetched from the dataset.\n\nReturns\n\n    \n\nLinkedTiledSample object that stores path_array and creds.\n\nReturn type\n\n    \n\nLinkedTiledSample\n\nExamples\n\n    \n    \n    >>> ds = deeplake.dataset(\"test/test_ds\")\n    >>> ds.create_tensor(\"images\", htype=\"link[image]\", sample_compression=\"jpeg\")\n    >>> arr = np.empty((10, 10), dtype=object)\n    >>> for j, i in itertools.product(range(10), range(10)):\n    ...     arr[j, i] = f\"s3://my_bucket/my_image_{j}_{i}.jpeg\"\n    ...\n    >>> ds.images.append(deeplake.link_tiled(arr, creds_key=\"my_s3_key\"))\n    >>> # If all images are 1000x1200x3, we now have a 10000x12000x3 image in our dataset.\n    \n\ndeeplake.tiled(_sample_shape : Tuple[int, ...]_, _tile_shape :\nOptional[Tuple[int, ...]] = None_, _dtype : Union[str, dtype] =\ndtype('uint8')_)\uf0c1\n\n    \n\nAllocates an empty sample of shape `sample_shape`, broken into tiles of shape\n`tile_shape` (except for edge tiles).",
        "node_46": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n    * Sample Compression\n    * Chunk Compression\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Compressions\n  * Edit on GitHub\n\n* * *\n\n# Compressions\uf0c1\n\nDeep Lake can read, compress, decompress and recompress data to different\nformats. The supported htype-compression configurations are given below.\n\nSample Type | Htype | Compressions  \n---|---|---  \nImage | image |  `bmp`, `dib`, `gif`, `ico`, `jpeg`, `jpeg2000`, `pcx`, `png`, `ppm`, `sgi`, `tga`, `tiff`, `webp`, `wmf`, `xbm`, `eps`, `fli`, `im`, `msp`, `mpo`, `apng`  \nVideo | video | `mp4`, `mkv`, `avi`  \nAudio | audio | `flac`, `mp3`, `wav`  \nDicom | dicom | `dcm`  \nPoint Cloud | point_cloud | `las`  \nMesh | mesh | `ply`  \nOther | bbox, text, list, json, generic, etc. | `lz4`  \n  \n## Sample Compression\uf0c1\n\nIf sample compression is specified when `creating tensors`, samples will be\ncompressed to the given format if possible.",
        "node_869": "* **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.boxes.info.update(coords = {\"type\": \"pixel\", \"mode\": \"LTRB\"})\n    \n\nNote\n\nIf the bounding box format is not specified, the visualizer will assume a YOLO\nformat (`fractional` \\+ `CCWH`) if the box coordinates are < 1 on average.\nOtherwise, it will assume the COCO format (`pixel` \\+ `LTWH`).\n\n### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.",
        "node_1032": ">\n> \u2019pil\u2019\n>  \n>\n> Returns samples as PIL images. Especially useful when transformation use\n> torchvision transforms, that require PIL images as input. Only supported for\n> tensors with sample_compression=\u2019jpeg\u2019 or \u2018png\u2019.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n**ValueError** \u2013 If .pytorch() or .tensorflow() or .numpy() has already been\ncalled.\n\noffset(_off : int = 0_)\uf0c1\n\n    \n\nReturns a shifted `DeepLakeDataLoader` object.\n\nParameters\n\n    \n\n**off** (_int_) \u2013 index that the dataloadee will start to iterate.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n**ValueError** \u2013 If .offset() has already been called.\n\npytorch(_num_workers : int = 0_, _collate_fn : Optional[Callable] = None_,\n_tensors : Optional[List[str]] = None_, _num_threads : Optional[int] = None_,\n_prefetch_factor : int = 2_, _distributed : bool = False_, _return_index :\nbool = True_, _decode_method : Optional[Dict[str, str]] = None_,\n_persistent_workers : bool = False_)\uf0c1\n\n    \n\nReturns a `DeepLakeDataLoader` object.\n\nParameters\n\n    \n\n  * **num_workers** (_int_) \u2013 Number of workers to use for transforming and processing the data. Defaults to 0.\n\n  * **collate_fn** (_Callable_ _,__Optional_) \u2013 merges a list of samples to form a mini-batch of Tensor(s).\n\n  * **tensors** (_List_ _[__str_ _]__,__Optional_) \u2013 List of tensors to load. If None, all tensors are loaded. Defaults to `None`.\n\n  * **num_threads** (_int_ _,__Optional_) \u2013 Number of threads to use for fetching and decompressing the data. If `None`, the number of threads is automatically determined. Defaults to `None`.\n\n  * **prefetch_factor** (_int_) \u2013 Number of batches to transform and collate in advance per worker. Defaults to 2.",
        "node_867": "`tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.\n\n### Appending class labels\uf0c1\n\n  * Class labels can be appended as `int`, `str`, `np.ndarray` or `list` of `int` or `str`.\n\n  * In case of strings, `tensor.info.class_names` is updated automatically.\n\nExamples\n\nAppending index\n\n    \n    \n    >>> ds.labels.append(0)\n    >>> ds.labels.append(np.zeros((5,), dtype=np.uint32))\n    \n\nExtending with list of indices\n\n    \n    \n    >>> ds.labels.extend([[0, 1, 2], [1, 3]])\n    \n\nAppending text labels\n\n    \n    \n    >>> ds.labels.append([\"cars\", \"airplanes\"])\n    \n\n## Tag Htype\uf0c1\n\n  * Sample dimensions: `(# tags,)`\n\nThis htype can be used to tag samples with one or more string values.\n\n### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.",
        "node_699": "The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.\n\n  * \\\\(f_x = F / p_x\\\\)\n\n  * \\\\(f_y = F / p_y\\\\)\n\n  * \\\\(F\\\\) \\- Focal length in world units, typically expressed in millimeters.\n\n  * \\\\((p_x, p_y)\\\\) \\- Size of the pixel in world units.\n\n### Creating an intrinsics tensor\uf0c1\n\nAn intrinsics tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"intrinsics\", htype=\"intrinsics\")\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending intrinsics matrices\uf0c1\n\n    \n    \n    >>> intrinsic_params = np.zeros((3, 3))\n    >>> ds.intrinsics.append(intrinsic_params)\n    \n\n## Segmentation Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width)`\n\nSegmentation masks are 2D representations of class labels where the numerical\nlabel data is encoded in an array of same shape as the image. The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**.",
        "node_240": "_property _is_link\uf0c1\n\n    \n\nWhether this tensor is a link tensor.\n\n_property _is_sequence\uf0c1\n\n    \n\nWhether this tensor is a sequence tensor.\n\nlist(_fetch_chunks : bool = False_)\uf0c1\n\n    \n\nReturn list data. Only applicable for tensors with \u2018list\u2019 or \u2018tag\u2019 base htype.\n\n_property _meta\uf0c1\n\n    \n\nMetadata of the tensor.\n\nmodified_samples(_target_id : Optional[str] = None_, _return_indexes :\nOptional[bool] = False_)\uf0c1\n\n    \n\nReturns a slice of the tensor with only those elements that were\nmodified/added. By default the modifications are calculated relative to the\nprevious commit made, but this can be changed by providing a `target id`.\n\nParameters\n\n    \n\n  * **target_id** (_str_ _,__optional_) \u2013 The commit id or branch name to calculate the modifications relative to. Defaults to `None`.\n\n  * **return_indexes** (_bool_ _,__optional_) \u2013 If `True`, returns the indexes of the modified elements. Defaults to `False`.\n\nReturns\n\n    \n\nA new tensor with only the modified elements if `return_indexes` is `False`.\nTuple[Tensor, List[int]]: A new tensor with only the modified elements and the\nindexes of the modified elements if `return_indexes` is `True`.\n\nReturn type\n\n    \n\nTensor\n\nRaises\n\n    \n\n**TensorModifiedError** \u2013 If a target id is passed which is not an ancestor of\nthe current commit.\n\n_property _ndim _: int_\uf0c1\n\n    \n\nNumber of dimensions of the tensor.\n\n_property _num_samples _: int_\uf0c1\n\n    \n\nReturns the length of the primary axis of the tensor. Ignores any applied\nindexing and returns the total length.\n\nnumpy(_aslist =False_, _fetch_chunks =False_) -> Union[ndarray,\nList[ndarray]]\uf0c1\n\n    \n\nComputes the contents of the tensor in numpy format.\n\nParameters\n\n    \n\n  * **aslist** (_bool_) \u2013 If `True`, a list of np.ndarrays will be returned. Helpful for dynamic tensors. If `False`, a single np.ndarray will be returned unless the samples are dynamically shaped, in which case an error is raised.",
        "node_471": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_1285": "# Sphinx\n\n### Navigation\n\n  * Documentation \u00bb\n  * Welcome\n\n### On this page\n\n  * Welcome\n    * Get started\n    * User Guides\n    * Community guide\n    * Reference guide\n\n### Site navigation\n\nGet started\n\n  * Getting Started\n  * Installing Sphinx\n  * Tutorial: Build your first project\n\nUser Guides\n\n  * Using Sphinx\n  * Writing Sphinx Extensions\n  * LaTeX customization\n  * Sphinx Extensions API\n\nCommunity\n\n  * Get support\n  * Contribute to Sphinx\n  * Sphinx FAQ\n  * Sphinx authors\n\nReference\n\n  * Command-Line Tools\n  * Configuration\n  * Extensions\n  * reStructuredText\n  * Glossary\n  * Changelog\n  * Projects using Sphinx\n\n# Welcome\u00b6\n\n> Sphinx makes it easy to create intelligent and beautiful documentation.\n\nHere are some of Sphinx\u2019s major features:\n\n  * **Output formats:** HTML (including Windows HTML Help), LaTeX (for printable PDF versions), ePub, Texinfo, manual pages, plain text\n\n  * **Extensive cross-references:** semantic markup and automatic links for functions, classes, citations, glossary terms and similar pieces of information\n\n  * **Hierarchical structure:** easy definition of a document tree, with automatic links to siblings, parents and children\n\n  * **Automatic indices:** general index as well as a language-specific module indices\n\n  * **Code handling:** automatic highlighting using the Pygments highlighter\n\n  * **Extensions:** automatic testing of code snippets, inclusion of docstrings from Python modules (API docs) via built-in extensions, and much more functionality via third-party extensions.\n\n  * **Themes:** modify the look and feel of outputs via creating themes, and reuse many third-party themes.\n\n  * **Contributed extensions:** dozens of extensions contributed by users; most of them installable from PyPI.\n\nSphinx uses the reStructuredText markup language by default, and can read MyST\nmarkdown via third-party extensions. Both of these are powerful and\nstraightforward to use, and have functionality for complex documentation and\npublishing workflows. They both build upon Docutils to parse and write\ndocuments.\n\nSee below for how to navigate Sphinx\u2019s documentation.\n\nSee also\n\nThe Sphinx documentation Table of Contents has a full list of this site\u2019s\npages.",
        "node_348": "---|---  \n`Dataset.sample_by` | Returns a sliced `Dataset` with given weighted sampler applied.  \n`Dataset.filter` | Filters the dataset in accordance of filter function `f(x: sample) -> bool`  \n`Dataset.save_view` | Saves a dataset view as a virtual dataset (VDS)  \n`Dataset.get_view` | Returns the dataset view corresponding to `id`.  \n`Dataset.load_view` | Loads the view and returns the `Dataset` by id.  \n`Dataset.delete_view` | Deletes the view with given view id.  \n`Dataset.get_views` | Returns list of views stored in this Dataset.  \n`Dataset.is_view` | Returns `True` if this dataset is a view and `False` otherwise.  \n`Dataset.min_view` | Returns a view of the dataset in which all tensors are sliced to have the same length as the shortest tensor.  \n`Dataset.max_view` | Returns a view of the dataset in which shorter tensors are padded with `None` s to have the same length as the longest tensor.  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_224": "Parameters\n\n    \n\n  * **width** \u2013 Union[int, str, None] Optional width of the visualizer canvas.\n\n  * **height** \u2013 Union[int, str, None] Optional height of the visualizer canvas.\n\nRaises\n\n    \n\n**Exception** \u2013 If the dataset is not a Deep Lake cloud dataset and the\nvisualization is attempted in colab.\n\n## DeepLakeCloudDataset\uf0c1\n\n_class _deeplake.core.dataset.DeepLakeCloudDataset\uf0c1\n\n    \n\nBases: `Dataset`\n\nSubclass of `Dataset`. Deep Lake cloud datasets are those datasets which are\nstored in or connected to Activeloop servers, their paths look like:\n`hub://username/dataset_name`.\n\nadd_creds_key(_creds_key : str_, _managed : bool = False_)\uf0c1\n\n    \n\nAdds a new creds key to the dataset. These keys are used for tensors that are\nlinked to external data.\n\nExamples\n\n    \n    \n    >>> # create/load a dataset\n    >>> ds = deeplake.dataset(\"hub://username/dataset\")\n    >>> # add a new creds key\n    >>> ds.add_creds_key(\"my_s3_key\")\n    \n\nParameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The key to be added.\n\n  * **managed** (_bool_) \u2013 If `True`, the creds corresponding to the key will be fetched from activeloop platform. Note, this is only applicable for datasets that are connected to activeloop platform. Defaults to `False`.\n\n_property _client\uf0c1\n\n    \n\nReturns the client of the dataset.\n\nconnect(_* args_, _** kwargs_)\uf0c1\n\n    \n\nConnect a Deep Lake cloud dataset through a deeplake path.",
        "node_1023": "Deep Lake will\nautomatically push all information required to reproduce the snapshot of the\ndata like your dataset\u2019s URI, commit ID, and view IDs of any views that you\nhave used in your training workflow.\n\nLearn more about Weights and Biases here.\n\n## Logging Dataset Creation\uf0c1\n\nIf you create a Deep Lake dataset using any of the functions mentioned in\nCreating Datasets, just perform a commit on the dataset to log its creation on\nW&B.\n\n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"dataset_upload\")\n    >>> ds = deeplake.empty(\"hub://fayazrahman4u/my_dataset\") # create dataset\n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\") # create a tensor\n    >>> ds.images.append(deeplake.read(\"files/images/dog.jpg\")) # add a sample\n    >>> ds.commit(\"creation\") # commit -> trigger logging\n    >>> run.finish()\n    \n\nNote\n\nIf you created your dataset using `deeplake.deepcopy()`, perform the commit\nonly if you have head changes.\n\nNote\n\nIf you make changes to an existing dataset, commit the changes with an active\nWeights and Biases run to log it\u2019s state.\n\n## Logging Dataset Read\uf0c1\n\nA dataset read will be logged if you iterate over a dataset or call\n`Dataset.pytorch()` or `Tensor.numpy()` on its tensors.\n\n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"torch dataloader\")\n    >>> train_loader = ds.pytorch()\n    >>> run.finish()\n    \n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"iteration\")\n    >>> for sample in ds:\n    >>>     print(sample[\"images\"].shape)\n    >>> run.finish()\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.",
        "node_668": "### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.\n    \n        * \u201ccenter\u201d: [center_x, center_y, center_z, size_x, size_y, size_z, rot_x, rot_y, rot_z]\n    \n          * Sample dimensions: `(# bounding boxes, 9)`\n\n          * `size_x` \\- is the length of the bounding box along x direction\n\n          * `size_y` \\- is the width of the bounding box along y direction\n\n          * `size_z` \\- is the height of the bounding box along z direction\n\n          * `rot_x` \\- rotation angle along x axis, given in degrees\n\n          * `rot_y` \\- rotation angle along y axis, given in degrees\n\n          * `rot_z` \\- rotation angle along z axis, given in degrees\n\n        * \u201cvertex\u201d: 8 3D vertices - [[x0, y0, z0], [x1, y1, z1], [x2, y2, z2], \u2026.., [x7, y7, z7]]\n    \n          * Sample dimensions: `(# bounding boxes, 8, 3)`\n\nThe vertex order is of the following form:\n\n                \n                                      4_____________________ 5\n                     /|                    /|\n                    / |                   / |\n                   /  |                  /  |\n                  /___|_________________/   |\n                0|    |                 | 1 |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |_________________|___|\n                 |   /  7               |   / 6\n                 |  /                   |  /\n                 | /                    | /\n                 |/_____________________|/\n                  3                      2\n                \n\n    * **dtype** : Defaults to `float32`.",
        "node_278": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n# Indices and tables\uf0c1\n\n  * Index\n\n  * Module Index\n\n  * Search Page\n\nNext\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_187": "* To see all htypes and their correspondent arguments, check out Htypes.\n\nReturns\n\n    \n\nThe new tensor, which can be accessed by `dataset[name]` or `dataset.name`.\n\nReturn type\n\n    \n\nTensor\n\nRaises\n\n    \n\n  * **TensorAlreadyExistsError** \u2013 If the tensor already exists and `exist_ok` is `False`.\n\n  * **TensorGroupAlreadyExistsError** \u2013 Duplicate tensor groups are not allowed.\n\n  * **InvalidTensorNameError** \u2013 If `name` is in dataset attributes.\n\n  * **NotImplementedError** \u2013 If trying to override `chunk_compression`.\n\n  * **TensorMetaInvalidHtype** \u2013 If invalid htype is specified.\n\n  * **ValueError** \u2013 If an illegal argument is specified.\n\ncreate_tensor_like(_name : str_, _source : Tensor_, _unlink : bool = False_)\n-> Tensor\uf0c1\n\n    \n\nCopies the `source` tensor\u2019s meta information and creates a new tensor with\nit. No samples are copied, only the meta/info for the tensor is.\n\nExamples\n\n    \n    \n    >>> ds.create_tensor_like(\"cats\", ds[\"images\"])\n    \n\nParameters\n\n    \n\n  * **name** (_str_) \u2013 Name for the new tensor.\n\n  * **source** (_Tensor_) \u2013 Tensor who\u2019s meta/info will be copied. May or may not be contained in the same dataset.\n\n  * **unlink** (_bool_) \u2013 Whether to unlink linked tensors.\n\nReturns\n\n    \n\nNew Tensor object.\n\nReturn type\n\n    \n\nTensor\n\ndataloader(_ignore_errors : bool = False_, _verbose : bool = False_)\uf0c1\n\n    \n\nReturns a `DeepLakeDataLoader` object.\n\nParameters\n\n    \n\n  * **ignore_errors** (_bool_) \u2013 If `True`, the data loader will ignore errors appeared during data iteration otherwise it will collect the statistics and report appeared errors. Default value is `False`\n\n  * **verbose** (_bool_) \u2013 If `True`, the data loader will dump verbose logs of it\u2019s steps. Default value is `False`\n\nReturns\n\n    \n\nA `deeplake.enterprise.DeepLakeDataLoader` object.",
        "node_211": "query(_query_string : str_, _runtime : Optional[Dict] = None_, _return_data :\nbool = False_)\uf0c1\n\n    \n\nReturns a sliced `Dataset` with given query results.\n\nIt allows to run SQL like queries on dataset and extract results. See\nsupported keywords and the Tensor Query Language documentation here.\n\nParameters\n\n    \n\n  * **query_string** (_str_) \u2013 An SQL string adjusted with new functionalities to run on the given `Dataset` object\n\n  * **runtime** (_Optional_ _[__Dict_ _]_) \u2013 Runtime parameters for query execution. Supported keys: {\u201ctensor_db\u201d: True or False}.\n\n  * **return_data** (_bool_) \u2013 Defaults to `False`. Whether to return raw data along with the view.\n\nRaises\n\n    \n\n**ValueError** \u2013 if `return_data` is True and runtime is not {\u201ctensor_db\u201d:\ntrue}\n\nReturns\n\n    \n\nA `Dataset` object.\n\nReturn type\n\n    \n\nDataset\n\nExamples\n\nQuery from dataset all the samples with lables other than `5`\n\n    \n    \n    >>> import deeplake\n    >>> ds = deeplake.load('hub://activeloop/fashion-mnist-train')\n    >>> query_ds = ds.query(\"select * where labels != 5\")\n    \n\nQuery from dataset first appeard `1000` samples where the `categories` is\n`car` and `1000` samples where the `categories` is `motorcycle`\n\n    \n    \n    >>> ds_train = deeplake.load('hub://activeloop/coco-train')\n    >>> query_ds_train = ds_train.query(\"(select * where contains(categories, 'car') limit 1000) union (select * where contains(categories, 'motorcycle') limit 1000)\")\n    \n\nrandom_split(_lengths : Sequence[Union[int, float]]_)\uf0c1\n\n    \n\nSplits the dataset into non-overlapping `Dataset` objects of given lengths. If\na list of fractions that sum up to 1 is given, the lengths will be computed\nautomatically as floor(frac * len(dataset)) for each fraction provided.\n\nAfter computing the lengths, if there are any remainders, 1 count will be\ndistributed in round-robin fashion to the lengths until there are no\nremainders left.",
        "node_68": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n    * Syntax\n      * SELECT\n      * WHERE\n      * ORDER BY\n      * LIMIT OFFSET\n      * Expressions\n      * Functions\n      * UNION, INTERSECT, EXCEPT\n    * Examples\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Tensor Query Language\n  * Edit on GitHub\n\n* * *\n\n# Tensor Query Language\uf0c1\n\nThis page describes the Tensor Query Language (TQL), an SQL-like language used\nfor Querying in Activeloop Platform as well as in `ds.query` in our Python\nAPI.\n\n## Syntax\uf0c1\n\n### SELECT\uf0c1\n\nTQL supports only `SELECT` statement. Every TQL expression starts with `SELECT\n*`. TQL supports only `*` which means to select all tensors. The common syntax\nfor select statement is the following:\n\n    \n    \n    SELECT * [FROM string] [WHERE expression] [LIMIT number [OFFSET number]] [ORDER BY expression [ASC/DESC]]\n    \n\nEach part of the `SELECT` statement can be omitted.\n\n`FROM` expression is allowed, but it does not have any effect on the query,\nbecause for now TQL queries are run on a specific dataset, so the `FROM` is\nknown from the context\n\n### WHERE\uf0c1\n\n`WHERE` expression is used to filter the samples in the dataset by conditions.",
        "node_1185": "query(_query_string : str_, _runtime : Optional[Dict] = None_, _return_data :\nbool = False_)\uf0c1\n\n    \n\nReturns a sliced `Dataset` with given query results.\n\nIt allows to run SQL like queries on dataset and extract results. See\nsupported keywords and the Tensor Query Language documentation here.\n\nParameters\n\n    \n\n  * **query_string** (_str_) \u2013 An SQL string adjusted with new functionalities to run on the given `Dataset` object\n\n  * **runtime** (_Optional_ _[__Dict_ _]_) \u2013 Runtime parameters for query execution. Supported keys: {\u201ctensor_db\u201d: True or False}.\n\n  * **return_data** (_bool_) \u2013 Defaults to `False`. Whether to return raw data along with the view.\n\nRaises\n\n    \n\n**ValueError** \u2013 if `return_data` is True and runtime is not {\u201ctensor_db\u201d:\ntrue}\n\nReturns\n\n    \n\nA `Dataset` object.\n\nReturn type\n\n    \n\nDataset\n\nExamples\n\nQuery from dataset all the samples with lables other than `5`\n\n    \n    \n    >>> import deeplake\n    >>> ds = deeplake.load('hub://activeloop/fashion-mnist-train')\n    >>> query_ds = ds.query(\"select * where labels != 5\")\n    \n\nQuery from dataset first appeard `1000` samples where the `categories` is\n`car` and `1000` samples where the `categories` is `motorcycle`\n\n    \n    \n    >>> ds_train = deeplake.load('hub://activeloop/coco-train')\n    >>> query_ds_train = ds_train.query(\"(select * where contains(categories, 'car') limit 1000) union (select * where contains(categories, 'motorcycle') limit 1000)\")\n    \n\nrandom_split(_lengths : Sequence[Union[int, float]]_)\uf0c1\n\n    \n\nSplits the dataset into non-overlapping `Dataset` objects of given lengths. If\na list of fractions that sum up to 1 is given, the lengths will be computed\nautomatically as floor(frac * len(dataset)) for each fraction provided.\n\nAfter computing the lengths, if there are any remainders, 1 count will be\ndistributed in round-robin fashion to the lengths until there are no\nremainders left.",
        "node_1297": "Release documentation\nto your users on each merge.\n\n__\n\n##  Ideal developer experience\n\nWrite documentation without changing your workflow or your tools using a\n**docs as code** approach.\n\n__\n\n##  Work privately or publicly\n\nEasily share within your team or with the whole world. Manage permissions\nyourself or automatically with GitHub.\n\n###  Features\n\n__\n\n###  Supports any doc tool\n\nIntegrated support for **Sphinx** , **MkDocs** , **Jupyter Book**. Flexible\nenough to work with any documentation tool.\n\n__\n\n###  Integrated search\n\nEasily search all your docs via our dashboard, and offer your users a more\npowerful search with our search API.\n\n__\n\n###  Pull request previews\n\nPreview each pull request before releasing any changes, allowing for fast\ncollaboration across your organization.\n\n__\n\n###  Versioned docs\n\nMatch your product release cycle with multiple versions of your docs.\nAutomatically build versions from any branch or tag.\n\n__\n\n###  Private repository support  __ Paid plan feature\n\nClone private repositories using a connected GitHub, GitLab, or Bitbucket\naccount, or clone from any Git provider with an SSH key.\n\n__\n\n###  Single-Sign On  __ Paid plan feature\n\nControl who has access to your documentation with integrated authentication.\nEnable **SSO with GitHub or GitLab** to easily manage permissions in one\nplace.\n\nDiscover all our features __\n\nTry it out\n\n##  Upgrade your documentation with Read the Docs\n\n__`.readthedocs.yaml`\n\n    \n    \n    version: 2\n    build:\n      os: ubuntu-22.04\n      tools:\n        python: \"3.10\"\n        # You can also specify other tool versions:\n        # nodejs: \"16\"\n    \n    # Build documentation in the docs/ directory with Sphinx\n    sphinx:\n       configuration: docs/conf.py\n    \n    # Dependencies required to build your docs\n    python:\n       install:\n       - requirements: docs/requirements.txt\n    \n\n__ Create an account  Sign up  with GitHub or your email.  __ Import your\nproject Select your existing Git repositories with a 1-click interface. __ Add\nYAML config Copy this example, it probably does what you want \ud83d\ude09 __ Your docs\nbuild on every commit Like magic.",
        "node_490": "### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.\n\nExamples\n\nAppending a tag\n\n    \n    \n    >>> ds.tags.append(\"verified\")\n    \n\nExtending with list of tags\n\n    \n    \n    >>> ds.tags.extend([\"verified\", \"unverified\"])\n    \n\n## Bounding Box Htype\uf0c1\n\n  * Sample dimensions: `(# bounding boxes, 4)`\n\nBounding boxes have a variety of conventions such as those used in YOLO, COCO,\nPascal-VOC and others. In order for bounding boxes to be correctly displayed\nby the visualizer, the format of the bounding box must be specified in the\ncoords key in tensor meta information mentioned below.\n\n### Creating a bbox tensor\uf0c1\n\nA bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"boxes\", htype=\"bbox\", coords={\"type\": \"fractional\", \"mode\": \"CCWH\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with keys \u201ctype\u201d and \u201cmode\u201d.\n    \n      * **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.",
        "node_1216": "Raises\n\n    \n\n  * **DynamicTensorNumpyError** \u2013 If reading a dynamically-shaped array slice without `aslist=True`.\n\n  * **ValueError** \u2013 If the tensor is a link and the credentials are not populated.\n\nReturns\n\n    \n\nA numpy array containing the data represented by this tensor.\n\nNote\n\nFor tensors of htype `polygon`, aslist is always `True`.\n\npath(_aslist : bool = True_, _fetch_chunks : bool = False_)\uf0c1\n\n    \n\nReturn path data. Only applicable for linked tensors.\n\nParameters\n\n    \n\n  * **aslist** (_bool_) \u2013 Returns links in a list if `True`.\n\n  * **fetch_chunks** (_bool_) \u2013 If `True`, full chunks will be retrieved from the storage, otherwise only required bytes will be retrieved.\n\nReturns\n\n    \n\nA list or numpy array of links.\n\nReturn type\n\n    \n\nUnion[np.ndarray, List]\n\nRaises\n\n    \n\n**Exception** \u2013 If the tensor is not a linked tensor.\n\nplay()\uf0c1\n\n    \n\nPlay video sample. Plays video in Jupyter notebook or plays in web browser.\nVideo is streamed directly from storage. This method will fail for\nincompatible htypes.\n\nExample\n\n    \n    \n    >>> ds = deeplake.load(\"./test/my_video_ds\")\n    >>> # play second sample\n    >>> ds.videos[2].play()\n    \n\nNote\n\nVideo streaming is not yet supported on colab.\n\npop(_index : Optional[Union[int, List[int]]] = None_)\uf0c1\n\n    \n\nRemoves element(s) at the given index / indices.\n\n_property _sample_indices\uf0c1\n\n    \n\nReturns all the indices pointed to by this tensor in the dataset view.\n\n_property _sample_info _: Union[Dict, List[Dict]]_\uf0c1\n\n    \n\nReturns info about particular samples in a tensor. Returns dict in case of\nsingle sample, otherwise list of dicts. Data in returned dict would depend on\nthe tensor\u2019s htype and the sample itself.",
        "node_364": "---|---  \n`deeplake.empty` | Creates an empty dataset  \n`deeplake.like` | Creates a new dataset by copying the `source` dataset's structure to a new location.  \n`deeplake.ingest_classification` | Ingest a dataset of images from a local folder to a Deep Lake Dataset.  \n`deeplake.ingest_coco` | Ingest images and annotations in COCO format to a Deep Lake Dataset.  \n`deeplake.ingest_yolo` | Ingest images and annotations (bounding boxes or polygons) in YOLO format to a Deep Lake Dataset.  \n`deeplake.ingest_kaggle` | Download and ingest a kaggle dataset and store it as a structured dataset to destination.  \n`deeplake.ingest_dataframe` | Convert pandas dataframe to a Deep Lake Dataset.  \n`deeplake.ingest_huggingface` | Converts Hugging Face datasets to Deep Lake format.  \n  \n## Loading Datasets\uf0c1\n\n`deeplake.load` | Loads an existing dataset  \n---|---  \n  \n## Deleting and Renaming Datasets\uf0c1\n\n`deeplake.delete` | Deletes a dataset at a given path.  \n---|---  \n`deeplake.rename` | Renames dataset at `old_path` to `new_path`.  \n  \n## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.",
        "node_1002": "* Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.\n\n    * If `verify=True` was specified during `create_tensor` of the tensor to which this is being added, some metadata is read from them to verify the integrity of the link samples. This is `True` by default.\n\n    * If you do not want to verify your links, all three of `verify`, `create_shape_tensor` and `create_sample_info_tensor` have to be set to `False`.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.dataset(\"......\")\n    \n\nAdding credentials to the dataset\n\nYou can add the names of the credentials you want to use (not needed for\nhttp/local urls)\n\n    \n    \n    >>> ds.add_creds_key(\"MY_S3_KEY\")\n    >>> ds.add_creds_key(\"GCS_KEY\")\n    \n\nand populate the added names with credentials dictionaries\n\n    \n    \n    >>> ds.populate_creds(\"MY_S3_KEY\", {})   # add creds here\n    >>> ds.populate_creds(\"GCS_KEY\", {})    # add creds here\n    \n\nThese creds are only present temporarily and will have to be repopulated on\nevery reload.\n\nFor datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.",
        "node_632": "* Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\n  * Recompression of samples read with `deeplake.read` is also not supported.\n\nExamples\n\nAppending Deep Lake video sample\n\n    \n    \n    >>> ds.videos.append(deeplake.read(\"videos/0012.mp4\"))\n    \n\nExtending with multiple videos\n\n    \n    \n    >>> ds.videos.extend([deeplake.read(f\"videos/00{i}.mp4\") for i in range(10)])\n    \n\n## Audio Htype\uf0c1\n\n  * Sample dimensions: `(# samples in audio, # channels)` or `(# samples in audio,)`\n\n### Creating an audio tensor\uf0c1\n\nAn audio tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"audios\", htype=\"audio\", sample_compression=\"mp3\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `float64`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.",
        "node_2": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n# Indices and tables\uf0c1\n\n  * Index\n\n  * Module Index\n\n  * Search Page\n\nNext\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_1301": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n# Indices and tables\uf0c1\n\n  * Index\n\n  * Module Index\n\n  * Search Page\n\nNext\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_15": "---|---  \n`Dataset.create_group` | Creates a tensor group.  \n`Dataset.create_tensor_like` | Copies the `source` tensor's meta information and creates a new tensor with it.  \n  \n## Deleting and Renaming Tensors\uf0c1\n\n`Dataset.delete_tensor` | Delete a tensor from the dataset.  \n---|---  \n`Dataset.delete_group` | Delete a tensor group from the dataset.  \n`Dataset.rename_tensor` | Renames tensor with name `name` to `new_name`  \n`Dataset.rename_group` | Renames group with name `name` to `new_name`  \n  \n## Adding and deleting samples\uf0c1\n\n`Tensor.append` | Appends a single sample to the end of the tensor.  \n---|---  \n`Tensor.extend` | Extends the end of the tensor by appending multiple elements from a sequence.  \n`Tensor.pop` | Removes element(s) at the given index / indices.  \n`Tensor.clear` | Deletes all samples from the tensor  \n`Tensor.__setitem__` | Update samples with new values.  \n  \n## Retrieving samples\uf0c1\n\n`Tensor.numpy` | Computes the contents of the tensor in numpy format.  \n---|---  \n`Tensor.data` | Returns data in the tensor in a format based on the tensor's base htype.  \n`Tensor.tobytes` | Returns the bytes of the tensor.  \n`Tensor.text` | Return text data.  \n`Tensor.dict` | Return json data.  \n`Tensor.list` | Return list data.  \n`Tensor._linked_sample` | Returns the linked sample at the given index.  \n  \n## Tensor Properties\uf0c1\n\n`Tensor.htype` | Htype of the tensor.  \n---|---  \n`Tensor.base_htype` | Base htype of the tensor.  \n`Tensor.dtype` | Dtype of the tensor.  \n`Tensor.shape` | Get the shape of this tensor.  \n`Tensor.shape_interval` | Returns a `ShapeInterval` object that describes this tensor's shape more accurately.  \n`Tensor.ndim` | Number of dimensions of the tensor.  \n`Tensor.num_samples` | Returns the length of the primary axis of the tensor.  \n`Tensor.__len__` | Returns the length of the primary axis of the tensor.",
        "node_853": "### Limitations\uf0c1\n\n  * The Deep Lake Performant Dataloader does not support Nifti data.\n\n### Creating a nifti tensor\uf0c1\n\nA nifti tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"patients\", htype=\"nifti\", sample_compression=\"nii.gz\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"nii.gz\", \"nii\", None]\n    \n\n### Appending nifti data\uf0c1\n\n  * Nifti samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw nifti data. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\nExamples\n\n    \n    \n    >>> ds.patients.append(deeplake.read(\"data/patient0.nii.gz\"))\n    \n    \n    \n    >>> ds.patients.extend([deeplake.read(f\"data/patient{i}.nii.gz\") for i in range(10)])\n    \n\n## Point Cloud Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Point cloud samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.",
        "node_1098": "Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\nReturns\n\n    \n\nThe renamed Dataset.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**DatasetHandlerError** \u2013 If a Dataset does not exist at the given path or if\nnew path is to a different directory.\n\ndeeplake.copy(_src : Union[str, Path, Dataset]_, _dest : Union[str, Path]_,\n_runtime : Optional[dict] = None_, _tensors : Optional[List[str]] = None_,\n_overwrite : bool = False_, _src_creds =None_, _dest_creds =None_, _token\n=None_, _num_workers : int = 0_, _scheduler ='threaded'_, _progressbar =True_,\n_** kwargs_)\uf0c1\n\n    \n\nCopies dataset at `src` to `dest`. Version control history is not included.\n\nParameters\n\n    \n\n  * **src** (_str_ _,__Dataset_ _,__pathlib.Path_) \u2013 The Dataset or the path to the dataset to be copied.\n\n  * **dest** (_str_ _,__pathlib.Path_) \u2013 Destination path to copy to.\n\n  * **runtime** (_dict_) \u2013 Parameters for Activeloop DB Engine. Only applicable for hub:// paths.\n\n  * **tensors** (_List_ _[__str_ _]__,__optional_) \u2013 Names of tensors (and groups) to be copied. If not specified all tensors are copied.\n\n  * **overwrite** (_bool_) \u2013 If True and a dataset exists at `dest`, it will be overwritten. Defaults to `False`.",
        "node_82": "Can be:\n\n    * a Deep Lake cloud path of the form `hub://username/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.\n\n    * Loading to a specific version:\n\n>       * You can also specify a `commit_id` or `branch` to load the dataset\n> to that version directly by using the `@` symbol.\n>\n>       * The path will then be of the form `hub://username/dataset@{branch}`\n> or `hub://username/dataset@{commit_id}`.\n>\n>       * See examples above.\n\n  * **runtime** (_dict_) \u2013 Parameters for Activeloop DB Engine. Only applicable for hub:// paths.\n\n  * **read_only** (_bool_ _,__optional_) \u2013 Opens dataset in read only mode if this is passed as `True`. Defaults to `False`. Datasets stored on Deep Lake cloud that your account does not have write access to will automatically open in read mode.\n\n  * **overwrite** (_bool_) \u2013 If set to `True` this overwrites the dataset if it already exists. Defaults to `False`.\n\n  * **public** (_bool_) \u2013 Defines if the dataset will have public access. Applicable only if Deep Lake cloud storage is used and a new Dataset is being created. Defaults to `True`.\n\n  * **memory_cache_size** (_int_) \u2013 The size of the memory cache to be used in MB.\n\n  * **local_cache_size** (_int_) \u2013 The size of the local filesystem cache to be used in MB.",
        "node_916": "For datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.\n\n    \n    \n    >>> ds.add_creds_key(\"my_s3_creds\", managed=True)\n    >>> ds.add_creds_key(\"my_gcs_creds\", managed=True)\n    \n\nCreate a link tensor\n\n    \n    \n    >>> ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")\n    \n\nPopulate the tensor with links\n\n    \n    \n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\", creds_key=\"my_s3_key\"))\n    >>> ds.img.append(deeplake.link(\"gcs://ghi/jkl.png\", creds_key=\"GCS_KEY\"))\n    >>> ds.img.append(deeplake.link(\"https://picsum.photos/200/300\")) # http path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"./path/to/cat.jpeg\")) # local path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))  # this will throw an exception as cloud paths always need creds_key\n    :bluebold:`Accessing the data`\n    \n    \n    \n    >>> for i in range(5):\n    ...     ds.img[i].numpy()\n    ...\n    \n\nUpdating a sample\n\n    \n    \n    >>> ds.img[0] = deeplake.link(\"./data/cat.jpeg\")\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_765": "* Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.\n\nExamples\n\nAppending polygons with 2-D points\n\n    \n    \n    >>> poly1 = [(1, 2), (2, 3), (3, 4)]\n    >>> poly2 = [(10, 12), (14, 19)]\n    >>> poly3 = [(33, 32), (54, 67), (67, 43), (56, 98)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with 3-D points\n\n    \n    \n    >>> poly1 = [(10, 2, 9), (12, 3, 8), (12, 10, 4)]\n    >>> poly2 = [(10, 1, 8), (5, 17, 11)]\n    >>> poly3 = [(33, 33, 31), (45, 76, 13), (60, 24, 17), (67, 87, 83)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> sample = np.random.randint(0, 10, (5, 7, 2))  # 5 polygons with 7 points\n    >>> ds.polygons.append(sample)\n    \n    \n    \n    >>> import numpy as np\n    >>> poly1 = np.random.randint(0, 10, (5, 2))\n    >>> poly2 = np.random.randint(0, 10, (8, 2))\n    >>> poly3 = np.random.randint(0, 10, (3, 2))\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\n## Nifti Htype\uf0c1\n\n  * Sample dimensions: `(# height, # width, # slices)` or `(# height, # width, # slices, # time unit)` in case of time-series data.",
        "node_910": "* Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.\n\nExamples\n\nAppending polygons with 2-D points\n\n    \n    \n    >>> poly1 = [(1, 2), (2, 3), (3, 4)]\n    >>> poly2 = [(10, 12), (14, 19)]\n    >>> poly3 = [(33, 32), (54, 67), (67, 43), (56, 98)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with 3-D points\n\n    \n    \n    >>> poly1 = [(10, 2, 9), (12, 3, 8), (12, 10, 4)]\n    >>> poly2 = [(10, 1, 8), (5, 17, 11)]\n    >>> poly3 = [(33, 33, 31), (45, 76, 13), (60, 24, 17), (67, 87, 83)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> sample = np.random.randint(0, 10, (5, 7, 2))  # 5 polygons with 7 points\n    >>> ds.polygons.append(sample)\n    \n    \n    \n    >>> import numpy as np\n    >>> poly1 = np.random.randint(0, 10, (5, 2))\n    >>> poly2 = np.random.randint(0, 10, (8, 2))\n    >>> poly3 = np.random.randint(0, 10, (3, 2))\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\n## Nifti Htype\uf0c1\n\n  * Sample dimensions: `(# height, # width, # slices)` or `(# height, # width, # slices, # time unit)` in case of time-series data.",
        "node_821": "For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.\n\n## Point Htype\uf0c1\n\n  * Sample dimensions: `(# points, 2)` in case of 2-D (X, Y) co-ordinates or `(# points, 3)` in case of 3-D (X, Y, Z) co-ordinates of the point.\n\nPoints does not contain a fixed mapping across samples between the point order\nand real-world objects (i.e., point 0 is an elbow, point 1 is a knee, etc.).\nIf you require such a mapping, use COCO Keypoints Htype.\n\n### Creating a point tensor\uf0c1\n\nA point tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"points\", htype=\"point\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending point samples\uf0c1\n\n  * Points can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.",
        "node_426": "core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.\n\nSupported htypes and their respective defaults are:\n\nHtype configs\uf0c1 HTYPE | DTYPE | COMPRESSION  \n---|---|---  \ngeneric | None | None  \nimage | uint8 | Required arg  \nimage.rgb | uint8 | Required arg  \nimage.gray | uint8 | Required arg  \nvideo | uint8 | Required arg  \naudio | float64 | Required arg  \nclass_label | uint32 | None  \ntag | str | None  \nbbox | float32 | None  \nbbox.3d | float32 | None  \nintrinsics | float32 | None  \nsegment_mask | uint32 | None  \nbinary_mask | bool | None  \nkeypoints_coco | int32 | None  \npoint | int32 | None  \npolygon | float32 | None  \ntext | str | None  \njson | Any | None  \nlist | List | None  \ndicom | None | dcm  \nnifti | None | Required arg  \npoint_cloud | None | las  \nmesh | None | ply  \ninstance_label | uint32 | None  \nembedding | None | None  \nlink | str | None  \nsequence | None | None  \n  \n## Image Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # channels)` or `(height, width)`.\n\nImages can be stored in Deep Lake as compressed bytes or as raw arrays.",
        "node_604": "* Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.\n\nExamples\n\nAppending Deep Lake audio sample\n\n    \n    \n    >>> ds.audios.append(deeplake.read(\"audios/001.mp3\"))\n    \n\nExtending with Deep Lake audio samples\n\n    \n    \n    >>> ds.audios.extend([deeplake.read(f\"videos/00{i}.mp3\") for i in range(10)])\n    \n\n## Class Label Htype\uf0c1\n\n  * Sample dimensions: `(# labels,)`\n\nClass labels are stored as numerical values in tensors, which are indices of\nthe list `tensor.info.class_names`.\n\n### Creating a class label tensor\uf0c1\n\nA class label tensor can be created using\n\n    \n    \n    >>> classes = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"]\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\", class_names=classes, chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.",
        "node_1295": "Example documentation\n\n    \n\nA full example of this theme output, with localized strings enabled.\n\n## Configuration\n\nThis theme is highly customizable on both the page level and on a global\nlevel. To see all the possible configuration options, read the documentation\non configuring the theme.\n\n## Contributing\n\nIf you would like to help modify or translate the theme, you'll find more\ninformation on contributing in our contributing guide.\n\n## About\n\nSphinx theme for readthedocs.org\n\nsphinx-rtd-theme.readthedocs.io/\n\n### Topics\n\nsphinx-theme  sphinx-doc\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\n### Code of conduct\n\nCode of conduct\n\nActivity\n\nCustom properties\n\n### Stars\n\n**4.6k** stars\n\n### Watchers\n\n**167** watching\n\n### Forks\n\n**1.7k** forks\n\nReport repository\n\n##  Releases\n\n42 tags\n\n##  Contributors 112\n\n  *   *   *   *   *   *   *   *   *   *   *   *   *   * \n\n\\+ 98 contributors\n\n## Languages\n\n  * Sass 46.4%\n  * HTML 22.1%\n  * JavaScript 15.7%\n  * Python 12.0%\n  * Dockerfile 2.3%\n  * Shell 0.9%\n  * Makefile 0.6%\n\n## Footer\n\n(C) 2024 GitHub, Inc.\n\n### Footer navigation\n\n  * Terms\n  * Privacy\n  * Security\n  * Status\n  * Docs\n  * Contact\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.",
        "node_182": "Version control history is not\nincluded.\n\nParameters\n\n    \n\n  * **dest** (_str_ _,__pathlib.Path_) \u2013 Destination dataset or path to copy to. If a Dataset instance is provided, it is expected to be empty.\n\n  * **tensors** (_List_ _[__str_ _]__,__optional_) \u2013 Names of tensors (and groups) to be copied. If not specified all tensors are copied.\n\n  * **runtime** (_dict_) \u2013 Parameters for Activeloop DB Engine. Only applicable for hub:// paths.\n\n  * **overwrite** (_bool_) \u2013 If `True` and a dataset exists at destination, it will be overwritten. Defaults to False.\n\n  * **creds** (_dict_ _,__Optional_) \u2013 creds required to create / overwrite datasets at dest.\n\n  * **token** (_str_ _,__Optional_) \u2013 token used to for fetching credentials to dest.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for copying. Defaults to 0. When set to 0, it will always use serial processing, irrespective of the scheduler.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for copying. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Defaults to \u2018threaded\u2019.\n\n  * **progressbar** (_bool_) \u2013 Displays a progress bar If `True` (default).\n\n  * **public** (_bool_) \u2013 Defines if the dataset will have public access. Applicable only if Deep Lake cloud storage is used and a new Dataset is being created. Defaults to False.\n\nReturns\n\n    \n\nNew dataset object.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**DatasetHandlerError** \u2013 If a dataset already exists at destination path and\noverwrite is False.\n\ncreate_group(_name : str_, _exist_ok =False_) -> Dataset\uf0c1\n\n    \n\nCreates a tensor group. Intermediate groups in the path are also created.\n\nParameters\n\n    \n\n  * **name** \u2013 The name of the group to create.\n\n  * **exist_ok** \u2013 If `True`, the group is created if it does not exist. If `False`, an error is raised if the group already exists. Defaults to `False`.",
        "node_957": "### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.\n\n### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.",
        "node_454": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_1120": "util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * deeplake.VectorStore\n  * Edit on GitHub\n\n* * *\n\n# deeplake.VectorStore\uf0c1\n\n_class _deeplake.core.vectorstore.deeplake_vectorstore.VectorStore\uf0c1\n\n    \n\nBase class for VectorStore\n\n__init__(_path: ~typing.Optional[~typing.Union[str, ~pathlib.Path]] = None,\ndataset: ~typing.Optional[~deeplake.core.dataset.dataset.Dataset] = None,\ntensor_params: ~typing.List[~typing.Dict[str, object]] = [{'name': 'text',\n'htype': 'text', 'create_id_tensor': False, 'create_sample_info_tensor':\nFalse, 'create_shape_tensor': False}, {'name': 'metadata', 'htype': 'json',\n'create_id_tensor': False, 'create_sample_info_tensor': False,\n'create_shape_tensor': False}, {'name': 'embedding', 'htype': 'embedding',\n'dtype': <class 'numpy.float32'>, 'create_id_tensor': False,\n'create_sample_info_tensor': False, 'create_shape_tensor': True,\n'max_chunk_size': 64000000}, {'name': 'id', 'htype': 'text',\n'create_id_tensor': False, 'create_sample_info_tensor': False,\n'create_shape_tensor': False}], embedding_function:\n~typing.Optional[~typing.Any] = None, read_only: ~typing.Optional[bool] =\nNone, ingestion_batch_size: int = 1000, index_params:\n~typing.Optional[~typing.Dict[str, ~typing.Union[int, str]]] = None,\nexec_option: str = 'auto', token: ~typing.Optional[str] = None, overwrite:\nbool = False, verbose: bool = True, runtime: ~typing.Optional[~typing.Dict] =\nNone, creds: ~typing.Optional[~typing.",
        "node_1254": "core.storage.MemoryProvider method)\n    * (deeplake.core.storage.S3Provider method)\n    * (deeplake.core.storage.StorageProvider method)\n    * (deeplake.core.tensor.Tensor method)\n  * __setstate__() (deeplake.core.storage.LRUCache method)\n  * __str__() (deeplake.core.index.Index method)\n    * (deeplake.core.index.IndexEntry method)\n  * __weakref__ (deeplake.core.index.Index attribute)\n    * (deeplake.core.index.IndexEntry attribute)\n    * (deeplake.core.storage.StorageProvider attribute)\n  * _all_keys() (deeplake.core.storage.GCSProvider method)\n    * (deeplake.core.storage.GDriveProvider method)\n    * (deeplake.core.storage.LocalProvider method)\n    * (deeplake.core.storage.LRUCache method)\n    * (deeplake.core.storage.MemoryProvider method)\n    * (deeplake.core.storage.S3Provider method)\n    * (deeplake.core.storage.StorageProvider method)\n  * _check_compatibility_with_htype() (deeplake.core.tensor.Tensor method)\n  * _check_is_file() (deeplake.core.storage.LocalProvider method)\n  * _check_update_creds() (deeplake.core.storage.S3Provider method)\n  * _config (deeplake.core.tensor.Tensor property)\n  * _flush_if_not_read_only() (deeplake.core.storage.LRUCache method)\n  * _forward() (deeplake.core.storage.LRUCache method)\n  * _forward_value() (deeplake.core.storage.LRUCache method)\n  * _free_up_space() (deeplake.core.storage.LRUCache method)\n  * _insert_in_cache() (deeplake.core.storage.LRUCache method)\n  * _is_hub_path (deeplake.core.storage.",
        "node_252": "* `DynamicTensorNumpyError`\n    * `InvalidShapeIntervalError`\n    * `InvalidKeyTypeError`\n    * `UnsupportedTensorTypeError`\n    * `InvalidBytesRequestedError`\n    * `ProviderListEmptyError`\n    * `DirectoryAtPathException`\n    * `FileAtPathException`\n    * `ProviderSizeListMismatch`\n    * `ModuleNotInstalledException`\n    * `LoginException`\n    * `UserNotLoggedInException`\n    * `InvalidHubPathException`\n    * `PathNotEmptyException`\n    * `AuthenticationException`\n    * `AuthorizationException`\n    * `InvalidPasswordException`\n    * `CouldNotCreateNewDatasetException`\n    * `ResourceNotFoundException`\n    * `BadRequestException`\n    * `OverLimitException`\n    * `ServerException`\n    * `BadGatewayException`\n    * `GatewayTimeoutException`\n    * `WaitTimeoutException`\n    * `LockedException`\n    * `UnexpectedStatusCodeException`\n    * `EmptyTokenException`\n    * `S3Error`\n    * `S3GetError`\n    * `S3SetError`\n    * `S3DeletionError`\n    * `S3ListError`\n    * `UnsupportedCompressionError`\n    * `SampleCompressionError`\n    * `SampleDecompressionError`\n    * `InvalidImageDimensions`\n    * `TensorUnsupportedSampleType`\n    * `MetaError`\n    * `MetaDoesNotExistError`\n    * `MetaAlreadyExistsError`\n    * `MetaInvalidKey`\n    * `MetaInvalidRequiredMetaKey`\n    * `TensorMetaInvalidHtype`\n    * `TensorMetaInvalidHtypeOverwriteValue`\n    * `TensorMetaMissingRequiredValue`\n    * `TensorMetaInvalidHtypeOverwriteKey`\n    * `TensorDtypeMismatchError`\n    *",
        "node_772": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.",
        "node_1163": "pass\n    \n\nCreating dataloader with custom transformation and batch size\n\n    \n    \n    >>> import deeplake\n    >>> import torch\n    >>> from torchvision import datasets, transforms, models\n    >>>\n    >>> ds_train = deeplake.load('hub://activeloop/fashion-mnist-train')\n    >>> tform = transforms.Compose([\n    .     transforms.ToPILImage(), # Must convert to PIL image for subsequent operations to run\n    .     transforms.RandomRotation(20), # Image augmentation\n    .     transforms.ToTensor(), # Must convert to pytorch tensor for subsequent operations to run\n    .     transforms.Normalize([0.5], [0.5]),\n    . ])\n    .\n    >>> batch_size = 32\n    >>> # create dataloader by chaining with transform function and batch size and returns batch of pytorch tensors\n    >>> train_loader = ds_train.dataloader()\\\n    .     .transform({'images': tform, 'labels': None})\\\n    .     .batch(batch_size)\\\n    .     .shuffle()\\\n    .     .pytorch()\n    .\n    >>> # loop over the elements\n    >>> for i, data in enumerate(train_loader):\n    .     # custom logic on data\n    .     pass\n    \n\nCreating dataloader and chaining with query\n\n    \n    \n    >>> ds = deeplake.load('hub://activeloop/coco-train')\n    >>> train_loader = ds_train.dataloader()\\\n    .     .query(\"(select * where contains(categories, 'car') limit 1000) union (select * where contains(categories, 'motorcycle') limit 1000)\")\\\n    .     .pytorch()\n    .\n    >>> # loop over the elements\n    >>> for i, data in enumerate(train_loader):\n    .     # custom logic on data\n    .     pass\n    \n\ndelete(_large_ok =False_)\uf0c1\n\n    \n\nDeletes the entire dataset from the cache layers (if any) and the underlying\nstorage. This is an **IRREVERSIBLE** operation. Data once deleted can not be\nrecovered.\n\nParameters\n\n    \n\n**large_ok** (_bool_) \u2013 Delete datasets larger than 1 GB. Defaults to `False`.",
        "node_943": "Examples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.\n\nExamples\n\n    \n    \n    >>> ds.create_tensor(\"seq\", htype=\"sequence\")\n    >>> ds.seq.append([1, 2, 3])\n    >>> ds.seq.append([4, 5, 6])\n    >>> ds.seq.numpy()\n    array([[[1],\n            [2],\n            [3]],\n           [[4],\n            [5],\n            [6]]])\n    \n    \n    \n    >>> ds.create_tensor(\"image_seq\", htype=\"sequence[image]\", sample_compression=\"jpg\")\n    >>> ds.image_seq.append([deeplake.read(\"img01.jpg\"), deeplake.read(\"img02.jpg\")])\n    \n\n## Link htype\uf0c1\n\n  * Link htype is a special meta htype that allows linking of external data (files) to the dataset, without storing the data in the dataset itself.\n\n  * Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.",
        "node_422": "`Tensor.tobytes` | Returns the bytes of the tensor.  \n`Tensor.text` | Return text data.  \n`Tensor.dict` | Return json data.  \n`Tensor.list` | Return list data.  \n`Tensor._linked_sample` | Returns the linked sample at the given index.  \n  \n## Tensor Properties\uf0c1\n\n`Tensor.htype` | Htype of the tensor.  \n---|---  \n`Tensor.base_htype` | Base htype of the tensor.  \n`Tensor.dtype` | Dtype of the tensor.  \n`Tensor.shape` | Get the shape of this tensor.  \n`Tensor.shape_interval` | Returns a `ShapeInterval` object that describes this tensor's shape more accurately.  \n`Tensor.ndim` | Number of dimensions of the tensor.  \n`Tensor.num_samples` | Returns the length of the primary axis of the tensor.  \n`Tensor.__len__` | Returns the length of the primary axis of the tensor.  \n`Tensor.is_dynamic` | Will return `True` if samples in this tensor have shapes that are unequal.  \n`Tensor.is_sequence` | Whether this tensor is a sequence tensor.  \n`Tensor.is_link` | Whether this tensor is a link tensor.  \n`Tensor.verify` | Whether linked data will be verified when samples are added.  \n  \n## Info\uf0c1\n\n`Tensor.info` | Returns the information about the tensor.  \n---|---  \n`Tensor.sample_info` | Returns info about particular samples in a tensor.  \n  \n## Video features\uf0c1\n\n`Tensor.play` | Play video sample.  \n---|---  \n`Tensor.timestamps` | Returns timestamps (in seconds) for video sample as numpy array.  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_301": "TFDS is primarily\nfocused on giving the public easy access to commonly available datasets, and\nmanagement of custom datasets is not the primary focus. A full comparison\narticle can be found here.\n\n**Deep Lake vs HuggingFace** Deep Lake and HuggingFace offer access to popular\ndatasets, but Deep Lake primarily focuses on computer vision, whereas\nHuggingFace focuses on natural language processing. HuggingFace Transforms and\nother computational tools for NLP are not analogous to features offered by\nDeep Lake.  **Deep Lake vs WebDatasets** Deep Lake and WebDatasets both offer\nrapid data streaming across networks. They have nearly identical steaming\nspeeds because the underlying network requests and data structures are very\nsimilar. However, Deep Lake offers superior random access and shuffling, its\nsimple API is in python instead of command-line, and Deep Lake enables simple\nindexing and modification of the dataset without having to recreate it.\n**Deep Lake vs Zarr** Deep Lake and Zarr both offer storage of data as chunked\narrays. However, Deep Lake is primarily designed for returning data as arrays\nusing a simple API, rather than actually storing raw arrays (even though\nthat's also possible). Deep Lake stores data in use-case-optimized formats,\nsuch as jpeg or png for images, or mp4 for video, and the user treats the data\nas if it's an array, because Deep Lake handles all the data processing in\nbetween.",
        "node_228": "Parameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The key whose management status is to be changed.\n\n  * **new_creds_key** (_str_ _,__optional_) \u2013 The new key to replace the old key. If not provided, the old key will be used.\n\n  * **managed** (_bool_) \u2013 The target management status. If `True`, the creds corresponding to the key will be fetched from activeloop platform.\n\nRaises\n\n    \n\n  * **ValueError** \u2013 If the dataset is not connected to activeloop platform.\n\n  * **ValueError** \u2013 If both `new_creds_key` and `managed` are `None`.\n\n  * **KeyError** \u2013 If the creds key is not present in the dataset.\n\n  * **Exception** \u2013 All other errors such as during population of managed creds.\n\nExamples\n\n    \n    \n    >>> # create/load a dataset\n    >>> ds = deeplake.dataset(\"path/to/dataset\")\n    >>> # add a new creds key\n    >>> ds.add_creds_key(\"my_s3_key\")\n    >>> # Populate the name added with creds dictionary\n    >>> # These creds are only present temporarily and will have to be repopulated on every reload\n    >>> ds.populate_creds(\"my_s3_key\", {})\n    >>> # Rename the key and change the management status of the key to True. Before doing this, ensure that the creds have been created on activeloop platform\n    >>> # Now, this key will no longer use the credentials populated in the previous step but will instead fetch them from activeloop platform\n    >>> # These creds don't have to be populated again on every reload and will be fetched every time the dataset is loaded\n    >>> ds.update_creds_key(\"my_s3_key\", \"my_managed_key\", True)\n    \n\nvisualize(_width : Optional[Union[int, str]] = None_, _height :\nOptional[Union[int, str]] = None_)\uf0c1\n\n    \n\nVisualizes the dataset in the Jupyter notebook.\n\nParameters\n\n    \n\n  * **width** \u2013 Union[int, str, None] Optional width of the visualizer canvas.\n\n  * **height** \u2013 Union[int, str, None] Optional height of the visualizer canvas.",
        "node_947": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.gray htypes\n    * Video Htype\n      * Limitations\n      * Creating a video tensor\n      * Appending video samples\n    * Audio Htype\n      * Creating an audio tensor\n      * Appending audio samples\n    * Class Label Htype\n      * Creating a class label tensor\n      * Appending class labels\n    * Tag Htype\n      * Creating a tag tensor\n      * Appending tag samples\n    * Bounding Box Htype\n      * Creating a bbox tensor\n      * Appending bounding boxes\n    * 3D Bounding Box Htype\n      * Creating a 3d bbox tensor\n      * Appending 3d bounding boxes\n    * Intrinsics Htype\n      * Creating an intrinsics tensor\n      * Appending intrinsics matrices\n    * Segmentation Mask Htype\n      * Creating a segment_mask tensor\n      * Appending segmentation masks\n    * Binary Mask Htype\n      * Creating a binary_mask tensor\n      * Appending binary masks\n    * COCO Keypoints Htype\n      * Creating a keypoints_coco tensor\n      * Appending keypoints\n    * Point Htype\n      * Creating a point tensor\n      * Appending point samples\n    * Polygon Htype\n      * Creating a polygon tensor\n      * Appending polygons\n    * Nifti Htype\n      * Limitations\n      * Creating a nifti tensor\n      * Appending nifti data\n    * Point Cloud Htype\n      * Creating a point cloud tensor\n      * Appending point clouds\n    * Mesh Htype\n      * Creating a mesh tensor\n      * Appending meshes\n    * Embedding Htype\n      * Creating an embedding tensor\n      * Appending embedding samples\n    * Sequence htype\n    * Link htype\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.",
        "node_1142": "Defaults to None.\n\n  * **ids** (_Optional_ _[__List_ _[__str_ _]__]__,__optional_) \u2013 hash ids of the elements for replacement. Defaults to None.\n\n  * **filter** (_Optional_ _[__Union_ _[__Dict_ _,__Callable_ _]__]__,__optional_) \u2013 Filter for finding samples for replacement. \\- `Dict` \\- Key-value search on tensors of htype json, evaluated on an AND basis (a sample must satisfy all key-value filters to be True) Dict = {\u201ctensor_name_1\u201d: {\u201ckey\u201d: value}, \u201ctensor_name_2\u201d: {\u201ckey\u201d: value}} \\- `Function` \\- Any function that is compatible with deeplake.filter\n\n  * **query** (_Optional_ _[__str_ _]__,__optional_) \u2013 TQL Query string for direct evaluation for finding samples for deletion, without application of additional filters. Defaults to None.\n\n  * **exec_option** (_Optional_ _[__str_ _]_) \u2013 Method for search execution. It could be either `\"python\"`, `\"compute_engine\"` or `\"tensor_db\"`. Defaults to `None`, which inherits the option from the Vector Store initialization. \\- `python` \\- Pure-python implementation that runs on the client and can be used for data stored anywhere. WARNING: using this option with big datasets is discouraged because it can lead to memory issues. \\- `compute_engine` \\- Performant C++ implementation of the Deep Lake Compute Engine that runs on the client and can be used for any data stored in or connected to Deep Lake. It cannot be used with in-memory or local datasets. \\- `tensor_db` \\- Performant and fully-hosted Managed Tensor Database that is responsible for storage and query execution. Only available for data stored in the Deep Lake Managed Database. Store datasets in this database by specifying runtime = {\u201ctensor_db\u201d: True} during dataset creation.\n\n  * **embedding_function** (_Optional_ _[__Union_ _[__Callable_ _,__List_ _[__Callable_ _]__]__]__,__optional_) \u2013 function for converting embedding_source_tensor into embedding. Only valid if embedding_source_tensor is specified. Defaults to None.",
        "node_329": "---|---  \n`deeplake.empty` | Creates an empty dataset  \n`deeplake.like` | Creates a new dataset by copying the `source` dataset's structure to a new location.  \n`deeplake.ingest_classification` | Ingest a dataset of images from a local folder to a Deep Lake Dataset.  \n`deeplake.ingest_coco` | Ingest images and annotations in COCO format to a Deep Lake Dataset.  \n`deeplake.ingest_yolo` | Ingest images and annotations (bounding boxes or polygons) in YOLO format to a Deep Lake Dataset.  \n`deeplake.ingest_kaggle` | Download and ingest a kaggle dataset and store it as a structured dataset to destination.  \n`deeplake.ingest_dataframe` | Convert pandas dataframe to a Deep Lake Dataset.  \n`deeplake.ingest_huggingface` | Converts Hugging Face datasets to Deep Lake format.  \n  \n## Loading Datasets\uf0c1\n\n`deeplake.load` | Loads an existing dataset  \n---|---  \n  \n## Deleting and Renaming Datasets\uf0c1\n\n`deeplake.delete` | Deletes a dataset at a given path.  \n---|---  \n`deeplake.rename` | Renames dataset at `old_path` to `new_path`.  \n  \n## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.",
        "node_453": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.gray htypes\n    * Video Htype\n      * Limitations\n      * Creating a video tensor\n      * Appending video samples\n    * Audio Htype\n      * Creating an audio tensor\n      * Appending audio samples\n    * Class Label Htype\n      * Creating a class label tensor\n      * Appending class labels\n    * Tag Htype\n      * Creating a tag tensor\n      * Appending tag samples\n    * Bounding Box Htype\n      * Creating a bbox tensor\n      * Appending bounding boxes\n    * 3D Bounding Box Htype\n      * Creating a 3d bbox tensor\n      * Appending 3d bounding boxes\n    * Intrinsics Htype\n      * Creating an intrinsics tensor\n      * Appending intrinsics matrices\n    * Segmentation Mask Htype\n      * Creating a segment_mask tensor\n      * Appending segmentation masks\n    * Binary Mask Htype\n      * Creating a binary_mask tensor\n      * Appending binary masks\n    * COCO Keypoints Htype\n      * Creating a keypoints_coco tensor\n      * Appending keypoints\n    * Point Htype\n      * Creating a point tensor\n      * Appending point samples\n    * Polygon Htype\n      * Creating a polygon tensor\n      * Appending polygons\n    * Nifti Htype\n      * Limitations\n      * Creating a nifti tensor\n      * Appending nifti data\n    * Point Cloud Htype\n      * Creating a point cloud tensor\n      * Appending point clouds\n    * Mesh Htype\n      * Creating a mesh tensor\n      * Appending meshes\n    * Embedding Htype\n      * Creating an embedding tensor\n      * Appending embedding samples\n    * Sequence htype\n    * Link htype\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.",
        "node_120": "* **unlink** (_bool_) \u2013 Downloads linked samples if set to `True`. Only applicable if `access_method` is `download` or `local`. Defaults to `False`.\n\n  * **reset** (_bool_) \u2013 If the specified dataset cannot be loaded due to a corrupted HEAD state of the branch being loaded, setting `reset=True` will reset HEAD changes and load the previous version.\n\n  * **check_integrity** (_bool_ _,__Optional_) \u2013 Performs an integrity check by default (None) if the dataset has 20 or fewer tensors. Set to `True` to force integrity check, `False` to skip integrity check.\n\nReturns\n\n    \n\nDataset loaded using the arguments provided.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **DatasetHandlerError** \u2013 If a Dataset does not exist at the given path.\n\n  * **AgreementError** \u2013 When agreement is rejected\n\n  * **UserNotLoggedInException** \u2013 When user is not authenticated\n\n  * **InvalidTokenException** \u2013 If the specified toke is invalid\n\n  * **TokenPermissionError** \u2013 When there are permission or other errors related to token\n\n  * **CheckoutError** \u2013 If version address specified in the path cannot be found\n\n  * **DatasetCorruptError** \u2013 If loading the dataset failed due to corruption and `reset` is not `True`\n\n  * **ReadOnlyModeError** \u2013 If reset is attempted in read-only mode\n\n  * **LockedException** \u2013 When attempting to open a dataset for writing when it is locked by another machine\n\n  * **ValueError** \u2013 If `org_id` is specified for a non-local dataset\n\n  * **Exception** \u2013 Re-raises caught exception if reset cannot fix the issue\n\n  * **ValueError** \u2013 If the org id is provided but the dataset is not local\n\nWarning\n\nSetting `access_method` to download will overwrite the local copy of the\ndataset if it was previously downloaded.\n\nNote\n\nAny changes made to the dataset in download / local mode will only be made to\nthe local copy and will not be reflected in the original dataset.",
        "node_860": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.gray htypes\n    * Video Htype\n      * Limitations\n      * Creating a video tensor\n      * Appending video samples\n    * Audio Htype\n      * Creating an audio tensor\n      * Appending audio samples\n    * Class Label Htype\n      * Creating a class label tensor\n      * Appending class labels\n    * Tag Htype\n      * Creating a tag tensor\n      * Appending tag samples\n    * Bounding Box Htype\n      * Creating a bbox tensor\n      * Appending bounding boxes\n    * 3D Bounding Box Htype\n      * Creating a 3d bbox tensor\n      * Appending 3d bounding boxes\n    * Intrinsics Htype\n      * Creating an intrinsics tensor\n      * Appending intrinsics matrices\n    * Segmentation Mask Htype\n      * Creating a segment_mask tensor\n      * Appending segmentation masks\n    * Binary Mask Htype\n      * Creating a binary_mask tensor\n      * Appending binary masks\n    * COCO Keypoints Htype\n      * Creating a keypoints_coco tensor\n      * Appending keypoints\n    * Point Htype\n      * Creating a point tensor\n      * Appending point samples\n    * Polygon Htype\n      * Creating a polygon tensor\n      * Appending polygons\n    * Nifti Htype\n      * Limitations\n      * Creating a nifti tensor\n      * Appending nifti data\n    * Point Cloud Htype\n      * Creating a point cloud tensor\n      * Appending point clouds\n    * Mesh Htype\n      * Creating a mesh tensor\n      * Appending meshes\n    * Embedding Htype\n      * Creating an embedding tensor\n      * Appending embedding samples\n    * Sequence htype\n    * Link htype\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.",
        "node_908": "For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.\n\n## Point Htype\uf0c1\n\n  * Sample dimensions: `(# points, 2)` in case of 2-D (X, Y) co-ordinates or `(# points, 3)` in case of 3-D (X, Y, Z) co-ordinates of the point.\n\nPoints does not contain a fixed mapping across samples between the point order\nand real-world objects (i.e., point 0 is an elbow, point 1 is a knee, etc.).\nIf you require such a mapping, use COCO Keypoints Htype.\n\n### Creating a point tensor\uf0c1\n\nA point tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"points\", htype=\"point\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending point samples\uf0c1\n\n  * Points can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.",
        "node_1184": "Only supported for\n> tensors with `sample_compression='jpeg'` or `'png'`.\n\n  * **cache_size** (_int_) \u2013 The size of the cache per tensor in MBs. Defaults to max(maximum chunk size of tensor, 32 MB).\n\nReturns\n\n    \n\nA torch.utils.data.DataLoader object.\n\nRaises\n\n    \n\n**EmptyTensorError** \u2013 If one or more tensors being passed to pytorch are\nempty.\n\nNote\n\nPytorch does not support uint16, uint32, uint64 dtypes. These are implicitly\ntype casted to int32, int64 and int64 respectively. This spins up it\u2019s own\nworkers to fetch data.\n\nquery(_query_string : str_, _runtime : Optional[Dict] = None_, _return_data :\nbool = False_)\uf0c1\n\n    \n\nReturns a sliced `Dataset` with given query results.\n\nIt allows to run SQL like queries on dataset and extract results. See\nsupported keywords and the Tensor Query Language documentation here.\n\nParameters\n\n    \n\n  * **query_string** (_str_) \u2013 An SQL string adjusted with new functionalities to run on the given `Dataset` object\n\n  * **runtime** (_Optional_ _[__Dict_ _]_) \u2013 Runtime parameters for query execution. Supported keys: {\u201ctensor_db\u201d: True or False}.\n\n  * **return_data** (_bool_) \u2013 Defaults to `False`. Whether to return raw data along with the view.\n\nRaises\n\n    \n\n**ValueError** \u2013 if `return_data` is True and runtime is not {\u201ctensor_db\u201d:\ntrue}\n\nReturns\n\n    \n\nA `Dataset` object.",
        "node_660": "Images can be stored in Deep Lake as compressed bytes or as raw arrays. Due to\nthe high compression ratio for most image formats, it is highly recommended to\nstore compressed images using the `sample_compression` input to the\ncreate_tensor method.\n\n### Creating an image tensor\uf0c1\n\nAn image tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\")\n    \n\nOR\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", chunk_compression=\"jpg\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"bmp\", \"dib\", \"gif\", \"ico\", \"jpeg\", \"jpeg2000\", \"pcx\", \"png\", \"ppm\", \"sgi\", \"tga\", \"tiff\",\n    ... \"webp\", \"wmf\", \"xbm\", \"eps\", \"fli\", \"im\", \"msp\", \"mpo\"]\n    \n\n### Appending image samples\uf0c1\n\n  * Image samples can be of type `np.ndarray` or Deep Lake `Sample` which can be created using `deeplake.read()`.\n\nExamples\n\nAppending pixel data with array\n\n    \n    \n    >>> ds.images.append(np.zeros((5, 5, 3), dtype=np.uint8))\n    \n\nAppening Deep Lake image sample\n\n    \n    \n    >>> ds.images.append(deeplake.read(\"images/0001.jpg\"))\n    \n\nYou can append multiple samples at the same time using `extend()`.\n\n    \n    \n    >>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type.",
        "node_29": "### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.\n    \n        * \u201ccenter\u201d: [center_x, center_y, center_z, size_x, size_y, size_z, rot_x, rot_y, rot_z]\n    \n          * Sample dimensions: `(# bounding boxes, 9)`\n\n          * `size_x` \\- is the length of the bounding box along x direction\n\n          * `size_y` \\- is the width of the bounding box along y direction\n\n          * `size_z` \\- is the height of the bounding box along z direction\n\n          * `rot_x` \\- rotation angle along x axis, given in degrees\n\n          * `rot_y` \\- rotation angle along y axis, given in degrees\n\n          * `rot_z` \\- rotation angle along z axis, given in degrees\n\n        * \u201cvertex\u201d: 8 3D vertices - [[x0, y0, z0], [x1, y1, z1], [x2, y2, z2], \u2026.., [x7, y7, z7]]\n    \n          * Sample dimensions: `(# bounding boxes, 8, 3)`\n\nThe vertex order is of the following form:\n\n                \n                                      4_____________________ 5\n                     /|                    /|\n                    / |                   / |\n                   /  |                  /  |\n                  /___|_________________/   |\n                0|    |                 | 1 |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |                 |   |\n                 |    |_________________|___|\n                 |   /  7               |   / 6\n                 |  /                   |  /\n                 | /                    | /\n                 |/_____________________|/\n                  3                      2\n                \n\n    * **dtype** : Defaults to `float32`.",
        "node_414": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n    * Creating Tensors\n    * Deleting and Renaming Tensors\n    * Adding and deleting samples\n    * Retrieving samples\n    * Tensor Properties\n    * Info\n    * Video features\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Tensors\n  * Edit on GitHub\n\n* * *\n\n# Tensors\uf0c1\n\n## Creating Tensors\uf0c1\n\n`Dataset.create_tensor` | Creates a new tensor in the dataset.  \n---|---  \n`Dataset.create_group` | Creates a tensor group.  \n`Dataset.create_tensor_like` | Copies the `source` tensor's meta information and creates a new tensor with it.  \n  \n## Deleting and Renaming Tensors\uf0c1\n\n`Dataset.delete_tensor` | Delete a tensor from the dataset.  \n---|---  \n`Dataset.delete_group` | Delete a tensor group from the dataset.  \n`Dataset.rename_tensor` | Renames tensor with name `name` to `new_name`  \n`Dataset.rename_group` | Renames group with name `name` to `new_name`  \n  \n## Adding and deleting samples\uf0c1\n\n`Tensor.append` | Appends a single sample to the end of the tensor.  \n---|---  \n`Tensor.extend` | Extends the end of the tensor by appending multiple elements from a sequence.",
        "node_125": "Version control history is not included.\n\nParameters\n\n    \n\n  * **src** (_str_ _,__Dataset_ _,__pathlib.Path_) \u2013 The Dataset or the path to the dataset to be copied.\n\n  * **dest** (_str_ _,__pathlib.Path_) \u2013 Destination path to copy to.\n\n  * **runtime** (_dict_) \u2013 Parameters for Activeloop DB Engine. Only applicable for hub:// paths.\n\n  * **tensors** (_List_ _[__str_ _]__,__optional_) \u2013 Names of tensors (and groups) to be copied. If not specified all tensors are copied.\n\n  * **overwrite** (_bool_) \u2013 If True and a dataset exists at `dest`, it will be overwritten. Defaults to `False`.\n\n  * **src_creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **dest_creds** (_dict_ _,__optional_) \u2013 creds required to create / overwrite datasets at `dest`.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for copying. Defaults to 0. When set to 0, it will always use serial processing, irrespective of the scheduler.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for copying.",
        "node_758": "The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"])\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending segmentation masks\uf0c1\n\n  * Segmentation masks can be appended as `np.ndarray`.\n\nExamples\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512)))\n    \n\nNote\n\nSince each pixel can only be labeled once, segmentation masks are not\nappropriate for datasets where objects might overlap, or where multiple\nobjects within the same class must be distinguished. For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.",
        "node_1143": "WARNING: using this option with big datasets is discouraged because it can lead to memory issues. \\- `compute_engine` \\- Performant C++ implementation of the Deep Lake Compute Engine that runs on the client and can be used for any data stored in or connected to Deep Lake. It cannot be used with in-memory or local datasets. \\- `tensor_db` \\- Performant and fully-hosted Managed Tensor Database that is responsible for storage and query execution. Only available for data stored in the Deep Lake Managed Database. Store datasets in this database by specifying runtime = {\u201ctensor_db\u201d: True} during dataset creation.\n\n  * **embedding_function** (_Optional_ _[__Union_ _[__Callable_ _,__List_ _[__Callable_ _]__]__]__,__optional_) \u2013 function for converting embedding_source_tensor into embedding. Only valid if embedding_source_tensor is specified. Defaults to None.\n\n  * **embedding_source_tensor** (_Union_ _[__str_ _,__List_ _[__str_ _]__]__,__optional_) \u2013 Name of tensor with data that needs to be converted to embeddings. Defaults to text.\n\n  * **embedding_tensor** (_Optional_ _[__Union_ _[__str_ _,__List_ _[__str_ _]__]__]__,__optional_) \u2013 Name of the tensor with embeddings. Defaults to None.\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_114": "Data in different splits of a DatasetDict will be stored under respective tensor groups.\n\n  * **dest** (_Dataset_ _,__str_ _,__pathlib.Path_) \u2013 Destination dataset or path to it.\n\n  * **use_progressbar** (_bool_) \u2013 Defines if progress bar should be used to show conversion progress.\n\n  * **token** (_Optional_ _[__str_ _]_) \u2013 The token to use for accessing the dataset and/or connecting it to Deep Lake.\n\n  * **connect_kwargs** (_Optional_ _[__Dict_ _]_) \u2013 If specified, the dataset will be connected to Deep Lake, and connect_kwargs will be passed to `Dataset.connect`.\n\n  * ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function. See `deeplake.empty()`.\n\nReturns\n\n    \n\nThe destination Deep Lake dataset.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**ValueError** \u2013 If `dest` is not a path or a Deep Lake `Dataset`.\n\nNote\n\n  * if DatasetDict looks like:\n    \n        >>> {\n    ...    train: Dataset({\n    ...        features: ['data']\n    ...    }),\n    ...    validation: Dataset({\n    ...        features: ['data']\n    ...    }),\n    ...    test: Dataset({\n    ...        features: ['data']\n    ...    }),\n    ... }\n    \n\nit will be converted to a Deep Lake `Dataset` with tensors `['train/data',\n'validation/data', 'test/data']`.\n\nFeatures of the type `Sequence(feature=Value(dtype='string'))` are not\nsupported. Columns of such type are skipped.",
        "node_1033": "Parameters\n\n    \n\n  * **num_workers** (_int_) \u2013 Number of workers to use for transforming and processing the data. Defaults to 0.\n\n  * **collate_fn** (_Callable_ _,__Optional_) \u2013 merges a list of samples to form a mini-batch of Tensor(s).\n\n  * **tensors** (_List_ _[__str_ _]__,__Optional_) \u2013 List of tensors to load. If None, all tensors are loaded. Defaults to `None`.\n\n  * **num_threads** (_int_ _,__Optional_) \u2013 Number of threads to use for fetching and decompressing the data. If `None`, the number of threads is automatically determined. Defaults to `None`.\n\n  * **prefetch_factor** (_int_) \u2013 Number of batches to transform and collate in advance per worker. Defaults to 2.\n\n  * **distributed** (_bool_) \u2013 Used for DDP training. Distributes different sections of the dataset to different ranks. Defaults to `False`.\n\n  * **return_index** (_bool_) \u2013 Used to idnetify where loader needs to retur sample index or not. Defaults to `True`.\n\n  * **persistent_workers** (_bool_) \u2013 If `True`, the data loader will not shutdown the worker processes after a dataset has been consumed once. Defaults to `False`.\n\n  * **decode_method** (_Dict_ _[__str_ _,__str_ _]__,__Optional_) \u2013 \n\nA dictionary of decode methods for each tensor. Defaults to `None`.\n\n    * Supported decode methods are:\n\n> \u2019numpy\u2019\n>  \n>\n> Default behaviour. Returns samples as numpy arrays.\n>\n> \u2019tobytes\u2019\n>  \n>\n> Returns raw bytes of the samples.\n>\n> \u2019pil\u2019\n>  \n>\n> Returns samples as PIL images. Especially useful when transformation use\n> torchvision transforms, that require PIL images as input. Only supported for\n> tensors with `sample_compression='jpeg'` or `'png'`.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n**ValueError** \u2013 If .pytorch() or .tensorflow() or .numpy() has already been\ncalled.",
        "node_1198": "Parameters\n\n    \n\n  * **width** \u2013 Union[int, str, None] Optional width of the visualizer canvas.\n\n  * **height** \u2013 Union[int, str, None] Optional height of the visualizer canvas.\n\nRaises\n\n    \n\n**Exception** \u2013 If the dataset is not a Deep Lake cloud dataset and the\nvisualization is attempted in colab.\n\n## DeepLakeCloudDataset\uf0c1\n\n_class _deeplake.core.dataset.DeepLakeCloudDataset\uf0c1\n\n    \n\nBases: `Dataset`\n\nSubclass of `Dataset`. Deep Lake cloud datasets are those datasets which are\nstored in or connected to Activeloop servers, their paths look like:\n`hub://username/dataset_name`.\n\nadd_creds_key(_creds_key : str_, _managed : bool = False_)\uf0c1\n\n    \n\nAdds a new creds key to the dataset. These keys are used for tensors that are\nlinked to external data.\n\nExamples\n\n    \n    \n    >>> # create/load a dataset\n    >>> ds = deeplake.dataset(\"hub://username/dataset\")\n    >>> # add a new creds key\n    >>> ds.add_creds_key(\"my_s3_key\")\n    \n\nParameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The key to be added.\n\n  * **managed** (_bool_) \u2013 If `True`, the creds corresponding to the key will be fetched from activeloop platform. Note, this is only applicable for datasets that are connected to activeloop platform. Defaults to `False`.\n\n_property _client\uf0c1\n\n    \n\nReturns the client of the dataset.\n\nconnect(_* args_, _** kwargs_)\uf0c1\n\n    \n\nConnect a Deep Lake cloud dataset through a deeplake path.",
        "node_895": "* Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.\n\nExamples\n\nAppending Deep Lake audio sample\n\n    \n    \n    >>> ds.audios.append(deeplake.read(\"audios/001.mp3\"))\n    \n\nExtending with Deep Lake audio samples\n\n    \n    \n    >>> ds.audios.extend([deeplake.read(f\"videos/00{i}.mp3\") for i in range(10)])\n    \n\n## Class Label Htype\uf0c1\n\n  * Sample dimensions: `(# labels,)`\n\nClass labels are stored as numerical values in tensors, which are indices of\nthe list `tensor.info.class_names`.\n\n### Creating a class label tensor\uf0c1\n\nA class label tensor can be created using\n\n    \n    \n    >>> classes = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"]\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\", class_names=classes, chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.",
        "node_320": "---|---  \n`Dataset.sample_by` | Returns a sliced `Dataset` with given weighted sampler applied.  \n`Dataset.filter` | Filters the dataset in accordance of filter function `f(x: sample) -> bool`  \n`Dataset.save_view` | Saves a dataset view as a virtual dataset (VDS)  \n`Dataset.get_view` | Returns the dataset view corresponding to `id`.  \n`Dataset.load_view` | Loads the view and returns the `Dataset` by id.  \n`Dataset.delete_view` | Deletes the view with given view id.  \n`Dataset.get_views` | Returns list of views stored in this Dataset.  \n`Dataset.is_view` | Returns `True` if this dataset is a view and `False` otherwise.  \n`Dataset.min_view` | Returns a view of the dataset in which all tensors are sliced to have the same length as the shortest tensor.  \n`Dataset.max_view` | Returns a view of the dataset in which shorter tensors are padded with `None` s to have the same length as the longest tensor.  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_1015": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n    * General Functions\n    * Making Deep Lake Samples\n    * Parallelism\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Utility Functions\n  * Edit on GitHub\n\n* * *\n\n# Utility Functions\uf0c1\n\n## General Functions\uf0c1\n\n`exists` | Checks if a dataset exists at the given `path`.  \n---|---  \n  \n## Making Deep Lake Samples\uf0c1\n\n`read` | Utility that reads raw data from supported files into Deep Lake format.  \n---|---  \n`link` | Utility that stores a link to raw data.  \n`link_tiled` | Utility that stores links to multiple images that act as tiles and together form a big image.  \n  \n## Parallelism\uf0c1\n\n`compute` | Compute is a decorator for functions.  \n---|---  \n`compose` | Takes a list of functions decorated using `deeplake.compute()` and creates a pipeline that can be evaluated using .eval  \n  \nTransform pipelines returned by `compute()` and `compose()` are evaluated\nusing `eval`:\n\n`eval` | Evaluates the pipeline on `data_in` to produce an output dataset `ds_out`.  \n---|---  \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.",
        "node_230": "delete()\uf0c1\n\n    \n\nDeletes the view.\n\n_property _id _: str_\uf0c1\n\n    \n\nReturns id of the view.\n\nload(_verbose =True_)\uf0c1\n\n    \n\nLoads the view and returns the `Dataset`.\n\nParameters\n\n    \n\n**verbose** (_bool_) \u2013 If `True`, logs will be printed. Defaults to `True`.\n\nReturns\n\n    \n\nLoaded dataset view.\n\nReturn type\n\n    \n\nDataset\n\n_property _message _: str_\uf0c1\n\n    \n\nReturns the message with which the view was saved.\n\noptimize(_tensors : Optional[List[str]] = None_, _unlink =True_, _num_workers\n=0_, _scheduler ='threaded'_, _progressbar =True_)\uf0c1\n\n    \n\nOptimizes the dataset view by copying and rechunking the required data. This\nis necessary to achieve fast streaming speeds when training models using the\ndataset view. The optimization process will take some time, depending on the\nsize of the data.\n\nExample\n\n    \n    \n    >>> # save view\n    >>> ds[:10].save_view(id=\"first_10\")\n    >>> # optimize view\n    >>> ds.get_view(\"first_10\").optimize()\n    >>> # load optimized view\n    >>> ds.load_view(\"first_10\")\n    \n\nParameters\n\n    \n\n  * **tensors** (_List_ _[__str_ _]_) \u2013 Tensors required in the optimized view. By default all tensors are copied.\n\n  * **unlink** (_bool_) \u2013 \n    * If `True`, this unlinks linked tensors (if any) by copying data from the links to the view.\n\n    * This does not apply to linked videos. Set `deeplake.constants._UNLINK_VIDEOS` to `True` to change this behavior.\n\n  * **num_workers** (_int_) \u2013 Number of workers to be used for the optimization process. Defaults to 0.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for optimization. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Only applicable if `optimize=True`. Defaults to \u2018threaded\u2019.\n\n  * **progressbar** (_bool_) \u2013 Whether to display a progressbar.",
        "node_612": "The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"])\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending segmentation masks\uf0c1\n\n  * Segmentation masks can be appended as `np.ndarray`.\n\nExamples\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512)))\n    \n\nNote\n\nSince each pixel can only be labeled once, segmentation masks are not\nappropriate for datasets where objects might overlap, or where multiple\nobjects within the same class must be distinguished. For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.",
        "node_985": "* **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.boxes.info.update(coords = {\"type\": \"pixel\", \"mode\": \"LTRB\"})\n    \n\nNote\n\nIf the bounding box format is not specified, the visualizer will assume a YOLO\nformat (`fractional` \\+ `CCWH`) if the box coordinates are < 1 on average.\nOtherwise, it will assume the COCO format (`pixel` \\+ `LTWH`).\n\n### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.",
        "node_370": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n    * Creating Datasets\n    * Loading Datasets\n    * Deleting and Renaming Datasets\n    * Copying Datasets\n    * Dataset Operations\n    * Dataset Visualization\n    * Dataset Credentials\n    * Dataset Properties\n    * Dataset Version Control\n    * Dataset Views\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Datasets\n  * Edit on GitHub\n\n* * *\n\n# Datasets\uf0c1\n\n## Creating Datasets\uf0c1\n\n`deeplake.dataset` | Returns a `Dataset` object referencing either a new or existing dataset.  \n---|---  \n`deeplake.empty` | Creates an empty dataset  \n`deeplake.like` | Creates a new dataset by copying the `source` dataset's structure to a new location.  \n`deeplake.ingest_classification` | Ingest a dataset of images from a local folder to a Deep Lake Dataset.  \n`deeplake.ingest_coco` | Ingest images and annotations in COCO format to a Deep Lake Dataset.  \n`deeplake.ingest_yolo` | Ingest images and annotations (bounding boxes or polygons) in YOLO format to a Deep Lake Dataset.  \n`deeplake.ingest_kaggle` | Download and ingest a kaggle dataset and store it as a structured dataset to destination.",
        "node_378": "---|---  \n`deeplake.empty` | Creates an empty dataset  \n`deeplake.like` | Creates a new dataset by copying the `source` dataset's structure to a new location.  \n`deeplake.ingest_classification` | Ingest a dataset of images from a local folder to a Deep Lake Dataset.  \n`deeplake.ingest_coco` | Ingest images and annotations in COCO format to a Deep Lake Dataset.  \n`deeplake.ingest_yolo` | Ingest images and annotations (bounding boxes or polygons) in YOLO format to a Deep Lake Dataset.  \n`deeplake.ingest_kaggle` | Download and ingest a kaggle dataset and store it as a structured dataset to destination.  \n`deeplake.ingest_dataframe` | Convert pandas dataframe to a Deep Lake Dataset.  \n`deeplake.ingest_huggingface` | Converts Hugging Face datasets to Deep Lake format.  \n  \n## Loading Datasets\uf0c1\n\n`deeplake.load` | Loads an existing dataset  \n---|---  \n  \n## Deleting and Renaming Datasets\uf0c1\n\n`deeplake.delete` | Deletes a dataset at a given path.  \n---|---  \n`deeplake.rename` | Renames dataset at `old_path` to `new_path`.  \n  \n## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.",
        "node_530": "For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.\n\n## Point Htype\uf0c1\n\n  * Sample dimensions: `(# points, 2)` in case of 2-D (X, Y) co-ordinates or `(# points, 3)` in case of 3-D (X, Y, Z) co-ordinates of the point.\n\nPoints does not contain a fixed mapping across samples between the point order\nand real-world objects (i.e., point 0 is an elbow, point 1 is a knee, etc.).\nIf you require such a mapping, use COCO Keypoints Htype.\n\n### Creating a point tensor\uf0c1\n\nA point tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"points\", htype=\"point\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending point samples\uf0c1\n\n  * Points can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.",
        "node_1064": "* **local_cache_size** (_int_) \u2013 The size of the local filesystem cache to be used in MB.\n\n  * **creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\n  * **org_id** (_str_ _,__Optional_) \u2013 Organization id to be used for enabling high-performance features. Only applicable for local datasets.\n\n  * **verbose** (_bool_) \u2013 If True, logs will be printed. Defaults to True.\n\n  * **lock_timeout** (_int_) \u2013 Number of seconds to wait before throwing a LockException. If None, wait indefinitely\n\n  * **lock_enabled** (_bool_) \u2013 If true, the dataset manages a write lock. NOTE: Only set to False if you are managing concurrent access externally.\n\n  * **index_params** \u2013 Optional[Dict[str, Union[int, str]]]: Index parameters used while creating vector store, passed down to dataset.\n\nReturns\n\n    \n\nDataset created using the arguments provided.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **DatasetHandlerError** \u2013 If a Dataset already exists at the given path and overwrite is False.",
        "node_303": "Deep Lake offers more flexibility for storing arrays with dynamic\nshape (ragged tensors), and it provides several features that are not naively\navailable in Zarr such as version control, data streaming, and connecting data\nto ML Frameworks.\n\n## Community\n\nJoin our **Slack community** to learn more about unstructured dataset\nmanagement using Deep Lake and to get help from the Activeloop team and other\nusers.\n\nWe'd love your feedback by completing our 3-minute **survey**.\n\nAs always, thanks to our amazing contributors!\n\nMade with contributors-img.\n\nPlease read CONTRIBUTING.md to get started with making contributions to Deep\nLake.\n\n## README Badge\n\nUsing Deep Lake? Add a README badge to let everyone know:\n\n    \n    \n    [![deeplake](https://img.shields.io/badge/powered%20by-Deep%20Lake%20-ff5a1f.svg)](https://github.com/activeloopai/deeplake)\n\n## Disclaimers\n\n**Dataset Licenses**\n\nDeep Lake users may have access to a variety of publicly available datasets.\nWe do not host or distribute these datasets, vouch for their quality or\nfairness, or claim that you have a license to use the datasets. It is your\nresponsibility to determine whether you have permission to use the datasets\nunder their license.\n\nIf you're a dataset owner and do not want your dataset to be included in this\nlibrary, please get in touch through a GitHub issue. Thank you for your\ncontribution to the ML community!\n\n**Usage Tracking**\n\nBy default, we collect usage data using Bugout (here's the code that does it).",
        "node_290": "**Instant\nVisualization Support in theDeep Lake App** Deep Lake datasets are instantly\nvisualized with bounding boxes, masks, annotations, etc. in Deep Lake\nVisualizer (see below).\n\n## \ud83d\ude80 Performance\n\nDeep Lake's performant dataloader built in C++ speeds up data streaming by >2x\ncompared to Hub 2.x (Ofeidis et al. 2022, Hambardzumyan et al. 2023)\n\n## \ud83d\ude80 How to install Deep Lake\n\nDeep Lake can be installed using pip:\n\n    \n    \n    pip3 install deeplake\n\n**By default, Deep Lake does not install dependencies for audio, video,\ngoogle-cloud, and other features. Details on all installation options\nareavailable here.**\n\n### To access all of Deep Lake's features, please register in the Deep Lake\nApp.\n\n## \ud83e\udde0 Deep Lake Code Examples by Application\n\n### Vector Store Applications\n\nUsing Deep Lake as a Vector Store for building LLM applications:\n\n### \\- Vector Store Quickstart\n\n### \\- Vector Store Getting Started Guide\n\n### \\- Using Deep Lake with LangChain\n\n### \\- Image Similarity Search with Deep Lake\n\n### Deep Learning Applications\n\nUsing Deep Lake for managing data while training Deep Learning models:\n\n### \\- Deep Learning Quickstart\n\n### \\- Deep Learning Getting Started Guide\n\n### \\- Tutorials for Training Models\n\n### \\- Tutorials for Creating Deep Learning Datasets\n\n### \\- Deep Learning Playbooks\n\n## \u2699\ufe0f Integrations\n\nDeep Lake offers integrations with other tools in order to streamline your\ndeep learning workflows.",
        "node_145": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n    * `VectorStore`\n      * `VectorStore.__init__()`\n      * `VectorStore.add()`\n      * `VectorStore.checkout()`\n      * `VectorStore.commit()`\n      * `VectorStore.dataset`\n      * `VectorStore.delete()`\n      * `VectorStore.delete_by_path()`\n      * `VectorStore.search()`\n      * `VectorStore.summary()`\n      * `VectorStore.tensors()`\n      * `VectorStore.update_embedding()`\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * deeplake.VectorStore\n  * Edit on GitHub\n\n* * *\n\n# deeplake.VectorStore\uf0c1\n\n_class _deeplake.core.vectorstore.deeplake_vectorstore.VectorStore\uf0c1\n\n    \n\nBase class for VectorStore\n\n__init__(_path: ~typing.Optional[~typing.Union[str, ~pathlib.Path]] = None,\ndataset: ~typing.Optional[~deeplake.core.dataset.dataset.Dataset] = None,\ntensor_params: ~typing.List[~typing.Dict[str, object]] = [{'name': 'text',\n'htype': 'text',",
        "node_333": "`Dataset.commits` | Lists all the commits leading to the current dataset state.  \n`Dataset.branches` | Lists all the branches of the dataset.  \n  \n## Dataset Views\uf0c1\n\nA dataset view is a subset of a dataset that points to specific samples\n(indices) in an existing dataset. Dataset views can be created by indexing a\ndataset, filtering a dataset with `Dataset.filter()`, querying a dataset with\n`Dataset.query()` or by sampling a dataset with `Dataset.sample_by()`.\nFiltering is done with user-defined functions or simplified expressions\nwhereas query can perform SQL-like queries with our Tensor Query Language. See\nthe full TQL spec here.\n\nDataset views can only be saved when a dataset has been committed and has no\nchanges on the HEAD node, in order to preserve data lineage and prevent the\nunderlying data from changing after the query or filter conditions have been\nevaluated.\n\n**Example**\n\n    \n    \n    >>> import deeplake\n    >>> # load dataset\n    >>> ds = deeplake.load(\"hub://activeloop/mnist-train\")\n    >>> # filter dataset\n    >>> zeros = ds.filter(\"labels == 0\")\n    >>> # save view\n    >>> zeros.save_view(id=\"zeros\")\n    >>> # load_view\n    >>> zeros = ds.load_view(id=\"zeros\")\n    >>> len(zeros)\n    5923\n    \n\n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n---|---  \n`Dataset.sample_by` | Returns a sliced `Dataset` with given weighted sampler applied.  \n`Dataset.filter` | Filters the dataset in accordance of filter function `f(x: sample) -> bool`  \n`Dataset.save_view` | Saves a dataset view as a virtual dataset (VDS)  \n`Dataset.get_view` | Returns the dataset view corresponding to `id`.  \n`Dataset.load_view` | Loads the view and returns the `Dataset` by id.  \n`Dataset.delete_view` | Deletes the view with given view id.  \n`Dataset.get_views` | Returns list of views stored in this Dataset.  \n`Dataset.is_view` | Returns `True` if this dataset is a view and `False` otherwise.",
        "node_368": "`Dataset.commits` | Lists all the commits leading to the current dataset state.  \n`Dataset.branches` | Lists all the branches of the dataset.  \n  \n## Dataset Views\uf0c1\n\nA dataset view is a subset of a dataset that points to specific samples\n(indices) in an existing dataset. Dataset views can be created by indexing a\ndataset, filtering a dataset with `Dataset.filter()`, querying a dataset with\n`Dataset.query()` or by sampling a dataset with `Dataset.sample_by()`.\nFiltering is done with user-defined functions or simplified expressions\nwhereas query can perform SQL-like queries with our Tensor Query Language. See\nthe full TQL spec here.\n\nDataset views can only be saved when a dataset has been committed and has no\nchanges on the HEAD node, in order to preserve data lineage and prevent the\nunderlying data from changing after the query or filter conditions have been\nevaluated.\n\n**Example**\n\n    \n    \n    >>> import deeplake\n    >>> # load dataset\n    >>> ds = deeplake.load(\"hub://activeloop/mnist-train\")\n    >>> # filter dataset\n    >>> zeros = ds.filter(\"labels == 0\")\n    >>> # save view\n    >>> zeros.save_view(id=\"zeros\")\n    >>> # load_view\n    >>> zeros = ds.load_view(id=\"zeros\")\n    >>> len(zeros)\n    5923\n    \n\n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n---|---  \n`Dataset.sample_by` | Returns a sliced `Dataset` with given weighted sampler applied.  \n`Dataset.filter` | Filters the dataset in accordance of filter function `f(x: sample) -> bool`  \n`Dataset.save_view` | Saves a dataset view as a virtual dataset (VDS)  \n`Dataset.get_view` | Returns the dataset view corresponding to `id`.  \n`Dataset.load_view` | Loads the view and returns the `Dataset` by id.  \n`Dataset.delete_view` | Deletes the view with given view id.  \n`Dataset.get_views` | Returns list of views stored in this Dataset.  \n`Dataset.is_view` | Returns `True` if this dataset is a view and `False` otherwise.",
        "node_727": "* sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nrotation angles are specified in degrees, not radians\n\n### Appending 3d bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98, 22, 36, 44, 18, 0, 36, 0]])\n    >>> ds.3d_boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77, 22, 36, 44, 18, 0, 28, 0],\n           [462, 123, 238,  98, 26, 34, 24, 19, 0, -50, 0],\n           [688, 108, 279, 116, 12, 32, 14, 38, 0, 30, 0]])\n    >>> boxes.shape\n    (9, 4)\n    >>> ds.3d_boxes.append(boxes)\n    \n\n## Intrinsics Htype\uf0c1\n\n  * Sample dimensions: `(# intrinsics matrices, 3, 3)`\n\nThe intrinsic matrix represents a projective transformation from the 3-D\ncamera\u2019s coordinates into the 2-D image coordinates. The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.",
        "node_549": "* **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.boxes.info.update(coords = {\"type\": \"pixel\", \"mode\": \"LTRB\"})\n    \n\nNote\n\nIf the bounding box format is not specified, the visualizer will assume a YOLO\nformat (`fractional` \\+ `CCWH`) if the box coordinates are < 1 on average.\nOtherwise, it will assume the COCO format (`pixel` \\+ `LTWH`).\n\n### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.",
        "node_1218": "Length is included.\n\nExample\n\n    \n    \n    >>> tensor.append(np.zeros((10, 10)))\n    >>> tensor.append(np.zeros((10, 15)))\n    >>> tensor.shape\n    (2, 10, None)\n    \n\nReturns\n\n    \n\nTuple where each value is either `None` (if that axis is dynamic) or an int\n(if that axis is fixed).\n\nReturn type\n\n    \n\ntuple\n\nNote\n\nIf you don\u2019t want `None` in the output shape or want the lower/upper bound\nshapes, use `shape_interval` instead.\n\n_property _shape_interval _: ShapeInterval_\uf0c1\n\n    \n\nReturns a `ShapeInterval` object that describes this tensor\u2019s shape more\naccurately. Length is included.\n\nExample\n\n    \n    \n    >>> tensor.append(np.zeros((10, 10)))\n    >>> tensor.append(np.zeros((10, 15)))\n    >>> tensor.shape_interval\n    ShapeInterval(lower=(2, 10, 10), upper=(2, 10, 15))\n    >>> str(tensor.shape_interval)\n    (2, 10, 10:15)\n    \n\nReturns\n\n    \n\nObject containing `lower` and `upper` properties.\n\nReturn type\n\n    \n\nShapeInterval\n\nNote\n\nIf you are expecting a tuple, use `shape` instead.\n\nshapes()\uf0c1\n\n    \n\nGet the shapes of all the samples in the tensor.\n\nReturns\n\n    \n\nList of shapes of all the samples in the tensor.\n\nReturn type\n\n    \n\nnp.ndarray\n\nsummary()\uf0c1\n\n    \n\nPrints a summary of the tensor.\n\ntext(_fetch_chunks : bool = False_)\uf0c1\n\n    \n\nReturn text data. Only applicable for tensors with \u2018text\u2019 base htype.\n\n_property _timestamps _: ndarray_\uf0c1\n\n    \n\nReturns timestamps (in seconds) for video sample as numpy array.",
        "node_669": "* sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nrotation angles are specified in degrees, not radians\n\n### Appending 3d bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98, 22, 36, 44, 18, 0, 36, 0]])\n    >>> ds.3d_boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77, 22, 36, 44, 18, 0, 28, 0],\n           [462, 123, 238,  98, 26, 34, 24, 19, 0, -50, 0],\n           [688, 108, 279, 116, 12, 32, 14, 38, 0, 30, 0]])\n    >>> boxes.shape\n    (9, 4)\n    >>> ds.3d_boxes.append(boxes)\n    \n\n## Intrinsics Htype\uf0c1\n\n  * Sample dimensions: `(# intrinsics matrices, 3, 3)`\n\nThe intrinsic matrix represents a projective transformation from the 3-D\ncamera\u2019s coordinates into the 2-D image coordinates. The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.",
        "node_261": "* **InvalidOutputDatasetError** \u2013 If all the tensors of `ds_out` passed to transform don\u2019t have the same length. Using scheduler other than \u201cthreaded\u201d with deeplake dataset having base storage as memory as `ds_out` will also raise this.\n\n  * **TensorMismatchError** \u2013 If one or more of the outputs generated during transform contain different tensors than the ones present in \u2018ds_out\u2019 provided to transform.\n\n  * **UnsupportedSchedulerError** \u2013 If the scheduler passed is not recognized. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019.\n\n  * **TransformError** \u2013 All other exceptions raised if there are problems while running the pipeline.\n\n  * **ValueError** \u2013 If `num_workers` > 0 and `checkpoint_interval` is not a multiple of `num_workers` or if `checkpoint_interval` > 0 and ds_out is None.\n\n# noqa: DAR401\n\nExample:\n\n    \n    \n    @deeplake.compute\n    def my_fn(sample_in: Any, samples_out, my_arg0, my_arg1=0):\n        samples_out.my_tensor.append(my_arg0 * my_arg1)\n    \n    # This transform can be used using the eval method in one of these 2 ways:-\n    \n    # Directly evaluating the method\n    # here arg0 and arg1 correspond to the 3rd and 4th argument in my_fn\n    my_fn(arg0, arg1).eval(data_in, ds_out, scheduler=\"threaded\", num_workers=5)\n    \n    # As a part of a Transform pipeline containing other functions\n    pipeline = deeplake.compose([my_fn(a, b), another_function(x=2)])\n    pipeline.eval(data_in, ds_out, scheduler=\"processed\", num_workers=2)\n    \n\nNote\n\n`pad_data_in` is only applicable if `data_in` is a Deep Lake dataset.\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.",
        "node_90": "* **local_cache_size** (_int_) \u2013 The size of the local filesystem cache to be used in MB.\n\n  * **creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\n  * **org_id** (_str_ _,__Optional_) \u2013 Organization id to be used for enabling high-performance features. Only applicable for local datasets.\n\n  * **verbose** (_bool_) \u2013 If True, logs will be printed. Defaults to True.\n\n  * **lock_timeout** (_int_) \u2013 Number of seconds to wait before throwing a LockException. If None, wait indefinitely\n\n  * **lock_enabled** (_bool_) \u2013 If true, the dataset manages a write lock. NOTE: Only set to False if you are managing concurrent access externally.\n\n  * **index_params** \u2013 Optional[Dict[str, Union[int, str]]]: Index parameters used while creating vector store, passed down to dataset.\n\nReturns\n\n    \n\nDataset created using the arguments provided.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **DatasetHandlerError** \u2013 If a Dataset already exists at the given path and overwrite is False.",
        "node_504": "### Limitations\uf0c1\n\n  * The Deep Lake Performant Dataloader does not support Nifti data.\n\n### Creating a nifti tensor\uf0c1\n\nA nifti tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"patients\", htype=\"nifti\", sample_compression=\"nii.gz\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"nii.gz\", \"nii\", None]\n    \n\n### Appending nifti data\uf0c1\n\n  * Nifti samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw nifti data. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\nExamples\n\n    \n    \n    >>> ds.patients.append(deeplake.read(\"data/patient0.nii.gz\"))\n    \n    \n    \n    >>> ds.patients.extend([deeplake.read(f\"data/patient{i}.nii.gz\") for i in range(10)])\n    \n\n## Point Cloud Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Point cloud samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.",
        "node_969": "### Limitations\uf0c1\n\n  * The Deep Lake Performant Dataloader does not support Nifti data.\n\n### Creating a nifti tensor\uf0c1\n\nA nifti tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"patients\", htype=\"nifti\", sample_compression=\"nii.gz\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"nii.gz\", \"nii\", None]\n    \n\n### Appending nifti data\uf0c1\n\n  * Nifti samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw nifti data. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\nExamples\n\n    \n    \n    >>> ds.patients.append(deeplake.read(\"data/patient0.nii.gz\"))\n    \n    \n    \n    >>> ds.patients.extend([deeplake.read(f\"data/patient{i}.nii.gz\") for i in range(10)])\n    \n\n## Point Cloud Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Point cloud samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.",
        "node_168": "Defaults to None.\n\n  * **ids** (_Optional_ _[__List_ _[__str_ _]__]__,__optional_) \u2013 hash ids of the elements for replacement. Defaults to None.\n\n  * **filter** (_Optional_ _[__Union_ _[__Dict_ _,__Callable_ _]__]__,__optional_) \u2013 Filter for finding samples for replacement. \\- `Dict` \\- Key-value search on tensors of htype json, evaluated on an AND basis (a sample must satisfy all key-value filters to be True) Dict = {\u201ctensor_name_1\u201d: {\u201ckey\u201d: value}, \u201ctensor_name_2\u201d: {\u201ckey\u201d: value}} \\- `Function` \\- Any function that is compatible with deeplake.filter\n\n  * **query** (_Optional_ _[__str_ _]__,__optional_) \u2013 TQL Query string for direct evaluation for finding samples for deletion, without application of additional filters. Defaults to None.\n\n  * **exec_option** (_Optional_ _[__str_ _]_) \u2013 Method for search execution. It could be either `\"python\"`, `\"compute_engine\"` or `\"tensor_db\"`. Defaults to `None`, which inherits the option from the Vector Store initialization. \\- `python` \\- Pure-python implementation that runs on the client and can be used for data stored anywhere. WARNING: using this option with big datasets is discouraged because it can lead to memory issues. \\- `compute_engine` \\- Performant C++ implementation of the Deep Lake Compute Engine that runs on the client and can be used for any data stored in or connected to Deep Lake. It cannot be used with in-memory or local datasets. \\- `tensor_db` \\- Performant and fully-hosted Managed Tensor Database that is responsible for storage and query execution. Only available for data stored in the Deep Lake Managed Database. Store datasets in this database by specifying runtime = {\u201ctensor_db\u201d: True} during dataset creation.\n\n  * **embedding_function** (_Optional_ _[__Union_ _[__Callable_ _,__List_ _[__Callable_ _]__]__]__,__optional_) \u2013 function for converting embedding_source_tensor into embedding. Only valid if embedding_source_tensor is specified. Defaults to None.",
        "node_751": "`tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.\n\n### Appending class labels\uf0c1\n\n  * Class labels can be appended as `int`, `str`, `np.ndarray` or `list` of `int` or `str`.\n\n  * In case of strings, `tensor.info.class_names` is updated automatically.\n\nExamples\n\nAppending index\n\n    \n    \n    >>> ds.labels.append(0)\n    >>> ds.labels.append(np.zeros((5,), dtype=np.uint32))\n    \n\nExtending with list of indices\n\n    \n    \n    >>> ds.labels.extend([[0, 1, 2], [1, 3]])\n    \n\nAppending text labels\n\n    \n    \n    >>> ds.labels.append([\"cars\", \"airplanes\"])\n    \n\n## Tag Htype\uf0c1\n\n  * Sample dimensions: `(# tags,)`\n\nThis htype can be used to tag samples with one or more string values.\n\n### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.",
        "node_706": "Examples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.",
        "node_1122": "Optional[bool] =\nNone, ingestion_batch_size: int = 1000, index_params:\n~typing.Optional[~typing.Dict[str, ~typing.Union[int, str]]] = None,\nexec_option: str = 'auto', token: ~typing.Optional[str] = None, overwrite:\nbool = False, verbose: bool = True, runtime: ~typing.Optional[~typing.Dict] =\nNone, creds: ~typing.Optional[~typing.Union[~typing.Dict, str]] = None,\norg_id: ~typing.Optional[str] = None, logger: ~logging.Logger = <Logger\ndeeplake.core.vectorstore.deeplake_vectorstore (INFO)>, branch: str = 'main',\n**kwargs: ~typing.Any_) -> None\uf0c1\n\n    \n\nCreates an empty VectorStore or loads an existing one if it exists at the\nspecified `path`.\n\nExamples\n\n    \n    \n    >>> # Create a vector store with default tensors\n    >>> data = VectorStore(\n    ...        path = \"./my_vector_store\",\n    ... )\n    \n    \n    \n    >>> # Create a vector store in the Deep Lake Managed Tensor Database\n    >>> data = VectorStore(\n    ...        path = \"hub://org_id/dataset_name\",\n    ...        runtime = {\"tensor_db\": True},\n    ... )\n    \n    \n    \n    >>> # Create a vector store with custom tensors\n    >>> data = VectorStore(\n    ...        path = \"./my_vector_store\",\n    ...        tensor_params = [{\"name\": \"text\", \"htype\": \"text\"},\n    ...                         {\"name\": \"embedding_1\", \"htype\": \"embedding\"},\n    ...                         {\"name\": \"embedding_2\", \"htype\": \"embedding\"},\n    ...                         {\"name\": \"source\", \"htype\": \"text\"},\n    ...                         {\"name\": \"metadata\", \"htype\": \"json\"}\n    ...                        ]\n    ... )\n    \n\nParameters\n\n    \n\n  * **path** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path for storing to the Deep Lake Vector Store. It can be:\n\n    * a Deep Lake cloud path of the form `hub://org_id/dataset_name`. Requires registration with Deep Lake.",
        "node_625": "For datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.\n\n    \n    \n    >>> ds.add_creds_key(\"my_s3_creds\", managed=True)\n    >>> ds.add_creds_key(\"my_gcs_creds\", managed=True)\n    \n\nCreate a link tensor\n\n    \n    \n    >>> ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")\n    \n\nPopulate the tensor with links\n\n    \n    \n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\", creds_key=\"my_s3_key\"))\n    >>> ds.img.append(deeplake.link(\"gcs://ghi/jkl.png\", creds_key=\"GCS_KEY\"))\n    >>> ds.img.append(deeplake.link(\"https://picsum.photos/200/300\")) # http path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"./path/to/cat.jpeg\")) # local path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))  # this will throw an exception as cloud paths always need creds_key\n    :bluebold:`Accessing the data`\n    \n    \n    \n    >>> for i in range(5):\n    ...     ds.img[i].numpy()\n    ...\n    \n\nUpdating a sample\n\n    \n    \n    >>> ds.img[0] = deeplake.link(\"./data/cat.jpeg\")\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_103": "The source data can be stored locally or in the cloud.\n\nExamples\n\n    \n    \n    >>> # Ingest local data in YOLO format to a Deep Lake dataset stored in Deep Lake storage.\n    >>> ds = deeplake.ingest_yolo(\n    >>>     \"path/to/data/directory\",\n    >>>     dest=\"hub://org_id/dataset\",\n    >>>     allow_no_annotation=True,\n    >>>     token=\"my_activeloop_token\",\n    >>>     num_workers=4,\n    >>> )\n    >>> # Ingest data from your cloud into another Deep Lake dataset in your cloud, and connect that dataset to the Deep Lake backend.\n    >>> ds = deeplake.ingest_yolo(\n    >>>     \"s3://bucket/data_directory\",\n    >>>     dest=\"s3://bucket/dataset_name\",\n    >>>     image_params={\"name\": \"image_links\", \"htype\": \"link[image]\"},\n    >>>     image_creds_key=\"my_s3_managed_credentials\",\n    >>>     src_creds=aws_creds, # Can also be inferred from environment\n    >>>     dest_creds=aws_creds, # Can also be inferred from environment\n    >>>     connect_kwargs={\"creds_key\": \"my_s3_managed_credentials\", \"org_id\": \"org_id\"},\n    >>>     num_workers=4,\n    >>> )\n    \n\nParameters\n\n    \n\n  * **data_directory** (_str_ _,__pathlib.Path_) \u2013 The path to the directory containing the data (images files and annotation files(see \u2018annotations_directory\u2019 input for specifying annotations in a separate directory).\n\n  * **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://org_id/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.",
        "node_588": "For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.\n\n## Point Htype\uf0c1\n\n  * Sample dimensions: `(# points, 2)` in case of 2-D (X, Y) co-ordinates or `(# points, 3)` in case of 3-D (X, Y, Z) co-ordinates of the point.\n\nPoints does not contain a fixed mapping across samples between the point order\nand real-world objects (i.e., point 0 is an elbow, point 1 is a knee, etc.).\nIf you require such a mapping, use COCO Keypoints Htype.\n\n### Creating a point tensor\uf0c1\n\nA point tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"points\", htype=\"point\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending point samples\uf0c1\n\n  * Points can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.",
        "node_569": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.gray htypes\n    * Video Htype\n      * Limitations\n      * Creating a video tensor\n      * Appending video samples\n    * Audio Htype\n      * Creating an audio tensor\n      * Appending audio samples\n    * Class Label Htype\n      * Creating a class label tensor\n      * Appending class labels\n    * Tag Htype\n      * Creating a tag tensor\n      * Appending tag samples\n    * Bounding Box Htype\n      * Creating a bbox tensor\n      * Appending bounding boxes\n    * 3D Bounding Box Htype\n      * Creating a 3d bbox tensor\n      * Appending 3d bounding boxes\n    * Intrinsics Htype\n      * Creating an intrinsics tensor\n      * Appending intrinsics matrices\n    * Segmentation Mask Htype\n      * Creating a segment_mask tensor\n      * Appending segmentation masks\n    * Binary Mask Htype\n      * Creating a binary_mask tensor\n      * Appending binary masks\n    * COCO Keypoints Htype\n      * Creating a keypoints_coco tensor\n      * Appending keypoints\n    * Point Htype\n      * Creating a point tensor\n      * Appending point samples\n    * Polygon Htype\n      * Creating a polygon tensor\n      * Appending polygons\n    * Nifti Htype\n      * Limitations\n      * Creating a nifti tensor\n      * Appending nifti data\n    * Point Cloud Htype\n      * Creating a point cloud tensor\n      * Appending point clouds\n    * Mesh Htype\n      * Creating a mesh tensor\n      * Appending meshes\n    * Embedding Htype\n      * Creating an embedding tensor\n      * Appending embedding samples\n    * Sequence htype\n    * Link htype\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.",
        "node_100": "* **annotation_files** (_str_ _,__pathlib.Path_ _,__List_ _[__str_ _]_) \u2013 Path to JSON annotation files in COCO format.\n\n  * **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://org_id/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.\n\n  * **key_to_tensor_mapping** (_Optional_ _[__Dict_ _]_) \u2013 A one-to-one mapping between COCO keys and Dataset tensor names.\n\n  * **file_to_group_mapping** (_Optional_ _[__Dict_ _]_) \u2013 A one-to-one mapping between COCO annotation file names and Dataset group names.\n\n  * **ignore_one_group** (_bool_) \u2013 Skip creation of group in case of a single annotation file. Set to `False` by default.\n\n  * **ignore_keys** (_List_ _[__str_ _]_) \u2013 A list of COCO keys to ignore.\n\n  * **image_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the images tensor.\n\n  * **image_creds_key** (_Optional_ _[__str_ _]_) \u2013 The name of the managed credentials to use for accessing the images in the linked tensor (is applicable).\n\n  * **src_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 Credentials to access the source data. If not provided, will be inferred from the environment.",
        "node_730": "For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.\n\n### Creating a binary_mask tensor\uf0c1\n\nA binary_mask tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"masks\", htype=\"binary_mask\", sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * ref:sample_compression <sample_compression> or chunk_compression\n\n    * dtype: Defaults to `bool`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`.",
        "node_109": "* **dest_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 The string `ENV` or a dictionary containing credentials used to access the destination path of the dataset.\n\n  * **kaggle_credentials** (_dict_) \u2013 A dictionary containing kaggle credentials {\u201cusername\u201d:\u201dYOUR_USERNAME\u201d, \u201ckey\u201d: \u201cYOUR_KEY\u201d}. If `None`, environment variables/the kaggle.json file will be used if available.\n\n  * **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Set to `True` by default.\n\n  * **summary** (_bool_) \u2013 Generates ingestion summary. Set to `True` by default.\n\n  * **shuffle** (_bool_) \u2013 Shuffles the input data prior to ingestion. Since data arranged in folders by class is highly non-random, shuffling is important in order to produce optimal results when training. Defaults to `True`.\n\n  * ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function. See `deeplake.dataset()`.\n\nReturns\n\n    \n\nNew dataset object with structured dataset.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**SamePathException** \u2013 If the source and destination path are same.\n\nNote\n\nCurrently only local source paths and image classification datasets are\nsupported for automatic ingestion.\n\ndeeplake.ingest_dataframe(_src_ , _dest : Union[str, Path]_, _column_params :\nOptional[Dict] = None_, _src_creds : Optional[Union[Dict, str]] = None_,\n_dest_creds : Optional[Union[Dict, str]] = None_, _creds_key : Optional[Dict]\n= None_, _progressbar : bool = True_, _token : Optional[str] = None_,\n_connect_kwargs : Optional[Dict] = None_, _** dataset_kwargs_)\uf0c1\n\n    \n\nConvert pandas dataframe to a Deep Lake Dataset. The contents of the dataframe\ncan be parsed literally, or can be treated as links to local or cloud files.\n\nExamples\n\n    \n    \n    >>> # Ingest data from a DataFrame into a Deep Lake dataset stored in Deep Lake storage.",
        "node_1020": "Deep Lake will\nautomatically push all information required to reproduce the snapshot of the\ndata like your dataset\u2019s URI, commit ID, and view IDs of any views that you\nhave used in your training workflow.\n\nLearn more about Weights and Biases here.\n\n## Logging Dataset Creation\uf0c1\n\nIf you create a Deep Lake dataset using any of the functions mentioned in\nCreating Datasets, just perform a commit on the dataset to log its creation on\nW&B.\n\n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"dataset_upload\")\n    >>> ds = deeplake.empty(\"hub://fayazrahman4u/my_dataset\") # create dataset\n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\") # create a tensor\n    >>> ds.images.append(deeplake.read(\"files/images/dog.jpg\")) # add a sample\n    >>> ds.commit(\"creation\") # commit -> trigger logging\n    >>> run.finish()\n    \n\nNote\n\nIf you created your dataset using `deeplake.deepcopy()`, perform the commit\nonly if you have head changes.\n\nNote\n\nIf you make changes to an existing dataset, commit the changes with an active\nWeights and Biases run to log it\u2019s state.\n\n## Logging Dataset Read\uf0c1\n\nA dataset read will be logged if you iterate over a dataset or call\n`Dataset.pytorch()` or `Tensor.numpy()` on its tensors.\n\n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"torch dataloader\")\n    >>> train_loader = ds.pytorch()\n    >>> run.finish()\n    \n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"iteration\")\n    >>> for sample in ds:\n    >>>     print(sample[\"images\"].shape)\n    >>> run.finish()\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.",
        "node_60": "Defaults to `False`.\n\n  * **decode_method** (_Dict_ _[__str_ _,__str_ _]__,__Optional_) \u2013 \n\nA dictionary of decode methods for each tensor. Defaults to `None`.\n\n    * Supported decode methods are:\n\n> \u2019numpy\u2019\n>  \n>\n> Default behaviour. Returns samples as numpy arrays.\n>\n> \u2019tobytes\u2019\n>  \n>\n> Returns raw bytes of the samples.\n>\n> \u2019pil\u2019\n>  \n>\n> Returns samples as PIL images. Especially useful when transformation use\n> torchvision transforms, that require PIL images as input. Only supported for\n> tensors with `sample_compression='jpeg'` or `'png'`.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n**ValueError** \u2013 If .pytorch() or .tensorflow() or .numpy() has already been\ncalled.\n\nExamples\n\n    \n    \n    >>> import deeplake\n    >>> from torchvision import transforms\n    >>> ds_train = deeplake.load('hub://activeloop/fashion-mnist-train')\n    >>> tform = transforms.Compose([\n    ...     transforms.RandomRotation(20), # Image augmentation\n    ...     transforms.ToTensor(), # Must convert to pytorch tensor for subsequent operations to run\n    ...     transforms.Normalize([0.5], [0.5]),\n    ... ])\n    ...\n    >>> batch_size = 32\n    >>> # create dataloader by chaining with transform function and batch size and returns batch of pytorch tensors\n    >>> train_loader = ds_train.dataloader()\\\n    ...     .transform({'images': tform, 'labels': None})\\\n    ...     .batch(batch_size)\\\n    ...     .shuffle()\\\n    ...     .pytorch(decode_method={'images': 'pil'}) # return samples as PIL images for transforms\n    ...\n    >>> # iterate over dataloader\n    >>> for i, sample in enumerate(train_loader):\n    ...     pass\n    ...\n    \n\nquery(_query_string : str_)\uf0c1\n\n    \n\nReturns a sliced `DeepLakeDataLoader` object with given query results. It\nallows to run SQL like queries on dataset and extract results. See supported\nkeywords and the Tensor Query Language documentation here.",
        "node_1027": "Note\n\nIf you make changes to an existing dataset, commit the changes with an active\nWeights and Biases run to log it\u2019s state.\n\n## Logging Dataset Read\uf0c1\n\nA dataset read will be logged if you iterate over a dataset or call\n`Dataset.pytorch()` or `Tensor.numpy()` on its tensors.\n\n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"torch dataloader\")\n    >>> train_loader = ds.pytorch()\n    >>> run.finish()\n    \n    \n    \n    >>> run = wandb.init(project=\"deeplake_wandb\", job_type=\"iteration\")\n    >>> for sample in ds:\n    >>>     print(sample[\"images\"].shape)\n    >>> run.finish()\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_645": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_1070": "* **dest_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 The string `ENV` or a dictionary containing credentials used to access the destination path of the dataset.\n\n  * **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Defaults to `True`.\n\n  * **summary** (_bool_) \u2013 If `True`, a summary of skipped files will be printed after completion. Defaults to `True`.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for ingestion. Set to `0` by default.\n\n  * **shuffle** (_bool_) \u2013 Shuffles the input data prior to ingestion. Since data arranged in folders by class is highly non-random, shuffling is important in order to produce optimal results when training. Defaults to `True`.\n\n  * **token** (_Optional_ _[__str_ _]_) \u2013 The token to use for accessing the dataset.\n\n  * **connect_kwargs** (_Optional_ _[__Dict_ _]_) \u2013 If specified, the dataset will be connected to Deep Lake, and connect_kwargs will be passed to `Dataset.connect`.\n\n  * ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function see `deeplake.empty()`.\n\nReturns\n\n    \n\nNew dataset object with structured dataset.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **InvalidPathException** \u2013 If the source directory does not exist.\n\n  * **SamePathException** \u2013 If the source and destination path are same.\n\n  * **AutoCompressionError** \u2013 If the source director is empty or does not contain a valid extension.\n\n  * **InvalidFileExtension** \u2013 If the most frequent file extension is found to be \u2018None\u2019 during auto-compression.\n\nNote\n\n  * Currently only local source paths and image classification datasets / csv files are supported for automatic ingestion.\n\n  * Supported filetypes: png/jpeg/jpg/csv.\n\n  * All files and sub-directories with unsupported filetypes are ignored.",
        "node_1171": "Also supports simplified expression evaluations. See `deeplake.core.query.query.DatasetQuery` for more details.\n\n  * **num_workers** (_int_) \u2013 Level of parallelization of filter evaluations. 0 indicates in-place for-loop evaluation, multiprocessing is used otherwise.\n\n  * **scheduler** (_str_) \u2013 Scheduler to use for multiprocessing evaluation. \u201cthreaded\u201d is default.\n\n  * **progressbar** (_bool_) \u2013 Display progress bar while filtering. `True` is default.\n\n  * **save_result** (_bool_) \u2013 If `True`, result of the filter will be saved to a dataset asynchronously.\n\n  * **result_path** (_Optional_ _,__str_) \u2013 Path to save the filter result. Only applicable if `save_result` is True.\n\n  * **result_ds_args** (_Optional_ _,__dict_) \u2013 Additional args for result dataset. Only applicable if `save_result` is True.\n\nReturns\n\n    \n\nView of Dataset with elements that satisfy filter function.\n\nExample\n\nFollowing filters are identical and return dataset view where all the samples\nhave label equals to 2.\n\n    \n    \n    >>> dataset.filter(lambda sample: sample.labels.numpy() == 2)\n    >>> dataset.filter('labels == 2')\n    \n\nfix_vc()\uf0c1\n\n    \n\nRebuilds version control info. To be used when the version control info is\ncorrupted.\n\nflush()\uf0c1\n\n    \n\nNecessary operation after writes if caches are being used. Writes all the\ndirty data from the cache layers (if any) to the underlying storage. Here\ndirty data corresponds to data that has been changed/assigned and but hasn\u2019t\nyet been sent to the underlying storage.\n\nget_commit_details(_commit_id_) -> Dict\uf0c1\n\n    \n\nGet details of a particular commit.\n\nParameters\n\n    \n\n**commit_id** (_str_) \u2013 commit id of the commit.\n\nReturns\n\n    \n\nDictionary of details with keys - `commit`, `author`, `time`, `message`.\n\nReturn type\n\n    \n\nDict\n\nRaises\n\n    \n\n**KeyError** \u2013 If given `commit_id` is was not found in the dataset.\n\nget_creds_keys() -> Set[str]\uf0c1\n\n    \n\nReturns the set of creds keys added to the dataset.",
        "node_570": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_777": ">>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type. i.e., if RGB images are appended to an `image.gray`\ntensor, Deep Lake will convert them to grayscale and if grayscale images are\nappended to an `image.rgb` tensor, Deep Lake will convert them to RGB format.\n\nimage.rgb and image.gray tensors can be created using\n\n    \n    \n    >>> ds.create_tensor(\"rgb_images\", htype=\"image.rgb\", sample_compression=\"...\")\n    \n    \n    \n    >>> ds.create_tensor(\"gray_images\", htype=\"image.gray\", sample_compression=\"...\")\n    \n\n## Video Htype\uf0c1\n\n  * Sample dimensions: `(# frames, height, width, # channels)` or `(# frames, height, width)`\n\n### Limitations\uf0c1\n\n  * Visualization of videos in the Deep Lake App is limited by the video coded support for various browsers.\n    \n    * Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.",
        "node_208": "* **collate_fn** (_Callable_ _,__Optional_) \u2013 merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset. Read torch.utils.data.DataLoader docs for more details.\n\n  * **pin_memory** (_bool_) \u2013 If `True`, the data loader will copy Tensors into CUDA pinned memory before returning them. Default value is `False`. Read torch.utils.data.DataLoader docs for more details.\n\n  * **shuffle** (_bool_) \u2013 If `True`, the data loader will shuffle the data indices. Default value is False. Details about how Deep Lake shuffles data can be found at Shuffling in ds.pytorch()\n\n  * **buffer_size** (_int_) \u2013 The size of the buffer used to shuffle the data in MBs. Defaults to 2048 MB. Increasing the buffer_size will increase the extent of shuffling.\n\n  * **use_local_cache** (_bool_) \u2013 If `True`, the data loader will use a local cache to store data. The default cache location is ~/.activeloop/cache, but it can be changed by setting the `LOCAL_CACHE_PREFIX` environment variable. This is useful when the dataset can fit on the machine and we don\u2019t want to fetch the data multiple times for each iteration. Default value is `False`\n\n  * **progressbar** (_bool_) \u2013 If `True`, tqdm will be wrapped around the returned dataloader. Default value is True.\n\n  * **return_index** (_bool_) \u2013 If `True`, the returned dataloader will have a key \u201cindex\u201d that contains the index of the sample(s) in the original dataset. Default value is True.\n\n  * **pad_tensors** (_bool_) \u2013 If `True`, shorter tensors will be padded to the length of the longest tensor. Default value is False.\n\n  * **transform_kwargs** (_optional_ _,__Dict_ _[__str_ _,__Any_ _]_) \u2013 Additional kwargs to be passed to `transform`.\n\n  * **decode_method** (_Dict_ _[__str_ _,__str_ _]__,__Optional_) \u2013 \n\nA dictionary of decode methods for each tensor. Defaults to `None`.",
        "node_646": "For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.\n\n## Point Htype\uf0c1\n\n  * Sample dimensions: `(# points, 2)` in case of 2-D (X, Y) co-ordinates or `(# points, 3)` in case of 3-D (X, Y, Z) co-ordinates of the point.\n\nPoints does not contain a fixed mapping across samples between the point order\nand real-world objects (i.e., point 0 is an elbow, point 1 is a knee, etc.).\nIf you require such a mapping, use COCO Keypoints Htype.\n\n### Creating a point tensor\uf0c1\n\nA point tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"points\", htype=\"point\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending point samples\uf0c1\n\n  * Points can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.",
        "node_133": "* **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\nReturns\n\n    \n\nA boolean confirming whether the dataset exists or not at the given path.\n\nRaises\n\n    \n\n**ValueError** \u2013 If version is specified in the path\n\ndeeplake.read(_path : Union[str, Path]_, _verify : bool = False_, _creds :\nOptional[Dict] = None_, _compression : Optional[str] = None_, _storage :\nOptional[StorageProvider] = None_, _timeout : Optional[float] = None_) ->\nSample\uf0c1\n\n    \n\nUtility that reads raw data from supported files into Deep Lake format.\n\n  * Recompresses data into format required by the tensor if permitted by the tensor htype.\n\n  * Simply copies the data in the file if file format matches sample_compression of the tensor, thus maximizing upload speeds.",
        "node_1310": "Revision `dbac1aa4`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: v3.0.16\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_326": "`Dataset.commits` | Lists all the commits leading to the current dataset state.  \n`Dataset.branches` | Lists all the branches of the dataset.  \n  \n## Dataset Views\uf0c1\n\nA dataset view is a subset of a dataset that points to specific samples\n(indices) in an existing dataset. Dataset views can be created by indexing a\ndataset, filtering a dataset with `Dataset.filter()`, querying a dataset with\n`Dataset.query()` or by sampling a dataset with `Dataset.sample_by()`.\nFiltering is done with user-defined functions or simplified expressions\nwhereas query can perform SQL-like queries with our Tensor Query Language. See\nthe full TQL spec here.\n\nDataset views can only be saved when a dataset has been committed and has no\nchanges on the HEAD node, in order to preserve data lineage and prevent the\nunderlying data from changing after the query or filter conditions have been\nevaluated.\n\n**Example**\n\n    \n    \n    >>> import deeplake\n    >>> # load dataset\n    >>> ds = deeplake.load(\"hub://activeloop/mnist-train\")\n    >>> # filter dataset\n    >>> zeros = ds.filter(\"labels == 0\")\n    >>> # save view\n    >>> zeros.save_view(id=\"zeros\")\n    >>> # load_view\n    >>> zeros = ds.load_view(id=\"zeros\")\n    >>> len(zeros)\n    5923\n    \n\n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n---|---  \n`Dataset.sample_by` | Returns a sliced `Dataset` with given weighted sampler applied.  \n`Dataset.filter` | Filters the dataset in accordance of filter function `f(x: sample) -> bool`  \n`Dataset.save_view` | Saves a dataset view as a virtual dataset (VDS)  \n`Dataset.get_view` | Returns the dataset view corresponding to `id`.  \n`Dataset.load_view` | Loads the view and returns the `Dataset` by id.  \n`Dataset.delete_view` | Deletes the view with given view id.  \n`Dataset.get_views` | Returns list of views stored in this Dataset.  \n`Dataset.is_view` | Returns `True` if this dataset is a view and `False` otherwise.",
        "node_513": "core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.\n\nSupported htypes and their respective defaults are:\n\nHtype configs\uf0c1 HTYPE | DTYPE | COMPRESSION  \n---|---|---  \ngeneric | None | None  \nimage | uint8 | Required arg  \nimage.rgb | uint8 | Required arg  \nimage.gray | uint8 | Required arg  \nvideo | uint8 | Required arg  \naudio | float64 | Required arg  \nclass_label | uint32 | None  \ntag | str | None  \nbbox | float32 | None  \nbbox.3d | float32 | None  \nintrinsics | float32 | None  \nsegment_mask | uint32 | None  \nbinary_mask | bool | None  \nkeypoints_coco | int32 | None  \npoint | int32 | None  \npolygon | float32 | None  \ntext | str | None  \njson | Any | None  \nlist | List | None  \ndicom | None | dcm  \nnifti | None | Required arg  \npoint_cloud | None | las  \nmesh | None | ply  \ninstance_label | uint32 | None  \nembedding | None | None  \nlink | str | None  \nsequence | None | None  \n  \n## Image Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # channels)` or `(height, width)`.\n\nImages can be stored in Deep Lake as compressed bytes or as raw arrays.",
        "node_623": "Examples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.\n\nExamples\n\n    \n    \n    >>> ds.create_tensor(\"seq\", htype=\"sequence\")\n    >>> ds.seq.append([1, 2, 3])\n    >>> ds.seq.append([4, 5, 6])\n    >>> ds.seq.numpy()\n    array([[[1],\n            [2],\n            [3]],\n           [[4],\n            [5],\n            [6]]])\n    \n    \n    \n    >>> ds.create_tensor(\"image_seq\", htype=\"sequence[image]\", sample_compression=\"jpg\")\n    >>> ds.image_seq.append([deeplake.read(\"img01.jpg\"), deeplake.read(\"img02.jpg\")])\n    \n\n## Link htype\uf0c1\n\n  * Link htype is a special meta htype that allows linking of external data (files) to the dataset, without storing the data in the dataset itself.\n\n  * Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read.",
        "node_650": "* Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.\n\nExamples\n\nAppending point clouds with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> point_cloud1 = np.random.randint(0, 10, (5, 3))\n    >>> ds.point_clouds.append(point_cloud1)\n    >>> point_cloud2 = np.random.randint(0, 10, (15, 3))\n    >>> ds.point_clouds.append(point_cloud2)\n    >>> ds.point_clouds.shape\n    >>> (2, None, 3)\n    \n\nOr we can use `deeplake.read()` method to add samples\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.las\") # point cloud with 100 points\n    >>> ds.point_cloud.append(sample)\n    >>> ds.point_cloud.shape\n    >>> (1, 100, 3)\n    \n\n## Mesh Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Mesh samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.",
        "node_560": "Examples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.",
        "node_1164": "load('hub://activeloop/coco-train')\n    >>> train_loader = ds_train.dataloader()\\\n    .     .query(\"(select * where contains(categories, 'car') limit 1000) union (select * where contains(categories, 'motorcycle') limit 1000)\")\\\n    .     .pytorch()\n    .\n    >>> # loop over the elements\n    >>> for i, data in enumerate(train_loader):\n    .     # custom logic on data\n    .     pass\n    \n\ndelete(_large_ok =False_)\uf0c1\n\n    \n\nDeletes the entire dataset from the cache layers (if any) and the underlying\nstorage. This is an **IRREVERSIBLE** operation. Data once deleted can not be\nrecovered.\n\nParameters\n\n    \n\n**large_ok** (_bool_) \u2013 Delete datasets larger than 1 GB. Defaults to `False`.\n\nRaises\n\n    \n\n  * **DatasetTooLargeToDelete** \u2013 If the dataset is larger than 1 GB and `large_ok` is `False`.\n\n  * **DatasetHandlerError** \u2013 If the dataset is marked as allow_delete=False.\n\ndelete_branch(_name : str_) -> None\uf0c1\n\n    \n\nDeletes the branch and cleans up any unneeded data. Branches can only be\ndeleted if there are no sub-branches and if it has never been merged into\nanother branch.\n\nParameters\n\n    \n\n**name** (_str_) \u2013 The branch to delete.\n\nRaises\n\n    \n\n  * **CommitError** \u2013 If `branch` could not be found.\n\n  * **ReadOnlyModeError** \u2013 If branch deletion is attempted in read-only mode.\n\n  * **Exception** \u2013 If you have the given branch currently checked out.",
        "node_890": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_96": "* **dest_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 The string `ENV` or a dictionary containing credentials used to access the destination path of the dataset.\n\n  * **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Defaults to `True`.\n\n  * **summary** (_bool_) \u2013 If `True`, a summary of skipped files will be printed after completion. Defaults to `True`.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for ingestion. Set to `0` by default.\n\n  * **shuffle** (_bool_) \u2013 Shuffles the input data prior to ingestion. Since data arranged in folders by class is highly non-random, shuffling is important in order to produce optimal results when training. Defaults to `True`.\n\n  * **token** (_Optional_ _[__str_ _]_) \u2013 The token to use for accessing the dataset.\n\n  * **connect_kwargs** (_Optional_ _[__Dict_ _]_) \u2013 If specified, the dataset will be connected to Deep Lake, and connect_kwargs will be passed to `Dataset.connect`.\n\n  * ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function see `deeplake.empty()`.\n\nReturns\n\n    \n\nNew dataset object with structured dataset.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **InvalidPathException** \u2013 If the source directory does not exist.\n\n  * **SamePathException** \u2013 If the source and destination path are same.\n\n  * **AutoCompressionError** \u2013 If the source director is empty or does not contain a valid extension.\n\n  * **InvalidFileExtension** \u2013 If the most frequent file extension is found to be \u2018None\u2019 during auto-compression.\n\nNote\n\n  * Currently only local source paths and image classification datasets / csv files are supported for automatic ingestion.\n\n  * Supported filetypes: png/jpeg/jpg/csv.\n\n  * All files and sub-directories with unsupported filetypes are ignored.",
        "node_789": "* Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`. A set of `K` keypoints of an object is represented as:\n\n[x1, y1, v1, x2, y2, v2, \u2026, xk, yk, vk]\n\nThe visibility `v` can be one of three values:\n\n0\n\n    \n\nkeypoint not in image.\n\n1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.",
        "node_1100": "\\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **dest_creds** (_dict_ _,__optional_) \u2013 creds required to create / overwrite datasets at `dest`.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for copying. Defaults to 0. When set to 0, it will always use serial processing, irrespective of the scheduler.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for copying. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Defaults to \u2018threaded\u2019.\n\n  * **progressbar** (_bool_) \u2013 Displays a progress bar if True (default).\n\n  * ****kwargs** (_dict_) \u2013 Additional keyword arguments\n\nReturns\n\n    \n\nNew dataset object.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **DatasetHandlerError** \u2013 If a dataset already exists at destination path and overwrite is False.\n\n  * **UnsupportedParameterException** \u2013 If a parameter that is no longer supported is specified.\n\n  * **DatasetCorruptError** \u2013 If loading source dataset fails with DatasetCorruptedError.\n\ndeeplake.deepcopy(_src : Union[str, Path, Dataset]_, _dest : Union[str,\nPath]_, _runtime : Optional[Dict] = None_, _tensors : Optional[List[str]] =\nNone_, _overwrite : bool = False_, _src_creds =None_, _dest_creds =None_,\n_token =None_, _num_workers : int = 0_, _scheduler ='threaded'_, _progressbar\n=True_, _public : bool = False_, _verbose : bool = True_, _** kwargs_)\uf0c1\n\n    \n\nCopies dataset at `src` to `dest` including version control history.",
        "node_1196": "Raises\n\n    \n\n  * **ValueError** \u2013 If partial update of a sample is attempted.\n\n  * **Exception** \u2013 Error while attempting to rollback updates.\n\nupdate_creds_key(_creds_key : str_, _new_creds_key : Optional[str] = None_,\n_managed : Optional[bool] = None_)\uf0c1\n\n    \n\nUpdates the name and/or management status of a creds key.\n\nParameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The key whose name and/or management status is to be changed.\n\n  * **new_creds_key** (_str_ _,__optional_) \u2013 The new key to replace the old key. If not provided, the old key will be used.\n\n  * **managed** (_bool_) \u2013 The target management status. If `True`, the creds corresponding to the key will be fetched from activeloop platform.\n\nRaises\n\n    \n\n  * **ValueError** \u2013 If the dataset is not connected to activeloop platform.\n\n  * **ValueError** \u2013 If both `new_creds_key` and `managed` are `None`.\n\n  * **KeyError** \u2013 If the creds key is not present in the dataset.\n\nExamples\n\n    \n    \n    >>> # create/load a dataset\n    >>> ds = deeplake.dataset(\"path/to/dataset\")\n    >>> # add a new creds key\n    >>> ds.add_creds_key(\"my_s3_key\")\n    >>> # Populate the name added with creds dictionary\n    >>> # These creds are only present temporarily and will have to be repopulated on every reload\n    >>> ds.populate_creds(\"my_s3_key\", {})\n    >>> # Rename the key and change the management status of the key to True.",
        "node_468": "For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.\n\n### Creating a binary_mask tensor\uf0c1\n\nA binary_mask tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"masks\", htype=\"binary_mask\", sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * ref:sample_compression <sample_compression> or chunk_compression\n\n    * dtype: Defaults to `bool`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`.",
        "node_759": "For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.\n\n### Creating a binary_mask tensor\uf0c1\n\nA binary_mask tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"masks\", htype=\"binary_mask\", sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * ref:sample_compression <sample_compression> or chunk_compression\n\n    * dtype: Defaults to `bool`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`.",
        "node_514": "Images can be stored in Deep Lake as compressed bytes or as raw arrays. Due to\nthe high compression ratio for most image formats, it is highly recommended to\nstore compressed images using the `sample_compression` input to the\ncreate_tensor method.\n\n### Creating an image tensor\uf0c1\n\nAn image tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\")\n    \n\nOR\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", chunk_compression=\"jpg\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"bmp\", \"dib\", \"gif\", \"ico\", \"jpeg\", \"jpeg2000\", \"pcx\", \"png\", \"ppm\", \"sgi\", \"tga\", \"tiff\",\n    ... \"webp\", \"wmf\", \"xbm\", \"eps\", \"fli\", \"im\", \"msp\", \"mpo\"]\n    \n\n### Appending image samples\uf0c1\n\n  * Image samples can be of type `np.ndarray` or Deep Lake `Sample` which can be created using `deeplake.read()`.\n\nExamples\n\nAppending pixel data with array\n\n    \n    \n    >>> ds.images.append(np.zeros((5, 5, 3), dtype=np.uint8))\n    \n\nAppening Deep Lake image sample\n\n    \n    \n    >>> ds.images.append(deeplake.read(\"images/0001.jpg\"))\n    \n\nYou can append multiple samples at the same time using `extend()`.\n\n    \n    \n    >>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type.",
        "node_1144": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n    * deeplake.core.sample\n    * deeplake.core.linked_sample\n    * deeplake.core.partial_sample\n    * deeplake.core.link_tiled_sample\n    * deeplake.core.storage\n    * deeplake.core.index\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * deeplake.core\n  * Edit on GitHub\n\n* * *\n\n# deeplake.core\uf0c1\n\n  * deeplake.core.sample\n    * `Sample`\n  * deeplake.core.linked_sample\n    * `LinkedSample`\n  * deeplake.core.partial_sample\n    * `PartialSample`\n  * deeplake.core.link_tiled_sample\n    * `LinkedTiledSample`\n  * deeplake.core.storage\n    * Base Storage Provider\n    * LRU Cache\n    * S3 Storage Provider\n    * Google Cloud Storage Provider\n    * Google Drive Storage Provider\n    * Local Storage Provider\n    * Memory Provider\n  * deeplake.core.index\n    * `IndexEntry`\n    * `Index`\n    * `merge_slices()`\n    * `slice_at_int()`\n    * `slice_length()`\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.",
        "node_1047": "## Examples\uf0c1\n\nQuerying for images containing 0 in MNIST Train Dataset with `ds.query`.\n\n    \n    \n    >>> import deeplake\n    >>> ds = deeplake.load(\"hub://activeloop/mnist-train\")\n    >>> result = ds.query(\"select * where labels == 0\")\n    >>> len(result)\n    5923\n    \n\nQuerying for samples with `car` or `motorcycle` in `categories` of COCO Train\nDataset.\n\n    \n    \n    >>> import deeplake\n    >>> ds = deeplake.load(\"hub://activeloop/coco-train\")\n    >>> result = ds.query(\"(select * where contains(categories, 'car')) union (select * where contains(categories, 'motorcycle'))\")\n    >>> len(result)\n    14376\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_300": "Deep\nLake datasets are compatible with both PyTorch and TensorFlow, whereas TFDS\nare only compatible with TensorFlow. A key difference between Deep Lake and\nTFDS is that Deep Lake datasets are designed for streaming from the cloud,\nwhereas TFDS must be downloaded locally prior to use. As a result, with Deep\nLake, one can import datasets directly from TensorFlow Datasets and stream\nthem either to PyTorch or TensorFlow. In addition to providing access to\npopular publicly available datasets, Deep Lake also offers powerful tools for\ncreating custom datasets, storing them on a variety of cloud storage\nproviders, and collaborating with others via simple API. TFDS is primarily\nfocused on giving the public easy access to commonly available datasets, and\nmanagement of custom datasets is not the primary focus. A full comparison\narticle can be found here.\n\n**Deep Lake vs HuggingFace** Deep Lake and HuggingFace offer access to popular\ndatasets, but Deep Lake primarily focuses on computer vision, whereas\nHuggingFace focuses on natural language processing. HuggingFace Transforms and\nother computational tools for NLP are not analogous to features offered by\nDeep Lake.  **Deep Lake vs WebDatasets** Deep Lake and WebDatasets both offer\nrapid data streaming across networks. They have nearly identical steaming\nspeeds because the underlying network requests and data structures are very\nsimilar. However, Deep Lake offers superior random access and shuffling, its\nsimple API is in python instead of command-line, and Deep Lake enables simple\nindexing and modification of the dataset without having to recreate it.",
        "node_1225": "util\uf0c1\n\n  * deeplake.util.shape_interval\n    * `ShapeInterval`\n  * deeplake.util.remove_cache\n    * `remove_memory_cache()`\n    * `get_base_storage()`\n    * `get_dataset_with_zero_size_cache()`\n    * `create_read_copy_dataset()`\n  * deeplake.util.notebook\n    * `is_notebook()`\n    * `is_jupyter()`\n    * `is_colab()`\n  * deeplake.util.exceptions\n    * `ExternalCommandError`\n    * `KaggleError`\n    * `KaggleMissingCredentialsError`\n    * `KaggleDatasetAlreadyDownloadedError`\n    * `InvalidPathException`\n    * `AutoCompressionError`\n    * `InvalidFileExtension`\n    * `SamePathException`\n    * `TensorInvalidSampleShapeError`\n    * `TensorMetaMissingKey`\n    * `TensorDoesNotExistError`\n    * `TensorAlreadyExistsError`\n    * `TensorGroupDoesNotExistError`\n    * `TensorGroupAlreadyExistsError`\n    * `InvalidTensorNameError`\n    * `InvalidTensorGroupNameError`\n    * `DynamicTensorNumpyError`\n    * `InvalidShapeIntervalError`\n    * `InvalidKeyTypeError`\n    * `UnsupportedTensorTypeError`\n    * `InvalidBytesRequestedError`\n    * `ProviderListEmptyError`\n    * `DirectoryAtPathException`\n    * `FileAtPathException`\n    * `ProviderSizeListMismatch`\n    * `ModuleNotInstalledException`\n    * `LoginException`\n    * `UserNotLoggedInException`\n    * `InvalidHubPathException`\n    * `PathNotEmptyException`\n    * `AuthenticationException`\n    * `AuthorizationException`\n    * `InvalidPasswordException`\n    * `CouldNotCreateNewDatasetException`\n    * `ResourceNotFoundException`\n    * `BadRequestException`\n    * `OverLimitException`",
        "node_312": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Installation\n  * Edit on GitHub\n\n* * *\n\n# Installation\uf0c1\n\nDeep Lake can be installed with pip\n\n    \n    \n    pip install deeplake\n    \n\nDeep Lake has the following extras that you can choose to install according to\nyour needs.\n\nInstallation commands\uf0c1 Install command | Description | Dependencies installed  \n---|---|---  \n`pip install \"deeplake[av]\"` | Audio and video support via PyAV | av  \n`pip install \"deeplake[visualizer]\"` | Visualize Deep Lake datasets within notebooks. This is required for `Dataset.visualize` to work.",
        "node_264": "Parameters\n\n    \n\n  * **dataset** (_Dataset_) \u2013 deeplake dataset object or path.\n\n  * **path** (_Union_ _[__str_ _,__pathlib.Path_ _]_) \u2013 Path to the dataset.\n\n  * **logger** (_logging.Logger_) \u2013 Logger object.\n\n  * **embedding_function** (_Optional_ _[__Any_ _]__,__optional_) \u2013 Embedding funtion class used to convert queries/documents to embeddings. Defaults to None.\n\n  * **token** (_Optional_ _[__str_ _]__,__optional_) \u2013 API token for the DeepMemory managed service. Defaults to None.\n\n  * **creds** (_Optional_ _[__Dict_ _[__str_ _,__Any_ _]__]__,__optional_) \u2013 Credentials to access the dataset. Defaults to None.\n\nRaises\n\n    \n\n**ImportError** \u2013 if indra is not installed\n\ncancel(_job_id : str_)\uf0c1\n\n    \n\nCancel a training job on DeepMemory managed service.\n\nExamples\n\n    \n    \n    >>> cancelled: bool = vectorstore.deep_memory.cancel(job_id)\n    \n\nParameters\n\n    \n\n**job_id** (_str_) \u2013 job_id of the training job.\n\nReturns\n\n    \n\nTrue if job was cancelled successfully, False otherwise.\n\nReturn type\n\n    \n\nbool\n\ndelete(_job_id : str_)\uf0c1\n\n    \n\nDelete a training job on DeepMemory managed service.\n\nExamples\n\n    \n    \n    >>> deleted: bool = vectorstore.deep_memory.delete(job_id)\n    \n\nParameters\n\n    \n\n**job_id** (_str_) \u2013 job_id of the training job.\n\nReturns\n\n    \n\nTrue if job was deleted successfully, False otherwise.\n\nReturn type\n\n    \n\nbool\n\nevaluate(_relevance : List[List[Tuple[str, int]]]_, _queries : List[str]_,\n_embedding_function : Optional[Callable[[...], List[ndarray]]] = None_,\n_embedding : Optional[Union[List[ndarray], List[List[float]]]] = None_, _top_k\n: List[int] = [1, 3, 5, 10, 50, 100]_, _qvs_params : Optional[Dict[str, Any]]\n= None_) -> Dict[str, Dict[str, float]]\uf0c1\n\n    \n\nEvaluate a model using the DeepMemory managed service.",
        "node_597": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.",
        "node_687": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_58": ">\n> \u2019pil\u2019\n>  \n>\n> Returns samples as PIL images. Especially useful when transformation use\n> torchvision transforms, that require PIL images as input. Only supported for\n> tensors with sample_compression=\u2019jpeg\u2019 or \u2018png\u2019.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n**ValueError** \u2013 If .pytorch() or .tensorflow() or .numpy() has already been\ncalled.\n\noffset(_off : int = 0_)\uf0c1\n\n    \n\nReturns a shifted `DeepLakeDataLoader` object.\n\nParameters\n\n    \n\n**off** (_int_) \u2013 index that the dataloadee will start to iterate.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n**ValueError** \u2013 If .offset() has already been called.\n\npytorch(_num_workers : int = 0_, _collate_fn : Optional[Callable] = None_,\n_tensors : Optional[List[str]] = None_, _num_threads : Optional[int] = None_,\n_prefetch_factor : int = 2_, _distributed : bool = False_, _return_index :\nbool = True_, _decode_method : Optional[Dict[str, str]] = None_,\n_persistent_workers : bool = False_)\uf0c1\n\n    \n\nReturns a `DeepLakeDataLoader` object.\n\nParameters\n\n    \n\n  * **num_workers** (_int_) \u2013 Number of workers to use for transforming and processing the data. Defaults to 0.\n\n  * **collate_fn** (_Callable_ _,__Optional_) \u2013 merges a list of samples to form a mini-batch of Tensor(s).\n\n  * **tensors** (_List_ _[__str_ _]__,__Optional_) \u2013 List of tensors to load. If None, all tensors are loaded. Defaults to `None`.\n\n  * **num_threads** (_int_ _,__Optional_) \u2013 Number of threads to use for fetching and decompressing the data. If `None`, the number of threads is automatically determined. Defaults to `None`.\n\n  * **prefetch_factor** (_int_) \u2013 Number of batches to transform and collate in advance per worker. Defaults to 2.",
        "node_198": "To be used when the version control info is\ncorrupted.\n\nflush()\uf0c1\n\n    \n\nNecessary operation after writes if caches are being used. Writes all the\ndirty data from the cache layers (if any) to the underlying storage. Here\ndirty data corresponds to data that has been changed/assigned and but hasn\u2019t\nyet been sent to the underlying storage.\n\nget_commit_details(_commit_id_) -> Dict\uf0c1\n\n    \n\nGet details of a particular commit.\n\nParameters\n\n    \n\n**commit_id** (_str_) \u2013 commit id of the commit.\n\nReturns\n\n    \n\nDictionary of details with keys - `commit`, `author`, `time`, `message`.\n\nReturn type\n\n    \n\nDict\n\nRaises\n\n    \n\n**KeyError** \u2013 If given `commit_id` is was not found in the dataset.\n\nget_creds_keys() -> Set[str]\uf0c1\n\n    \n\nReturns the set of creds keys added to the dataset. These are used to fetch\nexternal data in linked tensors\n\nget_managed_creds_keys() -> List[str]\uf0c1\n\n    \n\nReturns the list of creds keys added to the dataset that are managed by\nActiveloop platform. These are used to fetch external data in linked tensors.\n\nget_view(_id : str_) -> ViewEntry\uf0c1\n\n    \n\nReturns the dataset view corresponding to `id`.\n\nExamples\n\n    \n    \n    >>> # save view\n    >>> ds[:100].save_view(id=\"first_100\")\n    >>> # load view\n    >>> first_100 = ds.get_view(\"first_100\").load()\n    >>> # 100\n    >>> print(len(first_100))\n    \n\nSee `Dataset.save_view()` to learn more about saving views.\n\nParameters\n\n    \n\n**id** (_str_) \u2013 id of required view.\n\nReturns\n\n    \n\nViewEntry\n\nRaises\n\n    \n\n**KeyError** \u2013 If no such view exists.\n\nget_views(_commit_id : Optional[str] = None_) -> List[ViewEntry]\uf0c1\n\n    \n\nReturns list of views stored in this Dataset.\n\nParameters\n\n    \n\n**commit_id** (_str_ _,__optional_) \u2013\n\n  * Commit from which views should be returned.\n\n  * If not specified, views from all commits are returned.\n\nReturns\n\n    \n\nList of `ViewEntry` instances.",
        "node_456": "Images can be stored in Deep Lake as compressed bytes or as raw arrays. Due to\nthe high compression ratio for most image formats, it is highly recommended to\nstore compressed images using the `sample_compression` input to the\ncreate_tensor method.\n\n### Creating an image tensor\uf0c1\n\nAn image tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\")\n    \n\nOR\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", chunk_compression=\"jpg\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"bmp\", \"dib\", \"gif\", \"ico\", \"jpeg\", \"jpeg2000\", \"pcx\", \"png\", \"ppm\", \"sgi\", \"tga\", \"tiff\",\n    ... \"webp\", \"wmf\", \"xbm\", \"eps\", \"fli\", \"im\", \"msp\", \"mpo\"]\n    \n\n### Appending image samples\uf0c1\n\n  * Image samples can be of type `np.ndarray` or Deep Lake `Sample` which can be created using `deeplake.read()`.\n\nExamples\n\nAppending pixel data with array\n\n    \n    \n    >>> ds.images.append(np.zeros((5, 5, 3), dtype=np.uint8))\n    \n\nAppening Deep Lake image sample\n\n    \n    \n    >>> ds.images.append(deeplake.read(\"images/0001.jpg\"))\n    \n\nYou can append multiple samples at the same time using `extend()`.\n\n    \n    \n    >>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type.",
        "node_225": "These keys are used for tensors that are\nlinked to external data.\n\nExamples\n\n    \n    \n    >>> # create/load a dataset\n    >>> ds = deeplake.dataset(\"hub://username/dataset\")\n    >>> # add a new creds key\n    >>> ds.add_creds_key(\"my_s3_key\")\n    \n\nParameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The key to be added.\n\n  * **managed** (_bool_) \u2013 If `True`, the creds corresponding to the key will be fetched from activeloop platform. Note, this is only applicable for datasets that are connected to activeloop platform. Defaults to `False`.\n\n_property _client\uf0c1\n\n    \n\nReturns the client of the dataset.\n\nconnect(_* args_, _** kwargs_)\uf0c1\n\n    \n\nConnect a Deep Lake cloud dataset through a deeplake path.\n\nExamples\n\n    \n    \n    >>> # create/load an s3 dataset\n    >>> s3_ds = deeplake.dataset(\"s3://bucket/dataset\")\n    >>> ds = s3_ds.connect(dest_path=\"hub://my_org/dataset\", creds_key=\"my_managed_credentials_key\", token=\"my_activeloop_token)\n    >>> # or\n    >>> ds = s3_ds.connect(org_id=\"my_org\", creds_key=\"my_managed_credentials_key\", token=\"my_activeloop_token\")\n    \n\nParameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The managed credentials to be used for accessing the source path.\n\n  * **dest_path** (_str_ _,__optional_) \u2013 The full path to where the connected Deep Lake dataset will reside. Can be: a Deep Lake path like `hub://organization/dataset`\n\n  * **org_id** (_str_ _,__optional_) \u2013 The organization to where the connected Deep Lake dataset will be added.\n\n  * **ds_name** (_str_ _,__optional_) \u2013 The name of the connected Deep Lake dataset. Will be infered from `dest_path` or `src_path` if not provided.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token used to fetch the managed credentials.\n\nRaises\n\n    \n\n  * **InvalidSourcePathError** \u2013 If the dataset\u2019s path is not a valid s3, gcs or azure path.",
        "node_955": "### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.\n\nExamples\n\nAppending a tag\n\n    \n    \n    >>> ds.tags.append(\"verified\")\n    \n\nExtending with list of tags\n\n    \n    \n    >>> ds.tags.extend([\"verified\", \"unverified\"])\n    \n\n## Bounding Box Htype\uf0c1\n\n  * Sample dimensions: `(# bounding boxes, 4)`\n\nBounding boxes have a variety of conventions such as those used in YOLO, COCO,\nPascal-VOC and others. In order for bounding boxes to be correctly displayed\nby the visualizer, the format of the bounding box must be specified in the\ncoords key in tensor meta information mentioned below.\n\n### Creating a bbox tensor\uf0c1\n\nA bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"boxes\", htype=\"bbox\", coords={\"type\": \"fractional\", \"mode\": \"CCWH\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with keys \u201ctype\u201d and \u201cmode\u201d.\n    \n      * **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.",
        "node_469": "* Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`. A set of `K` keypoints of an object is represented as:\n\n[x1, y1, v1, x2, y2, v2, \u2026, xk, yk, vk]\n\nThe visibility `v` can be one of three values:\n\n0\n\n    \n\nkeypoint not in image.\n\n1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.",
        "node_1298": "Discover all our features __\n\nTry it out\n\n##  Upgrade your documentation with Read the Docs\n\n__`.readthedocs.yaml`\n\n    \n    \n    version: 2\n    build:\n      os: ubuntu-22.04\n      tools:\n        python: \"3.10\"\n        # You can also specify other tool versions:\n        # nodejs: \"16\"\n    \n    # Build documentation in the docs/ directory with Sphinx\n    sphinx:\n       configuration: docs/conf.py\n    \n    # Dependencies required to build your docs\n    python:\n       install:\n       - requirements: docs/requirements.txt\n    \n\n__ Create an account  Sign up  with GitHub or your email.  __ Import your\nproject Select your existing Git repositories with a 1-click interface. __ Add\nYAML config Copy this example, it probably does what you want \ud83d\ude09 __ Your docs\nbuild on every commit Like magic.\n\n###  __ Join thousands of happy users\n\nFlask\n\nWeb Framework\n\nFlask is a Python web framework built with a small core and easy-to-extend\nphilosophy.\n\nJupyter\n\nData Science Environment\n\nJupyter Notebook is a web-based interactive computational environment for\ncreating notebook documents.\n\nGodot Engine\n\nGame Engine\n\nGodot Engine is a free and open source community-driven 2D and 3D game engine.\n\n**Get your docs online in 5 minutes.**\n\n__Create an account\n\n#### Stay updated\n\nBlog Newsletter Status\n\n______\n\n#### Learn more\n\nDocumentation Getting started guide Configure your project Comparison to\nGitHub Pages Comparison to GitBook Comparison to Cloudflare Pages Docs as code\n\n#### Product\n\nFeatures Pricing Privacy Policy Terms of Service\n\n#### Company\n\nAbout us Support Advertise with Us Contribute\n\n__Copyright 2022, Read the Docs, Inc & contributors",
        "node_692": "* Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.\n\nExamples\n\nAppending Deep Lake audio sample\n\n    \n    \n    >>> ds.audios.append(deeplake.read(\"audios/001.mp3\"))\n    \n\nExtending with Deep Lake audio samples\n\n    \n    \n    >>> ds.audios.extend([deeplake.read(f\"videos/00{i}.mp3\") for i in range(10)])\n    \n\n## Class Label Htype\uf0c1\n\n  * Sample dimensions: `(# labels,)`\n\nClass labels are stored as numerical values in tensors, which are indices of\nthe list `tensor.info.class_names`.\n\n### Creating a class label tensor\uf0c1\n\nA class label tensor can be created using\n\n    \n    \n    >>> classes = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"]\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\", class_names=classes, chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.",
        "node_855": "* Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.\n\n### Creating a mesh tensor\uf0c1\n\nA mesh tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"mesh\", htype=\"mesh\", sample_compression=\"ply\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"ply\"]\n    \n\n### Appending meshes\uf0c1\n\nExamples\n\nAppending a ply file containing a mesh data to tensor\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.ply\")  # mesh with 100 points and 200 faces\n    >>> ds.mesh.append(sample)\n    \n    \n    \n    >>> ds.mesh.shape\n    >>> (1, 100, 3)\n    \n\n## Embedding Htype\uf0c1\n\n  * Sample dimensions: `(# elements in the embedding,)`\n\n### Creating an embedding tensor\uf0c1\n\nAn embedding tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"embedding\", htype=\"embedding\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\", None]\n    \n\n### Appending embedding samples\uf0c1\n\n  * Embedding samples can be of type `np.ndarray`.\n\nExamples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.",
        "node_550": "### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.\n\n### Creating a 3d bbox tensor\uf0c1\n\nNote\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below. In addition, for projecting 3D bounding\nboxes onto 2D data (such as an image), the intrinsics tensor must exist in the\ndataset, or the intrinsics matrix must be specified in the\n`ds.img_tensor.info` dictionary, where the key is `\"intrinsics\"` and the value\nis the matrix.\n\nA 3d bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"3d_boxes\", htype=\"bbox.3d\", coords={\"mode\": \"center\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with key \u201cmode\u201d.\n    \n      * **mode** : Specifies the convention for the bbox coordinates.",
        "node_606": "### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.\n\nExamples\n\nAppending a tag\n\n    \n    \n    >>> ds.tags.append(\"verified\")\n    \n\nExtending with list of tags\n\n    \n    \n    >>> ds.tags.extend([\"verified\", \"unverified\"])\n    \n\n## Bounding Box Htype\uf0c1\n\n  * Sample dimensions: `(# bounding boxes, 4)`\n\nBounding boxes have a variety of conventions such as those used in YOLO, COCO,\nPascal-VOC and others. In order for bounding boxes to be correctly displayed\nby the visualizer, the format of the bounding box must be specified in the\ncoords key in tensor meta information mentioned below.\n\n### Creating a bbox tensor\uf0c1\n\nA bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"boxes\", htype=\"bbox\", coords={\"type\": \"fractional\", \"mode\": \"CCWH\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with keys \u201ctype\u201d and \u201cmode\u201d.\n    \n      * **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.",
        "node_756": "* sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nrotation angles are specified in degrees, not radians\n\n### Appending 3d bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98, 22, 36, 44, 18, 0, 36, 0]])\n    >>> ds.3d_boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77, 22, 36, 44, 18, 0, 28, 0],\n           [462, 123, 238,  98, 26, 34, 24, 19, 0, -50, 0],\n           [688, 108, 279, 116, 12, 32, 14, 38, 0, 30, 0]])\n    >>> boxes.shape\n    (9, 4)\n    >>> ds.3d_boxes.append(boxes)\n    \n\n## Intrinsics Htype\uf0c1\n\n  * Sample dimensions: `(# intrinsics matrices, 3, 3)`\n\nThe intrinsic matrix represents a projective transformation from the 3-D\ncamera\u2019s coordinates into the 2-D image coordinates. The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.",
        "node_202": "Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Only applicable if optimize=True. Defaults to \u2018threaded\u2019.\n\n  * **progressbar** (_bool_) \u2013 Whether to use progressbar for optimization. Only applicable if optimize=True. Defaults to True.\n\nReturns\n\n    \n\nThe loaded view.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**KeyError** \u2013 if view with given id does not exist.\n\nlog()\uf0c1\n\n    \n\nDisplays the details of all the past commits.\n\n_property _max_len\uf0c1\n\n    \n\nReturn the maximum length of the tensor.\n\n_property _max_view\uf0c1\n\n    \n\nReturns a view of the dataset in which shorter tensors are padded with `None`\ns to have the same length as the longest tensor.\n\nExample\n\nCreating a dataset with 5 images and 4 labels. `ds.max_view` will return a\nview with `labels` tensor padded to have 5 samples.\n\n    \n    \n    >>> import deeplake\n    >>> ds = deeplake.dataset(\"../test/test_ds\", overwrite=True)\n    >>> ds.create_tensor(\"images\", htype=\"link[image]\", sample_compression=\"jpg\")\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\")\n    >>> ds.images.extend([deeplake.link(\"https://picsum.photos/20/20\") for _ in range(5)])\n    >>> ds.labels.extend([0, 1, 2, 1])\n    >>> len(ds.images)\n    5\n    >>> len(ds.labels)\n    4\n    >>> for i, sample in enumerate(ds.max_view):\n    ...     print(sample[\"images\"].shape, sample[\"labels\"].numpy())\n    ...\n    (20, 20, 3) [0]\n    (20, 20, 3) [1]\n    (20, 20, 3) [2]\n    (20, 20, 3) [1]\n    (20, 20, 3) [None]\n    \n\nmerge(_target_id : str_, _conflict_resolution : Optional[str] = None_,\n_delete_removed_tensors : bool = False_, _force : bool = False_)\uf0c1\n\n    \n\nMerges the target_id into the current dataset.",
        "node_302": "**Deep Lake vs WebDatasets** Deep Lake and WebDatasets both offer\nrapid data streaming across networks. They have nearly identical steaming\nspeeds because the underlying network requests and data structures are very\nsimilar. However, Deep Lake offers superior random access and shuffling, its\nsimple API is in python instead of command-line, and Deep Lake enables simple\nindexing and modification of the dataset without having to recreate it.\n**Deep Lake vs Zarr** Deep Lake and Zarr both offer storage of data as chunked\narrays. However, Deep Lake is primarily designed for returning data as arrays\nusing a simple API, rather than actually storing raw arrays (even though\nthat's also possible). Deep Lake stores data in use-case-optimized formats,\nsuch as jpeg or png for images, or mp4 for video, and the user treats the data\nas if it's an array, because Deep Lake handles all the data processing in\nbetween. Deep Lake offers more flexibility for storing arrays with dynamic\nshape (ragged tensors), and it provides several features that are not naively\navailable in Zarr such as version control, data streaming, and connecting data\nto ML Frameworks.\n\n## Community\n\nJoin our **Slack community** to learn more about unstructured dataset\nmanagement using Deep Lake and to get help from the Activeloop team and other\nusers.\n\nWe'd love your feedback by completing our 3-minute **survey**.\n\nAs always, thanks to our amazing contributors!\n\nMade with contributors-img.\n\nPlease read CONTRIBUTING.md to get started with making contributions to Deep\nLake.\n\n## README Badge\n\nUsing Deep Lake? Add a README badge to let everyone know:\n\n    \n    \n    [!",
        "node_502": "Examples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.",
        "node_204": "* If tensor is renamed on both target and current branch, tensor on target will be registered as a new tensor on current branch.\n\n      * If tensor is renamed on target and a new tensor of the new name was created on the current branch, they will be merged.\n\nRaises\n\n    \n\n  * **Exception** \u2013 if dataset is a filtered view.\n\n  * **ValueError** \u2013 if the conflict resolution strategy is not one of the None, \u201cours\u201d, or \u201ctheirs\u201d.\n\n_property _meta _: DatasetMeta_\uf0c1\n\n    \n\nReturns the metadata of the dataset.\n\n_property _min_len\uf0c1\n\n    \n\nReturn the minimum length of the tensor.\n\n_property _min_view\uf0c1\n\n    \n\nReturns a view of the dataset in which all tensors are sliced to have the same\nlength as the shortest tensor.\n\nExample\n\nCreating a dataset with 5 images and 4 labels. `ds.min_view` will return a\nview in which tensors are sliced to have 4 samples.\n\n    \n    \n    >>> import deeplake\n    >>> ds = deeplake.dataset(\"../test/test_ds\", overwrite=True)\n    >>> ds.create_tensor(\"images\", htype=\"link[image]\", sample_compression=\"jpg\")\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\")\n    >>> ds.images.extend([deeplake.link(\"https://picsum.photos/20/20\") for _ in range(5)])\n    >>> ds.labels.extend([0, 1, 2, 1])\n    >>> len(ds.images)\n    5\n    >>> len(ds.labels)\n    4\n    >>> for i, sample in enumerate(ds.max_view):\n    ...     print(sample[\"images\"].shape, sample[\"labels\"].numpy())\n    ...\n    (20, 20, 3) [0]\n    (20, 20, 3) [1]\n    (20, 20, 3) [2]\n    (20, 20, 3) [1]\n    \n\n_property _no_view_dataset\uf0c1\n\n    \n\nReturns the same dataset without slicing.\n\n_property _num_samples _: int_\uf0c1\n\n    \n\nReturns the length of the smallest tensor. Ignores any applied indexing and\nreturns the total length.\n\n_property _parent\uf0c1\n\n    \n\nReturns the parent of this group.",
        "node_462": "* **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.boxes.info.update(coords = {\"type\": \"pixel\", \"mode\": \"LTRB\"})\n    \n\nNote\n\nIf the bounding box format is not specified, the visualizer will assume a YOLO\nformat (`fractional` \\+ `CCWH`) if the box coordinates are < 1 on average.\nOtherwise, it will assume the COCO format (`pixel` \\+ `LTWH`).\n\n### Appending bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98]])\n    >>> ds.boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77],\n           [462, 123, 238,  98],\n           [688, 108, 279, 116]])\n    >>> boxes.shape\n    (3, 4)\n    >>> ds.boxes.append(boxes)\n    \n\n## 3D Bounding Box Htype\uf0c1\n\nIn order for 3D bounding boxes to be correctly displayed by the visualizer,\nthe format of the bounding box must be specified in the coords key in tensor\nmeta information mentioned below.",
        "node_970": "* Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.\n\nExamples\n\nAppending point clouds with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> point_cloud1 = np.random.randint(0, 10, (5, 3))\n    >>> ds.point_clouds.append(point_cloud1)\n    >>> point_cloud2 = np.random.randint(0, 10, (15, 3))\n    >>> ds.point_clouds.append(point_cloud2)\n    >>> ds.point_clouds.shape\n    >>> (2, None, 3)\n    \n\nOr we can use `deeplake.read()` method to add samples\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.las\") # point cloud with 100 points\n    >>> ds.point_cloud.append(sample)\n    >>> ds.point_cloud.shape\n    >>> (1, 100, 3)\n    \n\n## Mesh Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Mesh samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.",
        "node_1072": "* All files and sub-directories with unsupported filetypes are ignored.\n\n  * Valid source directory structures for image classification look like:\n    \n        data/\n        img0.jpg\n        img1.jpg\n        ...\n    \n\n  * or:\n    \n        data/\n        class0/\n            cat0.jpg\n            ...\n        class1/\n            dog0.jpg\n            ...\n        ...\n    \n\n  * or:\n    \n        data/\n        train/\n            class0/\n                img0.jpg\n                ...\n            ...\n        val/\n            class0/\n                img0.jpg\n                ...\n            ...\n        ...\n    \n\n  * Classes defined as sub-directories can be accessed at `ds[\"test/labels\"].info.class_names`.\n\n  * Support for train and test sub directories is present under `ds[\"train/images\"]`, `ds[\"train/labels\"]` and `ds[\"test/images\"]`, `ds[\"test/labels\"]`.\n\n  * Mapping filenames to classes from an external file is currently not supported.\n\ndeeplake.ingest_coco(_images_directory : Union[str, Path]_, _annotation_files\n: Union[str, Path, List[str]]_, _dest : Union[str, Path]_,\n_key_to_tensor_mapping : Optional[Dict] = None_, _file_to_group_mapping :\nOptional[Dict] = None_, _ignore_one_group : bool = True_, _ignore_keys :\nOptional[List[str]] = None_, _image_params : Optional[Dict] = None_,\n_image_creds_key : Optional[str] = None_, _src_creds : Optional[Union[Dict,\nstr]] = None_, _dest_creds : Optional[Union[Dict, str]] = None_,\n_inspect_limit : int = 1000000_, _progressbar : bool = True_, _shuffle : bool\n= False_, _num_workers : int = 0_, _token : Optional[str] = None_,\n_connect_kwargs : Optional[Dict] = None_, _** dataset_kwargs_) -> Dataset\uf0c1\n\n    \n\nIngest images and annotations in COCO format to a Deep Lake Dataset. The\nsource data can be stored locally or in the cloud.\n\nExamples\n\n    \n    \n    >>> # Ingest local data in COCO format to a Deep Lake dataset stored in Deep Lake storage.",
        "node_1244": "The outer list corresponds to the queries and the inner list corresponds to the doc_id, relevence_score pair for each query. doc_id is the document id in the corpus dataset. It is stored in the id tensor of the corpus dataset. relevence_score is the relevance score of the document for the query. The value is either 0 and 1, where 0 stands for not relevant (unknown relevance) and 1 stands for relevant. Currently, only values of 1 contribute to the training, and there is no reason to provide examples with relevance of 0.\n\n  * **embedding_function** (_Optional_ _[__Callable_ _[__[__str_ _]__,__np.ndarray_ _]__]__,__optional_) \u2013 Embedding funtion used to convert queries to embeddings. Defaults to None.\n\n  * **token** (_str_ _,__optional_) \u2013 API token for the DeepMemory managed service. Defaults to None.\n\nReturns\n\n    \n\njob_id of the training job.\n\nReturn type\n\n    \n\nstr\n\nRaises\n\n    \n\n**ValueError** \u2013 if embedding_function is not specified either during\ninitialization or during training.\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_1087": "* **creds_key** (_Optional_ _[__str_ _]_) \u2013 creds_key for linked tensors, applicable if the htype any tensor is specified as \u2018link[\u2026]\u2019 in the \u2018column_params\u2019 input.\n\n  * **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Set to `True` by default.\n\n  * **token** (_Optional_ _[__str_ _]_) \u2013 The token to use for accessing the dataset.\n\n  * **connect_kwargs** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing arguments to be passed to the dataset connect method. See `Dataset.connect()`.\n\n  * ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function. See `deeplake.empty()`.\n\nReturns\n\n    \n\nNew dataset created from the dataframe.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**Exception** \u2013 If `src` is not a valid pandas dataframe object.\n\ndeeplake.ingest_huggingface(_src_ , _dest_ , _use_progressbar =True_, _token :\nOptional[str] = None_, _connect_kwargs : Optional[Dict] = None_, _**\ndataset_kwargs_) -> Dataset\uf0c1\n\n    \n\nConverts Hugging Face datasets to Deep Lake format.\n\nParameters\n\n    \n\n  * **src** (_hfDataset_ _,__DatasetDict_) \u2013 Hugging Face Dataset or DatasetDict to be converted. Data in different splits of a DatasetDict will be stored under respective tensor groups.\n\n  * **dest** (_Dataset_ _,__str_ _,__pathlib.Path_) \u2013 Destination dataset or path to it.\n\n  * **use_progressbar** (_bool_) \u2013 Defines if progress bar should be used to show conversion progress.\n\n  * **token** (_Optional_ _[__str_ _]_) \u2013 The token to use for accessing the dataset and/or connecting it to Deep Lake.\n\n  * **connect_kwargs** (_Optional_ _[__Dict_ _]_) \u2013 If specified, the dataset will be connected to Deep Lake, and connect_kwargs will be passed to `Dataset.connect`.\n\n  * ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function. See `deeplake.empty()`.\n\nReturns\n\n    \n\nThe destination Deep Lake dataset.",
        "node_78": ">>> db.deep_memory.list_jobs()\n    ID                          STATUS     RESULTS                      PROGRESS\n    65198efcd28df3238c49a849    completed  recall@10: 0.62% (+0.62%)    eta: 2.5 seconds\n                                                                        recall@10: 0.62% (+0.62%)\n    651a4d41d05a21a5a6a15f67    completed  recall@10: 0.62% (+0.62%)    eta: 2.5 seconds\n                                                                        recall@10: 0.62% (+0.62%)\n    \n\n### Deep Memory Evaluation\uf0c1\n\nOnce the training is completed, you can use `db.deep_memory.evaluate` to\nevaluate the model performance on the custom dataset. Once again you would\nneed to preprocess the dataset so that, `corpus`, will become a list of list\nof tuples, where outer list corresponds to the query and inner list to the\nrelevant documents. Each tuple should contain the document id (`id` tensor\nfrom the corpus dataset) and the relevance score (range is 0-1, where 0\nrepresents unrelated document and 1 related). `queries` should be a list of\nstrings.\n\n    \n    \n    >>> recalls = db.deep_memory.evaluate(\n    ...     corpus: List[List[Tuple[str, float]]] = corpus,\n    ...     queries: List[str] = queries,\n    ...     embedding_function = embedding_function, # function that takes converts texts into embeddings, it is optional and can be skipped if provided during initialization\n    ...     qvs_params = {\"enbabled\": True}\n    ... )\n    \n\n`recalls` is a dictionary with the following keys: `with_model` contains a\ndictionary with recall metrics for the naive vector search on the custom\ndataset for different k values `without_model` contains a dictionary with\nrecall metrics for the naive vector search on the custom dataset for different\nk values `qvs_params` when specified creates a separate vectorstore that\ntracks all evaluation queries and documents, so that you can use it to compare\nthe performance of deep_memory to naive vector search. By default, it is\nturned off.",
        "node_1025": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n    * Logging Dataset Creation\n    * Logging Dataset Read\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Weights and Biases\n  * Edit on GitHub\n\n* * *\n\n# Weights and Biases\uf0c1\n\nDeep Lake\u2019s Weights and Biases integration allows you to track and improve\nreproducibility of your machine learning experiments. Deep Lake will\nautomatically push all information required to reproduce the snapshot of the\ndata like your dataset\u2019s URI, commit ID, and view IDs of any views that you\nhave used in your training workflow.\n\nLearn more about Weights and Biases here.\n\n## Logging Dataset Creation\uf0c1\n\nIf you create a Deep Lake dataset using any of the functions mentioned in\nCreating Datasets, just perform a commit on the dataset to log its creation on\nW&B.",
        "node_936": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_128": "Only applicable for hub:// paths.\n\n  * **tensors** (_List_ _[__str_ _]__,__optional_) \u2013 Names of tensors (and groups) to be copied. If not specified all tensors are copied.\n\n  * **overwrite** (_bool_) \u2013 If True and a dataset exists at destination, it will be overwritten. Defaults to False.\n\n  * **src_creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **dest_creds** (_dict_ _,__optional_) \u2013 creds required to create / overwrite datasets at `dest`.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for copying. Defaults to 0. When set to 0, it will always use serial processing, irrespective of the scheduler.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for copying. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Defaults to \u2018threaded\u2019.\n\n  * **progressbar** (_bool_) \u2013 Displays a progress bar if True (default).\n\n  * **public** (_bool_) \u2013 Defines if the dataset will have public access. Applicable only if Deep Lake cloud storage is used and a new Dataset is being created. Defaults to `False`.",
        "node_548": "### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.\n\nExamples\n\nAppending a tag\n\n    \n    \n    >>> ds.tags.append(\"verified\")\n    \n\nExtending with list of tags\n\n    \n    \n    >>> ds.tags.extend([\"verified\", \"unverified\"])\n    \n\n## Bounding Box Htype\uf0c1\n\n  * Sample dimensions: `(# bounding boxes, 4)`\n\nBounding boxes have a variety of conventions such as those used in YOLO, COCO,\nPascal-VOC and others. In order for bounding boxes to be correctly displayed\nby the visualizer, the format of the bounding box must be specified in the\ncoords key in tensor meta information mentioned below.\n\n### Creating a bbox tensor\uf0c1\n\nA bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"boxes\", htype=\"bbox\", coords={\"type\": \"fractional\", \"mode\": \"CCWH\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with keys \u201ctype\u201d and \u201cmode\u201d.\n    \n      * **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.",
        "node_87": "* **check_integrity** (_bool_ _,__Optional_) \u2013 Performs an integrity check by default (None) if the dataset has 20 or fewer tensors. Set to `True` to force integrity check, `False` to skip integrity check.\n\n  * **lock_timeout** (_int_) \u2013 Number of seconds to wait before throwing a LockException. If None, wait indefinitely\n\n  * **lock_enabled** (_bool_) \u2013 If true, the dataset manages a write lock. NOTE: Only set to False if you are managing concurrent access externally\n\n  * **index_params** \u2013 Optional[Dict[str, Union[int, str]]] = None : The index parameters used while creating vector store is passed down to dataset.\n\nReturns\n\n    \n\nDataset created using the arguments provided.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n  * **AgreementError** \u2013 When agreement is rejected\n\n  * **UserNotLoggedInException** \u2013 When user is not authenticated\n\n  * **InvalidTokenException** \u2013 If the specified token is invalid\n\n  * **TokenPermissionError** \u2013 When there are permission or other errors related to token\n\n  * **CheckoutError** \u2013 If version address specified in the path cannot be found\n\n  * **DatasetCorruptError** \u2013 If loading the dataset failed due to corruption and `reset` is not `True`\n\n  * **ValueError** \u2013 If version is specified in the path when creating a dataset or If the org id is provided but dataset is ot local, or If the org id is provided but dataset is ot local\n\n  * **ReadOnlyModeError** \u2013 If reset is attempted in read-only mode\n\n  * **LockedException** \u2013 When attempting to open a dataset for writing when it is locked by another machine\n\n  * **DatasetHandlerError** \u2013 If overwriting the dataset fails\n\n  * **Exception** \u2013 Re-raises caught exception if reset cannot fix the issue\n\nDanger\n\nSetting `overwrite` to `True` will delete all of your data if it exists! Be\nvery careful when setting this parameter.\n\nWarning\n\nSetting `access_method` to download will overwrite the local copy of the\ndataset if it was previously downloaded.",
        "node_559": "For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.\n\n## Point Htype\uf0c1\n\n  * Sample dimensions: `(# points, 2)` in case of 2-D (X, Y) co-ordinates or `(# points, 3)` in case of 3-D (X, Y, Z) co-ordinates of the point.\n\nPoints does not contain a fixed mapping across samples between the point order\nand real-world objects (i.e., point 0 is an elbow, point 1 is a knee, etc.).\nIf you require such a mapping, use COCO Keypoints Htype.\n\n### Creating a point tensor\uf0c1\n\nA point tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"points\", htype=\"point\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending point samples\uf0c1\n\n  * Points can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.",
        "node_509": "For datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.\n\n    \n    \n    >>> ds.add_creds_key(\"my_s3_creds\", managed=True)\n    >>> ds.add_creds_key(\"my_gcs_creds\", managed=True)\n    \n\nCreate a link tensor\n\n    \n    \n    >>> ds.create_tensor(\"img\", htype=\"link[image]\", sample_compression=\"jpg\")\n    \n\nPopulate the tensor with links\n\n    \n    \n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\", creds_key=\"my_s3_key\"))\n    >>> ds.img.append(deeplake.link(\"gcs://ghi/jkl.png\", creds_key=\"GCS_KEY\"))\n    >>> ds.img.append(deeplake.link(\"https://picsum.photos/200/300\")) # http path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"./path/to/cat.jpeg\")) # local path doesn\u2019t need creds\n    >>> ds.img.append(deeplake.link(\"s3://abc/def.jpeg\"))  # this will throw an exception as cloud paths always need creds_key\n    :bluebold:`Accessing the data`\n    \n    \n    \n    >>> for i in range(5):\n    ...     ds.img[i].numpy()\n    ...\n    \n\nUpdating a sample\n\n    \n    \n    >>> ds.img[0] = deeplake.link(\"./data/cat.jpeg\")\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_675": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_1263": "util.exceptions)\n  * enable_readonly() (deeplake.core.storage.StorageProvider method)\n\n|\n\n  * eval() (deeplake.core.transform.Pipeline method)\n  * evaluate() (deeplake.core.vectorstore.deep_memory.deep_memory.DeepMemory method)\n  * exists() (deeplake.api.dataset.dataset static method)\n    * (in module deeplake)\n  * extend() (deeplake.core.dataset.Dataset method)\n    * (deeplake.core.tensor.Tensor method)\n  * ExternalCommandError (class in deeplake.util.exceptions)\n\n  \n---|---  \n  \n## F\n\n  * FileAtPathException (class in deeplake.util.exceptions)\n  * fill_dataset() (deeplake.auto.structured.dataframe.DataFrame method)\n  * filter() (deeplake.core.dataset.Dataset method)\n  * FilterError (class in deeplake.util.exceptions)\n  * find_axis() (deeplake.core.index.Index method)\n\n|\n\n  * fix_vc() (deeplake.core.dataset.Dataset method)\n  * flush() (deeplake.core.dataset.Dataset method)\n    * (deeplake.core.storage.LRUCache method)\n    * (deeplake.core.storage.StorageProvider method)\n  * FullChunkError (class in deeplake.util.exceptions)\n\n  \n---|---  \n  \n## G\n\n  * GatewayTimeoutException (class in deeplake.util.exceptions)\n  * GCSDefaultCredsNotFoundError (class in deeplake.util.exceptions)\n  * GCSProvider (class in deeplake.core.storage)\n  * GDriveProvider (class in deeplake.core.storage)\n  * get() (deeplake.api.info.Info method)\n  * get_base_storage() (in module deeplake.util.remove_cache)\n  * get_bytes() (deeplake.core.storage.GCSProvider method)\n    * (deeplake.core.storage.LocalProvider method)\n    * (deeplake.core.storage.LRUCache method)\n    * (deeplake.core.storage.",
        "node_693": "`tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.\n\n### Appending class labels\uf0c1\n\n  * Class labels can be appended as `int`, `str`, `np.ndarray` or `list` of `int` or `str`.\n\n  * In case of strings, `tensor.info.class_names` is updated automatically.\n\nExamples\n\nAppending index\n\n    \n    \n    >>> ds.labels.append(0)\n    >>> ds.labels.append(np.zeros((5,), dtype=np.uint32))\n    \n\nExtending with list of indices\n\n    \n    \n    >>> ds.labels.extend([[0, 1, 2], [1, 3]])\n    \n\nAppending text labels\n\n    \n    \n    >>> ds.labels.append([\"cars\", \"airplanes\"])\n    \n\n## Tag Htype\uf0c1\n\n  * Sample dimensions: `(# tags,)`\n\nThis htype can be used to tag samples with one or more string values.\n\n### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.",
        "node_241": "Return type\n\n    \n\nTensor\n\nRaises\n\n    \n\n**TensorModifiedError** \u2013 If a target id is passed which is not an ancestor of\nthe current commit.\n\n_property _ndim _: int_\uf0c1\n\n    \n\nNumber of dimensions of the tensor.\n\n_property _num_samples _: int_\uf0c1\n\n    \n\nReturns the length of the primary axis of the tensor. Ignores any applied\nindexing and returns the total length.\n\nnumpy(_aslist =False_, _fetch_chunks =False_) -> Union[ndarray,\nList[ndarray]]\uf0c1\n\n    \n\nComputes the contents of the tensor in numpy format.\n\nParameters\n\n    \n\n  * **aslist** (_bool_) \u2013 If `True`, a list of np.ndarrays will be returned. Helpful for dynamic tensors. If `False`, a single np.ndarray will be returned unless the samples are dynamically shaped, in which case an error is raised.\n\n  * **fetch_chunks** (_bool_) \u2013 \n\nIf `True`, full chunks will be retrieved from the storage, otherwise only\nrequired bytes will be retrieved. This will always be `True` even if specified\nas `False` in the following cases:\n\n    * The tensor is ChunkCompressed.\n\n    * The chunk which is being accessed has more than 128 samples.\n\nRaises\n\n    \n\n  * **DynamicTensorNumpyError** \u2013 If reading a dynamically-shaped array slice without `aslist=True`.\n\n  * **ValueError** \u2013 If the tensor is a link and the credentials are not populated.\n\nReturns\n\n    \n\nA numpy array containing the data represented by this tensor.\n\nNote\n\nFor tensors of htype `polygon`, aslist is always `True`.\n\npath(_aslist : bool = True_, _fetch_chunks : bool = False_)\uf0c1\n\n    \n\nReturn path data. Only applicable for linked tensors.\n\nParameters\n\n    \n\n  * **aslist** (_bool_) \u2013 Returns links in a list if `True`.\n\n  * **fetch_chunks** (_bool_) \u2013 If `True`, full chunks will be retrieved from the storage, otherwise only required bytes will be retrieved.\n\nReturns\n\n    \n\nA list or numpy array of links.\n\nReturn type\n\n    \n\nUnion[np.ndarray, List]\n\nRaises\n\n    \n\n**Exception** \u2013 If the tensor is not a linked tensor.",
        "node_1193": "Applicable only if `optimize=True`. Defaults to 0.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for optimization. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Only applicable if `optimize=True`. Defaults to \u2018threaded\u2019.\n\n  * **verbose** (_bool_) \u2013 If `True`, logs will be printed. Defaults to `True`.\n\n  * **ignore_errors** (_bool_) \u2013 Skip samples that cause errors while saving views. Only applicable if `optimize=True`. Defaults to `False`.\n\n  * **ds_args** (_dict_) \u2013 Additional args for creating VDS when path is specified. (See documentation for `deeplake.dataset()`)\n\nReturns\n\n    \n\nPath to the saved VDS.\n\nReturn type\n\n    \n\nstr\n\nRaises\n\n    \n\n  * **ReadOnlyModeError** \u2013 When attempting to save a view inplace and the user doesn\u2019t have write access.\n\n  * **DatasetViewSavingError** \u2013 If HEAD node has uncommitted changes.\n\n  * **TypeError** \u2013 If `id` is not of type `str`.\n\nNote\n\nSpecifying `path` makes the view external. External views cannot be accessed\nusing the parent dataset\u2019s `Dataset.get_view()`, `Dataset.load_view()`,\n`Dataset.delete_view()` methods. They have to be loaded using\n`deeplake.load()`.\n\nset_token(_new_token : str_)\uf0c1\n\n    \n\nMethod to set a new token\n\nsize_approx()\uf0c1\n\n    \n\nEstimates the size in bytes of the dataset. Includes only content, so will\ngenerally return an under-estimate.\n\nsummary(_force : bool = False_)\uf0c1\n\n    \n\nPrints a summary of the dataset.\n\nParameters\n\n    \n\n**force** (_bool_) \u2013 Dataset views with more than 10000 samples might take a\nlong time to summarize. If force=True, the summary will be printed regardless.\nAn error will be raised otherwise.",
        "node_332": "`Dataset.read_only` | Returns True if dataset is in read-only mode and False otherwise.  \n`Dataset.info` | Returns the information about the dataset.  \n`Dataset.max_len` | Return the maximum length of the tensor.  \n`Dataset.min_len` | Return the minimum length of the tensor.  \n  \n## Dataset Version Control\uf0c1\n\n`Dataset.commit` | Stores a snapshot of the current state of the dataset.  \n---|---  \n`Dataset.diff` | Returns/displays the differences between commits/branches.  \n`Dataset.checkout` | Checks out to a specific commit_id or branch.  \n`Dataset.merge` | Merges the target_id into the current dataset.  \n`Dataset.log` | Displays the details of all the past commits.  \n`Dataset.reset` | Resets the uncommitted changes present in the branch.  \n`Dataset.get_commit_details` | Get details of a particular commit.  \n`Dataset.commit_id` | The lasted committed commit id of the dataset.  \n`Dataset.branch` | The current branch of the dataset  \n`Dataset.pending_commit_id` | The commit_id of the next commit that will be made to the dataset.  \n`Dataset.has_head_changes` | Returns True if currently at head node and uncommitted changes are present.  \n`Dataset.commits` | Lists all the commits leading to the current dataset state.  \n`Dataset.branches` | Lists all the branches of the dataset.  \n  \n## Dataset Views\uf0c1\n\nA dataset view is a subset of a dataset that points to specific samples\n(indices) in an existing dataset. Dataset views can be created by indexing a\ndataset, filtering a dataset with `Dataset.filter()`, querying a dataset with\n`Dataset.query()` or by sampling a dataset with `Dataset.sample_by()`.\nFiltering is done with user-defined functions or simplified expressions\nwhereas query can perform SQL-like queries with our Tensor Query Language. See\nthe full TQL spec here.\n\nDataset views can only be saved when a dataset has been committed and has no\nchanges on the HEAD node, in order to preserve data lineage and prevent the\nunderlying data from changing after the query or filter conditions have been\nevaluated.",
        "node_738": "* Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.\n\nExamples\n\nAppending point clouds with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> point_cloud1 = np.random.randint(0, 10, (5, 3))\n    >>> ds.point_clouds.append(point_cloud1)\n    >>> point_cloud2 = np.random.randint(0, 10, (15, 3))\n    >>> ds.point_clouds.append(point_cloud2)\n    >>> ds.point_clouds.shape\n    >>> (2, None, 3)\n    \n\nOr we can use `deeplake.read()` method to add samples\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.las\") # point cloud with 100 points\n    >>> ds.point_cloud.append(sample)\n    >>> ds.point_cloud.shape\n    >>> (1, 100, 3)\n    \n\n## Mesh Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Mesh samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.",
        "node_164": "* `Dict` \\- Key-value search on tensors of htype json, evaluated on an AND basis (a sample must satisfy all key-value filters to be True) Dict = {\u201ctensor_name_1\u201d: {\u201ckey\u201d: value}, \u201ctensor_name_2\u201d: {\u201ckey\u201d: value}}\n\n    * `Function` \\- Any function that is compatible with `Dataset.filter`.\n\n  * **exec_option** (_Optional_ _[__str_ _]_) \u2013 \n\nMethod for search execution. It could be either `\"python\"`, `\"compute_engine\"`\nor `\"tensor_db\"`. Defaults to `None`, which inherits the option from the\nVector Store initialization.\n\n    * `python` \\- Pure-python implementation that runs on the client and can be used for data stored anywhere. WARNING: using this option with big datasets is discouraged because it can lead to memory issues.\n\n    * `compute_engine` \\- Performant C++ implementation of the Deep Lake Compute Engine that runs on the client and can be used for any data stored in or connected to Deep Lake. It cannot be used with in-memory or local datasets.\n\n    * `tensor_db` \\- Performant and fully-hosted Managed Tensor Database that is responsible for storage and query execution. Only available for data stored in the Deep Lake Managed Database. Store datasets in this database by specifying runtime = {\u201ctensor_db\u201d: True} during dataset creation.\n\n  * **embedding_tensor** (_str_) \u2013 Name of tensor with embeddings. Defaults to \u201cembedding\u201d.\n\n  * **return_tensors** (_Optional_ _[__List_ _[__str_ _]__]_) \u2013 List of tensors to return data for. Defaults to None, which returns data for all tensors except the embedding tensor (in order to minimize payload). To return data for all tensors, specify return_tensors = \u201c*\u201d.\n\n  * **return_view** (_bool_) \u2013 Return a Deep Lake dataset view that satisfied the search parameters, instead of a dictionary with data. Defaults to False. If `True` return_tensors is set to \u201c*\u201d beucase data is lazy-loaded and there is no cost to including all tensors in the view.\n\n  * **deep_memory** (_bool_) \u2013 Whether to use the Deep Memory model for improving search results.",
        "node_389": "`Dataset.commits` | Lists all the commits leading to the current dataset state.  \n`Dataset.branches` | Lists all the branches of the dataset.  \n  \n## Dataset Views\uf0c1\n\nA dataset view is a subset of a dataset that points to specific samples\n(indices) in an existing dataset. Dataset views can be created by indexing a\ndataset, filtering a dataset with `Dataset.filter()`, querying a dataset with\n`Dataset.query()` or by sampling a dataset with `Dataset.sample_by()`.\nFiltering is done with user-defined functions or simplified expressions\nwhereas query can perform SQL-like queries with our Tensor Query Language. See\nthe full TQL spec here.\n\nDataset views can only be saved when a dataset has been committed and has no\nchanges on the HEAD node, in order to preserve data lineage and prevent the\nunderlying data from changing after the query or filter conditions have been\nevaluated.\n\n**Example**\n\n    \n    \n    >>> import deeplake\n    >>> # load dataset\n    >>> ds = deeplake.load(\"hub://activeloop/mnist-train\")\n    >>> # filter dataset\n    >>> zeros = ds.filter(\"labels == 0\")\n    >>> # save view\n    >>> zeros.save_view(id=\"zeros\")\n    >>> # load_view\n    >>> zeros = ds.load_view(id=\"zeros\")\n    >>> len(zeros)\n    5923\n    \n\n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n---|---  \n`Dataset.sample_by` | Returns a sliced `Dataset` with given weighted sampler applied.  \n`Dataset.filter` | Filters the dataset in accordance of filter function `f(x: sample) -> bool`  \n`Dataset.save_view` | Saves a dataset view as a virtual dataset (VDS)  \n`Dataset.get_view` | Returns the dataset view corresponding to `id`.  \n`Dataset.load_view` | Loads the view and returns the `Dataset` by id.  \n`Dataset.delete_view` | Deletes the view with given view id.  \n`Dataset.get_views` | Returns list of views stored in this Dataset.  \n`Dataset.is_view` | Returns `True` if this dataset is a view and `False` otherwise.",
        "node_733": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_1112": "deeplake.tiled(_sample_shape : Tuple[int, ...]_, _tile_shape :\nOptional[Tuple[int, ...]] = None_, _dtype : Union[str, dtype] =\ndtype('uint8')_)\uf0c1\n\n    \n\nAllocates an empty sample of shape `sample_shape`, broken into tiles of shape\n`tile_shape` (except for edge tiles).\n\nExample\n\n    \n    \n    >>> with ds:\n    ...    ds.create_tensor(\"image\", htype=\"image\", sample_compression=\"png\")\n    ...    ds.image.append(deeplake.tiled(sample_shape=(1003, 1103, 3), tile_shape=(10, 10, 3)))\n    ...    ds.image[0][-217:, :212, 1:] = np.random.randint(0, 256, (217, 212, 2), dtype=np.uint8)\n    \n\nParameters\n\n    \n\n  * **sample_shape** (_Tuple_ _[__int_ _,__...__]_) \u2013 Full shape of the sample.\n\n  * **tile_shape** (_Optional_ _,__Tuple_ _[__int_ _,__...__]_) \u2013 The sample will be will stored as tiles where each tile will have this shape (except edge tiles). If not specified, it will be computed such that each tile is close to half of the tensor\u2019s max_chunk_size (after compression).\n\n  * **dtype** (_Union_ _[__str_ _,__np.dtype_ _]_) \u2013 Dtype for the sample array. Default uint8.\n\nReturns\n\n    \n\nA PartialSample instance which can be appended to a Tensor.\n\nReturn type\n\n    \n\nPartialSample\n\ndeeplake.compute(_fn_ , _name : Optional[str] = None_) -> Callable[[...],\nComputeFunction]\uf0c1\n\n    \n\nCompute is a decorator for functions.\n\nThe functions should have atleast 2 argument, the first two will correspond to\n`sample_in` and `samples_out`.\n\nThere can be as many other arguments as required.\n\nThe output should be appended/extended to the second argument in a deeplake\nlike syntax.\n\nAny value returned by the fn will be ignored.",
        "node_385": "---|---  \n`deeplake.empty` | Creates an empty dataset  \n`deeplake.like` | Creates a new dataset by copying the `source` dataset's structure to a new location.  \n`deeplake.ingest_classification` | Ingest a dataset of images from a local folder to a Deep Lake Dataset.  \n`deeplake.ingest_coco` | Ingest images and annotations in COCO format to a Deep Lake Dataset.  \n`deeplake.ingest_yolo` | Ingest images and annotations (bounding boxes or polygons) in YOLO format to a Deep Lake Dataset.  \n`deeplake.ingest_kaggle` | Download and ingest a kaggle dataset and store it as a structured dataset to destination.  \n`deeplake.ingest_dataframe` | Convert pandas dataframe to a Deep Lake Dataset.  \n`deeplake.ingest_huggingface` | Converts Hugging Face datasets to Deep Lake format.  \n  \n## Loading Datasets\uf0c1\n\n`deeplake.load` | Loads an existing dataset  \n---|---  \n  \n## Deleting and Renaming Datasets\uf0c1\n\n`deeplake.delete` | Deletes a dataset at a given path.  \n---|---  \n`deeplake.rename` | Renames dataset at `old_path` to `new_path`.  \n  \n## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.",
        "node_795": "### Limitations\uf0c1\n\n  * The Deep Lake Performant Dataloader does not support Nifti data.\n\n### Creating a nifti tensor\uf0c1\n\nA nifti tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"patients\", htype=\"nifti\", sample_compression=\"nii.gz\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"nii.gz\", \"nii\", None]\n    \n\n### Appending nifti data\uf0c1\n\n  * Nifti samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw nifti data. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\nExamples\n\n    \n    \n    >>> ds.patients.append(deeplake.read(\"data/patient0.nii.gz\"))\n    \n    \n    \n    >>> ds.patients.extend([deeplake.read(f\"data/patient{i}.nii.gz\") for i in range(10)])\n    \n\n## Point Cloud Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Point cloud samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.",
        "node_594": "Examples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.\n\nExamples\n\n    \n    \n    >>> ds.create_tensor(\"seq\", htype=\"sequence\")\n    >>> ds.seq.append([1, 2, 3])\n    >>> ds.seq.append([4, 5, 6])\n    >>> ds.seq.numpy()\n    array([[[1],\n            [2],\n            [3]],\n           [[4],\n            [5],\n            [6]]])\n    \n    \n    \n    >>> ds.create_tensor(\"image_seq\", htype=\"sequence[image]\", sample_compression=\"jpg\")\n    >>> ds.image_seq.append([deeplake.read(\"img01.jpg\"), deeplake.read(\"img02.jpg\")])\n    \n\n## Link htype\uf0c1\n\n  * Link htype is a special meta htype that allows linking of external data (files) to the dataset, without storing the data in the dataset itself.\n\n  * Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.",
        "node_4": "Installation commands\uf0c1 Install command | Description | Dependencies installed  \n---|---|---  \n`pip install \"deeplake[av]\"` | Audio and video support via PyAV | av  \n`pip install \"deeplake[visualizer]\"` | Visualize Deep Lake datasets within notebooks. This is required for `Dataset.visualize` to work. | IPython, flask  \n`pip install \"deeplake[gcp]\"` | GCS support | google-cloud-storage, google-auth, google-auth-oauthlib  \n`pip install \"deeplake[azure]\"` | Azure Blob Storage support | azure-storage-blob, azure-cli, azure-identity  \n`pip install \"deeplake[medical]\"` | DICOM and NIfTI data support | pydicom, nibabel  \n`pip install \"deeplake[gdrive]\"` | Google Drive support | google-api-python-client, oauth2client, google-auth, google-auth-oauthlib  \n`pip install \"deeplake[point_cloud]\"` | Support for LiDAR point cloud data | laspy  \n`pip install \"deeplake[all]\"` | Installs all of the above |   \n  \nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_562": "### Limitations\uf0c1\n\n  * The Deep Lake Performant Dataloader does not support Nifti data.\n\n### Creating a nifti tensor\uf0c1\n\nA nifti tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"patients\", htype=\"nifti\", sample_compression=\"nii.gz\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"nii.gz\", \"nii\", None]\n    \n\n### Appending nifti data\uf0c1\n\n  * Nifti samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw nifti data. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\nExamples\n\n    \n    \n    >>> ds.patients.append(deeplake.read(\"data/patient0.nii.gz\"))\n    \n    \n    \n    >>> ds.patients.extend([deeplake.read(f\"data/patient{i}.nii.gz\") for i in range(10)])\n    \n\n## Point Cloud Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Point cloud samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.",
        "node_663": "* Supported compressions:\n\n    \n    \n    >>> [None, \"mp3\", \"wav\", \"flac\"]\n    \n\n### Appending audio samples\uf0c1\n\n  * Audio samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Like videos, Deep Lake does not support compression or recompression of input audio samples. Thus, samples of type `np.ndarray` can only be appended to tensors with `None` compression.\n\nExamples\n\nAppending Deep Lake audio sample\n\n    \n    \n    >>> ds.audios.append(deeplake.read(\"audios/001.mp3\"))\n    \n\nExtending with Deep Lake audio samples\n\n    \n    \n    >>> ds.audios.extend([deeplake.read(f\"videos/00{i}.mp3\") for i in range(10)])\n    \n\n## Class Label Htype\uf0c1\n\n  * Sample dimensions: `(# labels,)`\n\nClass labels are stored as numerical values in tensors, which are indices of\nthe list `tensor.info.class_names`.\n\n### Creating a class label tensor\uf0c1\n\nA class label tensor can be created using\n\n    \n    \n    >>> classes = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"]\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\", class_names=classes, chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**. `tensor.info.class_names` will be set to this list.\n\n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `uint32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.\n\n    \n    \n    >>> ds.labels.info.update(class_names = [\"airplanes\", \"cars\", \"birds\", \"cats\", \"deer\", \"dogs\", \"frogs\", \"horses\", \"ships\", \"trucks\"])\n    \n\nNote\n\nIf specifying compression, since the number of labels in one sample will be\ntoo low, `chunk_compression` would be the better option to use.",
        "node_118": "This is optional, tokens are normally autogenerated.\n\n  * **org_id** (_str_ _,__Optional_) \u2013 Organization id to be used for enabling high-performance features. Only applicable for local datasets.\n\n  * **verbose** (_bool_) \u2013 If `True`, logs will be printed. Defaults to `True`.\n\n  * **access_method** (_str_) \u2013 \n\nThe access method to use for the dataset. Can be:\n\n    * \u2019stream\u2019\n\n>       * Streams the data from the dataset i.e. only fetches data when\n> required. This is the default value.\n\n    * \u2019download\u2019\n\n>       * Downloads the data to the local filesystem to the path specified in\n> environment variable `DEEPLAKE_DOWNLOAD_PATH`. This will overwrite\n> `DEEPLAKE_DOWNLOAD_PATH`.\n>\n>       * Raises an exception if `DEEPLAKE_DOWNLOAD_PATH` environment variable\n> is not set or if the dataset does not exist.\n>\n>       * The \u2018download\u2019 access method can be modified to specify num_workers\n> and/or scheduler. For example: \u2018download:2:processed\u2019 will use 2 workers and\n> use processed scheduler, while \u2018download:3\u2019 will use 3 workers and default\n> scheduler (threaded), and \u2018download:processed\u2019 will use a single worker and\n> use processed scheduler.\n\n    * \u2019local\u2019\n\n>       * Downloads the dataset if it doesn\u2019t already exist, otherwise loads\n> from local storage.\n>\n>       * Raises an exception if `DEEPLAKE_DOWNLOAD_PATH` environment variable\n> is not set.\n>\n>       * The \u2018local\u2019 access method can be modified to specify num_workers\n> and/or scheduler to be used in case dataset needs to be downloaded. If\n> dataset needs to be downloaded, \u2018local:2:processed\u2019 will use 2 workers and\n> use processed scheduler, while \u2018local:3\u2019 will use 3 workers and default\n> scheduler (threaded), and \u2018local:processed\u2019 will use a single worker and use\n> processed scheduler.\n\n  * **unlink** (_bool_) \u2013 Downloads linked samples if set to `True`. Only applicable if `access_method` is `download` or `local`. Defaults to `False`.",
        "node_830": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.",
        "node_585": "* Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`. A set of `K` keypoints of an object is represented as:\n\n[x1, y1, v1, x2, y2, v2, \u2026, xk, yk, vk]\n\nThe visibility `v` can be one of three values:\n\n0\n\n    \n\nkeypoint not in image.\n\n1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.",
        "node_854": "* Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.\n\nExamples\n\nAppending point clouds with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> point_cloud1 = np.random.randint(0, 10, (5, 3))\n    >>> ds.point_clouds.append(point_cloud1)\n    >>> point_cloud2 = np.random.randint(0, 10, (15, 3))\n    >>> ds.point_clouds.append(point_cloud2)\n    >>> ds.point_clouds.shape\n    >>> (2, None, 3)\n    \n\nOr we can use `deeplake.read()` method to add samples\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.las\") # point cloud with 100 points\n    >>> ds.point_cloud.append(sample)\n    >>> ds.point_cloud.shape\n    >>> (1, 100, 3)\n    \n\n## Mesh Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Mesh samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.",
        "node_767": "* Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.\n\nExamples\n\nAppending point clouds with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> point_cloud1 = np.random.randint(0, 10, (5, 3))\n    >>> ds.point_clouds.append(point_cloud1)\n    >>> point_cloud2 = np.random.randint(0, 10, (15, 3))\n    >>> ds.point_clouds.append(point_cloud2)\n    >>> ds.point_clouds.shape\n    >>> (2, None, 3)\n    \n\nOr we can use `deeplake.read()` method to add samples\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.las\") # point cloud with 100 points\n    >>> ds.point_cloud.append(sample)\n    >>> ds.point_cloud.shape\n    >>> (1, 100, 3)\n    \n\n## Mesh Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Mesh samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.",
        "node_191": "Parameters\n\n    \n\n**large_ok** (_bool_) \u2013 Delete datasets larger than 1 GB. Defaults to `False`.\n\nRaises\n\n    \n\n  * **DatasetTooLargeToDelete** \u2013 If the dataset is larger than 1 GB and `large_ok` is `False`.\n\n  * **DatasetHandlerError** \u2013 If the dataset is marked as allow_delete=False.\n\ndelete_branch(_name : str_) -> None\uf0c1\n\n    \n\nDeletes the branch and cleans up any unneeded data. Branches can only be\ndeleted if there are no sub-branches and if it has never been merged into\nanother branch.\n\nParameters\n\n    \n\n**name** (_str_) \u2013 The branch to delete.\n\nRaises\n\n    \n\n  * **CommitError** \u2013 If `branch` could not be found.\n\n  * **ReadOnlyModeError** \u2013 If branch deletion is attempted in read-only mode.\n\n  * **Exception** \u2013 If you have the given branch currently checked out.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.empty(\"../test/test_ds\")\n    >>> ds.create_tensor(\"abc\")\n    Tensor(key='abc')\n    >>> ds.abc.append([1, 2, 3])\n    >>> first_commit = ds.commit()\n    >>> ds.checkout(\"alt\", create=True)\n    'firstdbf9474d461a19e9333c2fd19b46115348f'\n    >>> ds.abc.append([4, 5, 6])\n    >>> ds.abc.numpy()\n    array([[1, 2, 3],\n           [4, 5, 6]])\n    >>> ds.checkout(first_commit)\n    'firstdbf9474d461a19e9333c2fd19b46115348f'\n    >>> ds.delete_branch(\"alt\")\n    \n\ndelete_group(_name : str_, _large_ok : bool = False_)\uf0c1\n\n    \n\nDelete a tensor group from the dataset.\n\nExamples\n\n    \n    \n    >>> ds.delete_group(\"images/dogs\")\n    \n\nParameters\n\n    \n\n  * **name** (_str_) \u2013 The name of tensor group to be deleted.\n\n  * **large_ok** (_bool_) \u2013 Delete tensor groups larger than 1 GB. Disabled by default.",
        "node_111": "The filenames in `df_column_with_cloud_paths` will be used as the filenames for linked data in the dataset.\n    >>> ds = deeplake.ingest_dataframe(\n    >>>     df,\n    >>>     dest=\"hub://org_id/dataset\",\n    >>>     column_params={\"df_column_with_cloud_paths\": {\"name\": \"image_links\", \"htype\": \"link[image]\"}},\n    >>>     creds_key=\"my_s3_managed_credentials\"\n    >>> )\n    >>> # Ingest data from a DataFrame into a Deep Lake dataset stored in your cloud, and connect that dataset to the Deep Lake backend. The filenames in `df_column_with_cloud_paths` will be used as the filenames for linked data in the dataset.\n    >>> ds = deeplake.ingest_dataframe(\n    >>>     df,\n    >>>     dest=\"s3://bucket/dataset_name\",\n    >>>     column_params={\"df_column_with_cloud_paths\": {\"name\": \"image_links\", \"htype\": \"link[image]\"}},\n    >>>     creds_key=\"my_s3_managed_credentials\"\n    >>>     connect_kwargs={\"creds_key\": \"my_s3_managed_credentials\", \"org_id\": \"org_id\"},\n    >>> )\n    \n\nParameters\n\n    \n\n  * **src** (_pd.DataFrame_) \u2013 The pandas dataframe to be converted.\n\n  * **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * A Dataset or The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://username/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.",
        "node_851": "Examples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.",
        "node_62": "list, tuple and ndarray will be treated as the list of the weights per sample\n\n  * **replace** \u2013 Optional[bool] If true the samples can be repeated in the result view. (default: `True`).\n\n  * **size** \u2013 Optional[int] The length of the result view. (default: `len(dataset)`)\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nExamples\n\nSample the dataloader with `labels == 5` twice more than `labels == 6`\n\n    \n    \n    >>> ds = deeplake.load('hub://activeloop/fashion-mnist-train')\n    >>> sampled_ds = ds.dataloader().sample_by(\"max_weight(labels == 5: 10, labels == 6: 5)\")\n    \n\nSample the dataloader treating labels tensor as weights.\n\n    \n    \n    >>> ds = deeplake.load('hub://activeloop/fashion-mnist-train')\n    >>> sampled_ds = ds.dataloader().sample_by(\"labels\")\n    \n\nSample the dataloader with the given weights;\n\n    \n    \n    >>> ds_train = deeplake.load('hub://activeloop/coco-train')\n    >>> weights = list()\n    >>> for i in range(0, len(ds_train)):\n    ...     weights.append(i % 5)\n    ...\n    >>> sampled_ds = ds.dataloader().sample_by(weights, replace=False)\n    \n\nshuffle(_shuffle : bool = True_, _buffer_size : int = 2048_)\uf0c1\n\n    \n\nReturns a shuffled `DeepLakeDataLoader` object.\n\nParameters\n\n    \n\n  * **shuffle** (_bool_) \u2013 shows wheter we need to shuffle elements or not. Defaults to True.\n\n  * **buffer_size** (_int_) \u2013 The size of the buffer used to shuffle the data in MBs. Defaults to 2048 MB. Increasing the buffer_size will increase the extent of shuffling.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n  * **ValueError** \u2013 If .shuffle() has already been called.",
        "node_485": "Images can be stored in Deep Lake as compressed bytes or as raw arrays. Due to\nthe high compression ratio for most image formats, it is highly recommended to\nstore compressed images using the `sample_compression` input to the\ncreate_tensor method.\n\n### Creating an image tensor\uf0c1\n\nAn image tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\")\n    \n\nOR\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", chunk_compression=\"jpg\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"bmp\", \"dib\", \"gif\", \"ico\", \"jpeg\", \"jpeg2000\", \"pcx\", \"png\", \"ppm\", \"sgi\", \"tga\", \"tiff\",\n    ... \"webp\", \"wmf\", \"xbm\", \"eps\", \"fli\", \"im\", \"msp\", \"mpo\"]\n    \n\n### Appending image samples\uf0c1\n\n  * Image samples can be of type `np.ndarray` or Deep Lake `Sample` which can be created using `deeplake.read()`.\n\nExamples\n\nAppending pixel data with array\n\n    \n    \n    >>> ds.images.append(np.zeros((5, 5, 3), dtype=np.uint8))\n    \n\nAppening Deep Lake image sample\n\n    \n    \n    >>> ds.images.append(deeplake.read(\"images/0001.jpg\"))\n    \n\nYou can append multiple samples at the same time using `extend()`.\n\n    \n    \n    >>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type.",
        "node_997": "* Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.\n\nExamples\n\nAppending polygons with 2-D points\n\n    \n    \n    >>> poly1 = [(1, 2), (2, 3), (3, 4)]\n    >>> poly2 = [(10, 12), (14, 19)]\n    >>> poly3 = [(33, 32), (54, 67), (67, 43), (56, 98)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with 3-D points\n\n    \n    \n    >>> poly1 = [(10, 2, 9), (12, 3, 8), (12, 10, 4)]\n    >>> poly2 = [(10, 1, 8), (5, 17, 11)]\n    >>> poly3 = [(33, 33, 31), (45, 76, 13), (60, 24, 17), (67, 87, 83)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> sample = np.random.randint(0, 10, (5, 7, 2))  # 5 polygons with 7 points\n    >>> ds.polygons.append(sample)\n    \n    \n    \n    >>> import numpy as np\n    >>> poly1 = np.random.randint(0, 10, (5, 2))\n    >>> poly2 = np.random.randint(0, 10, (8, 2))\n    >>> poly3 = np.random.randint(0, 10, (3, 2))\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\n## Nifti Htype\uf0c1\n\n  * Sample dimensions: `(# height, # width, # slices)` or `(# height, # width, # slices, # time unit)` in case of time-series data.",
        "node_508": "* Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.\n\n    * If `verify=True` was specified during `create_tensor` of the tensor to which this is being added, some metadata is read from them to verify the integrity of the link samples. This is `True` by default.\n\n    * If you do not want to verify your links, all three of `verify`, `create_shape_tensor` and `create_sample_info_tensor` have to be set to `False`.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.dataset(\"......\")\n    \n\nAdding credentials to the dataset\n\nYou can add the names of the credentials you want to use (not needed for\nhttp/local urls)\n\n    \n    \n    >>> ds.add_creds_key(\"MY_S3_KEY\")\n    >>> ds.add_creds_key(\"GCS_KEY\")\n    \n\nand populate the added names with credentials dictionaries\n\n    \n    \n    >>> ds.populate_creds(\"MY_S3_KEY\", {})   # add creds here\n    >>> ds.populate_creds(\"GCS_KEY\", {})    # add creds here\n    \n\nThese creds are only present temporarily and will have to be repopulated on\nevery reload.\n\nFor datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.",
        "node_763": "For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.\n\n## Point Htype\uf0c1\n\n  * Sample dimensions: `(# points, 2)` in case of 2-D (X, Y) co-ordinates or `(# points, 3)` in case of 3-D (X, Y, Z) co-ordinates of the point.\n\nPoints does not contain a fixed mapping across samples between the point order\nand real-world objects (i.e., point 0 is an elbow, point 1 is a knee, etc.).\nIf you require such a mapping, use COCO Keypoints Htype.\n\n### Creating a point tensor\uf0c1\n\nA point tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"points\", htype=\"point\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending point samples\uf0c1\n\n  * Points can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.",
        "node_694": "### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.\n\nExamples\n\nAppending a tag\n\n    \n    \n    >>> ds.tags.append(\"verified\")\n    \n\nExtending with list of tags\n\n    \n    \n    >>> ds.tags.extend([\"verified\", \"unverified\"])\n    \n\n## Bounding Box Htype\uf0c1\n\n  * Sample dimensions: `(# bounding boxes, 4)`\n\nBounding boxes have a variety of conventions such as those used in YOLO, COCO,\nPascal-VOC and others. In order for bounding boxes to be correctly displayed\nby the visualizer, the format of the bounding box must be specified in the\ncoords key in tensor meta information mentioned below.\n\n### Creating a bbox tensor\uf0c1\n\nA bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"boxes\", htype=\"bbox\", coords={\"type\": \"fractional\", \"mode\": \"CCWH\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with keys \u201ctype\u201d and \u201cmode\u201d.\n    \n      * **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.",
        "node_973": "* Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.\n\n    * If `verify=True` was specified during `create_tensor` of the tensor to which this is being added, some metadata is read from them to verify the integrity of the link samples. This is `True` by default.\n\n    * If you do not want to verify your links, all three of `verify`, `create_shape_tensor` and `create_sample_info_tensor` have to be set to `False`.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.dataset(\"......\")\n    \n\nAdding credentials to the dataset\n\nYou can add the names of the credentials you want to use (not needed for\nhttp/local urls)\n\n    \n    \n    >>> ds.add_creds_key(\"MY_S3_KEY\")\n    >>> ds.add_creds_key(\"GCS_KEY\")\n    \n\nand populate the added names with credentials dictionaries\n\n    \n    \n    >>> ds.populate_creds(\"MY_S3_KEY\", {})   # add creds here\n    >>> ds.populate_creds(\"GCS_KEY\", {})    # add creds here\n    \n\nThese creds are only present temporarily and will have to be repopulated on\nevery reload.\n\nFor datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.",
        "node_43": "Examples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.\n\nExamples\n\n    \n    \n    >>> ds.create_tensor(\"seq\", htype=\"sequence\")\n    >>> ds.seq.append([1, 2, 3])\n    >>> ds.seq.append([4, 5, 6])\n    >>> ds.seq.numpy()\n    array([[[1],\n            [2],\n            [3]],\n           [[4],\n            [5],\n            [6]]])\n    \n    \n    \n    >>> ds.create_tensor(\"image_seq\", htype=\"sequence[image]\", sample_compression=\"jpg\")\n    >>> ds.image_seq.append([deeplake.read(\"img01.jpg\"), deeplake.read(\"img02.jpg\")])\n    \n\n## Link htype\uf0c1\n\n  * Link htype is a special meta htype that allows linking of external data (files) to the dataset, without storing the data in the dataset itself.\n\n  * Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.",
        "node_85": "This will overwrite\n> `DEEPLAKE_DOWNLOAD_PATH`.\n>\n>       * Raises an exception if `DEEPLAKE_DOWNLOAD_PATH` environment variable\n> is not set or if the dataset does not exist.\n>\n>       * The \u2018download\u2019 access method can be modified to specify num_workers\n> and/or scheduler. For example: \u2018download:2:processed\u2019 will use 2 workers and\n> use processed scheduler, while \u2018download:3\u2019 will use 3 workers and default\n> scheduler (threaded), and \u2018download:processed\u2019 will use a single worker and\n> use processed scheduler.\n\n    * \u2019local\u2019\n\n>       * Downloads the dataset if it doesn\u2019t already exist, otherwise loads\n> from local storage.\n>\n>       * Raises an exception if `DEEPLAKE_DOWNLOAD_PATH` environment variable\n> is not set.\n>\n>       * The \u2018local\u2019 access method can be modified to specify num_workers\n> and/or scheduler to be used in case dataset needs to be downloaded. If\n> dataset needs to be downloaded, \u2018local:2:processed\u2019 will use 2 workers and\n> use processed scheduler, while \u2018local:3\u2019 will use 3 workers and default\n> scheduler (threaded), and \u2018local:processed\u2019 will use a single worker and use\n> processed scheduler.\n\n  * **unlink** (_bool_) \u2013 Downloads linked samples if set to `True`. Only applicable if `access_method` is `download` or `local`. Defaults to `False`.\n\n  * **reset** (_bool_) \u2013 If the specified dataset cannot be loaded due to a corrupted HEAD state of the branch being loaded, setting `reset=True` will reset HEAD changes and load the previous version.\n\n  * **check_integrity** (_bool_ _,__Optional_) \u2013 Performs an integrity check by default (None) if the dataset has 20 or fewer tensors. Set to `True` to force integrity check, `False` to skip integrity check.\n\n  * **lock_timeout** (_int_) \u2013 Number of seconds to wait before throwing a LockException. If None, wait indefinitely\n\n  * **lock_enabled** (_bool_) \u2013 If true, the dataset manages a write lock.",
        "node_761": "1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.",
        "node_746": "core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.\n\nSupported htypes and their respective defaults are:\n\nHtype configs\uf0c1 HTYPE | DTYPE | COMPRESSION  \n---|---|---  \ngeneric | None | None  \nimage | uint8 | Required arg  \nimage.rgb | uint8 | Required arg  \nimage.gray | uint8 | Required arg  \nvideo | uint8 | Required arg  \naudio | float64 | Required arg  \nclass_label | uint32 | None  \ntag | str | None  \nbbox | float32 | None  \nbbox.3d | float32 | None  \nintrinsics | float32 | None  \nsegment_mask | uint32 | None  \nbinary_mask | bool | None  \nkeypoints_coco | int32 | None  \npoint | int32 | None  \npolygon | float32 | None  \ntext | str | None  \njson | Any | None  \nlist | List | None  \ndicom | None | dcm  \nnifti | None | Required arg  \npoint_cloud | None | las  \nmesh | None | ply  \ninstance_label | uint32 | None  \nembedding | None | None  \nlink | str | None  \nsequence | None | None  \n  \n## Image Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # channels)` or `(height, width)`.\n\nImages can be stored in Deep Lake as compressed bytes or as raw arrays.",
        "node_439": "For these use cases,\nplease use htype = \u201cbinary_mask\u201d.\n\n## Binary Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # objects in a sample)`\n\nBinary masks are similar to segmentation masks, except that each object is\nrepresented by a channel in the mask. Each channel in the mask encodes values\nfor a single object. A pixel in a mask channel should have a value of 1 if the\npixel of the image belongs to this object and 0 otherwise. The labels\ncorresponding to the channels should be stored in an adjacent tensor of htype\n`class_label`, in which the number of labels at a given index is equal to the\nnumber of objects (number of channels) in the binary mask.\n\n### Creating a binary_mask tensor\uf0c1\n\nA binary_mask tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"masks\", htype=\"binary_mask\", sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * ref:sample_compression <sample_compression> or chunk_compression\n\n    * dtype: Defaults to `bool`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`.",
        "node_740": "Examples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.\n\nExamples\n\n    \n    \n    >>> ds.create_tensor(\"seq\", htype=\"sequence\")\n    >>> ds.seq.append([1, 2, 3])\n    >>> ds.seq.append([4, 5, 6])\n    >>> ds.seq.numpy()\n    array([[[1],\n            [2],\n            [3]],\n           [[4],\n            [5],\n            [6]]])\n    \n    \n    \n    >>> ds.create_tensor(\"image_seq\", htype=\"sequence[image]\", sample_compression=\"jpg\")\n    >>> ds.image_seq.append([deeplake.read(\"img01.jpg\"), deeplake.read(\"img02.jpg\")])\n    \n\n## Link htype\uf0c1\n\n  * Link htype is a special meta htype that allows linking of external data (files) to the dataset, without storing the data in the dataset itself.\n\n  * Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read.",
        "node_102": "* **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Set to `True` by default.\n\n  * **shuffle** (_bool_) \u2013 Shuffles the input data prior to ingestion. Set to `False` by default.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for ingestion. Set to `0` by default.\n\n  * **token** (_Optional_ _[__str_ _]_) \u2013 The token to use for accessing the dataset and/or connecting it to Deep Lake.\n\n  * **connect_kwargs** (_Optional_ _[__Dict_ _]_) \u2013 If specified, the dataset will be connected to Deep Lake, and connect_kwargs will be passed to `Dataset.connect`.\n\n  * ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function. See `deeplake.empty()`.\n\nReturns\n\n    \n\nThe Dataset created from images and COCO annotations.\n\nReturn type\n\n    \n\nDataset\n\nRaises\n\n    \n\n**IngestionError** \u2013 If either `key_to_tensor_mapping` or\n`file_to_group_mapping` are not one-to-one.\n\ndeeplake.ingest_yolo(_data_directory : Union[str, Path]_, _dest : Union[str,\nPath]_, _class_names_file : Optional[Union[str, Path]] = None_,\n_annotations_directory : Optional[Union[str, Path]] = None_,\n_allow_no_annotation : bool = False_, _image_params : Optional[Dict] = None_,\n_label_params : Optional[Dict] = None_, _coordinates_params : Optional[Dict] =\nNone_, _src_creds : Optional[Union[Dict, str]] = None_, _dest_creds :\nOptional[Union[Dict, str]] = None_, _image_creds_key : Optional[str] = None_,\n_inspect_limit : int = 1000_, _progressbar : bool = True_, _shuffle : bool =\nFalse_, _num_workers : int = 0_, _token : Optional[str] = None_,\n_connect_kwargs : Optional[Dict] = None_, _** dataset_kwargs_) -> Dataset\uf0c1\n\n    \n\nIngest images and annotations (bounding boxes or polygons) in YOLO format to a\nDeep Lake Dataset. The source data can be stored locally or in the cloud.",
        "node_968": "* Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.\n\nExamples\n\nAppending polygons with 2-D points\n\n    \n    \n    >>> poly1 = [(1, 2), (2, 3), (3, 4)]\n    >>> poly2 = [(10, 12), (14, 19)]\n    >>> poly3 = [(33, 32), (54, 67), (67, 43), (56, 98)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with 3-D points\n\n    \n    \n    >>> poly1 = [(10, 2, 9), (12, 3, 8), (12, 10, 4)]\n    >>> poly2 = [(10, 1, 8), (5, 17, 11)]\n    >>> poly3 = [(33, 33, 31), (45, 76, 13), (60, 24, 17), (67, 87, 83)]\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\nAppending polygons with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> sample = np.random.randint(0, 10, (5, 7, 2))  # 5 polygons with 7 points\n    >>> ds.polygons.append(sample)\n    \n    \n    \n    >>> import numpy as np\n    >>> poly1 = np.random.randint(0, 10, (5, 2))\n    >>> poly2 = np.random.randint(0, 10, (8, 2))\n    >>> poly3 = np.random.randint(0, 10, (3, 2))\n    >>> sample = [poly1, poly2, poly3]\n    >>> ds.polygons.append(sample)\n    \n\n## Nifti Htype\uf0c1\n\n  * Sample dimensions: `(# height, # width, # slices)` or `(# height, # width, # slices, # time unit)` in case of time-series data.",
        "node_748": ">>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type. i.e., if RGB images are appended to an `image.gray`\ntensor, Deep Lake will convert them to grayscale and if grayscale images are\nappended to an `image.rgb` tensor, Deep Lake will convert them to RGB format.\n\nimage.rgb and image.gray tensors can be created using\n\n    \n    \n    >>> ds.create_tensor(\"rgb_images\", htype=\"image.rgb\", sample_compression=\"...\")\n    \n    \n    \n    >>> ds.create_tensor(\"gray_images\", htype=\"image.gray\", sample_compression=\"...\")\n    \n\n## Video Htype\uf0c1\n\n  * Sample dimensions: `(# frames, height, width, # channels)` or `(# frames, height, width)`\n\n### Limitations\uf0c1\n\n  * Visualization of videos in the Deep Lake App is limited by the video coded support for various browsers.\n    \n    * Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.",
        "node_710": "* Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.\n\n### Creating a mesh tensor\uf0c1\n\nA mesh tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"mesh\", htype=\"mesh\", sample_compression=\"ply\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"ply\"]\n    \n\n### Appending meshes\uf0c1\n\nExamples\n\nAppending a ply file containing a mesh data to tensor\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.ply\")  # mesh with 100 points and 200 faces\n    >>> ds.mesh.append(sample)\n    \n    \n    \n    >>> ds.mesh.shape\n    >>> (1, 100, 3)\n    \n\n## Embedding Htype\uf0c1\n\n  * Sample dimensions: `(# elements in the embedding,)`\n\n### Creating an embedding tensor\uf0c1\n\nAn embedding tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"embedding\", htype=\"embedding\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\", None]\n    \n\n### Appending embedding samples\uf0c1\n\n  * Embedding samples can be of type `np.ndarray`.\n\nExamples\n\nAppending Deep Lake embedding sample\n\n    \n    \n    >>> ds.embedding.append(np.random.uniform(low=-1, high=1, size=(1024)))\n    \n\nExtending with Deep Lake embeddding samples\n\n    \n    \n    >>> ds.embedding.extend([np.random.uniform(low=-1, high=1, size=(1024)) for i in range(10)])\n    \n\n## Sequence htype\uf0c1\n\n  * A special meta htype for tensors where each sample is a sequence. The items in the sequence are samples of another htype.\n\n  * It is a wrapper htype that can wrap other htypes like `sequence[image]`, `sequence[video]`, `sequence[text]`, etc.",
        "node_752": "### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.\n\nExamples\n\nAppending a tag\n\n    \n    \n    >>> ds.tags.append(\"verified\")\n    \n\nExtending with list of tags\n\n    \n    \n    >>> ds.tags.extend([\"verified\", \"unverified\"])\n    \n\n## Bounding Box Htype\uf0c1\n\n  * Sample dimensions: `(# bounding boxes, 4)`\n\nBounding boxes have a variety of conventions such as those used in YOLO, COCO,\nPascal-VOC and others. In order for bounding boxes to be correctly displayed\nby the visualizer, the format of the bounding box must be specified in the\ncoords key in tensor meta information mentioned below.\n\n### Creating a bbox tensor\uf0c1\n\nA bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"boxes\", htype=\"bbox\", coords={\"type\": \"fractional\", \"mode\": \"CCWH\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with keys \u201ctype\u201d and \u201cmode\u201d.\n    \n      * **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.",
        "node_178": "Returns\n\n    \n\nList of branches.\n\ncheckout(_address : str_, _create : bool = False_, _reset : bool = False_) ->\nOptional[str]\uf0c1\n\n    \n\nChecks out to a specific commit_id or branch. If `create = True`, creates a\nnew branch with name `address`.\n\nParameters\n\n    \n\n  * **address** (_str_) \u2013 The commit_id or branch to checkout to.\n\n  * **create** (_bool_) \u2013 If `True`, creates a new branch with name as address.\n\n  * **reset** (_bool_) \u2013 If checkout fails due to a corrupted HEAD state of the branch, setting `reset=True` will reset HEAD changes and attempt the checkout again.\n\nReturns\n\n    \n\nThe commit_id of the dataset after checkout.\n\nReturn type\n\n    \n\nOptional[str]\n\nRaises\n\n    \n\n  * **CheckoutError** \u2013 If `address` could not be found.\n\n  * **ReadOnlyModeError** \u2013 If branch creation or reset is attempted in read-only mode.\n\n  * **DatasetCorruptError** \u2013 If checkout failed due to dataset corruption and `reset` is not `True`.\n\n  * **Exception** \u2013 If the dataset is a filtered view.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.empty(\"../test/test_ds\")\n    >>> ds.create_tensor(\"abc\")\n    Tensor(key='abc')\n    >>> ds.abc.append([1, 2, 3])\n    >>> first_commit = ds.commit()\n    >>> ds.checkout(\"alt\", create=True)\n    'firstdbf9474d461a19e9333c2fd19b46115348f'\n    >>> ds.abc.append([4, 5, 6])\n    >>> ds.abc.numpy()\n    array([[1, 2, 3],\n           [4, 5, 6]])\n    >>> ds.checkout(first_commit)\n    'firstdbf9474d461a19e9333c2fd19b46115348f'\n    >>> ds.abc.numpy()\n    array([[1, 2, 3]])\n    \n\nNote\n\nCheckout from a head node in any branch that contains uncommitted data will\nlead to an automatic commit before the checkout.",
        "node_387": "`Dataset.flush` | Necessary operation after writes if caches are being used.  \n`Dataset.clear_cache` | \n\n  * Flushes (see `Dataset.flush()`) the contents of the cache layers (if any) and then deletes contents of all the layers of it.\n\n  \n`Dataset.size_approx` | Estimates the size in bytes of the dataset.  \n`Dataset.random_split` | Splits the dataset into non-overlapping `Dataset` objects of given lengths.  \n  \n## Dataset Visualization\uf0c1\n\n`Dataset.visualize` | Visualizes the dataset in the Jupyter notebook.  \n---|---  \n  \n## Dataset Credentials\uf0c1\n\n`Dataset.add_creds_key` | Adds a new creds key to the dataset.  \n---|---  \n`Dataset.populate_creds` | Populates the creds key added in add_creds_key with the given creds.  \n`Dataset.update_creds_key` | Updates the name and/or management status of a creds key.  \n`Dataset.get_creds_keys` | Returns the set of creds keys added to the dataset.  \n  \n## Dataset Properties\uf0c1\n\n`Dataset.tensors` | All tensors belonging to this group, including those within sub groups.  \n---|---  \n`Dataset.groups` | All sub groups in this group  \n`Dataset.num_samples` | Returns the length of the smallest tensor.  \n`Dataset.read_only` | Returns True if dataset is in read-only mode and False otherwise.  \n`Dataset.info` | Returns the information about the dataset.  \n`Dataset.max_len` | Return the maximum length of the tensor.  \n`Dataset.min_len` | Return the minimum length of the tensor.  \n  \n## Dataset Version Control\uf0c1\n\n`Dataset.commit` | Stores a snapshot of the current state of the dataset.  \n---|---  \n`Dataset.diff` | Returns/displays the differences between commits/branches.  \n`Dataset.checkout` | Checks out to a specific commit_id or branch.  \n`Dataset.merge` | Merges the target_id into the current dataset.  \n`Dataset.log` | Displays the details of all the past commits.  \n`Dataset.reset` | Resets the uncommitted changes present in the branch.  \n`Dataset.get_commit_details` | Get details of a particular commit.",
        "node_442": "`tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.\n\nExamples\n\nAppending keypoints sample with 3 keypoints and 4 objects\n\n    \n    \n    >>> ds.keypoints.update(keypoints = [\"left ear\", \"right ear\", \"nose\"])\n    >>> ds.keypoints.update(connections = [[0, 2], [1, 2]])\n    >>> kp_arr\n    array([[465, 398, 684, 469],\n           [178, 363, 177, 177],\n           [  2,   2,   2,   1],\n           [454, 387, 646, 478],\n           [177, 322, 137, 161],\n           [  2,   2,   2,   2],\n           [407, 379, 536, 492],\n           [271, 335, 150, 143],\n           [  2,   1,   2,   2]])\n    >>> kp_arr.shape\n    (9, 4)\n    >>> ds.keypoints.append(kp_arr)\n    \n\nWarning\n\nIn order to correctly use the keypoints and connections metadata, it is\ncritical that all objects in every sample have the same number of K keypoints\nin the same order. For keypoints that are not present in an image, they can be\nstored with dummy coordinates of x = 0, y = 0, and v = 0, and the visibility\nwill prevent them from being drawn in the visualizer.",
        "node_843": "* sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nrotation angles are specified in degrees, not radians\n\n### Appending 3d bounding boxes\uf0c1\n\n  * Bounding boxes can be appended as `np.ndarrays` or `list` or `lists of arrays`.\n\nExamples\n\nAppending one bounding box\n\n    \n    \n    >>> box\n    array([[462, 123, 238,  98, 22, 36, 44, 18, 0, 36, 0]])\n    >>> ds.3d_boxes.append(box)\n    \n\nAppending sample with 3 bounding boxes\n\n    \n    \n    >>> boxes\n    array([[965, 110, 262,  77, 22, 36, 44, 18, 0, 28, 0],\n           [462, 123, 238,  98, 26, 34, 24, 19, 0, -50, 0],\n           [688, 108, 279, 116, 12, 32, 14, 38, 0, 30, 0]])\n    >>> boxes.shape\n    (9, 4)\n    >>> ds.3d_boxes.append(boxes)\n    \n\n## Intrinsics Htype\uf0c1\n\n  * Sample dimensions: `(# intrinsics matrices, 3, 3)`\n\nThe intrinsic matrix represents a projective transformation from the 3-D\ncamera\u2019s coordinates into the 2-D image coordinates. The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.",
        "node_283": "main\n\nBranchesTags\n\nGo to file\n\nCode\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\n## History\n\n8,842 Commits  \n  \n### .github\n\n|\n\n### .github\n\n|  |   \n  \n### bin\n\n|\n\n### bin\n\n|  |   \n  \n### deeplake\n\n|\n\n### deeplake\n\n|  |   \n  \n### docs\n\n|\n\n### docs\n\n|  |   \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n|  |   \n  \n### .pre-commit-config.yaml\n\n|\n\n### .pre-commit-config.yaml\n\n|  |   \n  \n### .readthedocs.yaml\n\n|\n\n### .readthedocs.yaml\n\n|  |   \n  \n### CONTRIBUTING.md\n\n|\n\n### CONTRIBUTING.md\n\n|  |   \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n|  |   \n  \n### MANIFEST.in\n\n|\n\n### MANIFEST.in\n\n|  |   \n  \n### README.md\n\n|\n\n### README.md\n\n|  |   \n  \n### README.zh-cn.md\n\n|\n\n### README.zh-cn.md\n\n|  |   \n  \n### SECURITY.md\n\n|\n\n### SECURITY.md\n\n|  |   \n  \n### conftest.py\n\n|\n\n### conftest.py\n\n|  |   \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n|  |   \n  \n### setup.cfg\n\n|\n\n### setup.cfg\n\n|  |   \n  \n### setup.py\n\n|\n\n### setup.py\n\n|  |   \n  \n### sonar-project.properties\n\n|\n\n### sonar-project.",
        "node_505": "* Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.\n\nExamples\n\nAppending point clouds with numpy arrays\n\n    \n    \n    >>> import numpy as np\n    >>> point_cloud1 = np.random.randint(0, 10, (5, 3))\n    >>> ds.point_clouds.append(point_cloud1)\n    >>> point_cloud2 = np.random.randint(0, 10, (15, 3))\n    >>> ds.point_clouds.append(point_cloud2)\n    >>> ds.point_clouds.shape\n    >>> (2, None, 3)\n    \n\nOr we can use `deeplake.read()` method to add samples\n\n    \n    \n    >>> import deeplake as dp\n    >>> sample = dp.read(\"example.las\") # point cloud with 100 points\n    >>> ds.point_cloud.append(sample)\n    >>> ds.point_cloud.shape\n    >>> (1, 100, 3)\n    \n\n## Mesh Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Mesh samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each sample in a tensor of `mesh` htype is a mesh array (3-D object data).\n\n  * Each mesh is a list / array of points.\n\n  * Different meshes can have different number of points.",
        "node_1055": "deeplake.dataset(_path : Union[str, Path]_, _runtime : Optional[Dict] = None_,\n_read_only : Optional[bool] = None_, _overwrite : bool = False_, _public :\nbool = False_, _memory_cache_size : int = 2000_, _local_cache_size : int = 0_,\n_creds : Optional[Union[Dict, str]] = None_, _token : Optional[str] = None_,\n_org_id : Optional[str] = None_, _verbose : bool = True_, _access_method : str\n= 'stream'_, _unlink : bool = False_, _reset : bool = False_, _check_integrity\n: Optional[bool] = False_, _lock_enabled : Optional[bool] = True_,\n_lock_timeout : Optional[int] = 0_, _index_params : Optional[Dict[str,\nUnion[int, str]]] = None_)\uf0c1\n\n    \n\nReturns a `Dataset` object referencing either a new or existing dataset.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.dataset(\"hub://username/dataset\")\n    >>> ds = deeplake.dataset(\"s3://mybucket/my_dataset\")\n    >>> ds = deeplake.dataset(\"./datasets/my_dataset\", overwrite=True)\n    \n\nLoading to a specfic version:\n\n    \n    \n    >>> ds = deeplake.dataset(\"hub://username/dataset@new_branch\")\n    >>> ds = deeplake.dataset(\"hub://username/dataset@3e49cded62b6b335c74ff07e97f8451a37aca7b2)\n    \n    \n    \n    >>> my_commit_id = \"3e49cded62b6b335c74ff07e97f8451a37aca7b2\"\n    >>> ds = deeplake.dataset(f\"hub://username/dataset@{my_commit_id}\")\n    \n\nParameters\n\n    \n\n  * **path** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://username/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).",
        "node_544": ">>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type. i.e., if RGB images are appended to an `image.gray`\ntensor, Deep Lake will convert them to grayscale and if grayscale images are\nappended to an `image.rgb` tensor, Deep Lake will convert them to RGB format.\n\nimage.rgb and image.gray tensors can be created using\n\n    \n    \n    >>> ds.create_tensor(\"rgb_images\", htype=\"image.rgb\", sample_compression=\"...\")\n    \n    \n    \n    >>> ds.create_tensor(\"gray_images\", htype=\"image.gray\", sample_compression=\"...\")\n    \n\n## Video Htype\uf0c1\n\n  * Sample dimensions: `(# frames, height, width, # channels)` or `(# frames, height, width)`\n\n### Limitations\uf0c1\n\n  * Visualization of videos in the Deep Lake App is limited by the video coded support for various browsers.\n    \n    * Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.",
        "node_57": "Parameters\n\n    \n\n  * **num_workers** (_int_) \u2013 Number of workers to use for transforming and processing the data. Defaults to 0.\n\n  * **tensors** (_List_ _[__str_ _]__,__Optional_) \u2013 List of tensors to load. If None, all tensors are loaded. Defaults to None.\n\n  * **num_threads** (_int_ _,__Optional_) \u2013 Number of threads to use for fetching and decompressing the data. If None, the number of threads is automatically determined. Defaults to None.\n\n  * **prefetch_factor** (_int_) \u2013 Number of batches to transform and collate in advance per worker. Defaults to 2.\n\n  * **persistent_workers** (_bool_) \u2013 If `True`, the data loader will not shutdown the worker processes after a dataset has been consumed once. Defaults to `False`.\n\n  * **decode_method** (_Dict_ _[__str_ _,__str_ _]__,__Optional_) \u2013 \n\nA dictionary of decode methods for each tensor. Defaults to None.\n\n    * Supported decode methods are:-\n\n> \u2018numpy\u2019\n>  \n>\n> Default behaviour. Returns samples as numpy arrays.\n>\n> \u2019tobytes\u2019\n>  \n>\n> Returns raw bytes of the samples.\n>\n> \u2019pil\u2019\n>  \n>\n> Returns samples as PIL images. Especially useful when transformation use\n> torchvision transforms, that require PIL images as input. Only supported for\n> tensors with sample_compression=\u2019jpeg\u2019 or \u2018png\u2019.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n**ValueError** \u2013 If .pytorch() or .tensorflow() or .numpy() has already been\ncalled.\n\noffset(_off : int = 0_)\uf0c1\n\n    \n\nReturns a shifted `DeepLakeDataLoader` object.\n\nParameters\n\n    \n\n**off** (_int_) \u2013 index that the dataloadee will start to iterate.\n\nReturns\n\n    \n\nA `DeepLakeDataLoader` object.\n\nReturn type\n\n    \n\nDeepLakeDataLoader\n\nRaises\n\n    \n\n**ValueError** \u2013 If .offset() has already been called.",
        "node_156": "embedding_data = texts,\n    .     embedding_tensor = \"embedding_1\",\n    . )\n    \n\nParameters\n\n    \n\n  * **embedding_function** (_Optional_ _[__Callable_ _]_) \u2013 embedding function used to convert `embedding_data` into embeddings. Input to embedding_function is a list of data and output is a list of embeddings. Overrides the `embedding_function` specified when initializing the Vector Store.\n\n  * **embedding_data** (_Optional_ _[__List_ _]_) \u2013 Data to be converted into embeddings using the provided `embedding_function`. Defaults to None.\n\n  * **embedding_tensor** (_Optional_ _[__str_ _]_) \u2013 Tensor where results from the embedding function will be stored. If None, the embedding tensor is automatically inferred (when possible). Defaults to None.\n\n  * **return_ids** (_bool_) \u2013 Whether to return added ids as an ouput of the method. Defaults to False.\n\n  * **rate_limiter** (_Dict_) \u2013 Rate limiter configuration. Defaults to `{\"enabled\": False, \"bytes_per_minute\": MAX_BYTES_PER_MINUTE, \"batch_byte_size\": TARGET_BYTE_SIZE}`.\n\n  * ****tensors** \u2013 Keyword arguments where the key is the tensor name, and the value is a list of samples that should be uploaded to that tensor.\n\nReturns\n\n    \n\nList of ids if `return_ids` is set to True. Otherwise, None.\n\nReturn type\n\n    \n\nOptional[List[str]]\n\ncheckout(_branch : str = 'main'_, _create =False_) -> None\uf0c1\n\n    \n\nCheckout the Vector Store to a specific branch.\n\nParameters\n\n    \n\n  * **branch** (_str_) \u2013 Branch name to checkout. Defaults to \u201cmain\u201d.\n\n  * **create** (_bool_) \u2013 Whether to create the branch if it doesn\u2019t exist. Defaults to False.\n\ncommit(_allow_empty : bool = True_) -> None\uf0c1\n\n    \n\nCommits the Vector Store.\n\nParameters\n\n    \n\n**allow_empty** (_bool_) \u2013 Whether to allow empty commits. Defaults to True.",
        "node_553": "The intrinsic parameters\ninclude the focal length, the optical center, also known as the principal\npoint. The camera intrinsic matrix, \\\\(K\\\\), is defined as:\n\n\\\\[\\begin{split}\\begin{bmatrix} f_x & 0 & c_x \\\\\\ 0 & f_y & c_y \\\\\\ 0 & 0 & 1\n\\end{bmatrix}\\end{split}\\\\]\n\n  * \\\\([c_x, c_y]\\\\) \\- Optical center (the principal point), in pixels.\n\n  * \\\\([f_x, f_y]\\\\) \\- Focal length in pixels.\n\n  * \\\\(f_x = F / p_x\\\\)\n\n  * \\\\(f_y = F / p_y\\\\)\n\n  * \\\\(F\\\\) \\- Focal length in world units, typically expressed in millimeters.\n\n  * \\\\((p_x, p_y)\\\\) \\- Size of the pixel in world units.\n\n### Creating an intrinsics tensor\uf0c1\n\nAn intrinsics tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"intrinsics\", htype=\"intrinsics\")\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression.\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending intrinsics matrices\uf0c1\n\n    \n    \n    >>> intrinsic_params = np.zeros((3, 3))\n    >>> ds.intrinsics.append(intrinsic_params)\n    \n\n## Segmentation Mask Htype\uf0c1\n\n  * Sample dimensions: `(height, width)`\n\nSegmentation masks are 2D representations of class labels where the numerical\nlabel data is encoded in an array of same shape as the image. The numerical\nvalues are indices of the list `tensor.info.class_names`.\n\n### Creating a segment_mask tensor\uf0c1\n\nA segment_mask tensor can be created using\n\n    \n    \n    >>> classes = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\"]\n    >>> ds.create_tensor(\"masks\", htype=\"segment_mask\", class_names=classes, sample_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * class_names: This must be a **list of strings**.",
        "node_1150": "_managed : bool = False_)\uf0c1\n\n    \n\nAdds a new creds key to the dataset. These keys are used for tensors that are\nlinked to external data.\n\nExamples\n\n    \n    \n    >>> # create/load a dataset\n    >>> ds = deeplake.empty(\"path/to/dataset\")\n    >>> # add a new creds key\n    >>> ds.add_creds_key(\"my_s3_key\")\n    \n\nParameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The key to be added.\n\n  * **managed** (_bool_) \u2013 \n    * If `True`, the creds corresponding to the key will be fetched from Activeloop platform.\n\n    * Defaults to `False`.\n\nRaises\n\n    \n\n**ValueError** \u2013 If the dataset is not connected to Activeloop platform and\n`managed` is `True`.\n\nNote\n\n`managed` parameter is applicable only for datasets that are connected to\nActiveloop platform.\n\n_property _allow_delete _: bool_\uf0c1\n\n    \n\nReturns True if dataset can be deleted from storage. Whether it can be deleted\nor not is stored in the database_meta.json and can be changed with\nallow_delete = True|False\n\nappend(_sample : Dict[str, Any]_, _skip_ok : bool = False_, _append_empty :\nbool = False_)\uf0c1\n\n    \n\nAppend samples to mutliple tensors at once. This method expects all tensors\nbeing updated to be of the same length.\n\nParameters\n\n    \n\n  * **sample** (_dict_) \u2013 Dictionary with tensor names as keys and samples as values.\n\n  * **skip_ok** (_bool_) \u2013 Skip tensors not in `sample` if set to `True`.\n\n  * **append_empty** (_bool_) \u2013 Append empty samples to tensors not specified in `sample` if set to `True`. If True, `skip_ok` is ignored.\n\nRaises\n\n    \n\n  * **KeyError** \u2013 If any tensor in the dataset is not a key in `sample` and `skip_ok` is `False`.\n\n  * **TensorDoesNotExistError** \u2013 If tensor in `sample` does not exist.\n\n  * **ValueError** \u2013 If all tensors being updated are not of the same length.\n\n  * **NotImplementedError** \u2013 If an error occurs while writing tiles.",
        "node_690": ">>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type. i.e., if RGB images are appended to an `image.gray`\ntensor, Deep Lake will convert them to grayscale and if grayscale images are\nappended to an `image.rgb` tensor, Deep Lake will convert them to RGB format.\n\nimage.rgb and image.gray tensors can be created using\n\n    \n    \n    >>> ds.create_tensor(\"rgb_images\", htype=\"image.rgb\", sample_compression=\"...\")\n    \n    \n    \n    >>> ds.create_tensor(\"gray_images\", htype=\"image.gray\", sample_compression=\"...\")\n    \n\n## Video Htype\uf0c1\n\n  * Sample dimensions: `(# frames, height, width, # channels)` or `(# frames, height, width)`\n\n### Limitations\uf0c1\n\n  * Visualization of videos in the Deep Lake App is limited by the video coded support for various browsers.\n    \n    * Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.",
        "node_256": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * deeplake.client.log\n  * Edit on GitHub\n\n* * *\n\n# deeplake.client.log\uf0c1\n\nDeep Lake does logging using the \u201cdeeplake\u201d logger. Logging level is\n`logging.INFO` by default. See example on how to change this.\n\n    \n    \n    >>> import deeplake\n    >>> import logging\n    >>> logger = logging.getLogger(\"deeplake\")\n    >>> logger.setLevel(logging.WARNING)\n    \n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_1186": "If\na list of fractions that sum up to 1 is given, the lengths will be computed\nautomatically as floor(frac * len(dataset)) for each fraction provided.\n\nAfter computing the lengths, if there are any remainders, 1 count will be\ndistributed in round-robin fashion to the lengths until there are no\nremainders left.\n\nExample\n\n    \n    \n    >>> import deeplake\n    >>> ds = deeplake.dataset(\"../test/test_ds\", overwrite=True)\n    >>> ds.create_tensor(\"labels\", htype=\"class_label\")\n    >>> ds.labels.extend([0, 1, 2, 1, 3])\n    >>> len(ds)\n    5\n    >>> train_ds, val_ds = ds.random_split([0.8, 0.2])\n    >>> len(train_ds)\n    4\n    >>> len(val_ds)\n    1\n    >>> train_ds, val_ds = ds.random_split([3, 2])\n    >>> len(train_ds)\n    3\n    >>> len(val_ds)\n    2\n    >> train_loader = train_ds.pytorch(batch_size=2, shuffle=True)\n    >> val_loader = val_ds.pytorch(batch_size=2, shuffle=False)\n    \n\nParameters\n\n    \n\n**lengths** (_Sequence_ _[__Union_ _[__int_ _,__float_ _]__]_) \u2013 lengths or\nfractions of splits to be produced.\n\nReturns\n\n    \n\na tuple of datasets of the given lengths.\n\nReturn type\n\n    \n\nTuple[Dataset, \u2026]\n\nRaises\n\n    \n\n  * **ValueError** \u2013 If the sum of the lengths is not equal to the length of the dataset.\n\n  * **ValueError** \u2013 If the dataset has variable length tensors.\n\n  * **ValueError** \u2013 If lengths are floats and one or more of them are not between 0 and 1.\n\n_property _read_only\uf0c1\n\n    \n\nReturns True if dataset is in read-only mode and False otherwise.\n\nrechunk(_tensors : Optional[Union[str, List[str]]] = None_, _num_workers : int\n= 0_, _scheduler : str = 'threaded'_, _progressbar : bool = True_)\uf0c1\n\n    \n\nRewrites the underlying chunks to make their sizes optimal.",
        "node_793": "Examples\n\nAppending 2 2-D points\n\n    \n    \n    >>> ds.points.append([[0, 1], [1, 3]])\n    \n\nAppending 2 3-D points\n\n    \n    \n    >>> ds.points.append(np.zeros((2, 3)))\n    \n\n## Polygon Htype\uf0c1\n\n  * Sample dimensions: `(# polygons, # points per polygon, # co-ordinates per point)`\n\n  * Each sample in a tensor of `polygon` htype is a list of polygons.\n\n  * Each polygon is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates (eg., cannot mix 2-D points with 3-D points).\n\n  * Different samples can have different number of polygons.\n\n  * Different polygons can have different number of points.\n\n### Creating a polygon tensor\uf0c1\n\nA polygon tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"polygons\", htype=\"polygon\", sample_compression=None)\n    \n\n  * Optional args:\n    \n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `float32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending polygons\uf0c1\n\n  * Polygons can be appended as a `list` of `list of tuples` or `np.ndarray`.",
        "node_665": "### Creating a tag tensor\uf0c1\n\nA tag tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"tags\", htype=\"tag\", chunk_compression=\"lz4\")\n    \n\n  * Optional args:\n    \n    * chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\n### Appending tag samples\uf0c1\n\n  * Tag samples can be appended as `str` or `list` of `str`.\n\nExamples\n\nAppending a tag\n\n    \n    \n    >>> ds.tags.append(\"verified\")\n    \n\nExtending with list of tags\n\n    \n    \n    >>> ds.tags.extend([\"verified\", \"unverified\"])\n    \n\n## Bounding Box Htype\uf0c1\n\n  * Sample dimensions: `(# bounding boxes, 4)`\n\nBounding boxes have a variety of conventions such as those used in YOLO, COCO,\nPascal-VOC and others. In order for bounding boxes to be correctly displayed\nby the visualizer, the format of the bounding box must be specified in the\ncoords key in tensor meta information mentioned below.\n\n### Creating a bbox tensor\uf0c1\n\nA bbox tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"boxes\", htype=\"bbox\", coords={\"type\": \"fractional\", \"mode\": \"CCWH\"})\n    \n\n  * Optional args:\n    \n    * **coords** : A dictionary with keys \u201ctype\u201d and \u201cmode\u201d.\n    \n      * **type** : Specifies the units of bounding box coordinates.\n    \n        * \u201cpixel\u201d: is in unit of pixels.\n\n        * \u201cfractional\u201d: is in units relative to the width and height of the image, such as in YOLO format.\n\n      * **mode** : Specifies the convention for the 4 coordinates\n    \n        * \u201cLTRB\u201d: left_x, top_y, right_x, bottom_y\n\n        * \u201cLTWH\u201d: left_x, top_y, width, height\n\n        * \u201cCCWH\u201d: center_x, center_y, width, height\n\n    * **dtype** : Defaults to `float32`.\n\n    * sample_compression or chunk_compression.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set the class names after tensor creation.",
        "node_1245": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n    * `DeeplakeRandom`\n      * `DeeplakeRandom.get_seed()`\n      * `DeeplakeRandom.seed()`\n\n__Deep Lake\n\n  * \u00bb\n  * deeplake.random.seed\n  * Edit on GitHub\n\n* * *\n\n# deeplake.random.seed\uf0c1\n\n_class _deeplake.core.seed.DeeplakeRandom\uf0c1\n\n    \n\nget_seed() -> Optional[int]\uf0c1\n\n    \n\nReturns the seed which set to the deeplake to control the flows\n\nseed(_seed : Optional[int] = None_)\uf0c1\n\n    \n\nSet random seed to the deeplake engines\n\nParameters\n\n    \n\n**seed** (_int_ _,__optional_) \u2013 Integer seed for initializing the\ncomputational engines, used for bringing reproducibility to random operations.\nSet to `None` to reset the seed. Defaults to `None`.\n\nRaises\n\n    \n\n**TypeError** \u2013 If the provided value type is not supported.\n\n## Background\uf0c1\n\nSpecify a seed to train models and run randomized Deep Lake operations\nreproducibly.",
        "node_624": "* Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.\n\n    * If `verify=True` was specified during `create_tensor` of the tensor to which this is being added, some metadata is read from them to verify the integrity of the link samples. This is `True` by default.\n\n    * If you do not want to verify your links, all three of `verify`, `create_shape_tensor` and `create_sample_info_tensor` have to be set to `False`.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.dataset(\"......\")\n    \n\nAdding credentials to the dataset\n\nYou can add the names of the credentials you want to use (not needed for\nhttp/local urls)\n\n    \n    \n    >>> ds.add_creds_key(\"MY_S3_KEY\")\n    >>> ds.add_creds_key(\"GCS_KEY\")\n    \n\nand populate the added names with credentials dictionaries\n\n    \n    \n    >>> ds.populate_creds(\"MY_S3_KEY\", {})   # add creds here\n    >>> ds.populate_creds(\"GCS_KEY\", {})    # add creds here\n    \n\nThese creds are only present temporarily and will have to be repopulated on\nevery reload.\n\nFor datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.",
        "node_34": "* Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`. A set of `K` keypoints of an object is represented as:\n\n[x1, y1, v1, x2, y2, v2, \u2026, xk, yk, vk]\n\nThe visibility `v` can be one of three values:\n\n0\n\n    \n\nkeypoint not in image.\n\n1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.",
        "node_631": ">>> ds.images.extend([deeplake.read(f\"images/000{i}.jpg\") for i in range(10)])\n    \n\nNote\n\nIf the compression format of the input sample does not match the\n`sample_compression` of the tensor, Deep Lake will decompress and recompress\nthe image for storage, which may significantly slow down the upload process.\nThe upload process is fastest when the image compression matches the\n`sample_compression`.\n\n### image.rgb and image.gray htypes\uf0c1\n\n`image.rgb` and `image.gray` htypes can be used to force your samples to be of\nRGB or grayscale type. i.e., if RGB images are appended to an `image.gray`\ntensor, Deep Lake will convert them to grayscale and if grayscale images are\nappended to an `image.rgb` tensor, Deep Lake will convert them to RGB format.\n\nimage.rgb and image.gray tensors can be created using\n\n    \n    \n    >>> ds.create_tensor(\"rgb_images\", htype=\"image.rgb\", sample_compression=\"...\")\n    \n    \n    \n    >>> ds.create_tensor(\"gray_images\", htype=\"image.gray\", sample_compression=\"...\")\n    \n\n## Video Htype\uf0c1\n\n  * Sample dimensions: `(# frames, height, width, # channels)` or `(# frames, height, width)`\n\n### Limitations\uf0c1\n\n  * Visualization of videos in the Deep Lake App is limited by the video coded support for various browsers.\n    \n    * Chrome supports the codecs shown here.\n\n  * The Deep Lake Performant Dataloader does not support videos.\n\n### Creating a video tensor\uf0c1\n\nA video tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    \n\n  * Optional args:\n    \n    * dtype: Defaults to `uint8`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"mp4\", \"mkv\", \"avi\"]\n    \n\n### Appending video samples\uf0c1\n\n  * Video samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw video frames. Therefore, array of raw frames can only be appended to tensors with `None` compression.",
        "node_1108": "This is optional, tokens are normally autogenerated.\n\nReturns\n\n    \n\nA boolean confirming whether the dataset exists or not at the given path.\n\nRaises\n\n    \n\n**ValueError** \u2013 If version is specified in the path\n\ndeeplake.read(_path : Union[str, Path]_, _verify : bool = False_, _creds :\nOptional[Dict] = None_, _compression : Optional[str] = None_, _storage :\nOptional[StorageProvider] = None_, _timeout : Optional[float] = None_) ->\nSample\uf0c1\n\n    \n\nUtility that reads raw data from supported files into Deep Lake format.\n\n  * Recompresses data into format required by the tensor if permitted by the tensor htype.\n\n  * Simply copies the data in the file if file format matches sample_compression of the tensor, thus maximizing upload speeds.\n\nExamples\n\n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpeg\")\n    >>> ds.images.append(deeplake.read(\"path/to/cat.jpg\"))\n    >>> ds.images.shape\n    (1, 399, 640, 3)\n    \n    \n    \n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    >>> ds.videos.append(deeplake.read(\"path/to/video.mp4\"))\n    >>> ds.videos.shape\n    (1, 136, 720, 1080, 3)\n    \n    \n    \n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpeg\")\n    >>> ds.images.append(deeplake.read(\"https://picsum.photos/200/300\"))\n    >>> ds.images[0].shape\n    (300, 200, 3)\n    \n\nSupported file types:\n\n    \n    \n    Image: \"bmp\", \"dib\", \"gif\", \"ico\", \"jpeg\", \"jpeg2000\", \"pcx\", \"png\", \"ppm\", \"sgi\", \"tga\", \"tiff\", \"webp\", \"wmf\", \"xbm\"\n    Audio: \"flac\", \"mp3\", \"wav\"\n    Video: \"mp4\", \"mkv\", \"avi\"\n    Dicom: \"dcm\"\n    Nifti: \"nii\", \"nii.gz\"\n    \n\nParameters\n\n    \n\n  * **path** (_str_) \u2013 Path to a supported file.",
        "node_905": "* Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nNote\n\nSince segmentation masks often contain large amounts of data, it is\nrecommended to compress them using `lz4`.\n\n### Appending binary masks\uf0c1\n\n  * Binary masks can be appended as `np.ndarray`.\n\nExamples\n\nAppending a binary mask with 5 objects\n\n    \n    \n    >>> ds.masks.append(np.zeros((512, 512, 5), dtype=\"bool\"))\n    >>> ds.labels.append([\"aeroplane\", \"aeroplane\", \"bottle\", \"bottle\", \"bird\"])\n    \n\n## COCO Keypoints Htype\uf0c1\n\n  * Sample dimensions: `(3 x # keypoints, # objects in a sample)`\n\nCOCO keypoints are a convention for storing points of interest in an image.\nEach keypoint consists of 3 values: `x - coordinate`, `y - coordinate` and `v\n- visibility`. A set of `K` keypoints of an object is represented as:\n\n[x1, y1, v1, x2, y2, v2, \u2026, xk, yk, vk]\n\nThe visibility `v` can be one of three values:\n\n0\n\n    \n\nkeypoint not in image.\n\n1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.",
        "node_405": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n    * Creating Tensors\n    * Deleting and Renaming Tensors\n    * Adding and deleting samples\n    * Retrieving samples\n    * Tensor Properties\n    * Info\n    * Video features\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Tensors\n  * Edit on GitHub\n\n* * *\n\n# Tensors\uf0c1\n\n## Creating Tensors\uf0c1\n\n`Dataset.create_tensor` | Creates a new tensor in the dataset.  \n---|---  \n`Dataset.create_group` | Creates a tensor group.  \n`Dataset.create_tensor_like` | Copies the `source` tensor's meta information and creates a new tensor with it.  \n  \n## Deleting and Renaming Tensors\uf0c1\n\n`Dataset.delete_tensor` | Delete a tensor from the dataset.  \n---|---  \n`Dataset.delete_group` | Delete a tensor group from the dataset.  \n`Dataset.rename_tensor` | Renames tensor with name `name` to `new_name`  \n`Dataset.rename_group` | Renames group with name `name` to `new_name`  \n  \n## Adding and deleting samples\uf0c1\n\n`Tensor.append` | Appends a single sample to the end of the tensor.  \n---|---  \n`Tensor.extend` | Extends the end of the tensor by appending multiple elements from a sequence.",
        "node_891": "core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.\n\nSupported htypes and their respective defaults are:\n\nHtype configs\uf0c1 HTYPE | DTYPE | COMPRESSION  \n---|---|---  \ngeneric | None | None  \nimage | uint8 | Required arg  \nimage.rgb | uint8 | Required arg  \nimage.gray | uint8 | Required arg  \nvideo | uint8 | Required arg  \naudio | float64 | Required arg  \nclass_label | uint32 | None  \ntag | str | None  \nbbox | float32 | None  \nbbox.3d | float32 | None  \nintrinsics | float32 | None  \nsegment_mask | uint32 | None  \nbinary_mask | bool | None  \nkeypoints_coco | int32 | None  \npoint | int32 | None  \npolygon | float32 | None  \ntext | str | None  \njson | Any | None  \nlist | List | None  \ndicom | None | dcm  \nnifti | None | Required arg  \npoint_cloud | None | las  \nmesh | None | ply  \ninstance_label | uint32 | None  \nembedding | None | None  \nlink | str | None  \nsequence | None | None  \n  \n## Image Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # channels)` or `(height, width)`.\n\nImages can be stored in Deep Lake as compressed bytes or as raw arrays.",
        "node_135": "* **verify** (_bool_) \u2013 If True, contents of the file are verified.\n\n  * **creds** (_optional_ _,__Dict_) \u2013 Credentials for s3, gcp and http urls.\n\n  * **compression** (_optional_ _,__str_) \u2013 Format of the file. Only required if path does not have an extension.\n\n  * **storage** (_optional_ _,__StorageProvider_) \u2013 Storage provider to use to retrieve remote files. Useful if multiple files are being read from same storage to minimize overhead of creating a new provider.\n\n  * **timeout** (_optional_ _,__float_) \u2013 Timeout in seconds for reading the file. Applicable only for http(s) urls.\n\nReturns\n\n    \n\nSample object. Call `sample.array` to get the `np.ndarray`.\n\nReturn type\n\n    \n\nSample\n\nNote\n\nNo data is actually loaded until you try to get a property of the returned\n`Sample`. This is useful for passing along to `Tensor.append` and\n`Tensor.extend`.\n\ndeeplake.link(_path : str_, _creds_key : Optional[str] = None_) ->\nLinkedSample\uf0c1\n\n    \n\nUtility that stores a link to raw data. Used to add data to a Deep Lake\nDataset without copying it. See Link htype.\n\nSupported file types:\n\n    \n    \n    Image: \"bmp\", \"dib\", \"gif\", \"ico\", \"jpeg\", \"jpeg2000\", \"pcx\", \"png\", \"ppm\", \"sgi\", \"tga\", \"tiff\", \"webp\", \"wmf\", \"xbm\"\n    Audio: \"flac\", \"mp3\", \"wav\"\n    Video: \"mp4\", \"mkv\", \"avi\"\n    Dicom: \"dcm\"\n    Nifti: \"nii\", \"nii.gz\"\n    \n\nParameters\n\n    \n\n  * **path** (_str_) \u2013 Path to a supported file.\n\n  * **creds_key** (_optional_ _,__str_) \u2013 The credential key to use to read data for this sample. The actual credentials are fetched from the dataset.\n\nReturns\n\n    \n\nLinkedSample object that stores path and creds.",
        "node_357": "---|---  \n`deeplake.empty` | Creates an empty dataset  \n`deeplake.like` | Creates a new dataset by copying the `source` dataset's structure to a new location.  \n`deeplake.ingest_classification` | Ingest a dataset of images from a local folder to a Deep Lake Dataset.  \n`deeplake.ingest_coco` | Ingest images and annotations in COCO format to a Deep Lake Dataset.  \n`deeplake.ingest_yolo` | Ingest images and annotations (bounding boxes or polygons) in YOLO format to a Deep Lake Dataset.  \n`deeplake.ingest_kaggle` | Download and ingest a kaggle dataset and store it as a structured dataset to destination.  \n`deeplake.ingest_dataframe` | Convert pandas dataframe to a Deep Lake Dataset.  \n`deeplake.ingest_huggingface` | Converts Hugging Face datasets to Deep Lake format.  \n  \n## Loading Datasets\uf0c1\n\n`deeplake.load` | Loads an existing dataset  \n---|---  \n  \n## Deleting and Renaming Datasets\uf0c1\n\n`deeplake.delete` | Deletes a dataset at a given path.  \n---|---  \n`deeplake.rename` | Renames dataset at `old_path` to `new_path`.  \n  \n## Copying Datasets\uf0c1\n\n`deeplake.copy` | Copies dataset at `src` to `dest`.  \n---|---  \n`deeplake.deepcopy` | Copies dataset at `src` to `dest` including version control history.  \n  \n## Dataset Operations\uf0c1\n\n`Dataset.summary` | Prints a summary of the dataset.  \n---|---  \n`Dataset.append` | Append samples to mutliple tensors at once.  \n`Dataset.extend` | Appends multiple rows of samples to mutliple tensors at once.  \n`Dataset.update` | Update existing samples in the dataset with new values.  \n`Dataset.query` | Returns a sliced `Dataset` with given query results.  \n`Dataset.copy` | Copies this dataset or dataset view to `dest`.  \n`Dataset.delete` | Deletes the entire dataset from the cache layers (if any) and the underlying storage.",
        "node_1158": "Examples\n\n    \n    \n    >>> # create dataset\n    >>> ds = deeplake.dataset(\"path/to/dataset\")\n    \n    \n    \n    >>> # create tensors\n    >>> ds.create_tensor(\"images\", htype=\"image\", sample_compression=\"jpg\")\n    >>> ds.create_tensor(\"videos\", htype=\"video\", sample_compression=\"mp4\")\n    >>> ds.create_tensor(\"data\")\n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\")\n    \n    \n    \n    >>> # append data\n    >>> ds.images.append(np.ones((400, 400, 3), dtype='uint8'))\n    >>> ds.videos.append(deeplake.read(\"videos/sample_video.mp4\"))\n    >>> ds.data.append(np.zeros((100, 100, 2)))\n    \n\nParameters\n\n    \n\n  * **name** (_str_) \u2013 The name of the tensor to be created.\n\n  * **htype** (_str_) \u2013 \n    * The class of data for the tensor.\n\n    * The defaults for other parameters are determined in terms of this value.\n\n    * For example, `htype=\"image\"` would have `dtype` default to `uint8`.\n\n    * These defaults can be overridden by explicitly passing any of the other parameters to this function.\n\n    * May also modify the defaults for other parameters.\n\n  * **dtype** (_str_) \u2013 Optionally override this tensor\u2019s `dtype`. All subsequent samples are required to have this `dtype`.\n\n  * **sample_compression** (_str_) \u2013 All samples will be compressed in the provided format. If `None`, samples are uncompressed. For `link[]` tensors, `sample_compression` is used only for optimizing dataset views.\n\n  * **chunk_compression** (_str_) \u2013 All chunks will be compressed in the provided format. If `None`, chunks are uncompressed. For `link[]` tensors, `chunk_compression` is used only for optimizing dataset views.\n\n  * **hidden** (_bool_) \u2013 If `True`, the tensor will be hidden from ds.tensors but can still be accessed via `ds[tensor_name]`.\n\n  * **create_sample_info_tensor** (_bool_) \u2013 If `True`, meta data of individual samples will be saved in a hidden tensor.",
        "node_101": "* **ignore_one_group** (_bool_) \u2013 Skip creation of group in case of a single annotation file. Set to `False` by default.\n\n  * **ignore_keys** (_List_ _[__str_ _]_) \u2013 A list of COCO keys to ignore.\n\n  * **image_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the images tensor.\n\n  * **image_creds_key** (_Optional_ _[__str_ _]_) \u2013 The name of the managed credentials to use for accessing the images in the linked tensor (is applicable).\n\n  * **src_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 Credentials to access the source data. If not provided, will be inferred from the environment.\n\n  * **dest_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 The string `ENV` or a dictionary containing credentials used to access the destination path of the dataset.\n\n  * **inspect_limit** (_int_) \u2013 The maximum number of samples to inspect in the annotations json, in order to generate the set of COCO annotation keys. Set to `1000000` by default.\n\n  * **progressbar** (_bool_) \u2013 Enables or disables ingestion progress bar. Set to `True` by default.\n\n  * **shuffle** (_bool_) \u2013 Shuffles the input data prior to ingestion. Set to `False` by default.\n\n  * **num_workers** (_int_) \u2013 The number of workers to use for ingestion. Set to `0` by default.\n\n  * **token** (_Optional_ _[__str_ _]_) \u2013 The token to use for accessing the dataset and/or connecting it to Deep Lake.\n\n  * **connect_kwargs** (_Optional_ _[__Dict_ _]_) \u2013 If specified, the dataset will be connected to Deep Lake, and connect_kwargs will be passed to `Dataset.connect`.\n\n  * ****dataset_kwargs** \u2013 Any arguments passed here will be forwarded to the dataset creator function. See `deeplake.empty()`.\n\nReturns\n\n    \n\nThe Dataset created from images and COCO annotations.",
        "node_298": "The Deep Lake format makes dataset versioning\nsignificantly easier compared to traditional file structures by DVC when\ndatasets are composed of many files (i.e., many images). An additional\ndistinction is that DVC primarily uses a command-line interface, whereas Deep\nLake is a Python package. Lastly, Deep Lake offers an API to easily connect\ndatasets to ML frameworks and other common ML tools and enables instant\ndataset visualization through Activeloop's visualization tool.\n\n**Deep Lake vs MosaicML MDS format**\n\n  * **Data Storage Format:** Deep Lake operates on a columnar storage format, whereas MDS utilizes a row-wise storage approach. This fundamentally impacts how data is read, written, and organized in each system.\n  * **Compression:** Deep Lake offers a more flexible compression scheme, allowing control over both chunk-level and sample-level compression for each column or tensor. This feature eliminates the need for additional compressions like zstd, which would otherwise demand more CPU cycles for decompressing on top of formats like jpeg.\n  * **Shuffling:** MDS currently offers more advanced shuffling strategies.\n  * **Version Control & Visualization Support:** A notable feature of Deep Lake is its native version control and in-browser data visualization, a feature not present for MosaicML data format. This can provide significant advantages in managing, understanding, and tracking different versions of the data.\n\n**Deep Lake vs TensorFlow Datasets (TFDS)**\n\nDeep Lake and TFDS seamlessly connect popular datasets to ML frameworks. Deep\nLake datasets are compatible with both PyTorch and TensorFlow, whereas TFDS\nare only compatible with TensorFlow.",
        "node_1114": "It has the following arguments:\n\n  * `data_in`: Input passed to the transform to generate output dataset.\n\n>     * It should support `__getitem__` and `__len__`. This can be a Deep Lake\n> dataset.\n\n  * `ds_out (Dataset, optional)`: The dataset object to which the transform will get written.\n\n>     * If this is not provided, data_in will be overwritten if it is a Deep\n> Lake dataset, otherwise error will be raised.\n>\n>     * It should have all keys being generated in output already present as\n> tensors.\n>\n>     * It\u2019s initial state should be either:\n>\n\n>>       * Empty i.e. all tensors have no samples. In this case all samples\nare added to the dataset.\n\n>>\n\n>>       * All tensors are populated and have same length. In this case new\nsamples are appended to the dataset.\n\n  * `num_workers (int)`: The number of workers to use for performing the transform.\n\n>     * Defaults to 0. When set to 0, it will always use serial processing,\n> irrespective of the scheduler.\n\n  * `scheduler (str)`: The scheduler to be used to compute the transformation.\n\n>     * Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019.\n> Defaults to \u2018threaded\u2019.\n\n  * `progressbar (bool)`: Displays a progress bar if `True` (default).\n\n  * `skip_ok (bool)`: If `True`, skips the check for output tensors generated.\n\n>     * This allows the user to skip certain tensors in the function\n> definition.\n>\n>     * This is especially useful for inplace transformations in which certain\n> tensors are not modified. Defaults to `False`.\n\n  * `check_lengths (bool)`: If `True`, checks whether `ds_out` has tensors of same lengths initially.\n\n  * `pad_data_in (bool)`: If `True`, pads tensors of `data_in` to match the length of the largest tensor in `data_in`. Defaults to `False`.\n\n  * `ignore_errors (bool)`: If `True`, input samples that causes transform to fail will be skipped and the errors will be ignored **if possible**.",
        "node_35": "1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.",
        "node_1293": "0.txt\n\n|  |   \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n|  |   \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n|  |   \n  \n### MANIFEST.in\n\n|\n\n### MANIFEST.in\n\n|  |   \n  \n### Makefile\n\n|\n\n### Makefile\n\n|  |   \n  \n### OFL-License.txt\n\n|\n\n### OFL-License.txt\n\n|  |   \n  \n### README.rst\n\n|\n\n### README.rst\n\n|  |   \n  \n### babel.cfg\n\n|\n\n### babel.cfg\n\n|  |   \n  \n### docker-compose.yaml\n\n|\n\n### docker-compose.yaml\n\n|  |   \n  \n### docker-entrypoint.sh\n\n|\n\n### docker-entrypoint.sh\n\n|  |   \n  \n### package-lock.json\n\n|\n\n### package-lock.json\n\n|  |   \n  \n### package.json\n\n|\n\n### package.json\n\n|  |   \n  \n### pytest.ini\n\n|\n\n### pytest.ini\n\n|  |   \n  \n### setup.cfg\n\n|\n\n### setup.cfg\n\n|  |   \n  \n### setup.py\n\n|\n\n### setup.py\n\n|  |   \n  \n### tox.ini\n\n|\n\n### tox.ini\n\n|  |   \n  \n### webpack.common.js\n\n|\n\n### webpack.common.js\n\n|  |   \n  \n### webpack.dev.js\n\n|\n\n### webpack.dev.js\n\n|  |   \n  \n### webpack.prod.js\n\n|\n\n### webpack.prod.js\n\n|  |   \nView all files  \n  \n## Repository files navigation\n\n  * README\n  * Code of conduct\n  * MIT license\n\n# Read the Docs Sphinx Theme\n\nThis Sphinx theme was designed to provide a great reader experience for\ndocumentation users on both desktop and mobile devices. This theme is used\nprimarily on Read the Docs but can work with any Sphinx project.",
        "node_1119": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n  * Compressions\n  * PyTorch and Tensorflow Support\n  * Utility Functions\n\nIntegrations\n\n  * Weights and Biases\n  * MMDetection\n\nHigh-Performance Features\n\n  * Dataloader\n  * Sampler\n  * Tensor Query Language\n  * Random Split\n  * Deep Memory\n\nAPI Reference\n\n  * deeplake\n  * deeplake.VectorStore\n    * `VectorStore`\n      * `VectorStore.__init__()`\n      * `VectorStore.add()`\n      * `VectorStore.checkout()`\n      * `VectorStore.commit()`\n      * `VectorStore.dataset`\n      * `VectorStore.delete()`\n      * `VectorStore.delete_by_path()`\n      * `VectorStore.search()`\n      * `VectorStore.summary()`\n      * `VectorStore.tensors()`\n      * `VectorStore.update_embedding()`\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * deeplake.VectorStore\n  * Edit on GitHub\n\n* * *\n\n# deeplake.VectorStore\uf0c1\n\n_class _deeplake.core.vectorstore.deeplake_vectorstore.VectorStore\uf0c1\n\n    \n\nBase class for VectorStore\n\n__init__(_path: ~typing.Optional[~typing.Union[str, ~pathlib.Path]] = None,\ndataset: ~typing.Optional[~deeplake.core.dataset.dataset.Dataset] = None,\ntensor_params: ~typing.List[~typing.Dict[str, object]] = [{'name': 'text',\n'htype': 'text',",
        "node_270": "The outer list corresponds to the queries and the inner list corresponds to the doc_id, relevence_score pair for each query. doc_id is the document id in the corpus dataset. It is stored in the id tensor of the corpus dataset. relevence_score is the relevance score of the document for the query. The value is either 0 and 1, where 0 stands for not relevant (unknown relevance) and 1 stands for relevant. Currently, only values of 1 contribute to the training, and there is no reason to provide examples with relevance of 0.\n\n  * **embedding_function** (_Optional_ _[__Callable_ _[__[__str_ _]__,__np.ndarray_ _]__]__,__optional_) \u2013 Embedding funtion used to convert queries to embeddings. Defaults to None.\n\n  * **token** (_str_ _,__optional_) \u2013 API token for the DeepMemory managed service. Defaults to None.\n\nReturns\n\n    \n\njob_id of the training job.\n\nReturn type\n\n    \n\nstr\n\nRaises\n\n    \n\n**ValueError** \u2013 if embedding_function is not specified either during\ninitialization or during training.\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_600": "core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.\n\nSupported htypes and their respective defaults are:\n\nHtype configs\uf0c1 HTYPE | DTYPE | COMPRESSION  \n---|---|---  \ngeneric | None | None  \nimage | uint8 | Required arg  \nimage.rgb | uint8 | Required arg  \nimage.gray | uint8 | Required arg  \nvideo | uint8 | Required arg  \naudio | float64 | Required arg  \nclass_label | uint32 | None  \ntag | str | None  \nbbox | float32 | None  \nbbox.3d | float32 | None  \nintrinsics | float32 | None  \nsegment_mask | uint32 | None  \nbinary_mask | bool | None  \nkeypoints_coco | int32 | None  \npoint | int32 | None  \npolygon | float32 | None  \ntext | str | None  \njson | Any | None  \nlist | List | None  \ndicom | None | dcm  \nnifti | None | Required arg  \npoint_cloud | None | las  \nmesh | None | ply  \ninstance_label | uint32 | None  \nembedding | None | None  \nlink | str | None  \nsequence | None | None  \n  \n## Image Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # channels)` or `(height, width)`.\n\nImages can be stored in Deep Lake as compressed bytes or as raw arrays.",
        "node_227": "Parameters\n\n    \n\n**large_ok** (_bool_) \u2013 Delete datasets larger than 1 GB. Defaults to `False`.\n\nRaises\n\n    \n\n  * **DatasetTooLargeToDelete** \u2013 If the dataset is larger than 1 GB and `large_ok` is `False`.\n\n  * **DatasetHandlerError** \u2013 If the dataset is marked as allow_delete=False.\n\nget_managed_creds_keys() -> Set[str]\uf0c1\n\n    \n\nReturns the set of creds keys added to the dataset that are managed by\nActiveloop platform. These are used to fetch external data in linked tensors.\n\n_property _is_actually_cloud _: bool_\uf0c1\n\n    \n\nDatasets that are connected to Deep Lake cloud can still technically be stored\nanywhere. If a dataset is in Deep Lake cloud but stored without `hub://`\nprefix, it should only be used for testing.\n\nrename(_path_)\uf0c1\n\n    \n\nRenames the dataset to path.\n\nExample\n\n    \n    \n    >>> ds = deeplake.load(\"hub://username/dataset\")\n    >>> ds.rename(\"hub://username/renamed_dataset\")\n    \n\nParameters\n\n    \n\n**path** (_str_ _,__pathlib.Path_) \u2013 New path to the dataset.\n\nRaises\n\n    \n\n**RenameError** \u2013 If `path` points to a different directory.\n\n_property _token\uf0c1\n\n    \n\nGet attached token of the dataset\n\nupdate_creds_key(_creds_key : str_, _new_creds_key : Optional[str] = None_,\n_managed : Optional[bool] = None_)\uf0c1\n\n    \n\nUpdates the name and/or management status of a creds key.\n\nParameters\n\n    \n\n  * **creds_key** (_str_) \u2013 The key whose management status is to be changed.\n\n  * **new_creds_key** (_str_ _,__optional_) \u2013 The new key to replace the old key. If not provided, the old key will be used.\n\n  * **managed** (_bool_) \u2013 The target management status. If `True`, the creds corresponding to the key will be fetched from activeloop platform.\n\nRaises\n\n    \n\n  * **ValueError** \u2013 If the dataset is not connected to activeloop platform.\n\n  * **ValueError** \u2013 If both `new_creds_key` and `managed` are `None`.",
        "node_708": "### Limitations\uf0c1\n\n  * The Deep Lake Performant Dataloader does not support Nifti data.\n\n### Creating a nifti tensor\uf0c1\n\nA nifti tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"patients\", htype=\"nifti\", sample_compression=\"nii.gz\")\n    \n\n  * Supported compressions:\n\n    \n    \n    >>> [\"nii.gz\", \"nii\", None]\n    \n\n### Appending nifti data\uf0c1\n\n  * Nifti samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Deep Lake does not support compression of raw nifti data. Therefore, array of raw frames can only be appended to tensors with `None` compression.\n\nExamples\n\n    \n    \n    >>> ds.patients.append(deeplake.read(\"data/patient0.nii.gz\"))\n    \n    \n    \n    >>> ds.patients.extend([deeplake.read(f\"data/patient{i}.nii.gz\") for i in range(10)])\n    \n\n## Point Cloud Htype\uf0c1\n\n  * Sample dimensions: `(# num_points, 3)`\n\n  * Point cloud samples can be of type `np.ndarray` or `Sample` which is returned by `deeplake.read()`.\n\n  * Each point cloud is a list / array of points.\n\n  * All points in a sample should have the same number of co-ordinates.\n\n  * Different point clouds can have different number of points.\n\n### Creating a point cloud tensor\uf0c1\n\nA point cloud tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"point_clouds\", htype=\"point_cloud\", sample_compression=\"las\")\n    \n\n  * Optional args:\n    \n    * sample_compression\n\n  * Supported compressions:\n\n    \n    \n    >>> [None, \"las\"]\n    \n\n### Appending point clouds\uf0c1\n\n  * Point clouds can be appended as a `np.ndarray`.",
        "node_297": "Unlike Weaviate, Deep\nLake\u2019s data format can store raw data such as images, videos, and text, in\naddition to embeddings. Deep Lake datasets can be visualized and version\ncontrolled. Weaviate is limited to light metadata on top of the embeddings and\nhas no visualization. Deep Lake also has a performant dataloader for fine-\ntuning your Large Language Models.\n\n**Deep Lake vs DVC**\n\nDeep Lake and DVC offer dataset version control similar to git for data, but\ntheir methods for storing data differ significantly. Deep Lake converts and\nstores data as chunked compressed arrays, which enables rapid streaming to ML\nmodels, whereas DVC operates on top of data stored in less efficient\ntraditional file structures. The Deep Lake format makes dataset versioning\nsignificantly easier compared to traditional file structures by DVC when\ndatasets are composed of many files (i.e., many images). An additional\ndistinction is that DVC primarily uses a command-line interface, whereas Deep\nLake is a Python package. Lastly, Deep Lake offers an API to easily connect\ndatasets to ML frameworks and other common ML tools and enables instant\ndataset visualization through Activeloop's visualization tool.\n\n**Deep Lake vs MosaicML MDS format**\n\n  * **Data Storage Format:** Deep Lake operates on a columnar storage format, whereas MDS utilizes a row-wise storage approach. This fundamentally impacts how data is read, written, and organized in each system.\n  * **Compression:** Deep Lake offers a more flexible compression scheme, allowing control over both chunk-level and sample-level compression for each column or tensor.",
        "node_915": "* Moreover, there can be variations in this htype, such as `link[image]`, `link[video]`, `link[audio]`, etc. that would enable the activeloop visualizer to correctly display the data.\n\n  * No data is actually loaded until you try to read the sample from a dataset.\n\n  * There are a few exceptions to this:-\n    \n    * If `create_shape_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the shape of the sample is read. This is `True` by default.\n\n    * If `create_sample_info_tensor=True` was specified during `create_tensor` of the tensor to which this is being added, the sample info is read. This is `True` by default.\n\n    * If `verify=True` was specified during `create_tensor` of the tensor to which this is being added, some metadata is read from them to verify the integrity of the link samples. This is `True` by default.\n\n    * If you do not want to verify your links, all three of `verify`, `create_shape_tensor` and `create_sample_info_tensor` have to be set to `False`.\n\nExamples\n\n    \n    \n    >>> ds = deeplake.dataset(\"......\")\n    \n\nAdding credentials to the dataset\n\nYou can add the names of the credentials you want to use (not needed for\nhttp/local urls)\n\n    \n    \n    >>> ds.add_creds_key(\"MY_S3_KEY\")\n    >>> ds.add_creds_key(\"GCS_KEY\")\n    \n\nand populate the added names with credentials dictionaries\n\n    \n    \n    >>> ds.populate_creds(\"MY_S3_KEY\", {})   # add creds here\n    >>> ds.populate_creds(\"GCS_KEY\", {})    # add creds here\n    \n\nThese creds are only present temporarily and will have to be repopulated on\nevery reload.\n\nFor datasets connected to Activeloop Platform, you can store your credentials\non the platform as Managed Credentials and use them just by adding the keys to\nyour dataset. For example if you have managed credentials with names\n`\"my_s3_creds\"`, `\"my_gcs_creds\"`, you can add them to your dataset using\n`Dataset.add_creds_key` without having to populate them.",
        "node_169": "WARNING: using this option with big datasets is discouraged because it can lead to memory issues. \\- `compute_engine` \\- Performant C++ implementation of the Deep Lake Compute Engine that runs on the client and can be used for any data stored in or connected to Deep Lake. It cannot be used with in-memory or local datasets. \\- `tensor_db` \\- Performant and fully-hosted Managed Tensor Database that is responsible for storage and query execution. Only available for data stored in the Deep Lake Managed Database. Store datasets in this database by specifying runtime = {\u201ctensor_db\u201d: True} during dataset creation.\n\n  * **embedding_function** (_Optional_ _[__Union_ _[__Callable_ _,__List_ _[__Callable_ _]__]__]__,__optional_) \u2013 function for converting embedding_source_tensor into embedding. Only valid if embedding_source_tensor is specified. Defaults to None.\n\n  * **embedding_source_tensor** (_Union_ _[__str_ _,__List_ _[__str_ _]__]__,__optional_) \u2013 Name of tensor with data that needs to be converted to embeddings. Defaults to text.\n\n  * **embedding_tensor** (_Optional_ _[__Union_ _[__str_ _,__List_ _[__str_ _]__]__]__,__optional_) \u2013 Name of the tensor with embeddings. Defaults to None.\n\nPrevious Next\n\n* * *\n\n(C) Copyright 2022, Activeloop. Revision `ccc63099`.\n\nBuilt with Sphinx using a theme provided by Read the Docs.\n\nRead the Docs v: latest\n\nVersions\n\n    latest\n    v3.1.5\n    v3.1.0\n    v3.0.16\n    v3.0.15\n    v2.8.5\n\nDownloads\n\n    pdf\n    epub\n\nOn Read the Docs\n\n     Project Home\n     Builds",
        "node_975": "latest\n\nGetting Started\n\n  * Installation\n\nKey Concepts\n\n  * Datasets\n  * Vector Store\n  * Tensors\n  * Htypes\n    * Image Htype\n      * Creating an image tensor\n      * Appending image samples\n      * image.rgb and image.",
        "node_586": "1\n\n    \n\nkeypoint in image but not visible.\n\n2\n\n    \n\nkeypoint in image and visible.\n\n### Creating a keypoints_coco tensor\uf0c1\n\nA keypoints_coco tensor can be created using\n\n    \n    \n    >>> ds.create_tensor(\"keypoints\", htype=\"keypoints_coco\", keypoints=[\"knee\", \"elbow\", \"head\"], connections=[[0, 1], [1, 2]])\n    \n\n  * Optional args:\n    \n    * keypoints: List of strings describing the `i` th keypoint. `tensor.info.keypoints` will be set to this list.\n\n    * connections: List of strings describing which points should be connected by lines in the visualizer.\n\n    * sample_compression or chunk_compression\n\n    * dtype: Defaults to `int32`.\n\n  * Supported compressions:\n\n    \n    \n    >>> [\"lz4\"]\n    \n\nYou can also choose to set `keypoints` and / or `connections` after tensor\ncreation.\n\n    \n    \n    >>> ds.keypoints.info.update(keypoints = ['knee', 'elbow',...])\n    >>> ds.keypoints.info.update(connections = [[0,1], [2,3], ...])\n    \n\n### Appending keypoints\uf0c1\n\n  * Keypoints can be appended as `np.ndarray` or `list`.",
        "node_775": "core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.\n\nSupported htypes and their respective defaults are:\n\nHtype configs\uf0c1 HTYPE | DTYPE | COMPRESSION  \n---|---|---  \ngeneric | None | None  \nimage | uint8 | Required arg  \nimage.rgb | uint8 | Required arg  \nimage.gray | uint8 | Required arg  \nvideo | uint8 | Required arg  \naudio | float64 | Required arg  \nclass_label | uint32 | None  \ntag | str | None  \nbbox | float32 | None  \nbbox.3d | float32 | None  \nintrinsics | float32 | None  \nsegment_mask | uint32 | None  \nbinary_mask | bool | None  \nkeypoints_coco | int32 | None  \npoint | int32 | None  \npolygon | float32 | None  \ntext | str | None  \njson | Any | None  \nlist | List | None  \ndicom | None | dcm  \nnifti | None | Required arg  \npoint_cloud | None | las  \nmesh | None | ply  \ninstance_label | uint32 | None  \nembedding | None | None  \nlink | str | None  \nsequence | None | None  \n  \n## Image Htype\uf0c1\n\n  * Sample dimensions: `(height, width, # channels)` or `(height, width)`.\n\nImages can be stored in Deep Lake as compressed bytes or as raw arrays.",
        "node_861": "VectorStore\n  * deeplake.core\n  * deeplake.core.dataset\n  * deeplake.core.tensor\n  * deeplake.api\n  * deeplake.auto\n  * deeplake.util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * Htypes\n  * Edit on GitHub\n\n* * *\n\n# Htypes\uf0c1\n\nHtype is the class of a tensor: image, bounding box, generic tensor, etc.\n\nThe htype of a tensor can be specified at its creation\n\n    \n    \n    >>> ds.create_tensor(\"my_tensor\", htype=\"...\")\n    \n\nIf not specified, the tensor\u2019s htype defaults to \u201cgeneric\u201d.\n\nSpecifying an htype allows for strict settings and error handling, and it is\ncritical for increasing the performance of Deep Lake datasets containing rich\ndata such as images and videos.",
        "node_146": "util\n  * deeplake.client.log\n  * deeplake.core.transform\n  * deeplake.core.vectorstore.deep_memory\n  * deeplake.random.seed\n\n__Deep Lake\n\n  * \u00bb\n  * deeplake.VectorStore\n  * Edit on GitHub\n\n* * *\n\n# deeplake.VectorStore\uf0c1\n\n_class _deeplake.core.vectorstore.deeplake_vectorstore.VectorStore\uf0c1\n\n    \n\nBase class for VectorStore\n\n__init__(_path: ~typing.Optional[~typing.Union[str, ~pathlib.Path]] = None,\ndataset: ~typing.Optional[~deeplake.core.dataset.dataset.Dataset] = None,\ntensor_params: ~typing.List[~typing.Dict[str, object]] = [{'name': 'text',\n'htype': 'text', 'create_id_tensor': False, 'create_sample_info_tensor':\nFalse, 'create_shape_tensor': False}, {'name': 'metadata', 'htype': 'json',\n'create_id_tensor': False, 'create_sample_info_tensor': False,\n'create_shape_tensor': False}, {'name': 'embedding', 'htype': 'embedding',\n'dtype': <class 'numpy.float32'>, 'create_id_tensor': False,\n'create_sample_info_tensor': False, 'create_shape_tensor': True,\n'max_chunk_size': 64000000}, {'name': 'id', 'htype': 'text',\n'create_id_tensor': False, 'create_sample_info_tensor': False,\n'create_shape_tensor': False}], embedding_function:\n~typing.Optional[~typing.Any] = None, read_only: ~typing.Optional[bool] =\nNone, ingestion_batch_size: int = 1000, index_params:\n~typing.Optional[~typing.Dict[str, ~typing.Union[int, str]]] = None,\nexec_option: str = 'auto', token: ~typing.Optional[str] = None, overwrite:\nbool = False, verbose: bool = True, runtime: ~typing.Optional[~typing.Dict] =\nNone, creds: ~typing.Optional[~typing.",
        "node_1078": "* **dest** (_str_ _,__pathlib.Path_) \u2013 \n    * The full path to the dataset. Can be:\n\n    * a Deep Lake cloud path of the form `hub://org_id/datasetname`. To write to Deep Lake cloud datasets, ensure that you are authenticated to Deep Lake (pass in a token using the \u2018token\u2019 parameter).\n\n    * an s3 path of the form `s3://bucketname/path/to/dataset`. Credentials are required in either the environment or passed to the creds argument.\n\n    * a local file system path of the form `./path/to/dataset` or `~/path/to/dataset` or `path/to/dataset`.\n\n    * a memory path of the form `mem://path/to/dataset` which doesn\u2019t save the dataset but keeps it in memory instead. Should be used only for testing as it does not persist.\n\n  * **class_names_file** \u2013 Path to the file containing the class names on separate lines. This is typically a file titled classes.names.\n\n  * **annotations_directory** (_Optional_ _[__Union_ _[__str_ _,__pathlib.Path_ _]__]_) \u2013 Path to directory containing the annotations. If specified, the \u2018data_directory\u2019 will not be examined for annotations.\n\n  * **allow_no_annotation** (_bool_) \u2013 Flag to determine whether missing annotations files corresponding to an image should be treated as empty annoations. Set to `False` by default.\n\n  * **image_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the images tensor.\n\n  * **label_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the labels tensor.\n\n  * **coordinates_params** (_Optional_ _[__Dict_ _]_) \u2013 A dictionary containing parameters for the ccoordinates tensor. This tensor either contains bounding boxes or polygons.\n\n  * **src_creds** (_Optional_ _[__Union_ _[__str_ _,__Dict_ _]__]_) \u2013 Credentials to access the source data. If not provided, will be inferred from the environment.",
        "node_1292": "master\n\nBranchesTags\n\nGo to file\n\nCode\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\n## History\n\n1,481 Commits  \n  \n### .circleci\n\n|\n\n### .circleci\n\n|  |   \n  \n### .github\n\n|\n\n### .github\n\n|  |   \n  \n### .tx\n\n|\n\n### .tx\n\n|  |   \n  \n### bin\n\n|\n\n### bin\n\n|  |   \n  \n### docs\n\n|\n\n### docs\n\n|  |   \n  \n### sphinx_rtd_theme\n\n|\n\n### sphinx_rtd_theme\n\n|  |   \n  \n### src\n\n|\n\n### src\n\n|  |   \n  \n### tests\n\n|\n\n### tests\n\n|  |   \n  \n### .gitattributes\n\n|\n\n### .gitattributes\n\n|  |   \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n|  |   \n  \n### .readthedocs.yml\n\n|\n\n### .readthedocs.yml\n\n|  |   \n  \n### Apache-License-2.0.txt\n\n|\n\n### Apache-License-2.0.txt\n\n|  |   \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n|  |   \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n|  |   \n  \n### MANIFEST.in\n\n|\n\n### MANIFEST.in\n\n|  |   \n  \n### Makefile\n\n|\n\n### Makefile\n\n|  |   \n  \n### OFL-License.txt\n\n|\n\n### OFL-License.txt\n\n|  |   \n  \n### README.rst\n\n|\n\n### README.rst\n\n|  |   \n  \n### babel.cfg\n\n|\n\n### babel.cfg\n\n|  |   \n  \n### docker-compose.yaml\n\n|\n\n### docker-compose.yaml\n\n|  |   \n  \n### docker-entrypoint.sh\n\n|\n\n### docker-entrypoint.sh\n\n|  |   \n  \n### package-lock.json\n\n|\n\n### package-lock.json\n\n|  |   \n  \n### package.json\n\n|\n\n### package.json\n\n|  |   \n  \n### pytest.ini\n\n|\n\n### pytest.",
        "node_1091": "Defaults to `False`. Datasets stored on Deep Lake cloud that your account does not have write access to will automatically open in read mode.\n\n  * **memory_cache_size** (_int_) \u2013 The size of the memory cache to be used in MB.\n\n  * **local_cache_size** (_int_) \u2013 The size of the local filesystem cache to be used in MB.\n\n  * **creds** (_dict_ _,__str_ _,__optional_) \u2013 The string `ENV` or a dictionary containing credentials used to access the dataset at the path. \\- If \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019 are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths. \\- It supports \u2018aws_access_key_id\u2019, \u2018aws_secret_access_key\u2019, \u2018aws_session_token\u2019, \u2018endpoint_url\u2019, \u2018aws_region\u2019, \u2018profile_name\u2019 as keys. \\- If \u2018ENV\u2019 is passed, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets. For datasets connected to hub cloud, specifying \u2018ENV\u2019 will override the credentials fetched from Activeloop and use local ones.\n\n  * **token** (_str_ _,__optional_) \u2013 Activeloop token, used for fetching credentials to the dataset at path if it is a Deep Lake dataset. This is optional, tokens are normally autogenerated.\n\n  * **org_id** (_str_ _,__Optional_) \u2013 Organization id to be used for enabling high-performance features. Only applicable for local datasets.\n\n  * **verbose** (_bool_) \u2013 If `True`, logs will be printed. Defaults to `True`.\n\n  * **access_method** (_str_) \u2013 \n\nThe access method to use for the dataset. Can be:\n\n    * \u2019stream\u2019\n\n>       * Streams the data from the dataset i.e. only fetches data when\n> required. This is the default value.\n\n    * \u2019download\u2019\n\n>       * Downloads the data to the local filesystem to the path specified in\n> environment variable `DEEPLAKE_DOWNLOAD_PATH`. This will overwrite\n> `DEEPLAKE_DOWNLOAD_PATH`.",
        "node_218": "These virtual\ndatasets can also be loaded from their path like normal datasets.\n\nParameters\n\n    \n\n  * **message** (_Optional_ _,__str_) \u2013 Custom user message.\n\n  * **path** (_Optional_ _,__str_ _,__pathlib.Path_) \u2013 \n    * The VDS will be saved as a standalone dataset at the specified path.\n\n    * If not specified, the VDS is saved under `.queries` subdirectory of the source dataset\u2019s storage.\n\n  * **id** (_Optional_ _,__str_) \u2013 Unique id for this view. Random id will be generated if not specified.\n\n  * **optimize** (_bool_) \u2013 \n    * If `True`, the dataset view will be optimized by copying and rechunking the required data. This is necessary to achieve fast streaming speeds when training models using the dataset view. The optimization process will take some time, depending on the size of the data.\n\n    * You can also choose to optimize the saved view later by calling its `ViewEntry.optimize()` method.\n\n  * **tensors** (_List_ _,__optional_) \u2013 Names of tensors (and groups) to be copied. If not specified all tensors are copied.\n\n  * **num_workers** (_int_) \u2013 Number of workers to be used for optimization process. Applicable only if `optimize=True`. Defaults to 0.\n\n  * **scheduler** (_str_) \u2013 The scheduler to be used for optimization. Supported values include: \u2018serial\u2019, \u2018threaded\u2019, \u2018processed\u2019 and \u2018ray\u2019. Only applicable if `optimize=True`. Defaults to \u2018threaded\u2019.\n\n  * **verbose** (_bool_) \u2013 If `True`, logs will be printed. Defaults to `True`.\n\n  * **ignore_errors** (_bool_) \u2013 Skip samples that cause errors while saving views. Only applicable if `optimize=True`. Defaults to `False`.\n\n  * **ds_args** (_dict_) \u2013 Additional args for creating VDS when path is specified. (See documentation for `deeplake.dataset()`)\n\nReturns\n\n    \n\nPath to the saved VDS.\n\nReturn type\n\n    \n\nstr\n\nRaises\n\n    \n\n  * **ReadOnlyModeError** \u2013 When attempting to save a view inplace and the user doesn\u2019t have write access."
    },
    "relevant_docs": {
        "bf218a93-1b07-4aba-b735-242aeca4bc33": [
            "node_683"
        ],
        "1fb1d5c2-5714-4910-84a8-b1b4d188e69d": [
            "node_683"
        ],
        "66e45ea9-4b9a-4848-9b0f-97936c17faff": [
            "node_683"
        ],
        "cf2fd15e-6f94-4e60-a215-8ce86a3c2692": [
            "node_683"
        ],
        "9b41963b-88ba-4a3a-94c4-3f33c35ad273": [
            "node_683"
        ],
        "58626388-2c96-4eed-ab53-5e7eb1f4ff5e": [
            "node_682"
        ],
        "1644fdfa-8785-4180-a7e0-25b4804d42d0": [
            "node_682"
        ],
        "1e5eed95-f1e1-40e4-bcab-ba93a0f4780f": [
            "node_682"
        ],
        "2d1400dd-ef44-421a-8d7d-14541d06f2c7": [
            "node_682"
        ],
        "528d8124-0fc4-45e0-8dc9-93ccd75bf534": [
            "node_682"
        ],
        "13f4bdb6-2fad-4f3b-8c78-36d4c1eca394": [
            "node_620"
        ],
        "3928c0b6-360d-45ef-b6cc-9288d26b7960": [
            "node_620"
        ],
        "0a3ad364-0c68-4092-8fb3-078fb3e72970": [
            "node_620"
        ],
        "f9686329-bfdb-47f1-8d98-80ff804f55ab": [
            "node_620"
        ],
        "6785f730-6036-4f47-83a8-76769992869f": [
            "node_620"
        ],
        "6cec35f4-ef57-464c-b75f-ecbfb6e3b9e8": [
            "node_620"
        ],
        "89446eb4-36a1-4566-b308-561466009033": [
            "node_487"
        ],
        "0646756c-0393-4bb5-bad5-ab50179e0bb5": [
            "node_487"
        ],
        "f6c585bd-3c90-4cec-a531-1ed29c5eaddf": [
            "node_487"
        ],
        "a62cfeb7-b27a-48cd-b44c-aacb7c0bd1b8": [
            "node_487"
        ],
        "a0e8f120-4981-4337-b38a-ab7e24220f7a": [
            "node_487"
        ],
        "53be0048-a1e9-4fa0-8982-f0931389802d": [
            "node_944"
        ],
        "9512d9cb-991a-46c5-98b6-e3887d65cb87": [
            "node_944"
        ],
        "8b615dba-ad56-4e6e-87d9-faa97b7cdb77": [
            "node_944"
        ],
        "faa92e0a-81d4-41d2-a1ff-504415d79251": [
            "node_944"
        ],
        "44d33ea5-15f8-496f-bb7d-f1e9ac11e012": [
            "node_944"
        ],
        "d5699833-5101-4a53-a38d-6bc2d83a43e2": [
            "node_1136"
        ],
        "4cb39df2-31e7-4353-a3fc-04b050f2079d": [
            "node_1136"
        ],
        "07b530ce-ddee-433a-ad99-32b86f2e764b": [
            "node_1136"
        ],
        "7b64d58c-c462-41e9-88b8-c798fde9e759": [
            "node_1136"
        ],
        "1b8e211d-6cd2-4e7b-a67d-c9038b310ff3": [
            "node_1136"
        ],
        "8c704f2f-b9e7-4d87-8ca9-237843161bd0": [
            "node_461"
        ],
        "dfbf7c25-d0d1-452e-bdf1-dea71353eab2": [
            "node_461"
        ],
        "b4a9b7b5-0605-44e0-b3c5-6eaea7a9386f": [
            "node_461"
        ],
        "ebe3f7f9-684c-4c62-8800-27692b56fb73": [
            "node_461"
        ],
        "72cda61e-82fa-41b1-890e-ff45459d2424": [
            "node_461"
        ],
        "1b14ad18-e6a1-4d20-aa2c-8cdcfc46d5b0": [
            "node_461"
        ],
        "1db025fe-29f8-4773-b19d-7f2ac8e1ef2a": [
            "node_461"
        ],
        "3cb5d45f-fe80-45c1-a915-dfb244eab844": [
            "node_461"
        ],
        "8646f0fb-1ea8-4dd4-a4af-c1b08ca65c55": [
            "node_489"
        ],
        "189ad014-ce9c-4c44-a8ce-6c5dd583164b": [
            "node_489"
        ],
        "6b641621-581d-4dcc-a019-ed70d8e8847b": [
            "node_489"
        ],
        "f9deb05d-3c9b-4038-a605-3210748351f5": [
            "node_489"
        ],
        "746ab5c0-0759-449e-8c98-67c6a9418453": [
            "node_489"
        ],
        "2014231f-647c-4978-a0e9-925d4fe7bb1f": [
            "node_489"
        ],
        "d4a725c0-ac52-43b1-91b7-9001ccb4a9a4": [
            "node_489"
        ],
        "3d620fa4-e969-464e-97fc-2d50ed7fca76": [
            "node_799"
        ],
        "061cca48-7f26-4b2a-b04c-9f48c5407776": [
            "node_799"
        ],
        "210b8d86-46aa-488c-8e17-cbf3edfce868": [
            "node_799"
        ],
        "3aca4f73-fdae-4614-9d4d-827bf19a364a": [
            "node_799"
        ],
        "26153047-ef40-45c0-8a12-7bffabeb1919": [
            "node_799"
        ],
        "ee2dd077-39db-457d-b72f-9e321f5770ba": [
            "node_582"
        ],
        "8e2112fc-4a1b-40b9-bed3-e952e1af4436": [
            "node_582"
        ],
        "c6b878f6-db66-4af1-8180-b6c08dde3581": [
            "node_582"
        ],
        "e11e27ee-ee18-450f-a532-3814d842c4aa": [
            "node_582"
        ],
        "1724635f-f48f-44be-8c03-fac5060277cb": [
            "node_582"
        ],
        "6fc6a122-ab9a-4db3-beca-5767bed883b2": [
            "node_572"
        ],
        "bd5d31f7-3aa4-4a3d-9e93-ce93df8acea3": [
            "node_572"
        ],
        "35823ab2-ca9c-4128-b0be-bbb8d81c3f5a": [
            "node_572"
        ],
        "d00ddee0-47bc-482c-ab32-9f90603ed5cd": [
            "node_572"
        ],
        "309b2976-3c3a-431c-85e0-e03d6c617515": [
            "node_572"
        ],
        "7294863d-ab98-4b55-a603-4e98464f4c14": [
            "node_1123"
        ],
        "cdfcbb33-9f22-44b3-ab10-8be0f20d00f8": [
            "node_1123"
        ],
        "fc486aa3-9646-4434-8ffc-325a629dc3c2": [
            "node_1123"
        ],
        "80deba29-fc9c-431e-b5ca-345ddc08a0f5": [
            "node_1123"
        ],
        "780eaf35-b798-4820-9650-c4ceabc2a14a": [
            "node_1123"
        ],
        "04b61eeb-3c27-4d30-a8d8-62f8f1ab1bb8": [
            "node_115"
        ],
        "27293963-de99-4873-8006-740d3de4c516": [
            "node_115"
        ],
        "b014be21-0b59-484d-976f-a82f3c7760b0": [
            "node_115"
        ],
        "640d1180-6644-4dc4-850d-8bf0c5bdd353": [
            "node_115"
        ],
        "3090e597-5d33-48e2-84db-c9e670d1fc4e": [
            "node_115"
        ],
        "e719e2c1-1aec-4910-b442-f7d4cec27e01": [
            "node_400"
        ],
        "1379de7e-fdd8-48ae-80bc-118dd2da4af7": [
            "node_400"
        ],
        "427f50ee-cf1c-4b5d-9d6b-0d4d9fe0ea2a": [
            "node_400"
        ],
        "330ebc95-f61f-4128-9474-c5e6eeeb221b": [
            "node_400"
        ],
        "bc702242-781e-4385-8e6d-6182671e9f1e": [
            "node_400"
        ],
        "298e96da-961f-41a9-93e0-c26ae16865eb": [
            "node_192"
        ],
        "6e93b74c-bb26-4841-a004-2082caf63b95": [
            "node_192"
        ],
        "80277fdc-7ef6-4c8a-8bb8-22b16e57c42d": [
            "node_192"
        ],
        "8e55ff75-b2d3-40a2-99c6-641bded4e20f": [
            "node_192"
        ],
        "6f7c4290-9e17-43a8-9bda-4eaa87205ba3": [
            "node_192"
        ],
        "e2743a08-8146-4b3b-85b6-1d8034b71caa": [
            "node_94"
        ],
        "47cfd492-3b3b-494c-9944-c744838c0c79": [
            "node_94"
        ],
        "b4ebfbe2-3305-4400-9c79-c578720c6c01": [
            "node_94"
        ],
        "a149ae39-09bf-425d-8f05-8162e7393bc0": [
            "node_94"
        ],
        "0bab4758-729d-4478-888e-c17139e74dc1": [
            "node_94"
        ],
        "c3f1717e-d9e9-45dc-8b0e-c2c3673c116e": [
            "node_94"
        ],
        "c414c4a5-94aa-45e2-8538-20fd89a615ba": [
            "node_94"
        ],
        "9d670f22-d76c-4997-986d-98b81a0bde30": [
            "node_94"
        ],
        "7c9649ca-5d05-42a5-83ab-35487ecfe3b1": [
            "node_94"
        ],
        "907ac458-91e9-4b22-85cd-7c1ebb44f4b2": [
            "node_94"
        ],
        "b4551b2a-ea07-4624-b5bf-8fbabd6baf3d": [
            "node_1139"
        ],
        "43e03792-7063-4f3a-9d46-37e2d2993922": [
            "node_1139"
        ],
        "b498f379-ab97-4a5f-b684-88bcea01ffd2": [
            "node_1139"
        ],
        "4c310121-696b-4b47-b9be-054c75a61dec": [
            "node_1139"
        ],
        "5ae35ab1-5f13-4273-918a-712cc2aa26d4": [
            "node_1139"
        ],
        "380ddadb-fa7b-4361-b7e9-874f1cfd07ec": [
            "node_1139"
        ],
        "fe21d96c-0370-483a-a637-daee2eaa0d80": [
            "node_1139"
        ],
        "ac0ad536-7fdf-4b96-ad9b-d42f8d128159": [
            "node_1139"
        ],
        "c8de7fd6-31a5-463b-957d-a14ec51e7093": [
            "node_1139"
        ],
        "4e50ccc0-0ff1-4025-9f2c-df95e96f21fa": [
            "node_1139"
        ],
        "0dae81e3-67f1-420f-bd3d-694bcf72c8c4": [
            "node_63"
        ],
        "ebb69498-cc3b-45e7-83fa-73fd3a340f1f": [
            "node_63"
        ],
        "02486c90-db5b-4821-b971-36d3b0b8cc65": [
            "node_63"
        ],
        "93501578-886c-43f6-901b-22e38ff25afc": [
            "node_63"
        ],
        "e18bc69a-d3e4-40a7-8c80-14fa8b92b297": [
            "node_63"
        ],
        "ee7468b8-9586-4dc7-8907-60ff6ad2db33": [
            "node_848"
        ],
        "e780472b-7a78-435f-aaf1-fa459e8193bb": [
            "node_848"
        ],
        "35d7a4d0-5eee-44ab-bcdc-27309e77a7f7": [
            "node_848"
        ],
        "27e940be-b109-4475-84a2-c17974e08a4a": [
            "node_848"
        ],
        "e1403789-148a-4f7d-87e5-56fc1ead2ed1": [
            "node_848"
        ],
        "955a1b60-1963-42ce-9238-dcd182c8fbc8": [
            "node_1048"
        ],
        "38b0b9bd-6068-45f5-8302-27e07e85509e": [
            "node_1048"
        ],
        "9f93e8fd-eccd-425c-b6e8-070bf706e1a1": [
            "node_1048"
        ],
        "b28e5f9e-1a71-42e7-ae8f-de2c9e2920c2": [
            "node_1048"
        ],
        "4312583e-8793-4a4d-97f3-c4186d803727": [
            "node_1048"
        ],
        "cc3f0a84-179c-41bc-8a6e-f80aea6a1441": [
            "node_467"
        ],
        "0ba693cd-c7c7-4512-853c-943e8a8e4ab2": [
            "node_467"
        ],
        "15544dad-25ec-465e-8922-68543c72fb7c": [
            "node_467"
        ],
        "98270f53-0de7-417d-ac26-585146549348": [
            "node_467"
        ],
        "ef67cc80-0001-49e8-931a-4275386b0c1a": [
            "node_467"
        ],
        "84afac0f-50fc-482e-9ba2-fa6cce4ada79": [
            "node_217"
        ],
        "a798abee-c0df-4c73-837e-80a7cb30b091": [
            "node_217"
        ],
        "826cf805-932f-40e0-b0e9-ea93b25a651d": [
            "node_217"
        ],
        "1c4b5f79-2789-4e4b-adc4-407fc566756b": [
            "node_217"
        ],
        "2ea42b67-74bd-4d69-b5e9-85df15da6487": [
            "node_217"
        ],
        "d97d0d35-a9e7-4555-8e21-35bcc8161a27": [
            "node_217"
        ],
        "ce921962-f03b-47b3-88d0-9c5a26c39613": [
            "node_217"
        ],
        "4340b3f4-afef-43ff-9de2-033f6fe777a3": [
            "node_217"
        ],
        "5775c2b8-1f23-4922-ba7a-f673bb1a966d": [
            "node_217"
        ],
        "5880f4b9-c22d-41b9-9499-96855e2cbec2": [
            "node_217"
        ],
        "01ac432f-1c31-439e-86ab-9fefb4ee8301": [
            "node_804"
        ],
        "48e322f1-9067-4267-b929-78943b9b7591": [
            "node_804"
        ],
        "db14d2dc-c706-4170-9f4a-320dbe2aad6b": [
            "node_804"
        ],
        "1841d486-3549-4b09-ac74-17d6465e5733": [
            "node_804"
        ],
        "6d63c341-9bac-4c38-8699-af9c6f6ba16e": [
            "node_804"
        ],
        "a4ca3af8-82f0-4219-b54f-a8f0dab65b56": [
            "node_651"
        ],
        "f2f3d6dd-ca73-4835-960a-c61af8e239b8": [
            "node_651"
        ],
        "31fec093-d6f2-42c8-bfc7-0495a551268f": [
            "node_651"
        ],
        "033a37fe-33c2-496e-acfc-b5294b2ef0a5": [
            "node_651"
        ],
        "c4fcdcd3-e194-4d2b-b1d7-dbe48ab6e59d": [
            "node_651"
        ],
        "865181fb-8d09-469c-b44d-97931959779d": [
            "node_425"
        ],
        "4bc79cb9-c41c-4f5b-9dc2-a4ff9ee06205": [
            "node_425"
        ],
        "40148ebe-1e1d-4bed-ae42-a2896009b05b": [
            "node_425"
        ],
        "fe18e460-8e97-4c24-97f4-e58ae5843212": [
            "node_482"
        ],
        "7330c18a-bef2-4a0e-ba79-c1988503db32": [
            "node_1233"
        ],
        "ca8c823e-2ccc-49e3-8634-534260eff437": [
            "node_1233"
        ],
        "eb74337f-b203-41ef-97df-6149555f7672": [
            "node_1233"
        ],
        "2179c6c9-2243-4f92-b762-3af488d4586b": [
            "node_1233"
        ],
        "06716ae6-4c8d-493c-9001-e04a95927a14": [
            "node_1233"
        ],
        "4c7714df-6b67-457b-b8c3-c2d9ba11db13": [
            "node_369"
        ],
        "ede19def-869c-4734-9338-ee39bbd08c1f": [
            "node_369"
        ],
        "3b202eeb-cd4e-421d-90f3-622ed9850e9e": [
            "node_369"
        ],
        "c13ecb80-d4df-4d8d-9aea-bd1291368151": [
            "node_369"
        ],
        "f0508d79-e4f9-460f-81b2-5f4fee2f7ab9": [
            "node_369"
        ],
        "dd49a550-e2ec-4707-9b0c-a9d18edc644b": [
            "node_755"
        ],
        "6eea60e8-d08c-4042-9c1e-7cc92e80f908": [
            "node_755"
        ],
        "e6b73174-f525-433b-be54-e31dbee00b01": [
            "node_755"
        ],
        "969ddf7b-a54b-4cae-9bfc-102940210e7a": [
            "node_755"
        ],
        "3875a572-2885-4009-916d-a7f6c9ee4151": [
            "node_755"
        ],
        "ded8fb72-0f7d-4ee9-b7e3-5a821e5d9a64": [
            "node_755"
        ],
        "4a44d793-8492-43ed-99f4-0040dda1201e": [
            "node_1065"
        ],
        "80f2c0e6-284c-4f67-a089-b0c2aad2726d": [
            "node_1065"
        ],
        "8fe459e1-344f-463c-a621-a48d0dd4e126": [
            "node_1065"
        ],
        "ad450899-3b12-4e46-bb52-e9f9deb7501e": [
            "node_1065"
        ],
        "9b6cc3e9-ada7-4bf2-89b0-83408316bb1a": [
            "node_1065"
        ],
        "8d909ea0-4809-48cb-bfc6-98cdecfb8262": [
            "node_1188"
        ],
        "c174d987-4832-45d4-abd4-0b1dd5e794a1": [
            "node_1188"
        ],
        "4ed49504-6ca4-4f81-8890-a007fe01d00c": [
            "node_1188"
        ],
        "32edc1f1-d052-4201-b404-3c5d1f47185b": [
            "node_1188"
        ],
        "01744e35-fdb8-4404-811e-826b93ffd0db": [
            "node_1188"
        ],
        "df3c2d19-8cd4-47fa-ad0e-5f51b363b247": [
            "node_1188"
        ],
        "ba46bca2-80d4-47d7-ba89-a90345187942": [
            "node_1188"
        ],
        "9b0f55bf-6832-4f4e-9fdd-ca5714370530": [
            "node_1188"
        ],
        "336f79a1-c3d4-45ae-a361-88e7545a4bb8": [
            "node_1188"
        ],
        "b0726c6d-1ad7-4817-ab9e-cb762a62e4e0": [
            "node_1188"
        ],
        "6c82db69-d1c2-4695-9480-d39771a38e48": [
            "node_70"
        ],
        "33408598-be14-4441-9689-953054e0a7ea": [
            "node_70"
        ],
        "34b08723-e42c-463a-8b58-2b370ac70a29": [
            "node_70"
        ],
        "9f51fe0b-a1e6-4bd3-9f3b-ad11812a3440": [
            "node_70"
        ],
        "4ae81894-5967-45de-b9d4-a530518af32f": [
            "node_70"
        ],
        "54eeb8bb-1cb9-40be-9a30-53959e9708ab": [
            "node_70"
        ],
        "dde8b061-f87a-4389-b500-be16bb275dd5": [
            "node_45"
        ],
        "437dc77c-d9f1-4c83-a7b4-e514de0111e2": [
            "node_45"
        ],
        "71ef0661-9cde-4009-bff4-b74d40e18f46": [
            "node_45"
        ],
        "bef46686-7290-4223-9ef0-3ea9f8e38178": [
            "node_45"
        ],
        "d6e5af3b-e4a0-4e4a-ab1b-6efd7f53b45f": [
            "node_45"
        ],
        "c89b67be-7f4e-44b4-a95b-c1053e5d2629": [
            "node_45"
        ],
        "6bbecffc-37ba-460e-a017-6c833c85ce31": [
            "node_953"
        ],
        "55175656-58b9-4833-9154-f1ee81fa386d": [
            "node_953"
        ],
        "8198fab3-615f-4974-8108-ccfd305af27d": [
            "node_953"
        ],
        "9557d573-46b1-4656-90f8-cbeb92c75776": [
            "node_953"
        ],
        "27de9ab4-1ed6-440d-8331-8fd9e2e513ee": [
            "node_953"
        ],
        "5700dd0e-bb53-4b93-a4e4-4756fba54308": [
            "node_1279"
        ],
        "158bd160-fc1b-412e-8c4e-da70d5577701": [
            "node_1279"
        ],
        "a7b3aa8f-1b3c-46a5-b1c3-aa873e4356c0": [
            "node_1279"
        ],
        "ea722eb9-5d01-4274-9e46-56e51be1e4aa": [
            "node_1279"
        ],
        "d3709a44-8ac9-4409-90a5-dd72481b35e9": [
            "node_1279"
        ],
        "c5aba064-250f-438c-bef6-154f5fbb2cc4": [
            "node_76"
        ],
        "344cd961-07bc-454d-97b6-1d323e1ecf06": [
            "node_76"
        ],
        "928ce060-1f20-4ed2-937a-c4b9bac8d6a6": [
            "node_76"
        ],
        "e485ac9e-3dc9-4810-b1cf-7797aa0f43e1": [
            "node_76"
        ],
        "afb9cf2c-a34a-4994-bfae-9aaed8272438": [
            "node_76"
        ],
        "dba909a3-faef-4865-a34e-b843f9638fd1": [
            "node_1175"
        ],
        "58924f82-291f-49d7-aad8-5feba7a728c0": [
            "node_1175"
        ],
        "65d1428b-14bf-4fbb-8608-280bcdfd110e": [
            "node_1175"
        ],
        "03edcc8a-258a-47f1-befb-e62395124ae7": [
            "node_1175"
        ],
        "8cf01405-6d14-408a-906c-6e7e46c1befe": [
            "node_1175"
        ],
        "4c55e6bf-c44d-408f-abe1-88a98564470c": [
            "node_1175"
        ],
        "47531b0c-225d-45af-990e-b408defa5f17": [
            "node_1175"
        ],
        "23d63e0a-4476-4d11-87f5-b0bdc7a78045": [
            "node_1175"
        ],
        "368b18cb-7af7-46e5-a425-0a226a9b9839": [
            "node_1175"
        ],
        "c9e3883c-93e4-4158-9050-cd4a51dfe858": [
            "node_1175"
        ],
        "3f58a5f6-da4b-4feb-83be-124854fe6041": [
            "node_441"
        ],
        "8a75146b-b8fd-4c6d-8833-7ddb1f966e0b": [
            "node_441"
        ],
        "043622cd-3306-43cc-b487-1f586492635b": [
            "node_441"
        ],
        "387c76f6-8792-4672-bbd6-a38d51bcdbc7": [
            "node_441"
        ],
        "c6616a00-15d8-4ec2-af1f-3d1268f6ca3b": [
            "node_441"
        ],
        "78cfcd68-4251-47d1-9803-9ade7e39ed0c": [
            "node_372"
        ],
        "310fef52-cd23-409c-be2d-36900c190237": [
            "node_372"
        ],
        "ec0a4584-e226-4f32-bddf-8d10d0a229a2": [
            "node_372"
        ],
        "43d89598-1d03-4389-9f8f-e259987d6655": [
            "node_372"
        ],
        "e222e9cf-0a46-44a4-9275-6fd1da4d8f5f": [
            "node_372"
        ],
        "a032d2bd-62c1-4bba-94e1-baddd6879f84": [
            "node_47"
        ],
        "118c1b62-0e3b-45fb-9186-cdfd43a7fc53": [
            "node_47"
        ],
        "931f954d-b77a-4d4d-86b4-6b4403592b12": [
            "node_47"
        ],
        "eb6e62a6-4938-4a6d-94df-606c833692d8": [
            "node_47"
        ],
        "b8219f42-94ef-4b42-8009-2554cdc6a812": [
            "node_47"
        ],
        "1b282bee-09a3-470e-a6bf-1bb74dcc73cd": [
            "node_80"
        ],
        "aa1b78ec-cbe7-4c6a-9ed6-4242eb228b20": [
            "node_80"
        ],
        "ea67d5bf-6cc5-464a-a3a9-95086b014e45": [
            "node_80"
        ],
        "155b3cfd-89f7-43f1-872b-83bbff7d9042": [
            "node_80"
        ],
        "3b3d87ef-f3e5-4b85-bc4d-f97d9efceee8": [
            "node_80"
        ],
        "d31f4512-de8d-40a3-b456-8fbe61f57ac2": [
            "node_358"
        ],
        "740bde56-3e5b-4d83-8a7f-f2b646847ec3": [
            "node_358"
        ],
        "0445814f-5813-4dab-8fea-3a6070183cca": [
            "node_358"
        ],
        "d084389c-a7dd-47c4-a6ee-dc7ab36ff89b": [
            "node_358"
        ],
        "001d6cd2-077f-4d39-a565-53afa868114c": [
            "node_358"
        ],
        "02c10f41-8e6c-48e2-82c7-021269976334": [
            "node_243"
        ],
        "f8749da6-1f61-420f-9300-2ecf072af679": [
            "node_243"
        ],
        "669cb74b-c2f7-4e66-9e89-d4d7d60cd16a": [
            "node_243"
        ],
        "da147586-b7a9-45c3-a5f1-629d23968689": [
            "node_243"
        ],
        "9b21f2e1-d5a7-47a1-8822-c814da3f8bc4": [
            "node_243"
        ],
        "622662de-7c18-41e1-87ff-98a180feb524": [
            "node_243"
        ],
        "d1325d15-d5cd-4ce9-827f-d71e81b16994": [
            "node_1226"
        ],
        "cdaebb7d-399a-450d-8be5-d43b61dc97f2": [
            "node_1226"
        ],
        "66d502cf-f6b0-44ee-a7da-8ce5fcea1765": [
            "node_1226"
        ],
        "9264315f-e4c7-44dd-a23d-9c6fefdd1213": [
            "node_1226"
        ],
        "ba8c936e-239f-49f7-b931-505ee5ed8976": [
            "node_1226"
        ],
        "701fa49d-70b2-41fc-961f-d6a4714b0de3": [
            "node_1173"
        ],
        "9ca70551-2dfd-4408-8cbd-80fd83dc4c09": [
            "node_1173"
        ],
        "6679da68-b74e-4ea9-bac1-746e3217cd76": [
            "node_1173"
        ],
        "3caf5dea-6475-4f36-8013-a994587cce7d": [
            "node_1173"
        ],
        "433b9bf8-3713-4f12-8016-c5521a4dd711": [
            "node_1173"
        ],
        "90332c21-da77-4bed-bf05-c8d5979c23e2": [
            "node_1173"
        ],
        "864acd33-4b99-4c00-b61c-5afe0bf48b26": [
            "node_1173"
        ],
        "2a198a7b-ac11-452a-9423-4714cfb5bea1": [
            "node_1173"
        ],
        "2255bb88-87e9-4217-9cd6-90c00fd6f9c2": [
            "node_255"
        ],
        "7542e4b3-0456-4e4d-b9bd-9d8411d5c3f0": [
            "node_255"
        ],
        "12c7208c-c5e5-49f3-8936-e048a4d8b75a": [
            "node_255"
        ],
        "04c4e6bb-aa99-4ce9-bc5a-c25707600887": [
            "node_255"
        ],
        "b301b496-dd77-43d5-82cf-39d133a5be1f": [
            "node_255"
        ],
        "43d14205-d74b-49dd-a512-b3accf35c699": [
            "node_558"
        ],
        "5624fec1-dd86-458e-a367-8fdd97dd23d6": [
            "node_558"
        ],
        "ed1f1590-bde6-44e0-811f-caf53ac09938": [
            "node_558"
        ],
        "59e1faeb-786f-4286-adbf-017be6b033b5": [
            "node_558"
        ],
        "56c11e75-efbc-4914-9a64-1287d459aa9b": [
            "node_558"
        ],
        "f2f87db1-4d74-44b9-8670-59a7d3900737": [
            "node_112"
        ],
        "86ca5e3e-89c7-4652-aaf7-facb7f38e0a8": [
            "node_112"
        ],
        "1e6b6fba-58c5-4f96-8f15-6a25efdd5100": [
            "node_112"
        ],
        "877bb5bd-4927-48fb-bbd9-8119c9802b0e": [
            "node_112"
        ],
        "7532513a-391d-461f-b7bb-58d2151ea77b": [
            "node_112"
        ],
        "0e8dfdde-e12a-4902-bdcb-3b8af798fe05": [
            "node_112"
        ],
        "872d006b-389c-4922-b64c-e10eba331afe": [
            "node_1037"
        ],
        "1f8e147c-b74a-4675-8fbf-61554bccf0ce": [
            "node_1037"
        ],
        "79aea006-39c6-4509-96d6-a55222379e97": [
            "node_1037"
        ],
        "1d41ae8e-3463-4f15-ae0e-e5bc20b5a67e": [
            "node_1037"
        ],
        "20f6da26-d2cd-48c1-a3c2-9dbb32380127": [
            "node_1037"
        ],
        "6b752bbd-1ce0-4760-b1a3-0a0e20145552": [
            "node_566"
        ],
        "998ffc23-465e-4e6c-b154-79d43faac252": [
            "node_566"
        ],
        "0b55522f-615e-468f-ab30-38ad5fba9d01": [
            "node_566"
        ],
        "9387686d-cf16-4b30-a9c7-a8873cc63005": [
            "node_566"
        ],
        "53061e96-11e6-4a76-a065-b9a39f0dae73": [
            "node_566"
        ],
        "92d8c39c-61dd-4413-ab19-5da50710a4c2": [
            "node_576"
        ],
        "28709a2e-6e4e-4d49-afbf-5ffeb3cac9eb": [
            "node_576"
        ],
        "be4e4ffb-58c8-4621-9430-273829354ce6": [
            "node_576"
        ],
        "9ec06de7-6f76-4817-afd6-2abc80c05176": [
            "node_576"
        ],
        "4a2e1762-db8c-49eb-922b-4930b00a282d": [
            "node_576"
        ],
        "156aca8d-d051-4739-8ff8-b7ce9bd6e668": [
            "node_576"
        ],
        "9208d038-2c34-4b77-8b98-80dce2910b3a": [
            "node_576"
        ],
        "2449664c-07f6-428c-aadc-fa2ec9f94e42": [
            "node_576"
        ],
        "89ac4124-a5df-410e-89a0-e0302f595d74": [
            "node_576"
        ],
        "2d22702a-ffe7-4960-8c1e-f3a0be254a33": [
            "node_576"
        ],
        "82950b5f-1eb7-44b8-9b32-cb4715bb2377": [
            "node_1299"
        ],
        "83bd7e39-1486-4e6c-8a66-e7279d62b52c": [
            "node_1299"
        ],
        "bc23a854-4dc8-48a1-8d53-3759e87c0400": [
            "node_1299"
        ],
        "672681eb-57fc-4ab7-a763-4e3c0ad74e29": [
            "node_1299"
        ],
        "4053edbe-61c9-4f7d-98c1-e324676e728f": [
            "node_1299"
        ],
        "50678bdc-d69b-4549-a589-454aaba034f9": [
            "node_713"
        ],
        "f453ecc3-6a6c-48b3-944b-7d71b6d07b8e": [
            "node_713"
        ],
        "b692f250-5fba-48ac-b043-e4303d50159e": [
            "node_713"
        ],
        "c373c063-8b6e-496a-9f62-d0675cfa7c8d": [
            "node_713"
        ],
        "861bda92-45e9-4a61-8b89-564c350c854a": [
            "node_713"
        ],
        "37a636cd-875d-43f9-a31d-99de3205a7a6": [
            "node_713"
        ],
        "be6684dc-c0ca-4cbe-8394-df9488d028a6": [
            "node_713"
        ],
        "883c348c-443c-425d-bd8f-2998337cbf51": [
            "node_713"
        ],
        "e623c347-a89a-4bf8-91a0-0973bd25c379": [
            "node_408"
        ],
        "f7866bb3-4a59-49cd-8e88-942df3629b2b": [
            "node_408"
        ],
        "45212671-198d-4bc9-82ff-7b8c32fcb628": [
            "node_408"
        ],
        "fe29701d-e991-4449-91e1-7d80d9deee8f": [
            "node_408"
        ],
        "f33ba942-d722-4853-aab5-6e157ad0f340": [
            "node_408"
        ],
        "58d8581d-ec4f-41d2-825f-fc1bddec60da": [
            "node_37"
        ],
        "9ce5db4f-4da1-4328-a4a7-5bf46aaaa585": [
            "node_37"
        ],
        "5c19c462-cc07-4cd2-a8ce-430047bfc39d": [
            "node_37"
        ],
        "ec5864aa-c3ee-4c5a-9f70-ef5838c84772": [
            "node_37"
        ],
        "cde97804-b5cb-4919-9dac-f71ad1416c71": [
            "node_37"
        ],
        "5b433956-3792-4e35-babb-6d3e2f996dd0": [
            "node_37"
        ],
        "f18bdf30-3823-4c0a-a0eb-b735fa99c3c1": [
            "node_37"
        ],
        "1b4ccc1b-1804-4c2a-a34f-bca0dd1061f0": [
            "node_37"
        ],
        "7c0988c3-ed34-4564-af59-48d5ed509cc4": [
            "node_37"
        ],
        "0fde868f-8feb-4c56-b6c3-694e9ae325ff": [
            "node_37"
        ],
        "bb3296b3-1105-48fb-87a8-10369da34d8d": [
            "node_1128"
        ],
        "f652f2cd-1005-42f2-9d79-bf703719caa7": [
            "node_1128"
        ],
        "d3182e60-9d26-4763-85fe-043b241b34c8": [
            "node_1128"
        ],
        "3072f23b-964a-4f2c-8881-988571878a59": [
            "node_1128"
        ],
        "e592d443-09a2-4880-8f93-cfcbe24a787c": [
            "node_1128"
        ],
        "ec9ee05a-8d35-428f-a973-9b7a29b649bc": [
            "node_285"
        ],
        "f6dc9238-3bc0-403a-8a5f-4db3b7cf8c77": [
            "node_285"
        ],
        "b3d1e75d-5b3a-405b-b8b8-49d95f1b67b2": [
            "node_285"
        ],
        "99b0d091-a228-4f1f-a687-11df8b04942c": [
            "node_285"
        ],
        "4b64dfbe-a089-4875-aef8-0ed5984c8aa7": [
            "node_285"
        ],
        "767cf447-363a-4aff-8cda-a346dbefa626": [
            "node_12"
        ],
        "212d9a36-2488-4223-a984-5f52b0039d7d": [
            "node_587"
        ],
        "3f898c8b-bcdc-4291-ae79-55c754c83491": [
            "node_587"
        ],
        "2ff061a1-ff5d-49a6-b9fa-7797601e8d57": [
            "node_587"
        ],
        "b0d3f707-dede-4b8b-84df-64a23305c31e": [
            "node_587"
        ],
        "9bf94eff-d5a6-4d86-b981-3006187bfae3": [
            "node_587"
        ],
        "1edf5c42-8f40-49b3-bec2-580afdc5c111": [
            "node_760"
        ],
        "565997c3-db25-42ec-a75f-b7204d77af1c": [
            "node_760"
        ],
        "729621cb-ae11-4167-8f1e-04bb2fb132e3": [
            "node_760"
        ],
        "9d88c082-5856-4558-9555-aaac813da07d": [
            "node_760"
        ],
        "0a15ed39-181e-4c6d-aac0-bf2c6e6459fc": [
            "node_760"
        ],
        "101da9e6-89bd-47fd-9e8e-de767a596678": [
            "node_413"
        ],
        "f8ba30bb-5fae-4583-95f9-7b228ac48001": [
            "node_413"
        ],
        "23d29ad4-fd2f-4334-9e20-36d46bdd274f": [
            "node_413"
        ],
        "cc12ed83-1d4a-4e75-a86b-dd8ccd04af86": [
            "node_413"
        ],
        "f84bbcfa-0d8b-4063-ada2-e121425d8b2e": [
            "node_413"
        ],
        "ac094b91-9c61-4c1c-803f-df285cfa2ed0": [
            "node_69"
        ],
        "5f884daa-4454-4432-aff1-77bb0e573725": [
            "node_69"
        ],
        "6f58f2a4-fce9-4e62-9496-19778e2b3b48": [
            "node_69"
        ],
        "95cff3c1-b516-4675-a9aa-ebe16f6f3307": [
            "node_69"
        ],
        "b148460c-4aad-4988-826d-33484b051273": [
            "node_69"
        ],
        "697109f1-1d28-4883-8f14-211793c04e96": [
            "node_69"
        ],
        "57d22776-5f7c-4ee4-95fd-ea1de018bd3f": [
            "node_69"
        ],
        "cf841bf9-4235-4acb-9c1e-444e7d5a614d": [
            "node_69"
        ],
        "94c2a818-c291-4381-bc33-9af245f5c9bd": [
            "node_69"
        ],
        "2315ef3f-240d-4241-91ec-270ffa897c0e": [
            "node_69"
        ],
        "8d9a2420-8d87-467e-92f9-ef90a290ec5e": [
            "node_129"
        ],
        "421e05b9-7b78-41fd-a5c9-b4f9b8db6b3d": [
            "node_129"
        ],
        "638c287e-425e-4e65-8884-80d79b9479f5": [
            "node_129"
        ],
        "e5a11f69-5297-4b7a-8416-4865c4104ef4": [
            "node_129"
        ],
        "a5d7b7ee-c61b-46fe-9546-4599b08bcebe": [
            "node_129"
        ],
        "f745b0cb-cd36-4c61-b465-7f3407675f66": [
            "node_771"
        ],
        "6434292f-5f9b-4cbe-a369-973edacc104f": [
            "node_771"
        ],
        "597dac53-84e3-4c8f-a275-c21731e5f0d5": [
            "node_771"
        ],
        "66496750-a808-4d6d-878d-7e9a9080c9d8": [
            "node_771"
        ],
        "2090c8a1-4ace-4b6d-8b20-3f462fd7468b": [
            "node_771"
        ],
        "4d912e0c-d16e-422b-9a93-6edac4a8649e": [
            "node_771"
        ],
        "3da44855-0d8b-4e3c-bcf1-c79bae9e2713": [
            "node_771"
        ],
        "9802754e-e1c4-431b-aa8e-c8b7675fdc28": [
            "node_1219"
        ],
        "5e603d07-1277-4edc-a73e-5eb4a3a63b88": [
            "node_1219"
        ],
        "4fab5d04-7f3a-49fc-b91c-0dd83284eafb": [
            "node_1219"
        ],
        "c9238ede-58ef-41c5-add3-ea0b0b79640c": [
            "node_1219"
        ],
        "60df18ec-1ff4-49b1-b4bf-5d2e54c55091": [
            "node_375"
        ],
        "525addc7-7f1d-466d-988f-430e404b7e8a": [
            "node_375"
        ],
        "4591b1d8-5d5f-4fa9-a3bf-2dddaf08a14f": [
            "node_375"
        ],
        "9aa86ca0-6d2c-4c6a-832c-90e3e63bc51c": [
            "node_375"
        ],
        "7bf26939-1884-4bdb-a6e5-adef8a7d1352": [
            "node_375"
        ],
        "88ddf8e3-9091-476f-bc79-d0ebf5ebee12": [
            "node_472"
        ],
        "2b88c05f-7bad-4250-abe2-b9d1a1251f50": [
            "node_472"
        ],
        "9fdcab16-5bbe-493f-9a30-043f67a97782": [
            "node_472"
        ],
        "4654e57a-957a-41b2-9a7a-bf11194ac224": [
            "node_472"
        ],
        "dac43fea-8184-48e1-a788-7312d43689fe": [
            "node_472"
        ],
        "872bd5dd-37f8-49c3-88a5-924d034be8a5": [
            "node_435"
        ],
        "afeafcbb-bc1c-4f9d-87c6-89b6310b55d7": [
            "node_435"
        ],
        "f45e881e-1e30-4493-8e68-ca7c50df5ac2": [
            "node_435"
        ],
        "e9ef14c9-ff5c-4b74-925b-afecbe2c71b5": [
            "node_435"
        ],
        "f42324fe-8ca0-4fe1-8583-78a2ea3815cf": [
            "node_435"
        ],
        "6eea5537-a513-4b20-8d2f-0a1406b228fe": [
            "node_1252"
        ],
        "474fa4cb-c39a-43a0-9930-8e374c1f59e0": [
            "node_1252"
        ],
        "196a00ae-3a62-4614-baed-2169d90cd659": [
            "node_1252"
        ],
        "804dd724-576d-404e-9563-742ff7f60621": [
            "node_1252"
        ],
        "2bf46a27-48c1-4e6a-9a45-02ac161aa656": [
            "node_117"
        ],
        "19ade416-f4e7-4a5c-8093-f497727135a1": [
            "node_117"
        ],
        "01f66021-7dae-42e0-baa2-b271d685e7fd": [
            "node_117"
        ],
        "03c60f94-5f30-4767-a31b-a74344b8a8f0": [
            "node_117"
        ],
        "4efb6f8b-0d2c-486e-964c-90347d65ad60": [
            "node_117"
        ],
        "9d781ffd-636b-4af1-a5d8-de3502ce61c5": [
            "node_117"
        ],
        "7060d5e5-377e-4af3-b543-f2f19aca4ba2": [
            "node_117"
        ],
        "77c2f0f9-51df-4c9d-813b-572e0e42151f": [
            "node_117"
        ],
        "e38c84dd-f273-435a-8493-23dd342e4244": [
            "node_117"
        ],
        "fcb21122-93aa-41c4-abd6-fd5b80deb20d": [
            "node_117"
        ],
        "9bc6c867-b9c7-4bea-b65a-64534ca203cc": [
            "node_815"
        ],
        "8b01b8fb-62b7-40b7-8ec1-70a1b1f37b47": [
            "node_815"
        ],
        "61e14e22-e523-4afc-9352-a73571d91936": [
            "node_815"
        ],
        "00e31414-03bf-43db-bfd4-52aa1d1940e5": [
            "node_815"
        ],
        "a886f232-9c15-45dc-a86f-6ebbfeb0f512": [
            "node_815"
        ],
        "4b64ea22-0d9e-4c0b-82b1-9924a7f05816": [
            "node_1286"
        ],
        "ec38210f-1517-422d-913e-501646dfb6e5": [
            "node_1286"
        ],
        "a373a9cf-9d59-4319-9ca3-8ae005a45511": [
            "node_1286"
        ],
        "68cdc002-fd1c-49dd-98c0-b6d2033cb12f": [
            "node_1286"
        ],
        "24aaf88e-d8db-47c2-bc1f-fc71767904a3": [
            "node_1286"
        ],
        "f0183136-58bf-49ce-b116-baed58701bb4": [
            "node_1286"
        ],
        "01a2800a-bfba-41a3-a35b-8c2d1e63936b": [
            "node_1286"
        ],
        "6310b9c5-1c10-4c69-9dfd-e91b4f208671": [
            "node_1286"
        ],
        "c220933d-13ab-4388-82c0-44cfe6222755": [
            "node_1286"
        ],
        "f99e59ed-f135-4f56-a30a-902bb45ad921": [
            "node_1286"
        ],
        "d144f0bd-b903-42ed-9b32-316279636cf1": [
            "node_1282"
        ],
        "ff2ac809-3fc9-452a-81b1-2a9dc2504b86": [
            "node_1282"
        ],
        "815e5b31-8faa-4fac-b112-2b0f4d9281da": [
            "node_1282"
        ],
        "358051db-c9db-4a03-a2af-4298e4cb3f1f": [
            "node_1282"
        ],
        "f93b6a50-e4d6-4609-8f85-f7b842ff0b5d": [
            "node_1282"
        ],
        "ac1aba0e-68c7-41cf-a7d3-b0d2a0f2e00e": [
            "node_1029"
        ],
        "190f5672-a8a4-41a0-9ecc-f0bee149af53": [
            "node_1029"
        ],
        "3f6d09c3-118d-4b57-a8e9-88d9f9e32e71": [
            "node_1029"
        ],
        "79a4f305-a749-4411-bb24-1a3fae168127": [
            "node_1029"
        ],
        "90184223-99d5-47f2-a4cb-1b1da0443b39": [
            "node_1029"
        ],
        "90a1341f-f448-4d46-8fa0-e01295460093": [
            "node_1199"
        ],
        "70b5c86c-e41c-401c-ac71-e83969bbf99e": [
            "node_1199"
        ],
        "345773f9-cdcb-42a2-ba39-3367480d64bd": [
            "node_1199"
        ],
        "1babeca6-3367-4162-9827-01add4cf5571": [
            "node_1081"
        ],
        "67d8087a-b2fb-45c9-96f2-bbc7ed69dd54": [
            "node_1081"
        ],
        "c7a03e98-70e4-44f9-842b-6a6d700b303b": [
            "node_1081"
        ],
        "66c09305-c090-432b-ae10-fa85320aa83a": [
            "node_1081"
        ],
        "8819292c-b1cc-4126-89ca-2c486594efa4": [
            "node_1081"
        ],
        "f7080800-58c2-4c77-b045-c2db47512195": [
            "node_1238"
        ],
        "f529e63e-952b-4277-a35b-963a1659d72e": [
            "node_1238"
        ],
        "40b9754c-d817-40b0-9ebb-7b0c5fd1e63b": [
            "node_1238"
        ],
        "ac78b0f4-17cb-4614-a0de-f8201d0018be": [
            "node_1238"
        ],
        "2c738081-49a8-4f60-9722-2f000aa87161": [
            "node_1238"
        ],
        "106baefb-71b3-43e8-9560-f243619c56ec": [
            "node_762"
        ],
        "a871562b-625a-4762-8106-27e6be83baa5": [
            "node_762"
        ],
        "2ab0d73f-d6d4-4db6-8fc6-666f5e074920": [
            "node_762"
        ],
        "f05a548f-cec2-43b9-b7d7-201faac876ed": [
            "node_762"
        ],
        "82421864-4481-410f-8771-f95d918196b6": [
            "node_762"
        ],
        "52803b18-0a12-4385-aeea-e401f0dc1370": [
            "node_608"
        ],
        "662f1773-e6c1-4be5-b323-dfb10671f1f0": [
            "node_608"
        ],
        "b20e055f-67d0-43f4-ac76-edfe6107bdd1": [
            "node_608"
        ],
        "0242f331-2f08-4761-b1ce-a4551cb00e1d": [
            "node_608"
        ],
        "074fcf21-f100-44aa-80bf-75ada2616be2": [
            "node_608"
        ],
        "bfda9b59-eb54-456e-a017-8d60db69cc9a": [
            "node_798"
        ],
        "e729caa7-dbab-4940-a57a-bfb5359a7699": [
            "node_798"
        ],
        "59d318d7-a0a0-4de0-92a9-0f776ac1509d": [
            "node_798"
        ],
        "125a3f6d-f9b0-4bfe-8068-9ed108c47eee": [
            "node_798"
        ],
        "050c54fb-0446-4aea-9e84-6cc164ac2b6c": [
            "node_798"
        ],
        "253e4e46-b29d-4edd-83e0-f614736fa2bb": [
            "node_131"
        ],
        "d139b373-6c79-4e69-835b-6dcf631e1c3f": [
            "node_131"
        ],
        "6a861452-5ca1-4f97-8448-44f29aaa047d": [
            "node_131"
        ],
        "bd369f89-b9a4-4042-b04d-af7693b02efe": [
            "node_131"
        ],
        "2e07245e-2031-426f-968c-8099b0df5348": [
            "node_131"
        ],
        "af9fd01e-2ea3-46db-84f3-ec23843aa0f5": [
            "node_131"
        ],
        "911e42d3-b278-41ac-817f-55ad7df1cb6c": [
            "node_131"
        ],
        "35d1e05a-60a8-4373-8fb1-0472698aeca2": [
            "node_131"
        ],
        "c4a6c7d3-8094-4b20-b117-e07969b7ab91": [
            "node_131"
        ],
        "57b70413-3d27-44be-aca1-b3c98e722e34": [
            "node_131"
        ],
        "a88f564a-d30f-4ac5-9d8c-4b8f41c855fb": [
            "node_1001"
        ],
        "8fbf9643-432d-4a2d-b450-07a48f3ca1d0": [
            "node_1001"
        ],
        "3a127b30-9943-48b6-800b-887254882c48": [
            "node_1001"
        ],
        "8098820b-7e4c-4a52-991a-9a0dc9614242": [
            "node_1001"
        ],
        "189e41cd-258c-49c6-ac79-5a26fb04ca16": [
            "node_1001"
        ],
        "37a77726-f938-4dbb-a6d7-00eebb31504c": [
            "node_639"
        ],
        "a84aeb1d-dea1-4bda-8d55-fa6e64d9356c": [
            "node_639"
        ],
        "cec76f69-e3f6-43e6-8c71-94181e1f93b8": [
            "node_639"
        ],
        "fa802104-9b9f-4e31-ba59-821f6e7c6d09": [
            "node_95"
        ],
        "9bb7ac60-90b1-447c-933b-2941bed1a07b": [
            "node_95"
        ],
        "0e46eddb-20da-4ff9-90a8-e68541c87d3b": [
            "node_95"
        ],
        "b2c33c23-3657-4974-97ce-299e4e9c087e": [
            "node_95"
        ],
        "ae24923b-a3ef-4c0a-a81d-c2c713a20f14": [
            "node_95"
        ],
        "098b0d7f-b95d-431d-af68-0d80b1b5a021": [
            "node_1003"
        ],
        "c0d8a4d7-dc04-473c-b010-032c76e2d5bd": [
            "node_1003"
        ],
        "28cdadb1-9ad7-4125-a5f7-d08d187f1acf": [
            "node_1003"
        ],
        "7b076e19-631e-4f67-ba60-9afc04007ca4": [
            "node_1003"
        ],
        "84760531-f659-42ab-9f86-eca2d75d7924": [
            "node_1003"
        ],
        "8a22b3e1-5a79-4eec-91ba-a009defd8ee0": [
            "node_1003"
        ],
        "612f3140-3541-4e5b-a83a-6b90e4800b76": [
            "node_543"
        ],
        "bdc8d0f2-1937-4381-afaa-48391bd46123": [
            "node_543"
        ],
        "422e8765-0f1d-4cd1-9896-0bc34b8ec7db": [
            "node_543"
        ],
        "ba679a15-2071-4fc4-ad19-47db68a94d6c": [
            "node_543"
        ],
        "85677974-0156-4468-9b50-6d386f008a37": [
            "node_543"
        ],
        "a441d232-5bbc-48c0-960d-9733f2090ca6": [
            "node_941"
        ],
        "9eb33590-4b0f-4ff5-b82a-76472b449214": [
            "node_941"
        ],
        "ddb334e0-5601-4c59-854c-36b334bcb478": [
            "node_941"
        ],
        "86eb5585-b83e-4b63-936c-ddab9f8c6ce2": [
            "node_941"
        ],
        "f4a3bc73-ab19-4878-a4ad-e44bc58d658f": [
            "node_941"
        ],
        "395efe86-5e1a-4690-aa21-0fc45f5fc8ac": [
            "node_19"
        ],
        "e11379e5-e6eb-4288-8660-346fe6e10827": [
            "node_778"
        ],
        "74b1857e-6d71-4f63-8a34-dc0d80822829": [
            "node_778"
        ],
        "c756d2bd-4894-4843-9250-c08b15abdebc": [
            "node_778"
        ],
        "356255ba-ad5b-4dcf-ac44-dfe6b55282c7": [
            "node_778"
        ],
        "aacbcb8b-ef99-480b-8529-24ca7d9425d7": [
            "node_778"
        ],
        "4842240c-3663-4638-baba-486d22e072d8": [
            "node_1273"
        ],
        "e68943aa-3fc2-4e76-808f-ba607625500a": [
            "node_1273"
        ],
        "e567f6aa-8087-4716-b6c1-33f5955ab2cc": [
            "node_1273"
        ],
        "bcdad768-82dc-478c-b18b-0c932f49d2c6": [
            "node_1273"
        ],
        "21f105f6-7ca2-4f6c-8051-438b3c832790": [
            "node_1273"
        ],
        "90065421-4add-4984-a0bb-5e101299397a": [
            "node_1313"
        ],
        "313aa2a9-3a34-4f4b-a81c-02494ede78a7": [
            "node_1313"
        ],
        "ad4684a8-3533-49ce-8901-395a2cff1a72": [
            "node_1313"
        ],
        "263f4331-ea41-4564-9c40-907104999c8f": [
            "node_1313"
        ],
        "4776e86a-d455-4afa-b766-034986f7bf8e": [
            "node_1313"
        ],
        "97d00f83-5312-44b3-9ddf-fed3a4810b67": [
            "node_643"
        ],
        "3166093c-f9cd-4a86-8734-34d1b911302c": [
            "node_643"
        ],
        "781c1674-bd45-4914-874e-59de0f3cd2d8": [
            "node_643"
        ],
        "a8e3da47-4959-41e8-9c43-3ceb818dbad6": [
            "node_643"
        ],
        "a130375f-081a-42d6-80b2-f372bf51dfa0": [
            "node_643"
        ],
        "35436d83-e35b-4be7-bbaa-41764082809c": [
            "node_88"
        ],
        "399ad17d-4612-4dfa-8c9f-94682ea98a0a": [
            "node_88"
        ],
        "347bc5a1-c749-4312-9868-8d0c662a08e2": [
            "node_88"
        ],
        "db4b3272-d9cd-4062-a42d-6dd20a6e5b54": [
            "node_88"
        ],
        "46b95f9a-0dd9-4575-969d-64920a8e595f": [
            "node_88"
        ],
        "0f8e9372-665d-45bd-af41-99c3751ff07c": [
            "node_670"
        ],
        "002fafce-f8d6-4ba7-83ef-cde5cb69e601": [
            "node_670"
        ],
        "51054381-7bd2-4bae-923c-19bdb5e3ec59": [
            "node_670"
        ],
        "f05c65d3-f445-4d61-a946-a2e2002eb0be": [
            "node_670"
        ],
        "1a8ee347-20cd-4e53-9bed-146d5108f474": [
            "node_670"
        ],
        "4614249a-b3ad-41ba-ab84-f85bec732a7e": [
            "node_673"
        ],
        "fff7224d-e370-47d1-8d6a-b59dc7bafcf2": [
            "node_673"
        ],
        "c55c5f1b-2dee-45f9-ae8a-dc48e310e718": [
            "node_673"
        ],
        "ae0bb56e-17bd-4ffc-82ce-88b1aecfecd4": [
            "node_673"
        ],
        "9459fc41-57ed-4cca-b923-4767b7dd7c98": [
            "node_673"
        ],
        "9a75d5da-5e06-4d04-889e-337ddf3701ce": [
            "node_673"
        ],
        "3e35e75b-9e5b-4944-bcd7-ce2a7e5e78a9": [
            "node_673"
        ],
        "cde468f6-7b89-4517-a83e-ffc693faf16d": [
            "node_673"
        ],
        "ca5a52a2-4627-4ce5-9936-75c211797003": [
            "node_511"
        ],
        "4628baf6-8cbf-4897-a5e9-c4b088f51091": [
            "node_666"
        ],
        "f8b54a85-cfa0-4944-90a8-021014af3e67": [
            "node_666"
        ],
        "88c230ca-0a21-452a-936c-0a695ae44fb7": [
            "node_666"
        ],
        "3959f465-6fc3-4140-8d70-130ce2076425": [
            "node_666"
        ],
        "494bda3e-868d-41c3-8c59-d9f01cc87c2d": [
            "node_666"
        ],
        "2de0ca46-4e1f-45de-95cb-a7876664916c": [
            "node_1240"
        ],
        "2efdf9fb-570c-4aaf-9005-6c78304da1b8": [
            "node_1253"
        ],
        "fe5608ee-20b4-4a0c-9ece-9066e58a4eb4": [
            "node_1253"
        ],
        "5ca3a964-5ef7-4696-93fe-a243d63d55a5": [
            "node_1253"
        ],
        "96441dd3-60da-44c4-988b-57bd4cf756e6": [
            "node_1253"
        ],
        "93fe7c89-22dc-47dc-af6b-a7f80576bab9": [
            "node_1253"
        ],
        "36f73b36-1cf5-47f8-9e4e-3aa95ab79183": [
            "node_1253"
        ],
        "42c3e0a4-6db0-4f84-9f2b-94395c973c6f": [
            "node_1253"
        ],
        "047c5d4c-6b1e-43b8-828a-05d0a6f8ee3b": [
            "node_1253"
        ],
        "71477014-6026-4be2-985f-364d8b5547b6": [
            "node_406"
        ],
        "000783a1-9468-4439-96c9-89bb5bf742ad": [
            "node_406"
        ],
        "8c4294d6-3ccd-4924-a58c-465c590339fa": [
            "node_406"
        ],
        "69b52972-b1ba-4e1b-ac1b-0f63c7ed00e9": [
            "node_406"
        ],
        "c44c501a-ffdb-4b3a-a9c8-333103050a1d": [
            "node_406"
        ],
        "a8db593c-56da-4909-bd23-da4577b96015": [
            "node_523"
        ],
        "dde1865e-49da-4713-a9d2-0235e9249042": [
            "node_523"
        ],
        "1e0cf45b-0916-4791-b2fe-16310a16abb5": [
            "node_523"
        ],
        "000f2fc6-fecf-4a76-9ff3-f5c30733c26c": [
            "node_523"
        ],
        "00df84fa-6c4d-47b0-824e-0c58799d28ab": [
            "node_486"
        ],
        "11c0b5f2-6706-4373-b8c2-61a12defaea8": [
            "node_486"
        ],
        "740e5380-66d9-49f3-8e9f-6ed41ec3fda1": [
            "node_486"
        ],
        "d0cd4adf-a394-4ea2-8edd-4b75e63886f5": [
            "node_486"
        ],
        "d6222c53-4f0a-40ec-a13b-cd4cb7871648": [
            "node_486"
        ],
        "3478017a-3d2d-4355-bc37-6c145296fa7e": [
            "node_486"
        ],
        "30b37d92-3454-480a-a82a-15915b5fd97f": [
            "node_486"
        ],
        "d59821a2-1fb4-4c3d-90cf-6a0c08f24c20": [
            "node_486"
        ],
        "4eae264e-8d46-47fc-82da-74dd82595720": [
            "node_486"
        ],
        "fa5a5f64-e043-466a-aac5-c3667202e112": [
            "node_486"
        ],
        "af66534c-ee4f-4e28-b27c-b521c0bd0085": [
            "node_811"
        ],
        "3b81a7e6-022b-4c95-942e-76fabe552896": [
            "node_811"
        ],
        "019f33d1-78c1-43a7-a854-e86813bdb512": [
            "node_811"
        ],
        "16ad613e-d983-4443-9efd-63ae91f25dbc": [
            "node_811"
        ],
        "d5142051-3708-474b-bbf3-550d43896197": [
            "node_811"
        ],
        "f88affc2-99dc-417b-b49a-b0b70940a53c": [
            "node_1197"
        ],
        "bdafe150-9dd9-4cbc-87c5-398e82777ec6": [
            "node_1197"
        ],
        "4c37cce3-df4e-4718-bbeb-9edddf7d898e": [
            "node_1197"
        ],
        "3efbb085-9b44-4a6d-a1d3-a92dc2636501": [
            "node_1197"
        ],
        "b59993d3-fc73-4eba-aecb-9e9b315cf550": [
            "node_1197"
        ],
        "eb66e3dc-ea75-4236-964b-7f7c02331272": [
            "node_402"
        ],
        "685b1783-da51-4872-9dd5-478003c5e975": [
            "node_402"
        ],
        "60eded04-a1ab-41cd-868d-802e12215ea4": [
            "node_402"
        ],
        "41e1869c-d7a7-4bcc-b11d-447c8725cdb5": [
            "node_402"
        ],
        "906fcd09-d195-4a25-995a-a8f560e1d904": [
            "node_402"
        ],
        "1c4c1499-bf70-41ca-adab-1355eaebf968": [
            "node_541"
        ],
        "59449a1c-2ef3-4854-b520-e81866d13d7a": [
            "node_541"
        ],
        "2ed753fc-e33c-441f-b523-aff239d693a8": [
            "node_541"
        ],
        "ed62435d-5833-403b-b5a4-c0a744d907a0": [
            "node_541"
        ],
        "d72590bd-98de-4239-aa59-8f47b90efd1a": [
            "node_541"
        ],
        "db17d2f9-3f5a-473c-90f9-026f4d91a135": [
            "node_16"
        ],
        "c82f7bf9-6668-4220-8f76-5b33c0253d21": [
            "node_16"
        ],
        "85a69e74-45a8-4e0b-a894-2a64be065fa8": [
            "node_16"
        ],
        "7f7cc023-2109-4165-b85d-63d810bdfe9a": [
            "node_16"
        ],
        "41c6a782-72bb-4fc4-b6d9-aca7334fe4e3": [
            "node_16"
        ],
        "51340d14-a758-4263-95cf-dc0a62265ff6": [
            "node_361"
        ],
        "0315441a-f0a2-4cba-b413-a86cfa39996e": [
            "node_361"
        ],
        "fb49f9a4-5b8f-41f5-9ce1-514e04fa003b": [
            "node_361"
        ],
        "90576f0c-429f-4642-a637-1284f29be0fa": [
            "node_361"
        ],
        "0f1a5c9d-8c86-40c9-afe4-6d655d260b98": [
            "node_361"
        ],
        "3648f8d2-70f4-4a16-beb3-c9c3fdbcbdfa": [
            "node_592"
        ],
        "da883b7f-c707-42d5-96f1-1926e1c3e09a": [
            "node_592"
        ],
        "19d2fe84-2c19-478e-bc19-04f3513dfacf": [
            "node_592"
        ],
        "89babb3c-7364-40d7-bce2-a886fe56ee0a": [
            "node_592"
        ],
        "ac45e1d7-c6c7-4a1b-8d88-c0170645f0dc": [
            "node_592"
        ],
        "d919bee4-4c06-4945-9a57-c1efe1010a88": [
            "node_1126"
        ],
        "9d76d52e-4b4c-46a0-8a45-12bc02966b3a": [
            "node_1126"
        ],
        "3c9039af-30b4-4d65-8733-37e58d80e1fd": [
            "node_1126"
        ],
        "051ac692-b09c-439c-9e36-a38034462a8f": [
            "node_1126"
        ],
        "13ca2178-34a6-4d88-9519-82801328a866": [
            "node_1126"
        ],
        "61b8d2f8-0fa9-408d-88cc-45d4b5701a02": [
            "node_31"
        ],
        "5c88f375-7981-4c72-942e-939e63284ba0": [
            "node_31"
        ],
        "0bd05190-fd51-40ef-bae5-cfcd6f9f073a": [
            "node_31"
        ],
        "4ed291ca-7900-4223-a2f5-4e3c09509caf": [
            "node_31"
        ],
        "ca638127-eb6a-420f-99b4-3a89ab268b71": [
            "node_31"
        ],
        "e2fe4908-33d3-4559-b630-a9ff810fdc1a": [
            "node_647"
        ],
        "78c10670-3e58-45a8-88ce-bcfc71d8fdf0": [
            "node_647"
        ],
        "28bb512a-1fc5-44d0-8f8d-a21b77f8e3fd": [
            "node_647"
        ],
        "3a4b2973-c950-4556-8529-bcd140fff953": [
            "node_647"
        ],
        "c998d113-47e8-4cf4-a94e-beee7e8df7e6": [
            "node_647"
        ],
        "2c6e1013-92a7-4d3a-b4e7-f5a23024c439": [
            "node_647"
        ],
        "f41d196c-26cc-4d1f-ab92-f8bcebc40289": [
            "node_647"
        ],
        "7cf603c9-e1c3-47e5-87dc-c6815e7b59d1": [
            "node_647"
        ],
        "a80697e3-2748-4dda-9780-0cc26d43ce38": [
            "node_647"
        ],
        "aae82da0-5cdc-47ec-a5d6-23147122fd6b": [
            "node_647"
        ],
        "07968237-f394-4ee0-a296-b83605d7f1d4": [
            "node_1045"
        ],
        "8fc91d6c-bd78-43d3-905e-6fe7463bc858": [
            "node_1045"
        ],
        "2533fafb-de39-46c7-a1ef-59e36bcb25d1": [
            "node_1045"
        ],
        "a5c75972-c2ea-4e2f-bfa6-c08faa177393": [
            "node_1045"
        ],
        "0da18ffd-e533-42c1-8231-0cb6e64a10e7": [
            "node_1045"
        ],
        "038ce90b-a6ec-4a2c-a9ab-ae9a799c49b4": [
            "node_1275"
        ],
        "20bf4f54-40d9-4798-9dfe-84ea00a8e114": [
            "node_1275"
        ],
        "71cd6250-767c-49d7-9550-cef31e065e75": [
            "node_1275"
        ],
        "3ef48d73-7bd4-4dcd-bfe8-de2cfb5d5c3b": [
            "node_130"
        ],
        "d76d1d43-1a93-4a18-9efd-57ecdc04116a": [
            "node_130"
        ],
        "669890f1-dd2e-462d-a8d4-6e05373c56c4": [
            "node_130"
        ],
        "588aaf62-59f9-466b-84e6-c57ff5c1fe40": [
            "node_130"
        ],
        "acf4addf-9591-4296-94da-7d283c9f6903": [
            "node_130"
        ],
        "7ced8f13-734a-4118-bd1b-143785be39f4": [
            "node_972"
        ],
        "c34689ce-d1f8-4886-aaa5-9f56478679b1": [
            "node_972"
        ],
        "206101f8-ae79-483d-add3-f7c0534df5c1": [
            "node_972"
        ],
        "96084eb9-e257-4f6f-a98c-6014eea50de9": [
            "node_972"
        ],
        "f7f9784f-6b4e-42ee-89fc-78cf02186a3a": [
            "node_972"
        ],
        "a521e058-b7a1-49c5-8c5b-28f4f791385a": [
            "node_356"
        ],
        "edd70a33-7abb-408d-8fb6-eafac16ce2a2": [
            "node_356"
        ],
        "81a30824-11bd-4690-b268-46fc57cf54da": [
            "node_356"
        ],
        "74b5dce8-ca55-49cd-ae3b-a2b8560c5db6": [
            "node_356"
        ],
        "bd75ea83-00d0-4c3a-bd7c-361df15daeec": [
            "node_356"
        ],
        "5f9e158b-1ab6-4aba-97c0-8b340ba7a082": [
            "node_40"
        ],
        "fa08a826-8b73-4614-8d1f-76564a0c8374": [
            "node_40"
        ],
        "ca259c0a-df7b-4e65-a5fb-124549acd482": [
            "node_40"
        ],
        "b45ed564-0cf7-4555-9109-2a8807ee89e1": [
            "node_40"
        ],
        "2b160fba-ebc0-4404-9e57-17a8e8e360f4": [
            "node_40"
        ],
        "95b58959-0215-4409-85e5-289af4572d55": [
            "node_40"
        ],
        "2d6e48bb-e13b-4e48-9732-0eea0a911fae": [
            "node_219"
        ],
        "8b6e6482-4682-4d81-a47e-ad300765bc35": [
            "node_219"
        ],
        "676db95b-6378-4bf9-a2d2-04752205ca75": [
            "node_219"
        ],
        "bd7d3298-27cd-4c50-bdfa-6561f95a6734": [
            "node_219"
        ],
        "706ce7e0-875e-4aa0-9e85-4934a5f720a7": [
            "node_219"
        ],
        "e23850e1-a8d0-4666-9b83-bb44e71c22b8": [
            "node_1303"
        ],
        "85a558dc-3465-406a-b265-286928653710": [
            "node_788"
        ],
        "6cca9567-b2f1-41d0-9c21-75944a65b985": [
            "node_788"
        ],
        "c205d308-d6fe-4199-8577-4052906d05d6": [
            "node_788"
        ],
        "8afd2df0-3e7c-4f12-97cb-ada4fa5cb1e3": [
            "node_788"
        ],
        "98f10842-a949-4571-b252-776dd730939f": [
            "node_788"
        ],
        "d6e0f0d6-92fd-4d3f-b1af-115e8c0cce1f": [
            "node_222"
        ],
        "50f5438c-dfeb-4506-aeb8-cadae955d8b2": [
            "node_176"
        ],
        "960d4f63-ce76-460f-8786-397440a89428": [
            "node_176"
        ],
        "f38476d4-f44f-479c-bcce-ac112f1d6271": [
            "node_176"
        ],
        "74c5b381-268e-4aeb-898f-5504e4d9ae6a": [
            "node_176"
        ],
        "9c5faea9-202f-43cc-9c3b-50fcf370e255": [
            "node_176"
        ],
        "1603ce71-1955-4e65-b2d4-ca77eb654ccc": [
            "node_503"
        ],
        "29223bb3-d373-4730-8392-ea67842440aa": [
            "node_503"
        ],
        "ef0f1242-347b-464d-89c1-148958ea24e9": [
            "node_503"
        ],
        "fae1dd8f-f22d-4d5c-acfc-74678311899a": [
            "node_503"
        ],
        "4fe01ccc-0bb0-49ee-bcc3-4bbedf24a700": [
            "node_503"
        ],
        "3ef7409f-1b1b-45fc-8796-1dd1921220db": [
            "node_546"
        ],
        "520e1dc1-feb6-4dac-8f2e-dc93b5a1f37f": [
            "node_546"
        ],
        "8cad2ec3-e59b-4194-ac03-7e85df937038": [
            "node_546"
        ],
        "947e1f31-ff02-4bda-bdaa-512bc5b39fbe": [
            "node_546"
        ],
        "7ea53d03-c696-492b-b4a5-75f101ca7a29": [
            "node_546"
        ],
        "0004eb91-2cc6-4d3d-a054-843bb5cb6f54": [
            "node_284"
        ],
        "f1712447-6122-46aa-abf9-0d6286b94bea": [
            "node_284"
        ],
        "72a57275-72ff-483e-90af-ef713f7331bf": [
            "node_284"
        ],
        "789cc0dc-e9a5-4a41-b2d2-ef258cf768ac": [
            "node_284"
        ],
        "e91e80b1-315d-45dc-8d8d-65c2f328c967": [
            "node_284"
        ],
        "7bbc5c00-e807-4c18-a25f-a5048ad3fdec": [
            "node_930"
        ],
        "500c39f3-8775-4526-940e-7d30240f1c44": [
            "node_930"
        ],
        "d8c7ccb8-a003-44a9-bcae-450773e67b53": [
            "node_930"
        ],
        "8c5bb35c-38c6-42e1-ae5b-5ffda8e5e299": [
            "node_6"
        ],
        "28da4a09-6c07-441d-8127-bc6b7c874d0d": [
            "node_6"
        ],
        "8cb1f0ef-5d72-4df3-aa98-a048c85b3b03": [
            "node_6"
        ],
        "340fb31f-0dcd-43a9-8896-430609886667": [
            "node_6"
        ],
        "962c578d-847c-4e43-8647-eda69ac92658": [
            "node_6"
        ],
        "87fbe489-5c06-497c-ae81-92aec26cede1": [
            "node_1117"
        ],
        "1f93547b-6729-4d57-aa57-3842dc494b82": [
            "node_1117"
        ],
        "5464509b-c64c-4a51-b919-292c125ea70c": [
            "node_1117"
        ],
        "b6d0e0db-e87b-49d6-a1aa-e17e72608eab": [
            "node_1117"
        ],
        "e952fe90-6f67-406b-8b57-3c36da277bfd": [
            "node_1117"
        ],
        "345d141a-5bea-4850-9432-8171531f5fef": [
            "node_1117"
        ],
        "636f9bc6-3b87-4af5-aa2b-d3df9d25625f": [
            "node_1117"
        ],
        "efaea00e-f55c-4abe-9a8e-8cb7aa633c5e": [
            "node_1117"
        ],
        "ef73fc58-2557-45c0-a274-8a4abc51e371": [
            "node_1117"
        ],
        "54587970-c653-4c6e-bb9b-7a730d29344a": [
            "node_1117"
        ],
        "1b6c475b-6ceb-4de4-8b65-ef0148763d93": [
            "node_1212"
        ],
        "47408dea-da01-4b31-bcb5-b9bb6293d245": [
            "node_1212"
        ],
        "cdfc5f9e-5a5d-4ffa-a080-3c974cff29f0": [
            "node_1212"
        ],
        "9123a1fe-fed0-4ff6-92ff-db5319582e26": [
            "node_1212"
        ],
        "3296ca18-f63b-4e5e-b795-bf68a50b3986": [
            "node_1212"
        ],
        "6a04b626-00ce-432d-a7ee-6feaa7199f42": [
            "node_1248"
        ],
        "cce62873-fed1-437f-98da-b89ec77c78a2": [
            "node_1248"
        ],
        "fa67d714-1fe2-40ce-993e-e92913554c52": [
            "node_1248"
        ],
        "d864fb31-8287-43f1-863d-16605b8f8bad": [
            "node_1248"
        ],
        "2de91d6b-699d-440c-a104-8a0807b958d9": [
            "node_1248"
        ],
        "bc9fb46c-b52b-4ffc-a3e4-4c11bd9e34cf": [
            "node_1125"
        ],
        "e9923b91-8ef1-4c2c-bb2f-324627ba9a99": [
            "node_1125"
        ],
        "a924ff42-1f58-4635-9ced-1bd10a7c950d": [
            "node_1125"
        ],
        "486c50d9-e1b6-449a-a8a7-66d07e4a1ba4": [
            "node_1125"
        ],
        "6d6ef3f9-abd4-4f76-8881-abcc7778e309": [
            "node_1125"
        ],
        "83da3797-1008-4b4e-842c-5e42a8691b72": [
            "node_797"
        ],
        "4e5db231-0961-4e0e-806a-328db6a3827f": [
            "node_797"
        ],
        "3040a4cd-3b1e-452e-a140-5eb4cc2616f9": [
            "node_797"
        ],
        "13397256-7796-4e77-8508-057dbcafe56f": [
            "node_797"
        ],
        "32747c41-c423-407d-ae79-030e4fb5525e": [
            "node_797"
        ],
        "e724d080-4f8d-446d-bfce-0909d46a1a89": [
            "node_705"
        ],
        "a8c041bc-7dc5-4467-b3b9-444999342db6": [
            "node_705"
        ],
        "144d085b-8f98-421c-86f7-ccf3730936c7": [
            "node_705"
        ],
        "e78f5e46-a141-4c14-9088-12ce4738336d": [
            "node_705"
        ],
        "dfc6997b-cc88-43fb-a9f5-c10b8614f8c3": [
            "node_705"
        ],
        "99a05dbe-a0b6-42a6-a0d7-c74de156b3da": [
            "node_705"
        ],
        "1ddaa2a8-939a-433b-8de7-621f2260cce6": [
            "node_705"
        ],
        "6ac71ed1-7df7-4303-aa54-a87ed887db15": [
            "node_705"
        ],
        "5fa22afb-20c9-4cd8-b93d-660c5bc921b3": [
            "node_787"
        ],
        "cc7fc1b7-cec9-4b6c-a59b-d9f24103bfd4": [
            "node_787"
        ],
        "56e86e01-a887-422d-b91e-31bb8e83ea20": [
            "node_787"
        ],
        "df37279e-b609-45f4-a21b-bdee80728a08": [
            "node_787"
        ],
        "7ae02da0-682d-45a8-9776-f9f233f01734": [
            "node_787"
        ],
        "e81a9e2e-f19c-433e-b804-3b4a26235ef5": [
            "node_787"
        ],
        "7c0c4614-3695-422f-9c88-0face0db5ba8": [
            "node_626"
        ],
        "0828cd4b-770b-4abd-a7bf-c8d1824ebd11": [
            "node_626"
        ],
        "3fdef5cc-4952-4692-aa1d-e9b323b67c6c": [
            "node_626"
        ],
        "53da7d2c-9b4a-49b5-9411-a155e8d28172": [
            "node_626"
        ],
        "5072f2a4-6996-4a65-b59d-e3416e99502a": [
            "node_258"
        ],
        "1e70bf53-ad5c-4155-989c-00201a254c1f": [
            "node_258"
        ],
        "87003029-11d3-4dff-bfd3-9c693d2a86da": [
            "node_258"
        ],
        "7ebff365-ed0f-46a1-8d05-9df965abd2fd": [
            "node_258"
        ],
        "28cb9327-189a-45ae-b4fe-896ee75a6666": [
            "node_258"
        ],
        "eaadf400-e6d3-4e80-8ede-1b2763d7a46d": [
            "node_258"
        ],
        "0e3f1292-50da-4475-8826-bcf805ecad65": [
            "node_258"
        ],
        "6aaf2e97-7e6c-4b63-aa0c-2fb3c467c053": [
            "node_201"
        ],
        "c9739012-8ab4-4001-b036-e4700b127b6f": [
            "node_201"
        ],
        "7cfe2e13-367d-4a05-b5de-92985082d9ac": [
            "node_201"
        ],
        "3ad54602-af22-4604-9d90-2386ce2e2e9f": [
            "node_201"
        ],
        "fcb4a389-c2db-409a-90c9-619c1dcc645e": [
            "node_201"
        ],
        "4f7a6845-081a-4161-81b3-b26799c44d4e": [
            "node_152"
        ],
        "2c882eae-0bd0-4d85-becf-bcee5f4cda27": [
            "node_152"
        ],
        "50a56681-5203-4b14-a752-4738f6025c90": [
            "node_152"
        ],
        "5a24895a-27a6-4753-ae44-000b88364455": [
            "node_152"
        ],
        "014d06bd-40da-4875-8b08-9a7f8b1434ef": [
            "node_152"
        ],
        "335c9a20-fde0-43e4-8ba8-923229d0d9e4": [
            "node_495"
        ],
        "5ea71157-7ffc-4f2b-bff7-89dab2fbb811": [
            "node_495"
        ],
        "07e63f9b-2b95-48a4-81c3-0e862c3ad1f9": [
            "node_495"
        ],
        "29a2ce7c-33dc-4ae2-b2ca-f2fadd306703": [
            "node_495"
        ],
        "193276d1-d5a2-4acb-a372-ea22a041c11a": [
            "node_495"
        ],
        "157fc7e6-40c6-4638-9494-3a332a44f670": [
            "node_1182"
        ],
        "533df82e-83fb-4a25-a184-2be988053727": [
            "node_1182"
        ],
        "a5458044-5760-4811-95d1-0e829a6e65f2": [
            "node_1182"
        ],
        "2a144607-c2e7-41c9-a9a5-3af739c00984": [
            "node_1182"
        ],
        "281c98ef-be4e-4ca0-aa53-20bdf6981d3c": [
            "node_1182"
        ],
        "07cbf6fe-8d89-4c4b-b1d2-c48c6bde386e": [
            "node_379"
        ],
        "eb4e6d05-5a10-425b-a70f-a45b2a04ae6e": [
            "node_379"
        ],
        "a464b73b-3274-47b7-807e-88dbed74cc09": [
            "node_379"
        ],
        "5ebfbbe4-e7d5-4e5c-83ae-cf16a350a78f": [
            "node_379"
        ],
        "2163c27b-0ed4-4ac8-a358-dca5db9414d5": [
            "node_379"
        ],
        "773494f3-f67b-48f6-89da-5f313c4bd43b": [
            "node_1018"
        ],
        "32f87930-01c1-4a39-bdae-cce0f287d28f": [
            "node_1018"
        ],
        "e5407351-e1e4-4156-aaae-f218fc699930": [
            "node_1018"
        ],
        "b3b37aea-d3a1-4ff2-8d8e-895ce3981c58": [
            "node_1018"
        ],
        "8daf0d48-b681-4d8c-964f-0680ca6d203f": [
            "node_142"
        ],
        "3d3a824c-39e6-4598-904d-e0f80e46b4e4": [
            "node_142"
        ],
        "1263afe1-06d6-4b13-bc0b-d5db5a32ecaa": [
            "node_142"
        ],
        "64c8ac72-e213-4b42-8db4-2c2f14d8b155": [
            "node_142"
        ],
        "68ed2d47-157b-4658-a0dc-4b2b7f05bcae": [
            "node_142"
        ],
        "e004e042-6975-4451-9810-5168e4a4c841": [
            "node_108"
        ],
        "98d3bbd9-4f9f-4230-a014-a07056a0d1ef": [
            "node_108"
        ],
        "0171f0c1-a68f-4f22-9820-494d4a24a5c0": [
            "node_108"
        ],
        "b0e7add2-a01a-4bb2-bced-5b9f40793945": [
            "node_108"
        ],
        "44854745-a060-4cf7-a59e-8977383d1efd": [
            "node_108"
        ],
        "31d8d31f-d029-4a88-bf5e-0d3ecad0e39f": [
            "node_919"
        ],
        "0416e94e-3dc4-4770-bb10-2ca1ae191c09": [
            "node_919"
        ],
        "549673af-a38c-408c-bfd7-307fb145f3f7": [
            "node_919"
        ],
        "5e7d04b6-930c-46b1-9dd8-0870ef401319": [
            "node_1000"
        ],
        "b531ef76-6b85-4dc2-a295-70afab431021": [
            "node_1000"
        ],
        "035d4064-c6f4-4e99-97b7-2abfa2590703": [
            "node_1000"
        ],
        "5ce6d76f-43f2-415f-b6aa-2eca2f330b5d": [
            "node_1000"
        ],
        "322843cd-d645-4f5e-a617-b57ab46209c7": [
            "node_1000"
        ],
        "b3aa449b-4006-4a03-bd75-cdfd78076d80": [
            "node_967"
        ],
        "2293f29a-fa40-48e4-88d2-3cddeeae23b4": [
            "node_967"
        ],
        "ecff880e-82f1-4602-ac12-b2495ba4e76a": [
            "node_967"
        ],
        "492d24c1-6bc9-4dd5-854b-b309f4b0ba64": [
            "node_967"
        ],
        "ee0bec12-a1b0-4790-a989-811c91c97139": [
            "node_967"
        ],
        "52e795ef-3fb9-4740-a0ca-be69fb39895f": [
            "node_1014"
        ],
        "f6c9e92e-6b43-417a-89a0-7b360c557bd3": [
            "node_1014"
        ],
        "b98fb119-043b-4f0c-a39b-66c203c93dfa": [
            "node_1014"
        ],
        "2d176898-98c8-495c-a5af-ed95c264c38b": [
            "node_1014"
        ],
        "be5600b6-3a2f-4576-98c0-386a33422cde": [
            "node_1014"
        ],
        "8d169e46-7786-494c-8ae4-9e362ec9f237": [
            "node_104"
        ],
        "4c2e6c59-8a99-40ca-9116-dbe8623cec90": [
            "node_104"
        ],
        "234005f6-3baa-47c7-8a47-ac95fefb6795": [
            "node_104"
        ],
        "97240209-c066-4aad-87ab-00617eba6dbe": [
            "node_104"
        ],
        "c32e2298-1c40-433b-8663-7761531b1850": [
            "node_104"
        ],
        "b4cfd89f-97d1-4d27-9418-5479afd042d9": [
            "node_154"
        ],
        "e50afc76-ef82-4d59-abd5-badbfca78f4f": [
            "node_154"
        ],
        "8b19d77c-9edc-431b-a2dc-3e7d844bc9a7": [
            "node_154"
        ],
        "f85ca3d1-a5d9-4245-a5c7-32a9b432214a": [
            "node_154"
        ],
        "2ecaff65-be27-4176-bd2b-a57dbd806aa5": [
            "node_154"
        ],
        "2a3da9f1-b657-49f8-8e0e-5881548a518f": [
            "node_913"
        ],
        "0a3518c6-6721-476e-9893-9e55d924788f": [
            "node_913"
        ],
        "21013e3e-d47b-4198-a777-208bc218d600": [
            "node_913"
        ],
        "9c4d16ed-2b82-40e7-8e3e-4b1f452f9e3e": [
            "node_913"
        ],
        "0b1396d9-c03e-412d-ae95-5fa4f49ee664": [
            "node_913"
        ],
        "7af3121c-c280-4db5-8752-7d33c0612320": [
            "node_913"
        ],
        "be32327b-e1c8-4b89-afed-7d9c39da85cb": [
            "node_913"
        ],
        "97f1685d-e7db-40b1-8579-f9e2a604ec82": [
            "node_913"
        ],
        "833b83f9-a89a-4fff-827b-a48e87c3708d": [
            "node_913"
        ],
        "e733a782-6afa-49fd-abab-bdc3b6f714a7": [
            "node_913"
        ],
        "674c530c-41ec-4e82-aea2-803ed60eb85c": [
            "node_1046"
        ],
        "685ed4bd-6aa2-4896-b3e9-c35f3664499d": [
            "node_1046"
        ],
        "821e1ae9-31cb-4418-a3f2-4eaa00bf456f": [
            "node_1046"
        ],
        "e12c194c-93ef-41cf-8e2e-62219e9833d7": [
            "node_1046"
        ],
        "50b64441-971f-450d-a45f-800a55159e96": [
            "node_1046"
        ],
        "26bd147b-9ea6-4662-9c86-09e52d799ccf": [
            "node_1046"
        ],
        "15629552-ed07-4fba-840b-830933fca477": [
            "node_1046"
        ],
        "c4ab880a-e349-4909-86a6-3a91f00cb9d9": [
            "node_1046"
        ],
        "12956f46-dd9a-41b3-915a-eef9ac235e95": [
            "node_1046"
        ],
        "13e491dc-a634-40ae-8927-0781fc71d29e": [
            "node_1046"
        ],
        "29389e0d-86b9-41f5-82fa-355a80848b44": [
            "node_1076"
        ],
        "0d06f390-d611-4453-bf64-fedf4d2494cf": [
            "node_1076"
        ],
        "e9e784fa-5159-4572-b4fa-29e6362b13d8": [
            "node_1076"
        ],
        "e5a662a4-afbd-475e-8678-60a66116d859": [
            "node_1076"
        ],
        "2579c4ec-de81-45d3-95a8-ee0ff1482e7a": [
            "node_1076"
        ],
        "3acda66b-a858-4753-b543-bc9cbfb704b6": [
            "node_1076"
        ],
        "97895cd2-c309-45a2-9dd7-dff64a4d4f0a": [
            "node_1076"
        ],
        "5e1e7834-c46d-4533-b848-548963f027cb": [
            "node_1076"
        ],
        "da7a3b8d-ff9b-4cf5-a0e5-62db6a8cac55": [
            "node_1076"
        ],
        "4a68df6b-dac9-44e5-948b-80422078c540": [
            "node_1076"
        ],
        "95a14e9e-14dc-49bb-b33c-9325a0b342be": [
            "node_533"
        ],
        "e0be00cc-2ee7-44bb-813c-516df0db2987": [
            "node_533"
        ],
        "aa7323d5-925a-4020-8532-ef122ccc6b87": [
            "node_533"
        ],
        "e62299c0-db6c-42f7-aacc-2c769a2b238b": [
            "node_533"
        ],
        "e03b6fc5-b7e9-455c-ad15-a301d2ba8123": [
            "node_533"
        ],
        "03214314-2cbf-4bf6-917d-39501416d6e2": [
            "node_533"
        ],
        "129da165-1896-4368-942f-c8d9f7b1e6ad": [
            "node_99"
        ],
        "b4182d23-4c87-4129-9540-5147afc82c03": [
            "node_99"
        ],
        "34cb7609-15a2-44d8-b8b4-bfa959f94e38": [
            "node_99"
        ],
        "ea187566-6082-4c3b-a886-d6427e95eff3": [
            "node_99"
        ],
        "78cf3e05-ec1e-496a-a9b8-202051a5d9ac": [
            "node_99"
        ],
        "e0c67068-5eb0-418a-9247-98fa7f34bd28": [
            "node_159"
        ],
        "0106acdc-a88b-4f57-8701-35060a84759e": [
            "node_159"
        ],
        "bf766ad5-dba2-492a-9131-43bff04ddd27": [
            "node_159"
        ],
        "2ff0c11a-498d-4e8f-accf-203913d239d6": [
            "node_159"
        ],
        "173857e5-4293-480b-a65a-753e631f4550": [
            "node_159"
        ],
        "53b6b31d-5ca8-4b1d-8637-6b711eda8952": [
            "node_159"
        ],
        "eb0ec302-ada6-48d9-abd9-f246b63c0534": [
            "node_159"
        ],
        "7398b6f7-da0f-442e-9ad2-fe0e1333cc21": [
            "node_159"
        ],
        "3ac1d9b4-1ed6-4a35-a904-ab48d5fbcaf6": [
            "node_159"
        ],
        "26145583-fefd-4b8f-8753-b688ad505570": [
            "node_159"
        ],
        "66b57110-2b53-4bef-91e6-6c6f38ec7cf8": [
            "node_539"
        ],
        "58d10851-8766-4b7e-8e84-4b264f4acb73": [
            "node_539"
        ],
        "62a7f76e-66c1-4145-bd31-3845e3c38279": [
            "node_539"
        ],
        "82b914d0-5b9a-4649-bd31-6d71103ccbb0": [
            "node_539"
        ],
        "baf66fd5-df55-48f0-b1fa-2c9185cafb7b": [
            "node_539"
        ],
        "8e9de0b9-6aad-4687-a3c9-c31db19a1914": [
            "node_1043"
        ],
        "8c9dee25-cb60-4ae7-9459-18fc71628670": [
            "node_1043"
        ],
        "e3abe9a1-b951-44ef-8043-5e95387973af": [
            "node_1043"
        ],
        "9042f30b-366f-4d64-879f-ed253ea87160": [
            "node_1043"
        ],
        "8bbec35c-dcff-498f-b1e4-cbbac77aa0ec": [
            "node_1043"
        ],
        "97dd7cd5-8f5c-4a7b-a967-bf1533bdb2ec": [
            "node_1043"
        ],
        "514445ea-de7e-49fc-b493-b2212d9a9cd3": [
            "node_1043"
        ],
        "8cd850f5-4b14-46ec-9faf-bb6020be061e": [
            "node_1043"
        ],
        "acb62000-cb95-4e7c-a37a-c918f58c1fa9": [
            "node_1043"
        ],
        "47f57cc4-4f3f-4487-94dd-2d7435ff8691": [
            "node_1043"
        ],
        "7aac1a5b-3827-49b8-a4d5-d99844146efd": [
            "node_410"
        ],
        "c5a780f0-23f5-491f-acb0-34af08a38825": [
            "node_410"
        ],
        "75d6bb7d-4c3a-4472-843a-dbcbb9d3a16c": [
            "node_410"
        ],
        "893a79a1-055d-4541-a9df-57152b9f3717": [
            "node_410"
        ],
        "bc6f8892-6c62-4be1-995b-3b00eba3d4a3": [
            "node_410"
        ],
        "2e84c913-07dd-480b-a21c-2ccec4c3e0ef": [
            "node_20"
        ],
        "9e59c9fa-158c-4d1c-8f88-795962f5978d": [
            "node_20"
        ],
        "95732590-73bf-4b04-b226-c46cb552fad1": [
            "node_20"
        ],
        "febec912-414e-499e-9249-cda12dd78cf0": [
            "node_20"
        ],
        "945efbc6-5e37-431a-a4bc-788b595d0799": [
            "node_20"
        ],
        "e962ebed-88fa-47bc-adcb-78e0ef6ea168": [
            "node_346"
        ],
        "b33e63e9-b3ed-4398-aa25-d65617bcb64c": [
            "node_346"
        ],
        "f8567ee7-d067-4e2d-aa42-f9f59ef842aa": [
            "node_346"
        ],
        "49b72f20-9da3-4e72-a74e-d129e249d06c": [
            "node_346"
        ],
        "424e0786-38d9-4aad-98fc-ffcbafc52bec": [
            "node_346"
        ],
        "f15e1de0-ed46-4818-8143-e19cd5855d3b": [
            "node_1178"
        ],
        "2ecec9c1-2300-4396-851b-bd5ae66152ea": [
            "node_1178"
        ],
        "5b6ffbe2-f775-41e0-94b3-8c05d87db2d5": [
            "node_1178"
        ],
        "52f8679f-1da2-4584-89a4-4262a970bb61": [
            "node_1178"
        ],
        "79b8cb3b-d8a4-46c1-888d-0f3f043ae2e4": [
            "node_1178"
        ],
        "b3e7ec04-077d-479e-a7db-605f8d2202a2": [
            "node_1178"
        ],
        "8b26cfdd-c930-4d36-af25-29d4f15352aa": [
            "node_1178"
        ],
        "d88aa532-b0f1-4b33-9a4b-24e5ccef2754": [
            "node_1178"
        ],
        "3594fc95-0fca-4ba1-a40e-ad6b7ada98c3": [
            "node_1178"
        ],
        "70e3927c-162f-4874-ac63-3b95654b7e51": [
            "node_1145"
        ],
        "838386ef-d5c8-4301-b917-21a87195cf34": [
            "node_1145"
        ],
        "0a3b57e7-b6ba-4257-a643-fe25d631f848": [
            "node_1145"
        ],
        "074cbbd4-3b62-4e11-95f1-d922e215b698": [
            "node_1145"
        ],
        "6c85661a-6c4b-4b45-95a5-09493c547a1d": [
            "node_1145"
        ],
        "ff067bb7-071d-4dea-9fb1-5e8bcf221c39": [
            "node_589"
        ],
        "7b977b9f-7627-4c43-ae4f-d81d84348678": [
            "node_589"
        ],
        "51021452-b763-48d1-bbbd-d1c1ec389329": [
            "node_589"
        ],
        "da416fde-d199-4343-bbc3-ddf151205ef7": [
            "node_589"
        ],
        "acfb1fe5-2881-473d-bfe4-0533dbcff10a": [
            "node_589"
        ],
        "e1c333ab-6811-406b-bc63-b10aa0a5105f": [
            "node_589"
        ],
        "dd6158c1-96eb-4650-8b32-4e0a8ebb0ea8": [
            "node_589"
        ],
        "c2bbdb54-875d-416f-b90e-7eeb1ea5cfb8": [
            "node_1227"
        ],
        "333d1e60-d070-45eb-a480-4c202fa83f43": [
            "node_1227"
        ],
        "deb016bb-d28a-4620-9564-559827eb3841": [
            "node_1227"
        ],
        "944d365c-c355-4d18-90d0-606d416c5d29": [
            "node_1227"
        ],
        "d1ed382d-b10d-45aa-8093-f3430db5ed12": [
            "node_1227"
        ],
        "4811e805-7f8a-48ed-82c7-9bff0610afba": [
            "node_814"
        ],
        "394683c3-e77b-4e39-ab32-154052e539a3": [
            "node_814"
        ],
        "d5c9e34d-ded2-43a5-b6c7-c8638077594c": [
            "node_814"
        ],
        "a899e1d8-1adf-4c88-8548-913f7b4dd478": [
            "node_749"
        ],
        "02bffbe0-63ae-4b6c-8fec-23a4fce6cbfa": [
            "node_749"
        ],
        "218e5e88-d317-4ee8-a63d-132d3b6a3324": [
            "node_749"
        ],
        "aba3811b-55a3-43c2-8b73-aa87e48c7934": [
            "node_749"
        ],
        "7a85271e-2bb5-46ea-8aa8-2d595cdda034": [
            "node_749"
        ],
        "8c48ee48-5a64-4fa8-83aa-841eca29910d": [
            "node_749"
        ],
        "7b01cfa4-a2d5-4d80-b872-1c60357f0980": [
            "node_749"
        ],
        "b99f8347-cd80-4fac-8a56-c8e569657272": [
            "node_749"
        ],
        "26782de3-48b9-42da-9b0f-203013ca5dcf": [
            "node_749"
        ],
        "d6ce7083-f010-465d-b51f-7e9e13032035": [
            "node_749"
        ],
        "3e90b60a-7074-418c-839d-e43e35672560": [
            "node_949"
        ],
        "e6f8d7b1-0824-41bf-84a4-4e478f03a603": [
            "node_949"
        ],
        "4ba8b122-2afb-4f6b-86df-c0ed95cd216a": [
            "node_949"
        ],
        "54593071-c746-41c7-bd85-85cc96f7a849": [
            "node_949"
        ],
        "7db44e33-1ee6-400d-b6ce-346a7ef3c619": [
            "node_949"
        ],
        "f1a4e6e0-b8ad-437c-a61c-77bfaeb24e5e": [
            "node_561"
        ],
        "a1ae3904-8ba3-4a45-ad2c-5084c6272753": [
            "node_561"
        ],
        "5b8ac256-69eb-4905-9764-e19eb4a861bf": [
            "node_561"
        ],
        "6e7885ef-803a-4eb0-912d-65138049882d": [
            "node_561"
        ],
        "1d9743e2-8e22-4e91-8024-c5992c8aecb5": [
            "node_561"
        ],
        "20281e9c-c78f-42c9-9f60-d790f238b583": [
            "node_1154"
        ],
        "63fe02aa-4f1e-43ff-9591-d7e155ce3001": [
            "node_1154"
        ],
        "c1f09cd9-e301-4e72-9066-3545a1f56e26": [
            "node_1154"
        ],
        "7250e3a2-6f98-426c-b2e4-f742b39547d4": [
            "node_1154"
        ],
        "c9fbe0b0-34fa-4c9c-a176-da920ce62042": [
            "node_1154"
        ],
        "26ca30a8-542c-46cc-8963-67c14f32faaf": [
            "node_1124"
        ],
        "df0925d4-c53b-425e-a393-2ef280b2e5e9": [
            "node_1124"
        ],
        "95026700-e108-4c06-b261-6ed84833a102": [
            "node_1124"
        ],
        "b5bdf22e-7652-4f04-91c6-712b1d29674f": [
            "node_1124"
        ],
        "c40ee9c7-0120-4dd2-a913-634f81d34532": [
            "node_1124"
        ],
        "73e50efd-6e87-4c5b-8dbf-0c96f3ad0cf3": [
            "node_1270"
        ],
        "a021f778-c3ed-4bce-b725-3ed80d33406c": [
            "node_1270"
        ],
        "fb16c3d7-8286-4baf-adb0-4c4aa70762bf": [
            "node_1270"
        ],
        "44df94ff-6ead-4ed8-836e-96d11ad6d3dc": [
            "node_1270"
        ],
        "8fde3249-ac39-4ae9-9738-751045904b5d": [
            "node_1270"
        ],
        "51d58000-f4f1-4f7f-88d3-2cd1da3a8b5b": [
            "node_524"
        ],
        "226ca28b-9c5f-4df8-9093-796515074c01": [
            "node_524"
        ],
        "be193e12-aafc-4232-9e79-6510bc793a75": [
            "node_524"
        ],
        "ae55bc5a-c7b1-45a5-93c9-cf3009e169da": [
            "node_524"
        ],
        "4ccc22c0-f8a2-43a7-8629-48359277ee68": [
            "node_524"
        ],
        "413b5221-87eb-41bb-b903-ede80d83da8b": [
            "node_1153"
        ],
        "22de830f-d7ed-4c9b-a9b0-2195b390219d": [
            "node_1153"
        ],
        "5aae7442-27a0-49a4-b55a-9b508064de5e": [
            "node_1153"
        ],
        "f9583e53-6eef-486f-b45c-f06129bba1a8": [
            "node_1153"
        ],
        "a39b3012-4f69-40c8-9e31-919deb66ce35": [
            "node_1153"
        ],
        "8701f1f1-62aa-4e32-bb34-9665b91eb4fe": [
            "node_1153"
        ],
        "1fc29370-8436-4735-ab2d-1031835a3dea": [
            "node_829"
        ],
        "df439aa5-0e5b-485c-9b61-3bdeaac5b746": [
            "node_829"
        ],
        "c6b6d84e-a690-441e-a713-8e27a970e6ab": [
            "node_829"
        ],
        "be4d0693-73ac-465b-a986-24beed47cc2b": [
            "node_829"
        ],
        "5cd1b573-154f-42eb-a751-73abfd440f04": [
            "node_829"
        ],
        "4f5e6072-bb8d-42dd-bdce-ce67acc78e33": [
            "node_829"
        ],
        "7049d1ff-3785-423e-b4d8-a9599f634de3": [
            "node_829"
        ],
        "27833204-ea76-446a-95d9-84cf63b8adbc": [
            "node_938"
        ],
        "a2dc3a97-fbc4-487a-99ea-96fe57d54e92": [
            "node_540"
        ],
        "f50256b4-9ee1-4ba4-bbe6-80614494c762": [
            "node_540"
        ],
        "9d4ca566-6aab-479d-885a-d11597c28720": [
            "node_540"
        ],
        "a289cac3-a7ff-4815-b11f-7d643d4bc96d": [
            "node_540"
        ],
        "c78a4e42-785e-4cfd-9841-5b84eb383ae3": [
            "node_540"
        ],
        "3ddf34f0-b049-4467-8f72-e8b833afd331": [
            "node_857"
        ],
        "8b12dc96-afc1-452b-a4af-cf559b18daf1": [
            "node_857"
        ],
        "fe1b5f9d-c0dd-402c-9125-835b8467ce8e": [
            "node_857"
        ],
        "333004c8-e0dd-4084-b9d5-666e0e4a4180": [
            "node_857"
        ],
        "b3c534a5-9ec5-4603-aac6-1354379a735b": [
            "node_857"
        ],
        "e13822fb-f5cf-4edf-ace0-e26a8048804f": [
            "node_416"
        ],
        "3d73991d-f8f5-4a0d-9eee-ce021564d543": [
            "node_416"
        ],
        "ee23ea98-de49-4322-94e4-f5e9d52fb82b": [
            "node_416"
        ],
        "f7604f89-fc3c-4e38-b3c9-4e60afb7ad39": [
            "node_416"
        ],
        "8cd87101-756f-46a4-8825-27aa10352068": [
            "node_416"
        ],
        "bc087255-2abd-4873-9624-d1511b28f16e": [
            "node_416"
        ],
        "902a7c39-30f1-46e6-8814-8e11f89fd734": [
            "node_416"
        ],
        "99871a4c-c453-4116-a07b-e0edcc4ca923": [
            "node_416"
        ],
        "ff025dbe-a254-4451-bdcd-a1a1d9c14330": [
            "node_416"
        ],
        "ac16da4f-08ee-40c2-b87c-40bae0971f73": [
            "node_416"
        ],
        "fcba74d7-7be0-44e1-a59d-2e9ab73b0711": [
            "node_1165"
        ],
        "02580448-13fa-4861-8657-681ca20adac9": [
            "node_1165"
        ],
        "50ed2c40-3b98-4f2d-a381-ecdd6583c13f": [
            "node_1165"
        ],
        "e2cc864e-2ae3-42dc-b788-91d731d7e667": [
            "node_1165"
        ],
        "55432d19-220f-4ca9-a552-45c09aa9efe1": [
            "node_1165"
        ],
        "bd920f1c-0c0d-4de4-ac6e-6667ea22dc8f": [
            "node_521"
        ],
        "75def62d-d916-45bb-ad28-dc2aca8aea8b": [
            "node_521"
        ],
        "60a431ae-0278-4031-bb2e-8bc5f0c389d4": [
            "node_521"
        ],
        "252ef1e7-46fa-4043-a852-1deb412e067f": [
            "node_521"
        ],
        "b095ac90-7ecf-4315-904a-a8513e4a0ffc": [
            "node_521"
        ],
        "8a15d048-3b31-4f2f-815a-4ce92c694968": [
            "node_38"
        ],
        "293d343b-be5f-483a-9f49-d8aaafbedc6a": [
            "node_38"
        ],
        "864eed27-9fd0-4a49-a3ae-e30656a20b8b": [
            "node_38"
        ],
        "777a6374-16ab-4870-ad51-2f08cbdca046": [
            "node_38"
        ],
        "3a976604-0839-43c2-bc24-bac6de994592": [
            "node_38"
        ],
        "b9b35260-453d-4b9b-927f-16315dbc5c3b": [
            "node_38"
        ],
        "0f9686e6-2fe8-4a77-a2aa-34bc217cd6cb": [
            "node_1246"
        ],
        "f3589321-1765-467d-b6f5-eaf525287811": [
            "node_1246"
        ],
        "00be1277-9e77-4ab7-b7d1-805ee3aaaebe": [
            "node_1246"
        ],
        "89ed02d4-2927-4d9b-985e-af2847659d5f": [
            "node_1246"
        ],
        "8620e969-5e1b-4158-9fe0-bf310b8f8704": [
            "node_1246"
        ],
        "c50db239-a9e5-4ba7-86fb-e152e9348a0e": [
            "node_160"
        ],
        "e0a4d24e-e24e-45f0-bee7-3cf618974ca5": [
            "node_160"
        ],
        "b57a81e2-a602-4f14-ac8d-838da0bf7203": [
            "node_160"
        ],
        "c32f85c0-6f10-4907-b140-9e2e7d189af5": [
            "node_160"
        ],
        "fb81c7a3-23e7-4d07-a6e2-660da3f60930": [
            "node_160"
        ],
        "ecf8514f-19f9-404d-b5e3-4bbb06724b0d": [
            "node_380"
        ],
        "ce8cdf31-dba6-45b8-b409-8295a76152c9": [
            "node_380"
        ],
        "c54aeb37-18b2-4f97-a6d1-5ede7bb22e40": [
            "node_380"
        ],
        "6c867fdd-dc8c-497e-8259-5ff42ddf4c84": [
            "node_380"
        ],
        "7daa1935-e270-44a4-b801-e72d3b9f385c": [
            "node_380"
        ],
        "18a32b21-df99-4755-90ff-fe6f58a4c49c": [
            "node_36"
        ],
        "9b901e49-8e84-4e8c-a1fd-511f559b9792": [
            "node_36"
        ],
        "17930dec-259e-4c4d-8f69-2c8fca37af78": [
            "node_36"
        ],
        "5c16b2f2-24cb-4b9d-95aa-b27742f35734": [
            "node_36"
        ],
        "2c4a4ffe-8807-4dc1-b489-e79f4ec058f7": [
            "node_36"
        ],
        "404c1729-a7c0-4f05-ba07-2875b32a7020": [
            "node_215"
        ],
        "d17f4daa-cdf8-4a20-b378-f8a5bf8251f3": [
            "node_215"
        ],
        "15fe43a8-3363-42b2-be40-669456037a9f": [
            "node_215"
        ],
        "54ff0b2a-890e-4d01-bcbd-9382bdf71f00": [
            "node_215"
        ],
        "5e4ac249-6d68-44bf-ae5b-3e1f9abb9a30": [
            "node_215"
        ],
        "51282e86-a3b7-4117-b3a2-9bbfddb4cda4": [
            "node_1036"
        ],
        "5990eee5-1920-4bf4-a240-ebcf3bdb6401": [
            "node_1036"
        ],
        "42e053db-7668-49fe-81a4-6a488d5a65f0": [
            "node_1036"
        ],
        "7a3e788b-0288-4d1a-afeb-da30bd9558a4": [
            "node_1036"
        ],
        "95756de4-a896-4216-b443-913be829e435": [
            "node_1036"
        ],
        "340704dd-440c-4b75-b4e6-37193a0fd14f": [
            "node_1036"
        ],
        "9426e5c1-1a60-430b-b14d-ed123342201b": [
            "node_1036"
        ],
        "f2341afe-f7ce-4fdb-8846-da800fc0d591": [
            "node_704"
        ],
        "f82118dd-9df3-4b1c-9a57-7402d2f4c881": [
            "node_704"
        ],
        "c951c45c-abf9-4721-982d-01628e8454ab": [
            "node_704"
        ],
        "e545fd8d-c3bb-4c40-8a77-550038561d60": [
            "node_704"
        ],
        "de8102dc-ca3e-49ab-9efc-a8a45198f147": [
            "node_704"
        ],
        "40852c11-651f-4a5b-b411-859d856c1f3a": [
            "node_876"
        ],
        "0ae6efcc-29cb-4ca6-b960-4b2c5780fa55": [
            "node_876"
        ],
        "f88e6168-f707-4549-8fe1-d7b73ea26298": [
            "node_876"
        ],
        "99324f8b-b127-48a1-8dcf-d35cd1fe5b42": [
            "node_876"
        ],
        "4a60abdc-ed7d-4531-91b0-264afa97f27d": [
            "node_876"
        ],
        "cadcfba8-39c0-42cf-9f63-91c1aacd13f0": [
            "node_247"
        ],
        "e4b272e7-200a-4cea-8ed3-a4cd40510044": [
            "node_247"
        ],
        "d71c25cd-ec42-42f4-9faa-00c521708e4a": [
            "node_247"
        ],
        "0758d775-e836-4274-b693-a5224de02b75": [
            "node_247"
        ],
        "7851548e-e8e1-41ab-9790-71ba9d1de233": [
            "node_247"
        ],
        "cc287698-0638-412b-aaae-7ee5c831891a": [
            "node_1071"
        ],
        "319a40e3-eeae-4c8a-aaa5-27b2bb09cb1c": [
            "node_1071"
        ],
        "f7b7cc82-f59b-4504-a2bd-c73fe7370519": [
            "node_1071"
        ],
        "a3f8fd4d-1d47-4c45-8cfd-57ace072db6d": [
            "node_1071"
        ],
        "8e396de9-2785-4474-8769-d20325b3b04b": [
            "node_1071"
        ],
        "6fe4fc60-aaa2-457a-9b68-247ad224480f": [
            "node_1031"
        ],
        "ae760ed8-8bd5-4be3-a19a-14edbc8e00f7": [
            "node_1031"
        ],
        "826350dc-41d7-4847-8893-2cdd47331d0f": [
            "node_1031"
        ],
        "7ae8a21e-5cc7-4c7f-a349-b9fd9bb6bd2f": [
            "node_1031"
        ],
        "7d1c4548-362c-431c-b845-e923ea243602": [
            "node_1031"
        ],
        "e9e164c4-bc17-419a-98a2-d62651e348bc": [
            "node_637"
        ],
        "f14fec48-91bb-445c-8156-c388427b0d99": [
            "node_637"
        ],
        "c8034dae-9265-498e-a415-e527850e3362": [
            "node_637"
        ],
        "b7e2d649-a2ca-4055-bffe-1210c220ef33": [
            "node_637"
        ],
        "89e96e54-c853-454d-be65-f491d4afb254": [
            "node_637"
        ],
        "f90fb66f-0d24-45be-b6be-e16c1b1268fc": [
            "node_53"
        ],
        "24aff881-b3fb-44e2-a653-6e75449ad1f1": [
            "node_53"
        ],
        "37ae4088-e383-4c18-bc7a-5443b7c59119": [
            "node_53"
        ],
        "7181b11a-6f3c-42a1-9a15-1f8cd56207ed": [
            "node_53"
        ],
        "aff3378e-4f12-4c3e-8911-731d859f5867": [
            "node_53"
        ],
        "d9ddad03-1188-4b47-9c9f-2a1099a68906": [
            "node_742"
        ],
        "4fb68e58-ae1a-468a-9f6e-7b3fb92f747c": [
            "node_742"
        ],
        "b855ce85-1b91-4a74-aad7-493fe511d308": [
            "node_742"
        ],
        "c81ac613-0709-487b-a65c-47cf1e6a4784": [
            "node_742"
        ],
        "3ad11c83-c55b-4f37-aca3-be19abc548f8": [
            "node_742"
        ],
        "6aa5dc1c-5b59-4f9f-bddc-18966a30619c": [
            "node_742"
        ],
        "004842f0-ad31-47b2-a0db-755306a638ee": [
            "node_742"
        ],
        "82d50244-94b7-4515-aec5-4aff4907664d": [
            "node_742"
        ],
        "f0f765b1-9ca7-4f3a-82a7-ad58ab1c3dc5": [
            "node_736"
        ],
        "65887465-8608-4e87-87f5-1d4eced2c9e2": [
            "node_736"
        ],
        "bd9a2916-90ab-4257-a88a-851eece40330": [
            "node_736"
        ],
        "990e9cae-c4af-4a90-81d1-c76b98a78846": [
            "node_736"
        ],
        "a31f73f6-fec4-4245-be82-b71473ca4547": [
            "node_736"
        ],
        "39d98dee-4aad-41c2-84c3-f37e6029d88c": [
            "node_1005"
        ],
        "634e9559-02d7-42a6-9624-051e29e5e094": [
            "node_1005"
        ],
        "d3c21f53-8c04-44fa-9494-cae604cef812": [
            "node_1005"
        ],
        "454c0bcd-a913-4894-b553-bc8c11371413": [
            "node_1005"
        ],
        "bfea4385-66ac-4a1f-ad87-4d3529734bb8": [
            "node_1005"
        ],
        "815e1770-a9d9-472b-bc5c-194d74a03c47": [
            "node_980"
        ],
        "83a7d63f-f271-43f2-8c33-62dea6f7e8ee": [
            "node_980"
        ],
        "f99fd4a4-6bcb-4d1b-8db9-cafe793f57be": [
            "node_980"
        ],
        "e59b061a-e56d-4180-b602-b81c4efd4a7f": [
            "node_980"
        ],
        "3b4bc569-f5e9-4850-be11-4d8fdec5801d": [
            "node_980"
        ],
        "bf7182f3-0237-4e67-bac1-a3b267cab352": [
            "node_980"
        ],
        "e8d0d287-f7e5-4061-9812-ba49870ec5d7": [
            "node_64"
        ],
        "14021f40-ff52-4f04-96d7-f71df75eb16a": [
            "node_1305"
        ],
        "9ad1629d-fedf-4b79-a2a5-59ec0ee2df8d": [
            "node_1305"
        ],
        "e44c859b-d9e8-46bf-98fc-c9826f47a6d9": [
            "node_1305"
        ],
        "b377426b-37de-4041-8ce1-d2f2c7779396": [
            "node_1305"
        ],
        "e2e6ace0-55e2-4af2-b056-0bd92380143f": [
            "node_1305"
        ],
        "78a1740e-5080-4eac-88a0-fc1d9795ff3c": [
            "node_289"
        ],
        "0cfe1b52-ea54-4555-8904-06f04af8e652": [
            "node_289"
        ],
        "f499a663-c08b-42b8-9289-a195a75b93b8": [
            "node_289"
        ],
        "8203f30d-7764-4ee1-8f68-31b946117e92": [
            "node_289"
        ],
        "298a59c3-244f-4e01-9899-f62187e00710": [
            "node_289"
        ],
        "df24587c-0ce1-479d-84e8-2f4b0b66f6d2": [
            "node_894"
        ],
        "b9492c3d-24ea-41da-889f-40878c7e9377": [
            "node_894"
        ],
        "41be5f94-83de-4e97-a824-189643f92943": [
            "node_894"
        ],
        "9a7e8628-bb7a-4094-b6c6-a916a503d174": [
            "node_894"
        ],
        "4975b983-ed46-4239-8ada-70f2cdc14d33": [
            "node_894"
        ],
        "29a9f80d-a853-427a-a515-9127bb7e3edb": [
            "node_894"
        ],
        "f872a269-a254-4546-9f92-0273e1f598b3": [
            "node_894"
        ],
        "49384e61-8454-4cc6-bc75-867269ef9955": [
            "node_894"
        ],
        "e8421dc8-5f2c-4328-880b-f85ca329e13c": [
            "node_894"
        ],
        "ad4bb9d4-1941-4c36-a5e0-0eb5f5f87a86": [
            "node_894"
        ],
        "0ef28e9e-6d28-480a-a8d5-d0e6e01a102e": [
            "node_532"
        ],
        "ca732932-e4b8-4fe3-a38a-6fc427dabd33": [
            "node_532"
        ],
        "2e3d7c5d-a2a1-4057-a3d4-5eaf755255ce": [
            "node_532"
        ],
        "e4aed332-e3ed-4269-b691-a7aaad7355cd": [
            "node_532"
        ],
        "f5137b71-e910-4f0c-b710-9fe1b666b5cc": [
            "node_532"
        ],
        "7b88a9d5-328c-4007-99f8-68d2cf7c6933": [
            "node_835"
        ],
        "f165b53e-1b38-4c6e-a612-dc4824cd8286": [
            "node_835"
        ],
        "3262d31e-fb58-477e-8de0-e1c4bfde1449": [
            "node_835"
        ],
        "6864a7f8-4596-4c31-a4a2-58f422ff3f36": [
            "node_835"
        ],
        "d53bd163-e3fe-431d-b19c-0a5a964018c5": [
            "node_835"
        ],
        "865dae40-b4c9-4807-81c8-8edfbd691cb0": [
            "node_140"
        ],
        "c9792c42-9a51-4b30-9c1c-b4761b5fbd67": [
            "node_140"
        ],
        "3547a8a8-db5f-4c09-a214-40a2762b52ee": [
            "node_140"
        ],
        "e6109efe-3f77-4b61-bad3-f4cb69c16b8d": [
            "node_140"
        ],
        "5756a152-197c-4714-8e7f-36edd3a7c77c": [
            "node_140"
        ],
        "d5e4eb86-71fa-4adc-a37c-ead9c5aa14ca": [
            "node_140"
        ],
        "138831ef-ad23-4081-b0c4-ca27bfa87de9": [
            "node_140"
        ],
        "b851f6b6-0977-48d1-a3eb-f3360c93994c": [
            "node_140"
        ],
        "265cdc86-bc03-443b-bb0c-3a4134750247": [
            "node_877"
        ],
        "73a2f17e-1521-4be0-9655-ac38630574da": [
            "node_877"
        ],
        "02a23b68-75bc-4b11-850f-8f537dc6d842": [
            "node_877"
        ],
        "4d602e87-c958-4513-82e2-25bc6bdc8f61": [
            "node_877"
        ],
        "3b390112-b3b3-4548-a17d-563aa40228e6": [
            "node_877"
        ],
        "e3d96d60-0fa9-49b0-b8f4-873275d3fd66": [
            "node_54"
        ],
        "2701008a-6c9e-41d9-8de4-7b28e80d1dc9": [
            "node_54"
        ],
        "ee201951-926e-4576-8fa9-22680b347512": [
            "node_54"
        ],
        "caaff8cb-b219-4c01-b2d7-033f0f58407b": [
            "node_54"
        ],
        "01205ab8-b399-4180-b9e3-5c199c9a48da": [
            "node_54"
        ],
        "7b7e619d-3d7c-4787-a3a2-15cff47952d4": [
            "node_1213"
        ],
        "f6a15e13-b2a5-49d1-b22c-57168c179ba3": [
            "node_1213"
        ],
        "48f8996f-3c10-4b2d-8adc-d2132cf7ee95": [
            "node_1213"
        ],
        "cf3bb0c0-1cf2-4e9a-8b98-20f0d1e75b5b": [
            "node_1213"
        ],
        "58423ec3-7ea2-4a9a-b7d3-88f2e6d1cb01": [
            "node_1213"
        ],
        "4948c4ff-5d97-4faa-8722-b2d8589b9000": [
            "node_1213"
        ],
        "9931d469-77d6-4f30-9921-5f9e0f3eb528": [
            "node_1213"
        ],
        "036283a2-630d-4891-b2bd-ec2eeaff2dd6": [
            "node_1213"
        ],
        "82f23b2f-07e1-4ac0-ab1a-9235d053060f": [
            "node_1213"
        ],
        "d9f7de7e-be65-4da6-be58-47f24e098ff6": [
            "node_1213"
        ],
        "f114623a-e607-4ae2-b3a6-775b66e31ebf": [
            "node_611"
        ],
        "e1176e60-d44f-46c9-aa65-45b5633221c7": [
            "node_611"
        ],
        "ee4d5ad1-b346-4f76-a09f-b64394915118": [
            "node_611"
        ],
        "c0ebf6ed-d446-446b-9265-25423117b31e": [
            "node_611"
        ],
        "eeb6277e-e511-4ce6-b120-8ceae14fcaec": [
            "node_611"
        ],
        "9aeb0526-b061-4b14-81de-95d5b5936bfc": [
            "node_419"
        ],
        "75f80c43-d539-4d03-baa1-f1e075bc5d4d": [
            "node_419"
        ],
        "6fdc9094-5237-4260-b943-e6cea361c54e": [
            "node_419"
        ],
        "bd8c4cc9-5585-43aa-9c7b-db273da8d655": [
            "node_419"
        ],
        "b8430735-eb9f-4ad5-a022-2510ff48324f": [
            "node_419"
        ],
        "79341e72-e9aa-4d5f-9415-ae965445e000": [
            "node_376"
        ],
        "6f578d13-6c23-47fe-902c-928dc22e7404": [
            "node_376"
        ],
        "923f99de-8e3b-444a-a1ea-b36f21f299f3": [
            "node_376"
        ],
        "721fdc89-dd88-4f0b-9005-4980dcc41719": [
            "node_614"
        ],
        "1a245be4-c91a-4132-b3ae-c8962fe28647": [
            "node_614"
        ],
        "9cf6487c-6310-4b6c-8c62-f0a3ac6d4eb7": [
            "node_614"
        ],
        "646125aa-a10c-40ef-a7e3-8787fc8b4a68": [
            "node_614"
        ],
        "bd35af4f-f332-4d53-be81-1f8e9c08455f": [
            "node_614"
        ],
        "ef338735-bc7d-4916-955c-129f44660881": [
            "node_1261"
        ],
        "809e5391-2ada-410e-9670-c2c2bd1c4e1f": [
            "node_1261"
        ],
        "c599a801-a7de-4799-b074-363a4644413b": [
            "node_1261"
        ],
        "2510ff2e-5b18-490d-8db9-6745f74b59b1": [
            "node_1261"
        ],
        "cb3916fc-e9ba-4993-9010-30592afd6b6f": [
            "node_1261"
        ],
        "c13b1cf7-2b92-4f72-8fa3-727f043e4425": [
            "node_1040"
        ],
        "1b34281b-0952-4618-8187-bed721a8b366": [
            "node_1040"
        ],
        "3603e5dd-1283-414d-8b02-1c46239d10db": [
            "node_1040"
        ],
        "7bcd63a3-8efb-43e8-a1db-0c50afcdb481": [
            "node_1040"
        ],
        "eef4843d-917f-4041-8775-db72ad69fb36": [
            "node_1040"
        ],
        "f0bbdadf-d7cf-4393-8c6b-3487ab12bb33": [
            "node_1210"
        ],
        "e1fdad41-bba1-4faf-b867-2af11b8d6b27": [
            "node_1210"
        ],
        "b2eebb41-8812-46eb-8cce-5745c1a2e24c": [
            "node_1210"
        ],
        "c75200b6-91c1-4350-ad0a-f429204bf9e2": [
            "node_1210"
        ],
        "4057100c-9504-4a65-b577-e4c8ed08f097": [
            "node_1210"
        ],
        "8ed92c2b-fec0-471f-bd3c-730d90376a12": [
            "node_1210"
        ],
        "38c58bdb-43fe-4bd7-b5c8-d4813a1134a1": [
            "node_1210"
        ],
        "9eff9718-2604-41ec-8239-34478c4906ba": [
            "node_1146"
        ],
        "e61c6b61-9901-4e88-81dd-e4a6a8e169d9": [
            "node_1146"
        ],
        "5d88bfe8-c30a-4bef-a889-cee881f49979": [
            "node_1146"
        ],
        "acc07a60-ae1e-4846-858a-97af2fac6c1a": [
            "node_1146"
        ],
        "0d7a40b8-d257-4f0b-9de6-51b0ec30e73f": [
            "node_1146"
        ],
        "be4c728a-f053-4c46-a950-3069f7ad0082": [
            "node_1294"
        ],
        "5b46cabc-9803-43cd-9402-1da52c8192a0": [
            "node_1294"
        ],
        "43371348-e4b1-407d-8f0c-f0a2985d6b31": [
            "node_1294"
        ],
        "199bbd06-181a-4c29-97fc-002b9ec8307d": [
            "node_1294"
        ],
        "928b516c-4c1b-47e6-a75e-6c69db431adc": [
            "node_1294"
        ],
        "84450a24-77bf-4861-ae2c-d8a30449947c": [
            "node_1017"
        ],
        "014e023a-f60e-4f19-962e-b999003f0a13": [
            "node_1017"
        ],
        "a0a90225-a195-44ad-8a6a-0d74195aa4e6": [
            "node_1017"
        ],
        "bee03ddc-5163-49cd-bfc7-62857db465e4": [
            "node_1017"
        ],
        "f6be7501-c4e0-464b-8bd3-2e22269af789": [
            "node_1017"
        ],
        "b129905f-fd53-440e-bb5b-490dff1ba056": [
            "node_233"
        ],
        "a25d42c1-b027-43d4-8c3a-78cce4e94c27": [
            "node_233"
        ],
        "394ef68b-9034-482d-a08a-e5484919b3a8": [
            "node_233"
        ],
        "2dc9ea57-9834-4a94-ba03-8a17b9e46512": [
            "node_233"
        ],
        "5ef02930-eff4-449e-9f7e-66613b3e95d2": [
            "node_233"
        ],
        "1f4d0251-ff5a-4246-bd3e-ffa0a952ac7f": [
            "node_1314"
        ],
        "851fdfcc-5549-443c-b11f-05d857045d16": [
            "node_1302"
        ],
        "3a66a4d6-5571-42bc-8448-7c7bda950163": [
            "node_1302"
        ],
        "5db0471a-08ec-40e9-b84c-6606b4d07000": [
            "node_1302"
        ],
        "e1512f72-8e04-435f-af00-36518009ab66": [
            "node_1302"
        ],
        "697d34bc-42b3-4c62-a6e6-776ea8b23b26": [
            "node_1302"
        ],
        "a4465ba3-6178-47e1-afc8-75e3e708f61e": [
            "node_235"
        ],
        "187cfcfa-793e-4201-9102-33515b1986ff": [
            "node_235"
        ],
        "1463a0a9-a48e-4eee-a16c-2a4221eab9c4": [
            "node_235"
        ],
        "2bba8273-6e91-4430-818a-589edcebcb23": [
            "node_235"
        ],
        "f1345d34-3fca-4dbb-9e05-e0871da955e0": [
            "node_235"
        ],
        "a34bd753-5802-4a87-98c2-d8972ad84d54": [
            "node_235"
        ],
        "d89f775e-1ec7-42fd-b9c1-c0002589cb75": [
            "node_235"
        ],
        "0da9b6bb-92b7-4370-9dc9-76c98fb194c1": [
            "node_235"
        ],
        "ed38c093-c38f-4393-a9e4-8822cd8f4e05": [
            "node_235"
        ],
        "e74f1287-2b93-4e3b-a0ce-afd88fce4429": [
            "node_1111"
        ],
        "19b7c34b-ca99-4da7-87cc-02c2e8bb1293": [
            "node_1111"
        ],
        "4c7a79c3-16ba-4b97-be78-24d5fd33cf73": [
            "node_1111"
        ],
        "59d78e9f-7763-4bdf-b269-72e6ea0c5f82": [
            "node_1111"
        ],
        "1430ce23-54a4-4e30-b0f5-b595728c9ded": [
            "node_1111"
        ],
        "9b16db98-3906-4205-9483-152bb6d5fab1": [
            "node_46"
        ],
        "700b7bfc-c0ac-4249-87d0-18500a75ebc0": [
            "node_46"
        ],
        "322be874-c84b-4113-a234-397f481a7bbb": [
            "node_46"
        ],
        "18a0cadd-5a98-4c14-8f8d-47e93096fc7b": [
            "node_46"
        ],
        "5d76272b-7141-4e90-b799-c6afde90831f": [
            "node_46"
        ],
        "d71ad1f1-2272-48fb-bd0d-bf65596f9b13": [
            "node_869"
        ],
        "30c99b5b-0c98-44fe-8ca0-715bdbfd8332": [
            "node_869"
        ],
        "1f30f314-ddf9-4886-aaa6-cfff29d1d2fb": [
            "node_869"
        ],
        "963cd275-c398-404d-bbee-d3ba63e231f4": [
            "node_869"
        ],
        "2c511ba5-b6a4-4f63-94e2-69c7cb1a015a": [
            "node_869"
        ],
        "3395a2de-8d3b-4aad-a2de-138bc087fb0f": [
            "node_1032"
        ],
        "1a740a7d-d4fa-4491-987e-5ada1e6dd6cc": [
            "node_1032"
        ],
        "7f0fdaf8-8bc3-4d13-8b8a-c96a208d29b9": [
            "node_1032"
        ],
        "42802a9f-dc61-4a5b-87c8-bf9083522999": [
            "node_1032"
        ],
        "f890b489-0b3f-4a84-8196-b27fa753440d": [
            "node_1032"
        ],
        "394e0868-e80d-41ca-b614-f26d2a15b90b": [
            "node_867"
        ],
        "bfa06ef0-5450-4f93-b9e9-7720bf54138f": [
            "node_867"
        ],
        "06cc80aa-8b78-4bef-bc8f-a0023b1d1316": [
            "node_867"
        ],
        "133aed69-d45c-44ce-a719-2f769de6341c": [
            "node_867"
        ],
        "443f27b5-53a8-40e8-9a53-92294234ddbc": [
            "node_867"
        ],
        "7ad4b428-42f5-4378-9c6d-807f7b445804": [
            "node_867"
        ],
        "5200eb9b-2761-469b-98be-e39141cf63cd": [
            "node_867"
        ],
        "6b1ac39e-d058-483d-b2b3-6abbdde48cbf": [
            "node_867"
        ],
        "a0bf4377-ba35-4874-b2f1-e0ee7dfc877a": [
            "node_867"
        ],
        "8db878db-525a-42ef-9229-b4ff70e6cbc3": [
            "node_867"
        ],
        "e7a3143d-7e90-470f-a518-e8bb561e1311": [
            "node_699"
        ],
        "9286f33d-f1cd-40fb-86a8-7794a3ed1fe5": [
            "node_699"
        ],
        "c8572580-2364-4c40-ac03-15697390836e": [
            "node_699"
        ],
        "0f58c909-4644-4fa4-aaca-790c28ce2266": [
            "node_699"
        ],
        "45eff6ef-4528-41a5-9cab-c060ec2aa1cf": [
            "node_699"
        ],
        "8d38ae88-fe5b-4740-91be-73c606706e45": [
            "node_240"
        ],
        "ab804177-55d9-4028-a0b5-327e791e5fba": [
            "node_240"
        ],
        "4344f222-69c6-440b-af20-1a572475dd90": [
            "node_240"
        ],
        "6cbaac2d-9b44-4471-b8f1-e52dba1388f1": [
            "node_240"
        ],
        "f278438b-a0e9-4aaf-bd4b-00648560abcf": [
            "node_240"
        ],
        "920fa3d9-a810-4aa2-859e-aa35dc2b9a69": [
            "node_471"
        ],
        "53beffa1-f807-4081-9a01-9f7649bae8d0": [
            "node_471"
        ],
        "472e59f9-e481-41b6-b211-abff2f75d94b": [
            "node_471"
        ],
        "2f79aa9a-84c7-4422-84d9-29635669992a": [
            "node_471"
        ],
        "470ab3f8-949b-44c6-8ff2-dec5dccd30b4": [
            "node_1285"
        ],
        "7e7b88dd-9590-494a-ba6c-3cdb07b2769f": [
            "node_1285"
        ],
        "aa40dc8f-2679-475b-a9ed-fbb56e259dba": [
            "node_1285"
        ],
        "823c325a-cf28-40ad-8cc4-5c58b4b320d5": [
            "node_1285"
        ],
        "f290918e-b986-44a3-b43b-4de0dd8eeedd": [
            "node_1285"
        ],
        "0de446ac-84be-47f1-92f2-ccffb38f8d8d": [
            "node_348"
        ],
        "f1ca65bb-f94b-4aba-b370-9fec35f7fea1": [
            "node_348"
        ],
        "1e65eec3-c2fb-4ca3-883e-4f82adc65646": [
            "node_348"
        ],
        "7a484355-3ecf-42ea-b2a4-ea6d3eab548a": [
            "node_348"
        ],
        "3f2583e1-5344-4bc5-bfb6-32f37e8c06f0": [
            "node_348"
        ],
        "d4164f0d-bc6b-491f-9d66-8e46f74eebf8": [
            "node_224"
        ],
        "044c416e-8e0e-4f07-a611-a5623b9e925a": [
            "node_224"
        ],
        "e1e3f02e-1062-429f-9b28-86c036d6b5d3": [
            "node_224"
        ],
        "7e6cdfea-111e-47cd-b657-e1eeeacf5995": [
            "node_224"
        ],
        "f20dd66e-0711-4d04-a8be-8ebdba1065ae": [
            "node_224"
        ],
        "8fc7d6f6-2232-4ebd-9a71-b508bfcad15f": [
            "node_1023"
        ],
        "e26f1f91-7709-4841-bf68-9adeb2d09521": [
            "node_668"
        ],
        "f9d70b5d-7812-4167-ae62-9190c5f616c6": [
            "node_668"
        ],
        "90474971-9ba3-4ad4-9d69-100033441590": [
            "node_668"
        ],
        "c29073f2-a52a-4fc0-9efc-3595326b8c33": [
            "node_668"
        ],
        "6ac4e69e-696f-4994-a70a-5b8f149ecac0": [
            "node_668"
        ],
        "54eca9a5-81ae-43b4-8ddc-744c9ab2e324": [
            "node_278"
        ],
        "0e5d698d-9e26-492d-8a62-2d24f6d3055e": [
            "node_278"
        ],
        "63ec9631-b26d-47f0-9a76-9efdb110ac8c": [
            "node_278"
        ],
        "9c6cd520-13fa-4957-8b0b-49bbe87a1a59": [
            "node_278"
        ],
        "78a27a7b-0f59-450d-bff7-f64ec0b58de6": [
            "node_278"
        ],
        "0b4c4166-3fe5-47af-a871-a4b86d0b986a": [
            "node_187"
        ],
        "24ff76f4-4aa2-4be3-af4b-e3f33c35dbf0": [
            "node_187"
        ],
        "d8f92878-5b28-42d0-a23c-03eb699ccc74": [
            "node_187"
        ],
        "8a457f7c-6239-46cc-becc-d10d4c18580d": [
            "node_187"
        ],
        "9e139f35-b65d-46e0-a92c-4e8bc6d690e9": [
            "node_187"
        ],
        "0915bdbd-176a-4416-ae94-6671ccc9fcac": [
            "node_187"
        ],
        "f638150f-649a-474c-9bf7-35adf76ce353": [
            "node_187"
        ],
        "25f22e4e-24fc-4e65-9445-3005f887d6da": [
            "node_187"
        ],
        "8d157361-d837-45d8-9357-91b4336d6b49": [
            "node_187"
        ],
        "37f09d82-efa5-4ad7-98c6-217970f02955": [
            "node_187"
        ],
        "e5042dbc-7030-483b-b394-c5444b984e37": [
            "node_211"
        ],
        "c2a99ce6-a9c0-4875-b78f-5a2d2b13e5ac": [
            "node_211"
        ],
        "192f91d2-cdae-4ead-a6df-5faa32451b76": [
            "node_211"
        ],
        "a4009eec-6163-4dfb-b8c2-0e7213e8d1b8": [
            "node_211"
        ],
        "39e6bf73-526a-4c02-a76c-d0101cdb0c9e": [
            "node_211"
        ],
        "7a473da2-4f5c-4bdc-be75-d00e650ed49e": [
            "node_68"
        ],
        "1132dc4c-fd0c-44dc-90a6-4b88cc37c519": [
            "node_68"
        ],
        "d448f9d7-0000-4584-a039-e82166997079": [
            "node_68"
        ],
        "872ee725-a305-4d9d-a922-83942fc00927": [
            "node_68"
        ],
        "90b794b3-a0bb-4dd1-ae02-480e8165fb2d": [
            "node_68"
        ],
        "01ab283f-42fb-4805-9be4-23c2937b6211": [
            "node_68"
        ],
        "ad84f19d-1108-4f84-b1b1-cd5cb436b6ed": [
            "node_68"
        ],
        "d071206c-29f7-45b5-a7e1-ebb2180ed660": [
            "node_68"
        ],
        "29fae014-27c6-4705-8ae1-145b767b4ae2": [
            "node_68"
        ],
        "a26c2c4a-6f49-48d9-b4a5-bcb95ec013e2": [
            "node_68"
        ],
        "8187550b-3838-44c3-b2d6-fe439f6db414": [
            "node_1185"
        ],
        "b02141b1-3af8-453e-81e8-bbd0769b4f19": [
            "node_1185"
        ],
        "aaff198c-654b-4133-a548-a7e16b5e3a0f": [
            "node_1185"
        ],
        "6f30bce3-5d8d-4322-a2e5-f9eb95b17aca": [
            "node_1185"
        ],
        "93125d89-b1b2-4e29-a145-e1506cb59a56": [
            "node_1185"
        ],
        "c830d07a-37d9-4253-9720-1c8f50c609cb": [
            "node_1297"
        ],
        "0d117c4b-3453-435b-a073-c6445493f238": [
            "node_1297"
        ],
        "a6d2ad53-d534-4dba-8fe5-a3265ddb75f2": [
            "node_1297"
        ],
        "2f5c30f9-a819-472e-a245-a561e7106bb2": [
            "node_1297"
        ],
        "6730f103-94d4-49c2-94f9-1c41f5c76a11": [
            "node_1297"
        ],
        "974aa1ab-11c0-47c4-8bfa-e9e4094fa99a": [
            "node_1297"
        ],
        "52286277-a34b-402d-990d-99ee5c5cf58f": [
            "node_1297"
        ],
        "61d1d31e-2d9d-45d3-9806-5cfc575094d5": [
            "node_1297"
        ],
        "e6ce451d-883f-4303-b97e-a465323747ac": [
            "node_1297"
        ],
        "dd04149d-fbf0-444b-8abc-b48ffdc8280a": [
            "node_1297"
        ],
        "44264ac5-d899-4e0c-879a-b6bec5e83813": [
            "node_490"
        ],
        "af2f761d-8427-4fcd-835a-ee6776a3c6e6": [
            "node_490"
        ],
        "941e995d-1970-43bb-8a4a-cccae6442561": [
            "node_490"
        ],
        "3852d383-8b2d-41e0-91fc-28fdbceb2312": [
            "node_490"
        ],
        "08ccd921-67a1-4607-aa0a-5c69ed8385d1": [
            "node_490"
        ],
        "f07ae3e7-01cf-4a6a-851b-5c5afec4914a": [
            "node_490"
        ],
        "d9c3ecaf-878f-4df3-9a22-b0674fa80603": [
            "node_490"
        ],
        "8c4a704d-c50e-4a12-8081-59407c46f875": [
            "node_490"
        ],
        "d5e4cdf6-a832-46b0-8a73-7eb4894a0bcf": [
            "node_1216"
        ],
        "26853523-ba09-4497-a9f7-99846d5d0b0d": [
            "node_1216"
        ],
        "6674429d-6969-4ea2-853b-2f12581ae88c": [
            "node_1216"
        ],
        "2f19dc16-c830-4100-a0f9-68932ce53359": [
            "node_1216"
        ],
        "2be91189-0415-44f6-9fa3-82eb75ed9163": [
            "node_1216"
        ],
        "64d939a5-595b-4b8c-a50f-99b2e9d5d5aa": [
            "node_1216"
        ],
        "223b243e-e845-49ca-a2c2-a84899623cac": [
            "node_1216"
        ],
        "8f1ff53b-b781-4ff4-ad0b-5cc37e760464": [
            "node_1216"
        ],
        "2c5a529b-bf35-44b5-becc-07dbe2fe64e8": [
            "node_1216"
        ],
        "a24a0d75-f94e-424c-bd01-e9c9d5328a3f": [
            "node_364"
        ],
        "ddb66a36-7452-4c0d-8895-d5b58bc89768": [
            "node_364"
        ],
        "edf8cfee-e614-45ed-8a58-1960fdb232bc": [
            "node_364"
        ],
        "e3d9ee90-1a5d-4323-aed2-ffa6bbec7465": [
            "node_1002"
        ],
        "863f817a-860f-4028-b4d5-ecc4c3033280": [
            "node_1002"
        ],
        "d346ef9a-aa30-46d4-8f66-9c9aef2a5fae": [
            "node_1002"
        ],
        "b0e54e0b-eb6a-47d5-99ab-e30555a37908": [
            "node_1002"
        ],
        "6765c07b-a6c5-495c-aa09-5c7bdc2cdca2": [
            "node_1002"
        ],
        "7e30f233-1167-4714-976c-e49099a14097": [
            "node_632"
        ],
        "ee540278-99c3-4997-b3e1-a0daa8c512fd": [
            "node_632"
        ],
        "0f5898e5-aa6d-4e9d-878e-37c7ca3f1e49": [
            "node_632"
        ],
        "fcdfe002-5ca3-4ee0-96f6-a78c8d05bdb1": [
            "node_632"
        ],
        "da54099f-34ff-46c9-a870-fb8f97a64a1c": [
            "node_632"
        ],
        "b7655e0b-1c77-4e1a-b4e4-21006c01c977": [
            "node_632"
        ],
        "8d919a54-5dd3-4628-a8ec-d0907d368973": [
            "node_632"
        ],
        "a6087081-d89a-4e42-b9bb-437c01164e5a": [
            "node_632"
        ],
        "97364086-693a-4fdd-82e4-cf9dd0e2723f": [
            "node_632"
        ],
        "b7e1a3e7-c4bc-4923-83ae-934f61785133": [
            "node_632"
        ],
        "04b643d9-213f-4693-a0a4-ed1d8c5dcdbc": [
            "node_2"
        ],
        "6c9ceb09-d725-49dc-9bff-9cf49b008b21": [
            "node_2"
        ],
        "3ebd0b14-f989-4205-b7b6-3b1f8e00e282": [
            "node_2"
        ],
        "d0e42925-061c-4860-bddf-12e1858c8516": [
            "node_2"
        ],
        "ec0a3029-60cf-4f07-b819-72cb20ec809d": [
            "node_2"
        ],
        "91964e20-9c13-46d4-b161-7781cbfe9cc5": [
            "node_1301"
        ],
        "f2182e8f-1909-4f2d-b12d-018e6b8a89db": [
            "node_1301"
        ],
        "3ee7721c-8f88-4ddd-889f-69cdcb09a970": [
            "node_1301"
        ],
        "c2179081-44d1-4aab-a0ad-a6f82d631d1e": [
            "node_1301"
        ],
        "737785da-fd15-4d75-8959-88899974dc97": [
            "node_1301"
        ],
        "76b63f35-4c8e-43e3-9d02-f90b7fc64e01": [
            "node_15"
        ],
        "beb2260a-5bb5-4196-8749-f6e76721b4f1": [
            "node_15"
        ],
        "a3ded64f-910b-4b1d-958f-ed49552ead53": [
            "node_15"
        ],
        "8ed0f1f1-cb89-41ac-8f0c-7e7ca35fabdc": [
            "node_15"
        ],
        "1b0c2b4c-2e31-4890-8e52-6c32f724afb4": [
            "node_15"
        ],
        "f3c0d54a-0290-4391-bca5-08b2a4f04df7": [
            "node_15"
        ],
        "e98ca3e2-1ee1-419e-828c-8ab83ff37715": [
            "node_15"
        ],
        "fef4af26-3908-4e5b-a63a-26a0409b16ba": [
            "node_853"
        ],
        "5105455b-7ce8-44e7-9486-56fed38ce447": [
            "node_853"
        ],
        "5fde5fdf-26a7-430b-a571-38f0cd766fde": [
            "node_853"
        ],
        "cb007f10-53b9-4320-a88c-e46beaabe758": [
            "node_853"
        ],
        "7ae1340c-9162-472d-aaa2-e9c51d997453": [
            "node_853"
        ],
        "13787da9-c50b-484f-b672-1392b344f861": [
            "node_853"
        ],
        "7a50c53d-2fd8-4a8c-93ad-c2cf004c1a2c": [
            "node_1098"
        ],
        "c1bda325-a20d-4d86-823d-bbccb582dba1": [
            "node_1098"
        ],
        "a89d0053-9c4e-45d7-a020-cca0378a0b60": [
            "node_1098"
        ],
        "2de498cc-4f74-465a-8a05-a2b46cfc0da5": [
            "node_1098"
        ],
        "792954ec-ed42-4637-8ccc-3cd34337aad6": [
            "node_1098"
        ],
        "0308e846-f808-4ed8-aece-df7a2b07fd82": [
            "node_1098"
        ],
        "a6c3efb1-1fd4-4b16-b575-2e5a5e2dbd20": [
            "node_1098"
        ],
        "1d47859f-81f2-4e3e-8155-f157e21ae532": [
            "node_1098"
        ],
        "d5f89057-457b-4f75-9df1-40d78f5d2cf1": [
            "node_1098"
        ],
        "4dc7114e-f562-43cf-b477-87ea187ba05a": [
            "node_1098"
        ],
        "d50283c9-7dad-4aa7-93f5-9497f2a49f63": [
            "node_82"
        ],
        "31ae8e30-1016-4498-a561-f3ad7a51cfc3": [
            "node_82"
        ],
        "adde3a4a-7519-4618-b8d2-273793ff179a": [
            "node_82"
        ],
        "a2e9b6af-f2d9-47f5-98c6-0da993aa772e": [
            "node_82"
        ],
        "48c909b9-5202-4826-b028-644b6c975dbd": [
            "node_82"
        ],
        "c5762669-d364-42e2-8ec4-0f6ae866159b": [
            "node_82"
        ],
        "bfb256e7-24f6-4c05-9daf-33e691cf33be": [
            "node_82"
        ],
        "74af8343-4992-41f4-b26b-62d8eba24ebc": [
            "node_82"
        ],
        "2ebb9806-268d-4b11-aea9-3cbddbcc0c11": [
            "node_82"
        ],
        "d93862a6-7e7b-4cab-bfda-f5bb12c78898": [
            "node_82"
        ],
        "2d8e46b1-793f-492f-9bfb-0c05bb36e6a6": [
            "node_916"
        ],
        "e6ef3dbc-8be6-4583-b039-a118f88cb0a0": [
            "node_916"
        ],
        "78bfbe10-dfab-4e8b-8b68-6ccb8cfd6978": [
            "node_916"
        ],
        "7b580405-e40a-4441-b707-a193264f2c49": [
            "node_916"
        ],
        "f5274b00-ec42-4526-9837-7a32dfb05969": [
            "node_916"
        ],
        "6048f907-486a-4dde-8342-5ca7bd02492d": [
            "node_916"
        ],
        "d9393ebf-cccb-4e59-a20b-255bc995c3fe": [
            "node_765"
        ],
        "474b1a3d-d6eb-4136-b43d-e17669a03161": [
            "node_765"
        ],
        "cd056c45-49b5-4f1f-aa6e-3f051306b34d": [
            "node_765"
        ],
        "a3220242-3a9a-4a97-95f8-9e8abc7ce01c": [
            "node_765"
        ],
        "f44a3d4b-6113-4a4f-a853-309e283919b9": [
            "node_765"
        ],
        "932b2516-3541-4ea9-a737-8574343addcb": [
            "node_910"
        ],
        "8007c119-c607-454a-8c28-76e83abad1ed": [
            "node_910"
        ],
        "5d1c3c61-546e-44a3-8f1e-2a006c076f16": [
            "node_910"
        ],
        "1636a6e6-0d26-4e5b-9e1c-a2c40370d2a0": [
            "node_910"
        ],
        "02df3268-c900-495f-a4bc-50bb7bf7f909": [
            "node_910"
        ],
        "3bd6f124-3b10-4e33-8bfc-f2f109023b54": [
            "node_821"
        ],
        "8927e594-8811-426b-aeaf-36a08316cb94": [
            "node_821"
        ],
        "b7407819-4211-4f96-aa3b-8d1cb73885a1": [
            "node_821"
        ],
        "235d8322-ac2c-4f11-9d56-af05ccdec30a": [
            "node_821"
        ],
        "96f9bf94-070d-4456-a77f-3a81bb3cdd6f": [
            "node_821"
        ],
        "e998e51b-37b8-46e0-82e4-d894d030b7b4": [
            "node_821"
        ],
        "21991dc6-1121-4e86-adbd-7d29c7e8bb06": [
            "node_821"
        ],
        "e0591e0c-126d-4a81-a495-9c307f596688": [
            "node_821"
        ],
        "55277326-d23d-46a5-a7b6-cf3e867a06ad": [
            "node_821"
        ],
        "9b03ac1f-eff0-432f-a949-456c0986be36": [
            "node_821"
        ],
        "2b522e4b-7153-4a92-beb4-b959266a67c7": [
            "node_426"
        ],
        "60e2b29f-2b21-4508-a9bd-c1f8bdb46ae4": [
            "node_426"
        ],
        "8dd68a10-9af2-4386-b182-001e1e91a171": [
            "node_426"
        ],
        "5bf19acd-f13c-40dd-abbf-4537d6af9fe2": [
            "node_426"
        ],
        "a8b30e5d-a4ea-4cf8-bf27-c9dd343dde42": [
            "node_426"
        ],
        "e12f9a77-7927-4ff0-88fb-77174593eb9c": [
            "node_604"
        ],
        "b3cb4e60-18e0-4beb-8e6d-7cd4632f5730": [
            "node_604"
        ],
        "986eb6da-42c3-42ee-adbf-5c3b4a153e77": [
            "node_604"
        ],
        "271d6994-2790-4ccd-a0b0-90fcac71a27b": [
            "node_604"
        ],
        "13057dca-920a-4264-8805-c4f730bc0eae": [
            "node_604"
        ],
        "45fe70d7-e3f7-4f52-8bb5-29d61fb1bd43": [
            "node_1295"
        ],
        "98dd5770-94d1-4ee7-9982-beaa77e02016": [
            "node_182"
        ],
        "6c3fe2a7-5fc6-4825-8c1f-a8dc1fc7d838": [
            "node_182"
        ],
        "79df7a16-37ac-402d-b146-47a5685f9df7": [
            "node_182"
        ],
        "65db84e0-850c-4558-9961-4fb10b00caa8": [
            "node_182"
        ],
        "99c34bc8-49d0-4f0e-b597-3e448a22533e": [
            "node_182"
        ],
        "2fe41b7c-a275-494b-944c-deec1c05e1be": [
            "node_182"
        ],
        "78538f71-a93f-40ae-9ec6-06eaf6618694": [
            "node_182"
        ],
        "349d6962-b1cb-4371-8b6a-997c5f4f342f": [
            "node_957"
        ],
        "7167856f-92dd-4f83-a28c-3d79fc699786": [
            "node_957"
        ],
        "fc86487e-47d5-4693-a42d-959b189ababa": [
            "node_957"
        ],
        "4139e386-2486-4540-831b-fa64c93abe0d": [
            "node_957"
        ],
        "71208050-cb26-4973-99b6-ea25b0aa19ae": [
            "node_957"
        ],
        "0c8d7298-5034-4014-ad06-91b7609f5657": [
            "node_454"
        ],
        "c7272655-9146-429c-bf90-22fb71f0fce4": [
            "node_1120"
        ],
        "abbc3dae-5bbe-4b2b-b8a1-c0aac7b8eb89": [
            "node_1120"
        ],
        "11f5ef35-f714-4bb1-97db-6b79d4336b9b": [
            "node_1120"
        ],
        "5582f733-c474-4362-a1fc-e83bd51e0a68": [
            "node_1120"
        ],
        "d5095873-b345-41d7-a710-d9f3ee765f01": [
            "node_1120"
        ],
        "70344369-d923-4ea1-8289-b1db6c2a8378": [
            "node_1120"
        ],
        "2aacdcbc-e125-4e64-b5d8-f7645029ae8e": [
            "node_1120"
        ],
        "1fe9e5c7-f5f2-498c-9c16-111d19fb9798": [
            "node_1120"
        ],
        "a6225d25-7f86-4da0-87aa-f513efca0e52": [
            "node_1120"
        ],
        "52f16189-4f90-48d1-be62-6cd249764f99": [
            "node_1120"
        ],
        "05e367c1-6496-4c42-a30c-03e371e2d0bb": [
            "node_1254"
        ],
        "af24724d-68b6-4cbb-b4cb-d000be95fcde": [
            "node_1254"
        ],
        "3cd84ee1-f9a7-4ffc-ad8d-cc2b04f59052": [
            "node_1254"
        ],
        "6b1908b2-bcba-4c0d-aeaa-2c3797d0b24b": [
            "node_1254"
        ],
        "ea19109a-970a-4af8-b662-2aeab4dc496e": [
            "node_1254"
        ],
        "b2f55364-9fb0-4ef0-8e60-996ac5012d83": [
            "node_252"
        ],
        "9a3f42a4-5035-4aee-8563-28613a38342d": [
            "node_252"
        ],
        "fd18e39c-dc96-4e23-aa78-f11020f213d1": [
            "node_252"
        ],
        "b59f41b5-09f6-493f-aa84-11721a540994": [
            "node_252"
        ],
        "7eb15b5e-d3df-45b7-9ed8-8f4062870a9a": [
            "node_252"
        ],
        "1df84b50-729b-4cd1-af6d-acd57791bc47": [
            "node_772"
        ],
        "69c365d8-026e-480c-beda-782e21902df4": [
            "node_772"
        ],
        "e9095768-2630-491d-8af3-87409ef19580": [
            "node_772"
        ],
        "a63c045d-773a-4f07-a341-9ba6f30375ca": [
            "node_772"
        ],
        "874db484-3d72-4f64-a8e5-fe1218c3fa61": [
            "node_1163"
        ],
        "5e379340-434b-4691-a11e-d91cdfd80b8a": [
            "node_1163"
        ],
        "3076fb81-cccf-4116-82d0-b91b95c89583": [
            "node_1163"
        ],
        "7254ef9c-7584-479e-aa85-0c2b6615991a": [
            "node_943"
        ],
        "c984f379-ca4b-4a5c-9a94-d7d213dbf2ba": [
            "node_943"
        ],
        "a9c3feec-61e1-4158-bb14-383664d2fbeb": [
            "node_943"
        ],
        "0a906ef2-d131-418a-b3a7-c77b4d119174": [
            "node_943"
        ],
        "a9e0ceb7-bda8-40fa-ae9e-606b691ce771": [
            "node_422"
        ],
        "fd150a41-69c0-4cae-8483-205fc6611069": [
            "node_422"
        ],
        "031d7b24-a899-41f2-9205-d27fb2c94b27": [
            "node_422"
        ],
        "aab08d45-4874-43fd-836c-ff08f5695f35": [
            "node_422"
        ],
        "93a09b87-4d0e-4ede-bde8-95146ccde5fd": [
            "node_422"
        ],
        "08d5e0ae-ca3e-42e7-bc35-bfae2dd95bcd": [
            "node_301"
        ],
        "f461fff6-4879-4c0d-8bac-f091182a0ccc": [
            "node_301"
        ],
        "2e65af30-2a02-4884-8b47-d14178aaf483": [
            "node_301"
        ],
        "9d6d8e77-6b7d-455c-b56c-2cd3c0217721": [
            "node_301"
        ],
        "c97a12e8-e15e-4102-861d-b6e0941cb2fb": [
            "node_301"
        ],
        "a98368d5-9ac6-4945-82a3-adc644370bf0": [
            "node_228"
        ],
        "5f80f847-38f0-449e-8926-898b1f95330e": [
            "node_228"
        ],
        "5a8ca071-e21e-4d80-91db-f8cb054e12d8": [
            "node_228"
        ],
        "d79d7685-58f7-473b-84d1-3b17f52180aa": [
            "node_228"
        ],
        "8ecd38de-a29a-4baf-924f-88896b3a8b90": [
            "node_228"
        ],
        "ade305aa-1a99-4389-a994-74a39f4bc299": [
            "node_947"
        ],
        "f6234b65-fdf1-4b27-9a94-552c047c68f5": [
            "node_1142"
        ],
        "4328b029-204e-49c7-a05b-5e99113eeddc": [
            "node_1142"
        ],
        "55c19b8a-5969-4c13-83c8-d86db1b6067c": [
            "node_1142"
        ],
        "592eeab5-cb5e-4bbb-89ce-85f416f99c21": [
            "node_1142"
        ],
        "fc1b38ae-961d-439b-8517-ea2730e18c16": [
            "node_1142"
        ],
        "428570ca-e1be-46b2-9b5b-f52cc76d0237": [
            "node_329"
        ],
        "03684a20-4c80-466f-983d-99414b7bb324": [
            "node_329"
        ],
        "0a335ac8-b78d-4ea0-b627-d1c466a984d0": [
            "node_329"
        ],
        "1aa502e8-e3bc-498a-af7c-7f3245d42c43": [
            "node_329"
        ],
        "10ff6680-195c-45fe-8a19-ea4efabb75ea": [
            "node_329"
        ],
        "f0148272-8f09-4e47-ae3a-9266ed9510f9": [
            "node_453"
        ],
        "7e5c9ebe-248d-41a5-abe3-4cbba984759b": [
            "node_120"
        ],
        "f7aa45f8-7bcd-4575-bdba-a9f29fa0fa60": [
            "node_120"
        ],
        "028a240f-0bb8-40b8-8551-a399bd52c557": [
            "node_120"
        ],
        "07e242cb-412b-4b2d-8a48-47eb014a2ef9": [
            "node_120"
        ],
        "ee2ab59a-4f99-4c34-9263-d4270647a9dd": [
            "node_120"
        ],
        "a24a15d8-0539-480e-831d-a485d58ac08d": [
            "node_860"
        ],
        "a1e9e2a2-da8e-4d61-a4e6-5f77e8fd8dfc": [
            "node_908"
        ],
        "8953d382-394b-44ef-b31f-cfc327733f3f": [
            "node_908"
        ],
        "572465ba-0a7c-47fa-9a0e-124bddefc6cd": [
            "node_908"
        ],
        "6202f37c-f18f-49bb-8c39-4aecee076271": [
            "node_908"
        ],
        "4b5a53bf-f56e-427e-aec5-6e0a6f96daca": [
            "node_908"
        ],
        "8dc82bbe-fb92-4191-b1fe-0699b61fcefc": [
            "node_1184"
        ],
        "27e57f93-18ad-45fa-ac41-8aae2635feeb": [
            "node_1184"
        ],
        "d40228ff-e86b-449f-abce-797404a755c2": [
            "node_1184"
        ],
        "5b0c2cc4-1541-4999-9bcf-3fed95d11710": [
            "node_1184"
        ],
        "6dcfd637-3119-48e5-a426-3c837a17fe88": [
            "node_1184"
        ],
        "66f2afcf-2e98-4ee4-a18a-1e60b6a651db": [
            "node_660"
        ],
        "24134992-7347-4589-953d-a2e5419e6140": [
            "node_660"
        ],
        "59503292-4580-440e-96cf-81e0e7bc72bf": [
            "node_660"
        ],
        "a85b22e4-db5b-4557-a158-c4b85e23ac7b": [
            "node_660"
        ],
        "6ab269a0-8974-49bd-8da2-49e156ff068d": [
            "node_660"
        ],
        "ea241835-2476-432e-9425-5aa1f0df57ed": [
            "node_29"
        ],
        "e91dd328-accb-4214-b032-e0a468094003": [
            "node_29"
        ],
        "b929c967-eba4-43ba-8a6c-cc59ab6c68db": [
            "node_29"
        ],
        "fe9533cd-120d-4717-b3cd-e73e15c6afaf": [
            "node_29"
        ],
        "bc289224-e6b1-420d-93b3-3a6c0ac324e5": [
            "node_29"
        ],
        "6881f82b-0fda-4013-aee0-168a2d35d422": [
            "node_414"
        ],
        "e09ae867-0e8b-4322-82d6-a8d9bfa454d5": [
            "node_414"
        ],
        "c95a53c3-bf75-4bfd-9c45-87944929c998": [
            "node_414"
        ],
        "90cce896-6dc3-4655-a575-846b36892492": [
            "node_414"
        ],
        "8544d3dc-5e40-425e-88e7-511be28ecb6f": [
            "node_414"
        ],
        "5c135aa0-79fa-4c72-91c8-9cffe20364e2": [
            "node_125"
        ],
        "3666e792-bab7-4758-b382-f048d1a8802f": [
            "node_125"
        ],
        "716e706b-c0a4-4261-a711-dd0e7e06bf2d": [
            "node_125"
        ],
        "a4ef3959-1c2b-4fd2-85d7-e8be29bb24bc": [
            "node_125"
        ],
        "4056becc-08a2-47b5-8ce0-b65b23c496b7": [
            "node_125"
        ],
        "e03ce03b-1fa2-4501-9b76-7f5ff8ea3c03": [
            "node_758"
        ],
        "46930074-5234-42e8-ba98-f6f340762382": [
            "node_758"
        ],
        "78fac61c-b48f-4cbb-9ea0-343871a10647": [
            "node_758"
        ],
        "627d1781-3c84-4f12-a8c3-1ce765569a72": [
            "node_758"
        ],
        "44ee5c22-a110-40e9-8784-2157a93b32ce": [
            "node_758"
        ],
        "04761e8f-aab9-458b-a994-7f6fa749a74c": [
            "node_1143"
        ],
        "55ada801-9fe4-4622-8426-c299d65d59fb": [
            "node_1143"
        ],
        "3130d7e7-a842-467a-84b0-e52bee600a31": [
            "node_1143"
        ],
        "c09913b4-aa53-4cbf-8bf8-71c040f3c6e2": [
            "node_1143"
        ],
        "4449689d-1a1c-497a-93fb-54a12e6d94fe": [
            "node_1143"
        ],
        "8d07672e-f666-4b2d-a736-25593982645a": [
            "node_114"
        ],
        "4e5a0fbd-01e8-496f-8616-b235ba3ddbb3": [
            "node_114"
        ],
        "484d4240-f11a-4805-9e71-0fc2c87b44e2": [
            "node_114"
        ],
        "66dd4419-0054-4525-beda-1e8cd83ec234": [
            "node_114"
        ],
        "eb93c84a-69d8-4895-8ebc-3c1a42ea3d77": [
            "node_114"
        ],
        "e26207c4-9e9f-4b9c-90a4-b2ca429ca1a6": [
            "node_114"
        ],
        "71a92c5d-1d32-46e8-85ee-2af9daefc2d5": [
            "node_114"
        ],
        "21c67d00-aa0c-47cc-bd3c-536029bb6b65": [
            "node_114"
        ],
        "6518ee1f-4779-412e-8d4b-1616f8fd9066": [
            "node_114"
        ],
        "919f84ad-eeed-476c-b14b-f63709723317": [
            "node_114"
        ],
        "198d41eb-a446-4d1c-82e9-00c483b2bb02": [
            "node_1033"
        ],
        "125494b2-ae8f-4a3e-940e-32880ea85de0": [
            "node_1033"
        ],
        "2b9d3fe7-e7ad-4dbb-89f8-61711a27bb49": [
            "node_1033"
        ],
        "dbe46d04-5379-4c17-8163-61974d2c5c10": [
            "node_1033"
        ],
        "420de84a-0757-4926-ad56-1137136f3b7f": [
            "node_1033"
        ],
        "12829f39-994a-4294-aea3-0e3c433267a8": [
            "node_1198"
        ],
        "432a609a-8c61-4c8b-96cc-ee7385c3fc2a": [
            "node_1198"
        ],
        "ee980518-4e75-4ac8-94b7-b49a1b428371": [
            "node_1198"
        ],
        "837e1b4d-62d2-4ccf-9aae-c999cecd0b3d": [
            "node_1198"
        ],
        "028b256a-ba60-44a8-bd14-1888f8ff3b2e": [
            "node_1198"
        ],
        "ea2f3de4-76cc-4729-9ab2-31272a4497d2": [
            "node_895"
        ],
        "de09126b-5638-49bf-ba7a-22ee2740eec5": [
            "node_895"
        ],
        "d6df9a31-5707-4958-a84f-0f1a61a52eff": [
            "node_895"
        ],
        "f0bd6216-8460-4e6d-b248-8dff8f0720f0": [
            "node_895"
        ],
        "3469a11d-f461-4a5d-bf6f-2369ca41c834": [
            "node_895"
        ],
        "364dcd4e-7075-4955-8c53-a1a5fbe1bed6": [
            "node_320"
        ],
        "b936a969-6dc4-4346-9428-6d28e3ba897a": [
            "node_320"
        ],
        "8cf8a75f-0270-451e-81d3-f822a04eecde": [
            "node_320"
        ],
        "d04adb7b-b6d3-41e6-be59-0b61c3bedd67": [
            "node_320"
        ],
        "de2ae808-81d2-4a25-82c9-02fbf4b0138b": [
            "node_320"
        ],
        "a6b29b76-cb8e-450c-83c6-844527aa1a0f": [
            "node_1015"
        ],
        "9def2df9-ddc8-4e33-b8ce-48889937a774": [
            "node_1015"
        ],
        "09a31138-d53e-4f8f-9585-ba37b9889aac": [
            "node_1015"
        ],
        "cf094945-a90a-4ed5-89d2-c61423a35c72": [
            "node_1015"
        ],
        "8056cda9-6d31-4b5e-9e71-2facc8b52fcf": [
            "node_1015"
        ],
        "c10f2cc4-9a33-4492-b9d1-8c3b0b7d9591": [
            "node_230"
        ],
        "9a8a04fb-7e58-4b46-a937-789a7fc00389": [
            "node_230"
        ],
        "54901e75-f9cc-4fbf-af25-6b17b68c63c5": [
            "node_230"
        ],
        "94fe6f63-537d-48f9-aef0-420921b5b75a": [
            "node_230"
        ],
        "0f0be0dd-9e54-4e28-9587-2496a45f709d": [
            "node_230"
        ],
        "b478c6e6-33bc-4b7f-901f-d539cbe6ba4d": [
            "node_612"
        ],
        "5dae9a64-a401-4a43-83f5-f0e4e60ba0e1": [
            "node_612"
        ],
        "cb07410e-f168-4c6b-a167-6d504e5be891": [
            "node_612"
        ],
        "b5502832-d8ee-4907-98eb-672790a76df9": [
            "node_612"
        ],
        "f78f473a-29eb-484a-b4df-a37925b757e1": [
            "node_612"
        ],
        "494d66c0-bff3-40cb-b4eb-8b7d24a439da": [
            "node_985"
        ],
        "bdd30e6b-d545-4352-9ab5-19caf3c8e52a": [
            "node_985"
        ],
        "2635066b-59db-4f37-b2f4-ae37db30bd13": [
            "node_985"
        ],
        "0f982175-aa32-4443-9cc8-c71bfd54e17d": [
            "node_985"
        ],
        "162af543-35a0-4213-b2d5-08783567be35": [
            "node_985"
        ],
        "f0038ce4-9af4-419d-93e8-c5b72a88a894": [
            "node_370"
        ],
        "775cf92f-4573-4565-a014-b229be1ed816": [
            "node_370"
        ],
        "4e441a99-ffcb-4ea8-bc06-62791969b418": [
            "node_370"
        ],
        "0de5de97-0b68-473d-99c9-eaae5010a9bf": [
            "node_370"
        ],
        "12120981-57f5-46e1-ae87-85a583a5820a": [
            "node_370"
        ],
        "10bee498-41b5-476f-93fd-98c58504c73c": [
            "node_378"
        ],
        "7d00e51d-0921-49b6-a5f6-94d513f1a011": [
            "node_378"
        ],
        "6de103c3-5789-4ab4-8bc7-ce0ff204a901": [
            "node_378"
        ],
        "eede1d1f-fd84-4015-9243-2deabf8743cc": [
            "node_378"
        ],
        "c74968cc-6084-47ef-ae2a-63f33fd10f42": [
            "node_378"
        ],
        "8cdd8fed-6549-411e-9c07-a2dfbbc23331": [
            "node_530"
        ],
        "28c1c677-dee4-455a-9d73-7fdf7c65ebde": [
            "node_530"
        ],
        "c0dd2bc1-2dca-4306-98c6-12b589661bc9": [
            "node_530"
        ],
        "3de58c8e-ebd5-4f82-bd1e-9ef7019a79d6": [
            "node_530"
        ],
        "b293e357-b22f-4613-a4af-05a34eb8b0e0": [
            "node_530"
        ],
        "e87be08f-2ff1-4029-84f6-147dff7ede7e": [
            "node_1064"
        ],
        "26fc8c13-dc6a-48c5-ad0d-48860e0c94fd": [
            "node_1064"
        ],
        "01ddf161-a4cc-469d-8af8-4f88f975c160": [
            "node_1064"
        ],
        "265431d7-7ec1-491b-879c-f935b3e8b006": [
            "node_1064"
        ],
        "cb050c3e-b5c7-46e9-b0bf-e5c7efe813f2": [
            "node_1064"
        ],
        "b942c0c3-e1ff-42f0-9d03-42b4afe511e4": [
            "node_1064"
        ],
        "f2e2dbb2-3661-4401-a00a-a5d779ccea3a": [
            "node_1064"
        ],
        "391518ae-76ed-4210-ac1b-d860f9b4340d": [
            "node_1064"
        ],
        "13817af1-d952-48db-b324-45c67683c076": [
            "node_303"
        ],
        "e03691b9-4f8a-4052-9ea3-3ff7a7cf7cac": [
            "node_303"
        ],
        "daab0513-49a3-4801-b82e-4450cbe2ed10": [
            "node_303"
        ],
        "7a810a08-d7bb-40ce-bfca-755f37acc99c": [
            "node_303"
        ],
        "98f414f4-c726-40d7-93bc-1fe03f193baf": [
            "node_303"
        ],
        "c21d5dd8-e9e1-4d06-a11d-f23212091f7f": [
            "node_290"
        ],
        "1b469d87-0ddc-4bc9-88f4-84db22b2457e": [
            "node_290"
        ],
        "639399bd-7e1c-4cfd-b8dc-8dfa213e5476": [
            "node_290"
        ],
        "46a38042-7d18-453b-b156-b027d15f385f": [
            "node_290"
        ],
        "5e0a1f74-c7fa-40cf-a3a2-55badfd28c3c": [
            "node_290"
        ],
        "fc50b54b-6c94-40c6-8367-124423cfbe26": [
            "node_290"
        ],
        "d6ad396d-253d-4098-b99e-ec304601c332": [
            "node_290"
        ],
        "33cf731c-f9cb-4a1f-a348-27def40e6cad": [
            "node_290"
        ],
        "15462f63-1ef3-4fa1-b1ab-d4211aa1909d": [
            "node_145"
        ],
        "01406802-050e-4aa6-8939-a7e7244703b4": [
            "node_145"
        ],
        "08f04c3a-800d-4396-9a8d-2df0a766889f": [
            "node_145"
        ],
        "42d091c4-2e04-476b-80fc-6bea9be801ee": [
            "node_333"
        ],
        "b4fe2992-7478-4225-87b7-77a697a2ee4b": [
            "node_333"
        ],
        "8895fc30-0a7b-43a4-9313-b8aa12d513cb": [
            "node_333"
        ],
        "7d731a5c-f7c7-4fe6-bc88-f135afa40ecc": [
            "node_333"
        ],
        "90032d2f-d5ce-43aa-a2a2-ec462cd98658": [
            "node_333"
        ],
        "b5aa5811-02a5-4eb9-8528-84e51e4ad057": [
            "node_368"
        ],
        "70483fbe-e442-4e97-8156-89dbe0d19d60": [
            "node_368"
        ],
        "41e15944-db70-4efb-8957-61407decf865": [
            "node_368"
        ],
        "f55fa7b8-b51d-4a9b-8def-abc9c959e21b": [
            "node_368"
        ],
        "3494459a-3440-429a-9216-df3f3f393848": [
            "node_368"
        ],
        "5454110b-d9a7-462c-83df-989bea17edcb": [
            "node_368"
        ],
        "0c925801-f6f0-448a-a306-c6225120a68b": [
            "node_368"
        ],
        "5ec86ea8-c8c3-403a-8ddc-1ec2fb4fe4d4": [
            "node_368"
        ],
        "75ef2afe-3a7f-44a8-8c98-05859c91ab8a": [
            "node_368"
        ],
        "86e0a46b-83cd-4ed9-9b43-e602169d804d": [
            "node_368"
        ],
        "8e6594be-00fa-4427-b559-cd54d7d9849e": [
            "node_727"
        ],
        "40ad8f41-6505-453b-9b95-404e35b6e5eb": [
            "node_727"
        ],
        "931558e2-9f42-444c-a767-dc5a7009653d": [
            "node_727"
        ],
        "cd00126a-6a8a-4985-a38d-1d5640ecfe4e": [
            "node_727"
        ],
        "fa21334b-e397-4ef7-bf07-55142a3b926a": [
            "node_549"
        ],
        "e69a5e95-b558-48f7-a5aa-206e7962db89": [
            "node_549"
        ],
        "33c0b63e-93f0-4c64-ae04-abeea2abcb7d": [
            "node_549"
        ],
        "15f525ed-dcac-4cf1-9b88-8220c4eca714": [
            "node_549"
        ],
        "38b1cedd-779a-4211-ac68-d468651b7371": [
            "node_549"
        ],
        "fbfa2f6e-508d-493b-b3a2-7f4078f727ea": [
            "node_549"
        ],
        "409b0d24-d114-4c8a-b80e-f657adec9e68": [
            "node_549"
        ],
        "11a453c5-8aea-4877-a08a-c29764c088ec": [
            "node_549"
        ],
        "280ab1ea-5f97-46d8-b65f-d8b9fbcd0633": [
            "node_1218"
        ],
        "5a164b40-8d1a-4289-8595-d40697a569f8": [
            "node_1218"
        ],
        "a69321ec-6136-4622-8c8e-f96a33aebf4c": [
            "node_1218"
        ],
        "b3bb359c-b0b6-4573-9a9b-689db996730a": [
            "node_1218"
        ],
        "a0e942ec-87d5-4ee9-aa24-d80e1e967782": [
            "node_1218"
        ],
        "5b3fdd7c-dc7c-466e-bd6b-d3267e6eb902": [
            "node_669"
        ],
        "6d40843f-a51c-46a1-88b8-d9b70951febf": [
            "node_669"
        ],
        "fd232f4e-6566-4bf6-be91-58d501401b7c": [
            "node_669"
        ],
        "0f16b310-7cce-49e5-87cf-7b460821336a": [
            "node_261"
        ],
        "5df94983-c164-4156-9409-f8e35ef6de1d": [
            "node_261"
        ],
        "4ae50d21-aba1-416a-8709-d43db93ba417": [
            "node_261"
        ],
        "64fd3814-6cfd-4736-9818-c063afe63d1a": [
            "node_261"
        ],
        "808974a2-04b7-4890-b7ce-ef5dd377217d": [
            "node_261"
        ],
        "b200a4ff-5e35-4c1f-9125-ca87686d4843": [
            "node_90"
        ],
        "2180caad-22b1-4009-adc8-4954e1b7a9ed": [
            "node_90"
        ],
        "18f02e37-6cee-4c0e-9ec3-b52d22deadac": [
            "node_90"
        ],
        "cd254803-95de-465e-b2a8-7aec1c7608fc": [
            "node_90"
        ],
        "216b1e19-fb10-4358-9116-1f01a1f3cc50": [
            "node_90"
        ],
        "d5cece95-3fb5-47c8-a96e-8cac243b6eee": [
            "node_90"
        ],
        "0549a633-a7fb-4281-ad1b-1521e9245a09": [
            "node_90"
        ],
        "5626402c-7059-4874-844d-c04b7892aa3c": [
            "node_90"
        ],
        "6a13f936-bb43-4d58-bef7-12a99ce43c16": [
            "node_90"
        ],
        "9128a556-c461-47fc-8869-3896c9312e7a": [
            "node_504"
        ],
        "d84f1edc-7431-4723-a1c4-88468f339fa6": [
            "node_504"
        ],
        "e0e80024-b3bf-4d9e-b9bb-c7df641181bd": [
            "node_504"
        ],
        "759d0c52-8261-4f4d-acc6-fd29477abdce": [
            "node_504"
        ],
        "cafac8e0-2751-4620-b303-f50d9633cb62": [
            "node_504"
        ],
        "628a23be-8a81-4b2e-9b41-5933d2848d6c": [
            "node_969"
        ],
        "b3976d5b-4b08-44aa-90c7-882b8954c942": [
            "node_969"
        ],
        "1031a81f-ea72-4164-abee-4e08157995ec": [
            "node_969"
        ],
        "692c4400-fb0a-4d25-92b6-f492a3d40a5e": [
            "node_969"
        ],
        "8d5e926f-cd17-4dc5-a40b-84ce295d45f4": [
            "node_969"
        ],
        "b7254cb0-b126-443b-81ef-2c12dbfba63d": [
            "node_168"
        ],
        "a3bd05ef-17b1-4a2c-9559-8993d1cc2a87": [
            "node_168"
        ],
        "e2f6fdba-a0ba-454a-bdde-9dc0b275d0a6": [
            "node_168"
        ],
        "9615bf9c-a49b-458e-a7b6-835de1d2095f": [
            "node_168"
        ],
        "647569b2-d46f-4c41-a395-1195472b806d": [
            "node_168"
        ],
        "3d32835a-8130-4815-bd55-9a594df74e06": [
            "node_751"
        ],
        "30ccad49-691a-4da0-98f2-5851adb90c39": [
            "node_751"
        ],
        "fb79e0e8-e8bb-44a9-a47d-f391f02c78da": [
            "node_751"
        ],
        "d03d852d-7126-4018-9dbe-e6751ca760b4": [
            "node_751"
        ],
        "a791f4bb-6434-4307-9c72-d091bf81b858": [
            "node_751"
        ],
        "f7949543-ea06-47a8-8a39-76494827df6a": [
            "node_751"
        ],
        "9b630500-cfea-470c-a0f2-0e149bfcb765": [
            "node_751"
        ],
        "5fdd599a-6c5a-4e3a-921f-df01870e74ed": [
            "node_751"
        ],
        "290f7dfd-9f93-475b-afb2-e24d297bb168": [
            "node_706"
        ],
        "838c8b26-5a28-43bd-b1a1-b6e0d6731600": [
            "node_706"
        ],
        "3a1fd221-e3b5-4593-8631-e618a0d3c6f4": [
            "node_706"
        ],
        "caf4fdd5-0838-447f-9b91-a63578a7d05d": [
            "node_706"
        ],
        "ef6cf42d-a597-4381-8f83-e79cd11d486d": [
            "node_706"
        ],
        "c7957482-7df1-4579-a873-fb568af9eba5": [
            "node_706"
        ],
        "67cf0efc-fa9f-4152-b2c4-5f334e371375": [
            "node_706"
        ],
        "87c42fdc-f085-4087-ab51-71915be8fc45": [
            "node_1122"
        ],
        "2ea43272-9cfe-4882-84ba-6503bb26f2cf": [
            "node_1122"
        ],
        "cc93de4e-1f76-4727-96f2-d42d1875199e": [
            "node_1122"
        ],
        "38a7e32e-6c38-40cb-9749-d87aa748f592": [
            "node_1122"
        ],
        "e89240fb-e676-42e4-826a-ac79a4668d7a": [
            "node_1122"
        ],
        "d6c78e62-4e70-4b3c-829e-2230c265b1eb": [
            "node_625"
        ],
        "0ee20065-6883-4fef-9e39-577ee71b0d6c": [
            "node_625"
        ],
        "ada8ceed-e98f-4f0f-98e9-da6d27f6df9b": [
            "node_625"
        ],
        "21c9c25b-af95-46c0-ba5f-cb64bf83fca3": [
            "node_625"
        ],
        "d5dc69db-2177-438b-bb6a-8be625349f9f": [
            "node_625"
        ],
        "22ff0416-f2d3-476e-8645-cd027b4f2195": [
            "node_625"
        ],
        "8f59e75a-3a49-4243-9232-c37e752bfc20": [
            "node_103"
        ],
        "a6bd5f88-69f4-485d-ab76-72b059a970eb": [
            "node_103"
        ],
        "2797edb7-3537-4903-a7b6-3e81e6296500": [
            "node_103"
        ],
        "cf4dfb70-3145-430b-9882-1967d6ad4e96": [
            "node_103"
        ],
        "36cedd47-dc09-4925-bd93-fe33c6d8ee73": [
            "node_103"
        ],
        "ac303c5d-705b-4d2e-97a6-9aca5c787373": [
            "node_588"
        ],
        "df641f64-b17e-4181-a7df-6dc3912eee9b": [
            "node_588"
        ],
        "4a49ade5-7ead-4451-ba9f-458ca1a7b775": [
            "node_588"
        ],
        "2194baa8-8b3b-4559-bbe5-9e6bfc4106f2": [
            "node_588"
        ],
        "81cb822d-8b1c-46f5-bc95-1ff88c6bb24c": [
            "node_588"
        ],
        "0f18562e-2298-4874-b790-bc6bad29cfc6": [
            "node_569"
        ],
        "3f9a992e-415d-4285-ba2e-c46ed5b210db": [
            "node_100"
        ],
        "2ead4d0f-7458-46cb-9df9-2653cf63413a": [
            "node_100"
        ],
        "32056038-1ae4-4947-8a4e-850d10b6b5b0": [
            "node_100"
        ],
        "fbfcd9c1-f4f8-4f2f-b1ac-3c9d65aa5b0f": [
            "node_100"
        ],
        "f6f0b95b-efb3-4ca1-a3c5-a9fa71ef343c": [
            "node_100"
        ],
        "7e4b6259-662d-4b9c-863a-cd069e098b82": [
            "node_100"
        ],
        "469fe6b2-d1a9-42ed-a424-cf9e8d180d64": [
            "node_100"
        ],
        "f7457b8c-e4ba-4481-abb4-831632be8cca": [
            "node_100"
        ],
        "0021381b-0bca-4481-93ca-3b64ccfaa765": [
            "node_100"
        ],
        "ec9291d8-79a5-47f7-9a3d-27e0fbc05cbf": [
            "node_730"
        ],
        "f233d6c9-ef03-4cfa-8637-958501a72140": [
            "node_730"
        ],
        "b6a0005c-aeb0-495f-a44d-fde1e67b0f9a": [
            "node_730"
        ],
        "ad971cfc-1fdf-40aa-a245-d2d7ad5a1c1c": [
            "node_730"
        ],
        "729415e5-3114-4661-86c9-558f8b9d3687": [
            "node_730"
        ],
        "94cacbd2-fee9-4aeb-8d51-0ef1dbae35f3": [
            "node_109"
        ],
        "70508b6e-cc06-4cd3-a18e-71dec8aea439": [
            "node_109"
        ],
        "5222ec9f-7e0e-4150-9195-94f1c0b51b16": [
            "node_109"
        ],
        "2b26b8ea-5a8f-4c56-95a1-96d3681e4980": [
            "node_109"
        ],
        "e4c68915-79a8-4a4a-adb9-4767cc0f3670": [
            "node_109"
        ],
        "86af4052-606b-46f6-a0f9-4d0adbc940b9": [
            "node_1020"
        ],
        "34311103-3f05-44b8-93d4-1e9b53a3e4d2": [
            "node_60"
        ],
        "c6ebc16b-80dc-45b8-929d-723043a13b15": [
            "node_60"
        ],
        "85250beb-cdfd-459d-8982-0573d7793c54": [
            "node_60"
        ],
        "98420810-354a-4b16-abcf-034d29eaae34": [
            "node_60"
        ],
        "c672e844-b816-4fe1-b6ac-08bf4631472e": [
            "node_60"
        ],
        "e02abe4e-078b-4e51-8f34-cc4427bab53c": [
            "node_1027"
        ],
        "b95ca7e2-c54d-4897-9002-88502faebf14": [
            "node_1027"
        ],
        "69f6a6a5-83f2-4177-91ca-4f82414439bd": [
            "node_1027"
        ],
        "daf2f5bb-78d5-42c7-9217-28c04b307a7b": [
            "node_1027"
        ],
        "4209601d-a2fc-4081-801a-4382944e29a8": [
            "node_1027"
        ],
        "50153e68-0445-40ce-852b-a560a20e715a": [
            "node_645"
        ],
        "71a2189b-0842-485d-9a37-49cbaed93640": [
            "node_645"
        ],
        "aee4852b-c55e-4d91-ae2a-64a3424ab7ee": [
            "node_645"
        ],
        "a6dddb83-e5e6-4de2-bd26-1945d9763b2f": [
            "node_645"
        ],
        "2790bb70-78af-41d5-bdd8-3a546130d04e": [
            "node_645"
        ],
        "eb2c4434-bb11-4007-9d25-c0a3afb54b29": [
            "node_1070"
        ],
        "2e5498b0-e4b8-42a5-93ea-7cadf22f9077": [
            "node_1070"
        ],
        "fbbb2f5f-1429-4642-8ba1-02a9b6500075": [
            "node_1070"
        ],
        "f7be11ec-f29d-47ed-913e-938734d62b85": [
            "node_1070"
        ],
        "0eff54a7-412b-4bff-b111-98733dbc48cb": [
            "node_1070"
        ],
        "256db365-6799-42ae-8fe4-d840af3bbbdb": [
            "node_1171"
        ],
        "cdbd68ee-241e-4b24-adaf-6e88aa2e4de1": [
            "node_1171"
        ],
        "7a4a8c8f-2a68-4bd6-a936-6a65071f9665": [
            "node_1171"
        ],
        "9209302c-e739-4958-ab79-1a9ce8beae75": [
            "node_1171"
        ],
        "dcad79ea-e629-4340-ad89-9709e2c94a2b": [
            "node_1171"
        ],
        "6d46ceda-b155-45ab-b910-781a5672998c": [
            "node_1171"
        ],
        "399f6d77-0c2e-4d0c-91e9-0ba320accfa5": [
            "node_1171"
        ],
        "64db6f8d-374a-4cf9-bac3-e656d2a237ed": [
            "node_570"
        ],
        "fb04ab84-0b01-4b09-85d4-56f3f3a55a4f": [
            "node_570"
        ],
        "252c766a-0c14-4c1c-a0d2-c0738a90489d": [
            "node_570"
        ],
        "319fbc8d-ec71-4fb8-ba25-53e35f66caa5": [
            "node_777"
        ],
        "285c5f3f-5135-45ed-92a3-12f17b9b3c7c": [
            "node_777"
        ],
        "f8895379-1d65-4210-87f0-f740b68e928b": [
            "node_777"
        ],
        "bf3fc8d4-5c39-4ed2-9513-2c5d9d8f0568": [
            "node_777"
        ],
        "040a1292-f660-4ddb-a347-aef6990df6e8": [
            "node_777"
        ],
        "19509396-716f-4fb1-b5cd-a8d3e65aa94d": [
            "node_777"
        ],
        "fa159102-7626-4359-8286-180948849b47": [
            "node_208"
        ],
        "6bd0e48c-4bc1-47b5-b1fb-21d105708eeb": [
            "node_208"
        ],
        "4a0b93ce-ffb9-4654-b363-334fb33cd292": [
            "node_208"
        ],
        "22688846-f5bc-4707-aae1-cfc88418806e": [
            "node_208"
        ],
        "0185ba50-02a8-49f5-8998-2140638759eb": [
            "node_208"
        ],
        "face7929-8a5d-4801-a97c-b7a2a41340c7": [
            "node_208"
        ],
        "67cc4fa2-b502-48b1-a210-17e5a42e84d0": [
            "node_208"
        ],
        "f1675c6e-d7c7-43a4-8373-967c385cd21e": [
            "node_208"
        ],
        "f0ab34a4-1160-4ced-9e33-70f729c6a736": [
            "node_208"
        ],
        "8a4ff6eb-fe0a-47cc-86bb-6eb1c01bb95c": [
            "node_646"
        ],
        "7dde7f1d-503e-480b-8ba5-5f09bd08cd0c": [
            "node_646"
        ],
        "3ece4f8d-1b0c-46c6-aa3c-8dadd89ed19e": [
            "node_646"
        ],
        "b5d90e3a-5ab7-463d-b37f-d173f5c9ae9a": [
            "node_646"
        ],
        "1f3af598-d07a-4606-a1f4-e8876f3bbd55": [
            "node_646"
        ],
        "833ae4f2-9242-4977-8fe4-1ae7582dc9ee": [
            "node_133"
        ],
        "4d5bf016-e679-4ee6-99d6-8faf799323d8": [
            "node_133"
        ],
        "f0830aa5-831b-4d25-81a6-a21538926dc2": [
            "node_133"
        ],
        "7bc538e2-6cdf-40e4-af43-250b78fe8947": [
            "node_133"
        ],
        "6706e015-5bc7-4641-9299-0be841c242ca": [
            "node_133"
        ],
        "5ebb83f8-e698-45fc-a1ee-41ac986cf3d4": [
            "node_1310"
        ],
        "6a4827f8-57c7-4767-b9f7-ad72a6e63284": [
            "node_1310"
        ],
        "83c68464-6a9b-44e4-ac26-f283eb9bdf7a": [
            "node_1310"
        ],
        "883926fa-26d2-4f69-aa53-8f6ded37e03e": [
            "node_1310"
        ],
        "0d990f3a-d95a-4423-8f1b-e329ad78d1e2": [
            "node_1310"
        ],
        "81da9af0-356b-48ca-993c-b8afeae61f6a": [
            "node_326"
        ],
        "a982a946-b000-4362-9288-ef10eee3b58d": [
            "node_326"
        ],
        "c45904b3-ed8d-44c4-bb6e-f31693824726": [
            "node_326"
        ],
        "173ff351-98ab-46ae-9618-fc2d76383872": [
            "node_326"
        ],
        "bac201a4-1d16-4679-82d8-a61c40efee29": [
            "node_326"
        ],
        "cc0e9bca-7dbd-4307-9668-a1ffe1524255": [
            "node_513"
        ],
        "dae3a607-c4fa-4262-8d87-443427fabb0c": [
            "node_513"
        ],
        "5c1619b8-0ea4-4d27-a4d3-50082175830c": [
            "node_513"
        ],
        "6229646a-5463-4e7f-8764-4ae199013328": [
            "node_513"
        ],
        "1c01e8b2-7c7f-4b78-aba6-f7ac6561e2e4": [
            "node_513"
        ],
        "9622945c-2ad7-442b-b7d3-bfd23296d09b": [
            "node_623"
        ],
        "98f3e598-73dd-4cb2-bdca-d2fac55febdc": [
            "node_623"
        ],
        "edacf459-fb9c-4be2-84f4-d0786b6ebcbe": [
            "node_623"
        ],
        "69b2701e-eff8-4d83-99aa-e7fac17f4da3": [
            "node_623"
        ],
        "131b24f9-1357-4c30-bb11-27d01401e855": [
            "node_623"
        ],
        "7b8edf44-f285-4a04-9955-f0f91c68e442": [
            "node_650"
        ],
        "d59d74eb-6f9c-4aad-bec8-cf6dd8e2f71b": [
            "node_650"
        ],
        "b1bc2516-c500-4873-a8d0-0fc973fc34dc": [
            "node_650"
        ],
        "12336b82-dcd2-4ead-80fe-43ef5062fe0c": [
            "node_650"
        ],
        "a1552295-8a28-4cd8-bd38-0e63854c9c02": [
            "node_650"
        ],
        "3bdc05c8-30ef-477a-9952-daa937df5999": [
            "node_650"
        ],
        "46571ebb-1e9f-4701-86f0-eeb18b461638": [
            "node_650"
        ],
        "60958dd3-6241-4dba-a324-cfc0f271a20e": [
            "node_650"
        ],
        "1d3feaff-c68b-4a98-98b3-33eecefbc233": [
            "node_650"
        ],
        "2d388c50-75d2-4ff9-8312-9122fafafe13": [
            "node_650"
        ],
        "80340300-930d-4cb7-b61f-1be52124168b": [
            "node_560"
        ],
        "94fa2ee1-b7d0-4abe-a756-b32c11b9628d": [
            "node_560"
        ],
        "59d3c4e6-fd0e-464b-98ab-9ffa354d118c": [
            "node_560"
        ],
        "dc5083ba-644a-4d7e-b9f3-0909106c2ec3": [
            "node_560"
        ],
        "c31ec5ac-d624-4b41-9cdd-04368f9bdf23": [
            "node_560"
        ],
        "35213c0b-e29b-433c-8e52-34cbbf85b1ac": [
            "node_560"
        ],
        "8a88780f-efb0-4c33-9f3f-4b201b3e0027": [
            "node_1164"
        ],
        "80397aac-2348-4835-a2d6-b8da50c6b36f": [
            "node_1164"
        ],
        "d49f60f0-609e-4884-8f48-947204ff90bb": [
            "node_1164"
        ],
        "7db89ce2-48f4-4d17-94c7-ba3457cd7d4e": [
            "node_890"
        ],
        "03559bd9-42cb-451b-a701-e589d486fcfd": [
            "node_96"
        ],
        "bd73a6b4-c33b-4ca9-ac78-59dbc1c4dfa2": [
            "node_96"
        ],
        "d6790045-5eb5-4779-8632-c763522c4ac6": [
            "node_96"
        ],
        "dbc9b7cb-344a-47cd-a0b4-7816a25d52a5": [
            "node_96"
        ],
        "15dcb9e6-5473-4965-b070-6e0a31d52cf6": [
            "node_96"
        ],
        "b4ad36ec-61f3-4414-8027-e31889b59bd0": [
            "node_789"
        ],
        "707ea0de-1acb-4be4-9bf9-79f5ebadc8c2": [
            "node_789"
        ],
        "56987097-fdca-417b-a689-aac95ad569b6": [
            "node_789"
        ],
        "5ae66cfe-1467-425c-823e-026cb17b6f04": [
            "node_789"
        ],
        "675573b4-3bdd-42b9-b5f7-0af18fb5bc68": [
            "node_789"
        ],
        "939e5872-bf7e-4986-b1f9-eb0945329a07": [
            "node_1100"
        ],
        "c02f52cd-7e25-47c9-a87d-0a2756abc2eb": [
            "node_1100"
        ],
        "72d38d60-3fe1-4309-b2ad-28af071b6497": [
            "node_1100"
        ],
        "37e774be-815e-4448-9a10-14b0d79efbe5": [
            "node_1100"
        ],
        "556cf847-1352-45ab-a67a-14a9cf343f37": [
            "node_1100"
        ],
        "539fc141-a2bb-4bb9-aa73-a2748b5570f5": [
            "node_1196"
        ],
        "b3144560-a6de-41e1-9caf-0084d5fac910": [
            "node_1196"
        ],
        "7f2783c1-4887-4b67-9b1c-f8a6fd88b6fc": [
            "node_1196"
        ],
        "e04ce5b6-cd9b-48bf-853a-e1e494b97e75": [
            "node_1196"
        ],
        "22c43b23-13ff-4c5d-9d6c-acb7cda525d1": [
            "node_1196"
        ],
        "28140a12-fbc5-4b23-a831-c78f899652eb": [
            "node_1196"
        ],
        "23163342-3b6b-41f2-bb4e-8cb61bbbbe39": [
            "node_1196"
        ],
        "b0b4d968-8d72-4130-8575-fc3be0e5a312": [
            "node_468"
        ],
        "5f61fda6-f0d3-4bed-bd5e-705497afc1c1": [
            "node_468"
        ],
        "cb7f2774-822d-46b7-ae0c-815f0015be12": [
            "node_468"
        ],
        "e14d785d-9ab4-4b26-b81b-c7b109f74ea8": [
            "node_468"
        ],
        "05cbec8c-a70d-4d4f-a460-fd3b656514a7": [
            "node_468"
        ],
        "5a1acca2-69bd-4785-9590-8956b806bec2": [
            "node_759"
        ],
        "b855ade4-f8da-4389-a977-cf432510fc2c": [
            "node_759"
        ],
        "31985253-6339-46c8-b964-59d30bca2f74": [
            "node_759"
        ],
        "97894baf-fda6-4b6b-81d4-892211c49b95": [
            "node_759"
        ],
        "68051f1f-d578-4f5a-aff0-a0f8c3c99cea": [
            "node_759"
        ],
        "df69934b-fc93-4f0a-bfd5-45a771ab36b8": [
            "node_514"
        ],
        "b7415f41-1363-4940-bdfb-02821a43d5e8": [
            "node_514"
        ],
        "02dea8c7-143e-4fc1-9c79-7f0f83fa4c0d": [
            "node_514"
        ],
        "d7d508b6-a597-4596-8fc4-d2d8310609e0": [
            "node_514"
        ],
        "e5d7355e-aae8-4b0d-bd39-eca8b353d8d2": [
            "node_514"
        ],
        "e409bc65-e64e-4654-9f3c-bf373e67a89c": [
            "node_1144"
        ],
        "5c0cfa8a-98cb-40e5-8f95-a90aad03c864": [
            "node_1047"
        ],
        "5f446115-a57f-435a-8e10-15f1bd8d11b2": [
            "node_1047"
        ],
        "73e077fb-8447-406a-bdf1-4d6951e794bf": [
            "node_1047"
        ],
        "3b017558-c590-48e8-9a2b-f71068a5212c": [
            "node_1047"
        ],
        "1c6eb9f5-1c66-487c-a44c-2d22832a693e": [
            "node_1047"
        ],
        "36ebc17c-9dbd-4ae5-96e5-5d1e7a2de5b7": [
            "node_300"
        ],
        "253e08fb-e32d-4dbc-aeb0-37269f7ec0e6": [
            "node_300"
        ],
        "8f7a3df3-d926-416e-b72f-4b2fba0f6ccc": [
            "node_300"
        ],
        "1e7d4dc2-bfeb-47e6-980b-7a738392ab18": [
            "node_300"
        ],
        "c469f94d-2486-4d8f-97fe-5de30a6979a4": [
            "node_300"
        ],
        "d7a46bfc-a34c-4b3e-9cbe-9a15f7096b7d": [
            "node_1225"
        ],
        "7b8a2705-4593-4e7e-8a74-d2d1114d0341": [
            "node_1225"
        ],
        "f83f2cd3-50f1-492b-a086-73c038c79022": [
            "node_1225"
        ],
        "1659ef78-ec0c-43e6-ae47-8219a9039430": [
            "node_1225"
        ],
        "cb3128a7-4300-4835-a4f4-49aa81c59149": [
            "node_1225"
        ],
        "f921b00e-6e23-4795-98b4-076c7f1e3037": [
            "node_312"
        ],
        "8804e55d-74bd-4890-8a16-1f18927ad648": [
            "node_312"
        ],
        "aa51a1f5-cdf0-49cc-8df2-4b5392f2c483": [
            "node_312"
        ],
        "e250e850-c75d-4c54-aa34-c469cefc43a0": [
            "node_312"
        ],
        "aff77601-6c5e-43b1-aa8d-65ad5a335472": [
            "node_312"
        ],
        "a38e4385-3938-40d8-b816-0dc19d7ceddd": [
            "node_264"
        ],
        "2b085a2a-9786-45b1-a0c1-d1cb1a128108": [
            "node_264"
        ],
        "8fe5f53a-7185-4344-8f82-c361ecf60ba6": [
            "node_264"
        ],
        "7964951c-dce1-4114-b05e-9566ca27bb52": [
            "node_264"
        ],
        "65e3ca05-29ea-45aa-91ef-adf13813ef8b": [
            "node_597"
        ],
        "4bb56af8-0381-48da-a29d-1c378d1cd2ef": [
            "node_597"
        ],
        "b16c0031-93c9-4651-8aed-6568dc95ee29": [
            "node_597"
        ],
        "b68ff603-348b-43dd-b1ae-c084720270dc": [
            "node_597"
        ],
        "a12df5a4-289e-4e58-ac82-9b06e43afa9c": [
            "node_687"
        ],
        "d9e447c5-f78f-48f1-b8da-32ba10d6f17b": [
            "node_687"
        ],
        "14558a19-ad7c-4a4c-bc25-aea29addf586": [
            "node_687"
        ],
        "22953cec-cc72-4d21-99dd-c1b8cf144e80": [
            "node_687"
        ],
        "88e44668-e850-44f8-9d10-19a1ebc95653": [
            "node_687"
        ],
        "dc338672-389e-45b8-9e4f-d0c99079cf1b": [
            "node_58"
        ],
        "6833d298-50a9-4582-9057-405741d23c75": [
            "node_58"
        ],
        "6162b077-8564-48df-9ebc-7e67315eea8c": [
            "node_58"
        ],
        "5bea24be-67d5-44d0-92d3-6e9ced9ad893": [
            "node_58"
        ],
        "7b29371c-b113-461a-b617-9f1f2339e7ad": [
            "node_58"
        ],
        "0f466bef-74ad-45f3-aa26-42377e049883": [
            "node_198"
        ],
        "4f59c517-2055-4f39-af94-3ef85ca052c7": [
            "node_198"
        ],
        "c53e824f-fdd0-4276-b724-b129cddd1417": [
            "node_198"
        ],
        "a58eabda-8bcd-4afb-89c5-bddbe241b156": [
            "node_198"
        ],
        "8b7f8960-a6b9-4a0e-8735-d789ecf4a765": [
            "node_198"
        ],
        "ad5b21a5-2dd5-43f5-a9b2-88041546c58b": [
            "node_198"
        ],
        "53a71ccf-df50-4901-b02d-f7f6c34fa529": [
            "node_456"
        ],
        "4832aa94-9e20-4daa-982f-0ceb42c582e1": [
            "node_456"
        ],
        "2b600143-0180-41eb-b681-bdd0346951a3": [
            "node_456"
        ],
        "02f6efd8-b696-4cf9-b653-e8b4131be8e7": [
            "node_456"
        ],
        "af4dbb80-4bae-4d23-8c36-ca308edfb45c": [
            "node_456"
        ],
        "7c197997-e553-43a7-889b-1f41240f7d34": [
            "node_456"
        ],
        "685a9300-7a95-4312-9e48-ea009306e25c": [
            "node_456"
        ],
        "7f60b1c7-6559-4199-830c-e44e63ce2e42": [
            "node_225"
        ],
        "361929d6-4a2e-42c2-b69b-3f3345da075d": [
            "node_225"
        ],
        "996b15b8-7a3d-495c-a41c-2cf86e572239": [
            "node_225"
        ],
        "85d4a536-7f81-4c53-877b-54b3b3efd170": [
            "node_955"
        ],
        "45f8272a-c435-434e-9e42-38075fc71a46": [
            "node_955"
        ],
        "45fe5942-c699-46d2-8daf-b141e8f3db7e": [
            "node_955"
        ],
        "79bef728-adaf-4525-883f-74113b7f8ccc": [
            "node_955"
        ],
        "fef84cc3-7ab5-4576-9cd8-3364cfb9b584": [
            "node_955"
        ],
        "7e98f729-f222-4e60-aad5-86520a71f022": [
            "node_469"
        ],
        "8bc859ab-df40-4558-b744-b50622e873a8": [
            "node_469"
        ],
        "573269d8-f0f3-43b5-8b52-8eddea252439": [
            "node_469"
        ],
        "d3c49d5b-575a-4bdf-a998-912384d15a12": [
            "node_469"
        ],
        "81c29c67-4b67-4756-9dda-e46ab2b35656": [
            "node_469"
        ],
        "52fa5761-0e79-4152-9ef7-4aec5d40da8e": [
            "node_1298"
        ],
        "92bb8b7c-9a4b-4bb8-aadb-15981ac238df": [
            "node_1298"
        ],
        "747a1720-b339-4541-aa52-d40b5d22f5f9": [
            "node_1298"
        ],
        "286e8fff-9d40-47aa-8bd1-ff71ce39f5f6": [
            "node_1298"
        ],
        "d106d927-b363-4fdb-8d1d-269c65dd35df": [
            "node_1298"
        ],
        "85a4ea80-e002-4eee-af9e-72df8a063eaa": [
            "node_692"
        ],
        "b788d7f4-fef9-45c9-a7c1-863324a81d15": [
            "node_692"
        ],
        "6007eb3e-dad1-4254-9d5c-f12caf5181f2": [
            "node_692"
        ],
        "3de45201-61e9-4565-9e75-f88eb7bd7a03": [
            "node_692"
        ],
        "92f2417a-89dd-40eb-ab9d-1e47105b644c": [
            "node_692"
        ],
        "dc87ac1a-0394-47a6-a387-a53847256ce2": [
            "node_855"
        ],
        "e6eb0b9c-4ce5-46fd-96b5-f130f931ab1d": [
            "node_855"
        ],
        "bdb13fe3-0c76-4cb6-98ac-d197c5fa3b33": [
            "node_855"
        ],
        "a1eb009d-2ec8-4615-8225-3924c291cf10": [
            "node_855"
        ],
        "596ec184-a8d7-4472-9111-d34f81c78186": [
            "node_855"
        ],
        "bcf35a35-9f3c-48b9-b8ab-003c024787bf": [
            "node_550"
        ],
        "9c809218-9a60-4571-a356-54d815a08d2a": [
            "node_550"
        ],
        "e0612eed-61e5-436a-98b8-33977836235f": [
            "node_550"
        ],
        "072f3967-f372-4437-a66e-39dfde1c10d1": [
            "node_550"
        ],
        "1f0de180-3f5f-4dfe-96b1-17f9140cf4f5": [
            "node_550"
        ],
        "9c20e800-04e6-427b-8084-b095379ecc97": [
            "node_606"
        ],
        "1a0c7a08-ee45-4d06-a493-232cb63308cc": [
            "node_606"
        ],
        "ba54bf03-baef-450a-8635-3f1b81079456": [
            "node_606"
        ],
        "edc9ceb1-b7b2-4bfc-8c4f-2e6577ef6ef9": [
            "node_606"
        ],
        "8093d1b6-c0ac-4d74-96fa-206eadb5ceaf": [
            "node_606"
        ],
        "4dacfcc3-d068-4ccb-8115-51f271d4da2c": [
            "node_606"
        ],
        "26608b35-21c0-4c19-a8bd-cd0c6f346ef0": [
            "node_606"
        ],
        "3cddb0fd-460a-4374-a198-0c2a75a4c9e2": [
            "node_606"
        ],
        "e9a6a3be-3086-43e9-8b03-432bc329e576": [
            "node_606"
        ],
        "2d9b4bd7-470b-4b2f-a8ee-f05ac3a546f4": [
            "node_756"
        ],
        "cbb5c24f-f3ad-44f0-a6a0-66b830701a03": [
            "node_756"
        ],
        "3b874128-76bb-4948-91e2-3d9127c7f663": [
            "node_756"
        ],
        "0b77c3a7-1768-481c-a677-7b10f297f337": [
            "node_202"
        ],
        "047f469a-72b0-4d19-8405-1719f61096fa": [
            "node_202"
        ],
        "7aa8b8d1-2766-4fe1-9578-f75c8d46091a": [
            "node_202"
        ],
        "abbf2c89-ec4e-40c4-8376-b59a0c7fc47d": [
            "node_202"
        ],
        "4531829a-679e-46bd-bff5-1b37a5fa1c65": [
            "node_202"
        ],
        "33bd5d30-8b29-4446-9417-1981945e78e0": [
            "node_302"
        ],
        "b76c7a51-bb47-4f62-951a-e40515e79908": [
            "node_502"
        ],
        "76848951-864f-421d-9c76-cbd120afdf8e": [
            "node_502"
        ],
        "6cad9857-86c9-49f1-b269-5985b9f4bbe8": [
            "node_502"
        ],
        "5cdbd9b1-85ff-40e1-b62f-0b3e39eb2e3e": [
            "node_502"
        ],
        "ce2fc8ba-2450-49a3-b55a-29f926fe7d94": [
            "node_502"
        ],
        "18b43156-a646-4297-a42e-0bb3d758aff8": [
            "node_204"
        ],
        "0ba10753-a19c-42d7-9243-de9732c8140c": [
            "node_204"
        ],
        "67d8793f-9478-41d8-a5d9-95f5f2ebc10f": [
            "node_204"
        ],
        "bb30c5c3-e197-438a-b74c-dd7cc1a694d4": [
            "node_204"
        ],
        "a5c13958-0585-4d29-ae05-5612c8434136": [
            "node_204"
        ],
        "5c6ae368-9c25-45b9-88dc-65b609140701": [
            "node_204"
        ],
        "362aa129-1731-4a3d-8df7-c593a8ef5ced": [
            "node_204"
        ],
        "039d3b09-23e6-4106-97bc-04d1fff9932e": [
            "node_204"
        ],
        "1fb10b5d-8980-4022-b0b3-22e16643584b": [
            "node_204"
        ],
        "67bbad3f-c821-4aa2-aef0-d52295d671fc": [
            "node_462"
        ],
        "26476eb8-c515-44e5-8f4a-0b8a9c21d700": [
            "node_462"
        ],
        "53880fa3-f43c-498f-9091-a7871608387c": [
            "node_462"
        ],
        "6e934b3a-75a8-4449-8d0b-7bdf7aaeafd5": [
            "node_462"
        ],
        "8339e242-a003-4454-b8bc-67a3e29f1f40": [
            "node_462"
        ],
        "c518d8b3-9af3-4d76-a630-3b2ea81f4b1a": [
            "node_970"
        ],
        "4547799f-f6ce-4223-9816-6d4ab0d92e9a": [
            "node_970"
        ],
        "dc21fcab-e96c-4a3c-bcd5-46beed053f60": [
            "node_970"
        ],
        "e2663447-9d8c-4a8d-aaa4-790176899737": [
            "node_970"
        ],
        "f776d7bc-c28c-4efd-8f22-19b472c04e22": [
            "node_970"
        ],
        "2ea679b5-077a-45a9-953e-cb4120b76233": [
            "node_1072"
        ],
        "90acc0c3-bf08-49ad-b4dd-105271fcde69": [
            "node_1072"
        ],
        "326c8c29-8a16-4ce3-b121-ebe8d3b1a3c3": [
            "node_1072"
        ],
        "7faa05d6-85fe-470f-896d-ecb85260e89b": [
            "node_1072"
        ],
        "98dd5f9e-7181-4134-879d-54c9d8098f81": [
            "node_1072"
        ],
        "f460b68b-39df-48ab-a15a-4eaea5e41c2b": [
            "node_1244"
        ],
        "0a68a2f7-1bdf-4869-a6f5-f6339411499a": [
            "node_1244"
        ],
        "af858bf7-f62d-4fd3-8f66-4a17f670ab38": [
            "node_1244"
        ],
        "826ec81d-efbb-49d9-9bfc-61dbd981d28d": [
            "node_1244"
        ],
        "50c02af3-36f9-44ef-a83a-1f423f113fed": [
            "node_1244"
        ],
        "6c10b720-a602-46f5-ab2c-2910567458cf": [
            "node_1244"
        ],
        "9f2bd508-e476-41e8-b9ff-a4b67e0a06da": [
            "node_1244"
        ],
        "88b19f2f-f052-460c-9404-b1bace41c3fa": [
            "node_1087"
        ],
        "32f738a3-d788-4119-a8dd-0a74f1de90ef": [
            "node_1087"
        ],
        "02e38d43-cb67-4070-9636-9f02565b26cd": [
            "node_1087"
        ],
        "75f61eb5-2dca-40f0-a969-2e15e9956da3": [
            "node_1087"
        ],
        "e0918cb9-90ba-42ee-be27-1d6761b06d6f": [
            "node_1087"
        ],
        "92f79a3e-6c3d-4957-b9b6-a5658e8b8f46": [
            "node_1087"
        ],
        "f4f19cb4-0e63-49ee-8b3d-bfccf538c8c0": [
            "node_1087"
        ],
        "a883f6e1-dd70-44aa-8ad0-90c2100a277e": [
            "node_1087"
        ],
        "d5b99bcf-a7e4-4639-b28a-cd41a2712bc0": [
            "node_1087"
        ],
        "a5fcd62d-7aee-4e34-a841-1c2961255db0": [
            "node_1087"
        ],
        "7752aec3-401f-4ab1-835b-485af9f1c3b9": [
            "node_78"
        ],
        "af896b8e-964b-4500-8006-6b7a0b77bab9": [
            "node_78"
        ],
        "7b4dc898-49a1-475e-96be-8b3e91f4b776": [
            "node_78"
        ],
        "8270d65d-1b5f-4787-9761-0b7499c4bab7": [
            "node_78"
        ],
        "ad8010d6-e1cf-458c-a7a1-e07f7e1a6b88": [
            "node_78"
        ],
        "916f74b1-fe56-41cb-b5cf-6ea19c097d4a": [
            "node_1025"
        ],
        "72b14502-01bf-4373-877e-d6230b9b09ad": [
            "node_1025"
        ],
        "f15f612c-ecc8-4324-93cd-1e0022e11531": [
            "node_1025"
        ],
        "69435783-44c3-4b6b-b72f-4b9437809a3d": [
            "node_1025"
        ],
        "b3a85228-2fe3-496f-aa66-e312c2e11220": [
            "node_1025"
        ],
        "6acd555d-63af-4f86-8350-00cf8c60232d": [
            "node_936"
        ],
        "0e3821c3-da73-4a98-bcd9-0ac8efd46105": [
            "node_936"
        ],
        "2916ec23-7cd4-4e88-8c1e-378428935c72": [
            "node_936"
        ],
        "48342f3c-d44e-4330-b0f8-83680265e6fb": [
            "node_936"
        ],
        "a13da49f-a24e-4df6-b4d2-e82abe796c76": [
            "node_936"
        ],
        "b0d97432-6edd-48cc-937f-575e5d909306": [
            "node_128"
        ],
        "826557a0-304d-4d31-b6c7-9debc14025de": [
            "node_128"
        ],
        "df8da502-b54f-4e8d-a6b5-edb0452dc8f5": [
            "node_128"
        ],
        "2dbc5271-a937-4fc1-ac70-a1d14d5c9a59": [
            "node_128"
        ],
        "26d69c6e-5135-4a1b-882d-4945c68a3e41": [
            "node_128"
        ],
        "fea5f60a-d14a-4256-9012-b5d3a8e962ad": [
            "node_548"
        ],
        "2208692f-1d33-4332-98e8-85af4637e325": [
            "node_548"
        ],
        "211cf262-0757-40ae-96c3-2d9e06fb7f87": [
            "node_548"
        ],
        "ccbc7e26-b7c2-4cea-83a7-33ff58001f2f": [
            "node_548"
        ],
        "e1339cc2-850d-4d7a-8da4-f6053b7e76f0": [
            "node_548"
        ],
        "c51b0e4c-ca92-47e4-bb40-01b93e5c4922": [
            "node_548"
        ],
        "893a5499-c700-4742-8a7f-63d4729caff9": [
            "node_548"
        ],
        "b7ef2e39-c8c2-45a8-b45e-8d066776146a": [
            "node_548"
        ],
        "f0e87075-6a0c-469c-8eb3-f9b2ef349d58": [
            "node_87"
        ],
        "4fc3bf16-cfb3-40aa-85e2-e014e5528cd2": [
            "node_87"
        ],
        "4e2a7846-9a4c-4101-89a4-aa146ef780ea": [
            "node_87"
        ],
        "291b55ef-8872-4e3c-b427-b3f6182ca49e": [
            "node_87"
        ],
        "b1e3a180-0dab-4c81-bf75-9d915b502eb9": [
            "node_87"
        ],
        "65df5cf9-4b07-47bd-b645-9aceb5af84e2": [
            "node_87"
        ],
        "2039b6c4-5bfa-4b71-9454-f9cc947a7bec": [
            "node_87"
        ],
        "4daaa71e-e3bd-4f16-b292-e384c8fd594d": [
            "node_87"
        ],
        "e6562299-5391-4456-9a89-3a221dcd1a7e": [
            "node_87"
        ],
        "53e87812-c1b6-4e9c-9b7c-6c1a47839900": [
            "node_87"
        ],
        "75d30097-c8cd-40bb-a7ca-189131c68328": [
            "node_559"
        ],
        "e5274884-bd65-4b45-b9fd-a7773388ff36": [
            "node_559"
        ],
        "ee228351-d00d-4f06-a898-bcd7cbb9e76f": [
            "node_559"
        ],
        "d9805202-40a3-4156-90d4-ebb489253c80": [
            "node_559"
        ],
        "5b92bfc2-497e-4848-9fc5-08649e15bb4d": [
            "node_559"
        ],
        "4674acfb-d2f5-4d1c-8820-213a17445f78": [
            "node_559"
        ],
        "fe630376-0b7a-4896-835d-c8fa254639f5": [
            "node_559"
        ],
        "e8027310-23ae-4386-8143-56e8072f7e5a": [
            "node_509"
        ],
        "6aa0e5be-1b67-439d-acf1-80f1c1599bf2": [
            "node_509"
        ],
        "40ee9bf8-08b6-4eea-ab5b-5aa0d504a82a": [
            "node_509"
        ],
        "9597d104-203b-47d1-bfe2-f74230fab82d": [
            "node_509"
        ],
        "413c25c6-3d6b-4344-ae4f-cb9cd2a6342a": [
            "node_509"
        ],
        "70849b4d-a4fd-4ea9-8a84-7b013d3a33fb": [
            "node_509"
        ],
        "eeb744b0-b7df-4a4c-94a5-762c36d5148c": [
            "node_509"
        ],
        "775477cb-288b-494c-9a9c-44d8335b2653": [
            "node_675"
        ],
        "8334f2a4-0766-497a-820c-fea28c708a9c": [
            "node_675"
        ],
        "01b5aa50-9319-447b-846c-111e5f2b682e": [
            "node_675"
        ],
        "ae38e16a-1cdc-4c11-978b-944f96c6a8c6": [
            "node_675"
        ],
        "d6cb310f-d33b-4a58-bcf3-f00d80e6b87c": [
            "node_675"
        ],
        "0c4f69b5-b44f-4389-b8a8-c81363f34634": [
            "node_1263"
        ],
        "dce453b6-f8fa-45cc-abcc-52af246df805": [
            "node_1263"
        ],
        "0807668e-118b-4a2c-ad56-ca2a36fff8fe": [
            "node_1263"
        ],
        "29ab896f-ed68-4ab2-a672-b8028700926b": [
            "node_1263"
        ],
        "89b3e9db-1df0-44c7-9f63-04bc63e4a385": [
            "node_1263"
        ],
        "9db4973d-8f59-4445-bbb9-8fe268dd432a": [
            "node_693"
        ],
        "59facee4-07fb-4062-a2df-2a9f72aeec75": [
            "node_693"
        ],
        "88f52bad-872b-4189-8a40-7c53b1651cb1": [
            "node_693"
        ],
        "e86f0ca8-a849-4bef-975b-2d1f70a0a1f9": [
            "node_693"
        ],
        "1471f70f-20fa-42ee-bab8-bbdcbb411fd8": [
            "node_693"
        ],
        "9a459a7f-fb84-41d1-bd38-fb619369efe2": [
            "node_693"
        ],
        "33e306b9-d562-49f1-8215-1ca4acc6c986": [
            "node_693"
        ],
        "8d48d774-d253-4eb6-b51d-59e237bb8053": [
            "node_693"
        ],
        "16e46be5-cf6e-428f-9088-28b2db656a96": [
            "node_693"
        ],
        "f78762ee-6041-401b-9467-0b52c87901b9": [
            "node_693"
        ],
        "b99406b0-69f2-4cc7-9dc9-fbd9b3092715": [
            "node_241"
        ],
        "4ebcf959-d269-4c70-8c9f-befd7ef63c07": [
            "node_241"
        ],
        "37b2e49c-7207-4b15-a92e-fbf8b89ec0e6": [
            "node_241"
        ],
        "bf7cb4d7-3722-4cc7-9bb4-4c5f1be8dd26": [
            "node_241"
        ],
        "09f5d5c7-e849-47ea-a85c-f998268bd760": [
            "node_241"
        ],
        "3873e561-9223-479f-8a70-e73bebd48183": [
            "node_1193"
        ],
        "bfdcfa37-f860-4611-a8fe-6ac29e770045": [
            "node_1193"
        ],
        "73cf4775-c1ac-4044-9208-8a8ed42e6439": [
            "node_1193"
        ],
        "ec5268c1-bfe3-4e77-9124-0dda5df22e75": [
            "node_1193"
        ],
        "94df0a96-af49-48a5-bb36-92bc717ec3d9": [
            "node_1193"
        ],
        "c9bac743-9787-4047-ab6d-8460bed75251": [
            "node_1193"
        ],
        "7b1a3479-61f4-432b-8901-59f6ab46909d": [
            "node_1193"
        ],
        "33490816-db34-463e-af1a-e81739dd3349": [
            "node_1193"
        ],
        "80018252-64b9-4089-a2fa-2018fb9d1674": [
            "node_332"
        ],
        "265dc50e-9077-4f5a-b759-4f3e9b907943": [
            "node_332"
        ],
        "762f255f-21eb-41f2-8208-638dee70550a": [
            "node_332"
        ],
        "67fd48f7-3c7b-463f-8d98-2d32bf15874f": [
            "node_332"
        ],
        "e1e6325f-710f-4aec-84ff-fc0821ee4f56": [
            "node_332"
        ],
        "795e0ef5-5f0d-4906-9db8-da5ecdd056f6": [
            "node_738"
        ],
        "e81c126f-0795-448b-9934-305e9efb5805": [
            "node_738"
        ],
        "05f300ad-9d83-4d22-b50c-4c758973066d": [
            "node_738"
        ],
        "373e69fb-de0a-4ff7-9b20-58ace5c5477a": [
            "node_738"
        ],
        "c6779aa6-48d7-46eb-9dc5-a30d03a0caaf": [
            "node_738"
        ],
        "eeff8f80-c0e7-422d-8629-0fecdd04ce4e": [
            "node_164"
        ],
        "5c2a455f-d654-416d-9b6d-39fabe6cb188": [
            "node_164"
        ],
        "76bae9e4-12c8-40f6-a94b-7ebf28e5e647": [
            "node_164"
        ],
        "c6ac3aa9-b1f6-4cfd-ab92-5f1c7378e9f6": [
            "node_164"
        ],
        "e1f09775-ee01-4354-8c65-64f644669e58": [
            "node_164"
        ],
        "4e0ca481-b9ca-4c08-bfbb-2a0eaef93e3f": [
            "node_389"
        ],
        "c43eb2d1-fc88-430c-9f43-ea291af2d9a5": [
            "node_389"
        ],
        "4064b002-988d-4842-beb8-d763350829b5": [
            "node_389"
        ],
        "d352f6ee-9205-4837-bacf-22435c1379fb": [
            "node_389"
        ],
        "27abb7c5-4875-4d28-b52a-8ed414358b08": [
            "node_389"
        ],
        "cc757ff7-588b-41a1-8da0-db2f143a2ca2": [
            "node_733"
        ],
        "04efb53b-b26f-471c-a441-550c3f381a7c": [
            "node_733"
        ],
        "7b683a4a-f496-41ba-8b1f-16c77e4f39df": [
            "node_733"
        ],
        "83a39083-013f-4021-b347-09851fc4c37a": [
            "node_733"
        ],
        "ca28f1d4-e80c-470f-ac64-b9cf96d8871a": [
            "node_733"
        ],
        "706682f1-e6d2-45c6-bf2d-88266caa2b22": [
            "node_1112"
        ],
        "a75d00c5-9e20-4551-8aed-f76331e48158": [
            "node_1112"
        ],
        "27b4fb66-c55b-447a-a552-2dee1377302a": [
            "node_1112"
        ],
        "6b23f301-cd4d-424d-b641-5938e5fd9f0d": [
            "node_1112"
        ],
        "f429758d-c36a-4a84-a17d-bab3628e5073": [
            "node_1112"
        ],
        "5b5a0696-b5fc-46ea-bca0-aa1144f25b4e": [
            "node_385"
        ],
        "b56deb61-283f-4d03-9376-b3a10935db8f": [
            "node_385"
        ],
        "4d02f262-02e6-4ea2-a7d1-8b53845c6834": [
            "node_385"
        ],
        "6178e64c-d384-488a-96ea-1fcd646e0bbd": [
            "node_385"
        ],
        "fd344550-9682-4251-9849-58793712ddd5": [
            "node_385"
        ],
        "c39337dc-9ca2-4a96-bd76-a36e68ce9177": [
            "node_795"
        ],
        "33b51a06-5e29-45d7-b5d6-08116c63b45c": [
            "node_795"
        ],
        "42c9a229-a622-4974-8f07-3a91e77d0e33": [
            "node_795"
        ],
        "1b11586e-0a93-452c-910b-bb8d766c3eb5": [
            "node_795"
        ],
        "3728ec24-76d2-4891-b9fb-db4ad3d6668b": [
            "node_795"
        ],
        "4db4c28d-b645-4403-9640-b3a001c6e09c": [
            "node_594"
        ],
        "d6540c77-335c-434a-a35c-38cfe582a050": [
            "node_594"
        ],
        "edbf59eb-0baf-41ea-a2ea-9cae6c820ed9": [
            "node_594"
        ],
        "752395d3-d6c8-490a-a117-c9a2b62be227": [
            "node_594"
        ],
        "d18214eb-adf0-48b3-9d67-56bdbd45428c": [
            "node_594"
        ],
        "378cda6b-4be5-4cc1-9b27-51a05da484e6": [
            "node_4"
        ],
        "0f6a18a9-db0c-4285-8b16-78facd1fd5ef": [
            "node_4"
        ],
        "8e4f2271-46bd-490b-afbc-c4fd2e6e9cc9": [
            "node_4"
        ],
        "c3b55691-319f-4829-8a73-49f7bb85806f": [
            "node_4"
        ],
        "1eed59cf-eabd-4633-8b83-602947215818": [
            "node_4"
        ],
        "88174f45-4904-494f-bbb1-3ef20224bac8": [
            "node_562"
        ],
        "c3278bab-1793-4f3a-a289-3e0a0299be03": [
            "node_562"
        ],
        "32a2f030-16b4-4c6f-9b8d-21d66d40c0c1": [
            "node_562"
        ],
        "f82e88e1-9e7c-4e30-9b45-b585676e2ad2": [
            "node_562"
        ],
        "f2da853b-dbc1-40b0-bc3e-4f16b2a25f8a": [
            "node_562"
        ],
        "6d5703dd-2d42-418b-8c10-83734132b63d": [
            "node_562"
        ],
        "fb3bbce0-5a6c-4383-91cc-bee62effa461": [
            "node_663"
        ],
        "996d8fa3-01fe-444f-ac96-96f26675b4e9": [
            "node_663"
        ],
        "3dfe7d21-1fb9-4542-8947-4e04e8eaee7d": [
            "node_663"
        ],
        "89782e9b-d113-4114-93a0-0155e30c894c": [
            "node_663"
        ],
        "46ff60ec-c3d5-4ba6-800f-318f1f407c84": [
            "node_663"
        ],
        "0c635133-5a20-43bf-bcaf-f5ec67162d2d": [
            "node_118"
        ],
        "13c2532b-afec-4c8a-a8f0-2fb46984737b": [
            "node_118"
        ],
        "ccc8dd11-8640-4eb2-915f-6e7ec920b314": [
            "node_118"
        ],
        "76591c96-748b-4213-bc79-f24addc4c0ac": [
            "node_118"
        ],
        "dc8bcf2d-5712-4cae-bfab-f32dff969b46": [
            "node_118"
        ],
        "1b1e132c-1e4f-499e-b9c0-212dc9b30530": [
            "node_830"
        ],
        "bce3cc68-091c-47db-8607-8b6d5e823030": [
            "node_830"
        ],
        "86dfdeeb-906b-442a-918d-38b8549cb960": [
            "node_830"
        ],
        "9b446c22-6aa1-41b0-b12a-fc18944a9d3d": [
            "node_830"
        ],
        "38b58eb7-5c12-46b1-956e-c3d3b4636ca2": [
            "node_585"
        ],
        "ef965b5d-56db-4e2c-8e12-1e2cbb9cb667": [
            "node_585"
        ],
        "e3d64f37-b58d-4191-af86-e4b37409c7c2": [
            "node_585"
        ],
        "4ec3b5c0-bf87-412a-83b1-e012a46718a4": [
            "node_585"
        ],
        "74b1a91f-0b64-4e9c-b675-a8785c3d6c2f": [
            "node_585"
        ],
        "6ae3daef-46b3-4a49-9b8f-aacc94d64081": [
            "node_854"
        ],
        "cf47bd80-7886-4369-8caa-c4a87b1d5847": [
            "node_854"
        ],
        "b3b86d57-210a-4e76-8792-942d8bb00c7a": [
            "node_854"
        ],
        "f1a86d6a-0fbb-4d22-a7c5-f7ace8890ba3": [
            "node_854"
        ],
        "ba75dabb-b820-4367-8bd5-56f95a7ab096": [
            "node_767"
        ],
        "45a047ec-0b43-44ec-8bef-27b8bdfee127": [
            "node_767"
        ],
        "dafc1bf5-ac23-4501-9e85-a602cbefca7f": [
            "node_767"
        ],
        "00b02a2c-abc2-4c16-96c3-bccec8fde9b1": [
            "node_767"
        ],
        "5133c554-92e7-4bed-ab02-0dc5b1d1f1fb": [
            "node_767"
        ],
        "99ddc11a-70d4-49ab-8db2-85c8d864df11": [
            "node_191"
        ],
        "e13e9d9c-bb45-4551-ab34-7042d5731ae7": [
            "node_191"
        ],
        "345aa517-a6f1-42ab-a3f0-114f2e387c54": [
            "node_191"
        ],
        "b86cb1c3-4914-48f8-a841-af586d4fa1d7": [
            "node_191"
        ],
        "6fd6a736-6b95-4159-86fa-6839f9aeb7fc": [
            "node_191"
        ],
        "1857de34-8f1a-4fea-a77c-1b233a24330b": [
            "node_111"
        ],
        "e0d53105-6dd9-4e09-965c-1cadad4ed565": [
            "node_111"
        ],
        "2cf64e64-c662-47c1-9a9f-7e1ca7e8f005": [
            "node_111"
        ],
        "558efd44-2c77-4c34-b129-3f08a2436a4a": [
            "node_111"
        ],
        "59df631e-64d5-4c81-8120-1979f91581db": [
            "node_111"
        ],
        "42e204f4-52c6-4c50-bab2-a0cfd001fc75": [
            "node_851"
        ],
        "f768e94e-43d9-44ae-9b8e-a110aa96a6d1": [
            "node_851"
        ],
        "b6ae2a52-4cba-4701-86e5-269e875532ea": [
            "node_851"
        ],
        "9376f7f1-b753-4d25-99d2-4619e965f916": [
            "node_851"
        ],
        "7a7054e1-b9eb-4344-8f57-7cbfa0ce23ac": [
            "node_851"
        ],
        "1feb3509-7b1b-4d70-9f61-bd8ff01acbff": [
            "node_851"
        ],
        "4a8fed0c-cac5-498a-ad4b-ccba2a6265b1": [
            "node_851"
        ],
        "557344c7-3eaa-44b9-a127-1ab778c3c755": [
            "node_62"
        ],
        "66086c29-537c-4ec8-93fb-87a68cf69887": [
            "node_62"
        ],
        "6c1827ac-9c0a-46f9-b4c4-30b571e4adb7": [
            "node_62"
        ],
        "84486d7c-c493-4ad3-b487-d9a6dc6eaad1": [
            "node_62"
        ],
        "263cab2a-13d8-40a1-b81a-7c1a846bbb42": [
            "node_62"
        ],
        "4cb95bae-3ea1-4fa0-a161-9843f046e9f8": [
            "node_485"
        ],
        "52c0e789-9423-45d9-a890-aabda865fde4": [
            "node_485"
        ],
        "1011bf85-9585-4085-836a-a86daaa2e58a": [
            "node_485"
        ],
        "574bd9be-adbb-4e38-aa74-e8ae165d18ed": [
            "node_485"
        ],
        "9db3b503-543b-4395-a809-1ad309becf4a": [
            "node_485"
        ],
        "228fdc6a-d403-4796-bab5-75674f2a8ff6": [
            "node_485"
        ],
        "009d02d3-72e1-403c-a805-f8ae92048da7": [
            "node_485"
        ],
        "310c410c-7b87-4994-b5ff-48e5fcc97752": [
            "node_997"
        ],
        "46b6606c-4d33-4b70-b8da-a85e4e69d211": [
            "node_997"
        ],
        "7211b0e6-8e5d-464d-a768-673c0dc4a81e": [
            "node_997"
        ],
        "6d5e2971-ee1e-4cfa-8fe3-6d20e3ba34a3": [
            "node_997"
        ],
        "0bd0ed3d-c259-46b8-b367-2149aedda753": [
            "node_997"
        ],
        "a77375db-6845-4357-b8ef-fc28ca543329": [
            "node_508"
        ],
        "5f3614d4-66de-4fa2-bc9a-5c7eb3950b7f": [
            "node_508"
        ],
        "1dce242d-be97-467c-a18f-65e443328a66": [
            "node_508"
        ],
        "d9a66704-8c81-4574-be54-75a22db5ef38": [
            "node_508"
        ],
        "c2cb5a24-b050-4c45-bd2e-596eca2835b1": [
            "node_508"
        ],
        "850f967a-5fa2-44c4-919f-90e89aba3124": [
            "node_763"
        ],
        "7aebf5c6-98b7-4b86-a3e7-0a9a9eaffb94": [
            "node_763"
        ],
        "af291b84-497a-4a05-9365-275cf9bd4c5a": [
            "node_763"
        ],
        "5558988f-7338-4107-8369-7763a80d883a": [
            "node_763"
        ],
        "14b2b3b3-2173-4cd1-a20d-22a26f2f7aff": [
            "node_763"
        ],
        "c886e3ee-9f42-4168-af0a-29bfb1620d77": [
            "node_763"
        ],
        "ba7812fa-a502-4937-b806-953a85065e3b": [
            "node_763"
        ],
        "5e0a1f08-4094-40e4-933a-32befd08524d": [
            "node_763"
        ],
        "4387445f-e523-46c8-b79d-fb9a3ec33c62": [
            "node_763"
        ],
        "f5256953-dd7f-4286-9ce5-8126b101bff6": [
            "node_763"
        ],
        "27ac3be3-222b-4e3e-a41d-e4a50ccb08d2": [
            "node_694"
        ],
        "f0e2080d-08c4-41c0-89a4-02133b1226fb": [
            "node_694"
        ],
        "245c4364-ed51-4e60-bc44-96473dc6f869": [
            "node_694"
        ],
        "f9c0722f-d934-4459-ba6d-d6f25b474bd0": [
            "node_694"
        ],
        "d9cf1249-93f2-48ec-a1bd-a691e998c15a": [
            "node_694"
        ],
        "80a12592-4610-41af-a868-cd6493fe41d6": [
            "node_694"
        ],
        "dbfa70e0-3f91-4a05-b538-449cf773f2ca": [
            "node_694"
        ],
        "3668ba66-c76f-46c8-a405-dcc2e686a78e": [
            "node_694"
        ],
        "4bc4e813-b87c-4d2c-82cf-aa47aea4f34d": [
            "node_973"
        ],
        "f50473d2-3882-4d4b-84cd-39bb28562cf2": [
            "node_973"
        ],
        "b2d57a55-dc77-4238-a4db-33db3eabaefd": [
            "node_973"
        ],
        "9fe9a568-d606-45d2-b587-a0bfd02843af": [
            "node_973"
        ],
        "8edc2e19-b266-40fe-b84e-03cd7444b282": [
            "node_973"
        ],
        "1bfd8c37-4177-4aa3-99af-1c6b2037524c": [
            "node_973"
        ],
        "ebb194f2-2346-4d86-8043-640da4d0b16b": [
            "node_43"
        ],
        "2423e8e2-dd5d-447b-b431-61becbcbad2d": [
            "node_43"
        ],
        "748a331a-697f-4131-abe7-d6b6d5578722": [
            "node_43"
        ],
        "87c17844-a8e3-40a7-b1ac-d2052bdf9910": [
            "node_43"
        ],
        "4a8163a7-8af0-42e3-8002-ad5b395c487a": [
            "node_43"
        ],
        "deb0e486-b95e-4ff7-be41-6a0d4f86d518": [
            "node_85"
        ],
        "349f329f-f04d-4672-ac6b-8eebc28938c5": [
            "node_85"
        ],
        "42c46319-0054-426a-aa8e-b6a5264b5e9e": [
            "node_85"
        ],
        "c64f3558-4a06-4c94-8324-d25221d0d88c": [
            "node_85"
        ],
        "7b3fbbfd-cc72-435b-892b-ccc1b0e35288": [
            "node_85"
        ],
        "58fce4cd-e543-48aa-b104-c67986428cc1": [
            "node_85"
        ],
        "50c05d1e-4f60-4ab4-8d68-e9e95a4976ee": [
            "node_85"
        ],
        "0558e56b-8315-44e2-8e58-6ee6f5790600": [
            "node_85"
        ],
        "a2dcf0ca-2759-405c-91a0-cc6d3fa709be": [
            "node_85"
        ],
        "5186f875-f4ac-4b5f-89ca-474151327044": [
            "node_761"
        ],
        "32c24cbb-3914-4f9e-b275-8044d396feee": [
            "node_761"
        ],
        "fe7e0da5-8ba3-4b41-a23d-b81374e363da": [
            "node_761"
        ],
        "ee0dc645-917c-4f88-9163-1bf2beaccf55": [
            "node_761"
        ],
        "149863fc-0dd4-4687-a5ee-a5cb4de59bb7": [
            "node_761"
        ],
        "d17d8301-8470-4ff3-84fc-c656350e1cd9": [
            "node_746"
        ],
        "526fc34e-2e75-4587-a8c4-dff5a8908034": [
            "node_746"
        ],
        "a254a2a4-2eba-436c-8413-b0592342e3ba": [
            "node_746"
        ],
        "3a2b877d-7026-47d2-aaa6-65d4a6dbb456": [
            "node_746"
        ],
        "a4e1f8f5-fcd7-4236-a5c1-79c9f75e30e2": [
            "node_746"
        ],
        "4b37c448-5bef-44c0-a63d-20503cca7891": [
            "node_439"
        ],
        "0e550725-291a-41f1-a368-4424c49e2140": [
            "node_439"
        ],
        "86a9031b-6e1a-437a-bcc4-9a25af27fbb5": [
            "node_439"
        ],
        "eade2219-d3a4-422b-b136-30ef8bae4d61": [
            "node_439"
        ],
        "66cf36c3-5eab-419c-90a6-d98583bc4345": [
            "node_439"
        ],
        "07c750c4-bcc9-4c53-9a69-77870dab2b8c": [
            "node_740"
        ],
        "93260e6b-003d-445a-b8fc-952ca6f12c38": [
            "node_740"
        ],
        "e5a1c178-2d4b-44b5-89f2-1502aee56a89": [
            "node_102"
        ],
        "07294c62-49b1-43d8-9348-ac3c12ca3a17": [
            "node_102"
        ],
        "fcafa06f-6003-422d-a74d-e053fdcf02f4": [
            "node_102"
        ],
        "485d000d-5021-4a9d-bde2-52c613d63076": [
            "node_102"
        ],
        "5d8dec49-e04a-4a5f-939c-2d5c091e06a8": [
            "node_102"
        ],
        "43d0e718-0c79-43fe-891c-61c468ffc299": [
            "node_102"
        ],
        "865701d5-deb8-42be-bc63-936bfb134fc1": [
            "node_102"
        ],
        "e356e508-a95c-4e02-8e78-3974c95e1def": [
            "node_102"
        ],
        "31b36e2a-d678-4445-953d-5d3b6c1fcd0b": [
            "node_102"
        ],
        "9e8bbbf8-de9b-4e07-8f3a-446511228207": [
            "node_102"
        ],
        "8932855c-73c4-4437-8a1d-eb470a25ecd7": [
            "node_968"
        ],
        "2476ef0f-bf24-478e-9e1e-e1554197c37e": [
            "node_968"
        ],
        "9686c649-9495-4bfe-9530-2f489e89d46a": [
            "node_968"
        ],
        "657d4398-d837-4d3f-97c3-015c3cff948a": [
            "node_968"
        ],
        "c9fac5bd-28da-40ba-b22f-b57fe37f7a6a": [
            "node_968"
        ],
        "f5c1e524-8e29-45fd-a2bc-16ccf5176bfa": [
            "node_748"
        ],
        "0180d39d-0727-40d1-82fd-39f1637ff472": [
            "node_748"
        ],
        "ea5df130-de5c-434d-ad8b-937fc3fc05c5": [
            "node_748"
        ],
        "3e82336d-5e09-491d-a315-861faf8c7b32": [
            "node_748"
        ],
        "b092c79a-5062-4876-ae07-c029eda88122": [
            "node_748"
        ],
        "43f5021b-8cf5-428f-8d8c-398196470394": [
            "node_748"
        ],
        "7a500ad1-cbba-4adc-a38d-e10c647a1bbc": [
            "node_710"
        ],
        "88fe9351-c794-415b-a9c6-19519a6435b6": [
            "node_710"
        ],
        "b1f8c1cc-7872-4885-b5f9-c43ae064afd4": [
            "node_710"
        ],
        "0d2f8639-0654-4064-ba2d-e3ec71cac3a6": [
            "node_710"
        ],
        "5cf9ce88-1391-43f9-8b03-5db80be21640": [
            "node_710"
        ],
        "92c51da9-1e85-4587-9862-6ff709138d7d": [
            "node_710"
        ],
        "82a28a85-a386-4e33-9de1-fc050c905e88": [
            "node_710"
        ],
        "efa53420-80d4-47c1-9ed2-1df41d6fb234": [
            "node_710"
        ],
        "0058f434-75f0-4040-83a4-c65d22c423be": [
            "node_710"
        ],
        "8920eb3e-2702-4b54-8981-65ee658c3b5b": [
            "node_710"
        ],
        "9de36219-5d6c-462a-a79f-391c255be81f": [
            "node_752"
        ],
        "1390ef85-8dd4-4382-b574-9a5d93ede0e6": [
            "node_752"
        ],
        "53f448d4-54f2-4c1c-a8ba-b0d4c1e42849": [
            "node_752"
        ],
        "2f37164c-c2f2-43ba-ab7d-60e30c5b9320": [
            "node_752"
        ],
        "8c47c70c-87ba-4f9d-a023-920bff0c2a8d": [
            "node_752"
        ],
        "6cf0c224-a2d8-4c46-afd7-74fc7d426834": [
            "node_752"
        ],
        "095d8323-e41e-4cc6-9977-e7c098294795": [
            "node_752"
        ],
        "f3f6bea3-79af-4592-a553-fca82f2a7130": [
            "node_752"
        ],
        "1e9a9ccc-1921-4e48-8269-e44730bc278d": [
            "node_178"
        ],
        "4bba743e-2b5b-4775-b219-a8d449e4fa39": [
            "node_178"
        ],
        "d1741e3e-2cf4-44d8-b1d6-71237ed1b739": [
            "node_178"
        ],
        "573e61e1-7ed9-4b62-b8fb-7394b2fac0e5": [
            "node_178"
        ],
        "14dfc901-7a9b-481c-bbab-66938a386c77": [
            "node_178"
        ],
        "67fe1ac8-3296-4acc-aa56-af911cf08cc8": [
            "node_387"
        ],
        "e1a79b48-8316-467a-9e97-fc8fc4e334b2": [
            "node_387"
        ],
        "017e6e25-edf5-4223-8925-06ce190cad72": [
            "node_387"
        ],
        "abeb7667-266a-46f2-bfe5-301ef58b26fc": [
            "node_387"
        ],
        "e0b70f3d-fe94-4684-8265-0fd528189b6f": [
            "node_387"
        ],
        "0978fe7b-8c05-4e79-9974-0e0518e2215b": [
            "node_442"
        ],
        "1308ba82-e58a-441a-991c-492b01539765": [
            "node_442"
        ],
        "2c5abfd7-53c6-461d-93fe-42efee88218c": [
            "node_442"
        ],
        "6e208941-b4c5-4022-93ad-ecb7e28b8f68": [
            "node_442"
        ],
        "83dd2f88-b0f2-4060-83ee-7c9456c9daf2": [
            "node_442"
        ],
        "e6531884-6a52-4b45-b129-85f35af15631": [
            "node_843"
        ],
        "950b8ab7-1a99-494d-bb07-d5bf41df1739": [
            "node_843"
        ],
        "0b76d01d-de3e-4516-9acf-25f44feef26c": [
            "node_843"
        ],
        "67adf266-a50b-43d8-9910-06c59667fe7e": [
            "node_283"
        ],
        "4581fb08-20eb-483c-abc7-e549dde577d4": [
            "node_283"
        ],
        "f35048b4-d945-49d3-b6fa-e8c54b45b563": [
            "node_283"
        ],
        "6416e092-4307-4800-9d49-5a76fc7ce095": [
            "node_283"
        ],
        "5b76581d-d58f-4811-a77e-36962605bf52": [
            "node_283"
        ],
        "c2692541-b2a4-43a8-b8a9-003f8e3defb8": [
            "node_505"
        ],
        "2ee309a1-202b-45fc-a0d1-c3f569303908": [
            "node_505"
        ],
        "193f50a3-0ba5-46b2-9585-15fa90665a28": [
            "node_505"
        ],
        "a05e46e7-bc53-4445-a62b-3b685cbfc539": [
            "node_505"
        ],
        "12cbe2a2-c952-4a39-ad87-747377d67af3": [
            "node_505"
        ],
        "476d898e-d6cf-4358-a154-c0fda958507c": [
            "node_1055"
        ],
        "0709bf9e-ac9c-4ba8-afaa-e12fffed4258": [
            "node_1055"
        ],
        "d09043f6-0600-4fdc-a35a-c4e05c6f3a80": [
            "node_1055"
        ],
        "000941ac-cba3-4ad1-ac2e-dd155299010b": [
            "node_1055"
        ],
        "91ca96e3-36c9-4312-80f9-727854bfb50b": [
            "node_1055"
        ],
        "3d140bbc-dc3b-4095-9433-d0d3cdac336a": [
            "node_544"
        ],
        "10078eae-6407-4697-8668-b8bd1e131a85": [
            "node_544"
        ],
        "ed059579-51e6-4498-8d2a-0b56ff2b6da5": [
            "node_544"
        ],
        "57471475-1767-4177-9124-d80294c0dcbc": [
            "node_544"
        ],
        "0560b20c-dfce-4788-a3d2-44be0fac845d": [
            "node_544"
        ],
        "15b48e33-a9b8-4144-9409-a196839ebfb2": [
            "node_544"
        ],
        "1ce1e01f-ff06-4e85-8b6d-610d91c0e8b6": [
            "node_544"
        ],
        "12d90b2d-0fd8-41da-9789-2250cc09ae55": [
            "node_57"
        ],
        "b35948af-c10b-4808-8378-f01774631aa6": [
            "node_57"
        ],
        "f211c1a4-0266-43b5-8280-599e394b7d24": [
            "node_57"
        ],
        "163b2fc4-3a21-4244-be35-c4e02f036fea": [
            "node_57"
        ],
        "4f5d7dcf-d7bb-4c43-ad56-f06bc5c0a39f": [
            "node_57"
        ],
        "4a34f49c-a449-42e6-a44d-d439286192e5": [
            "node_156"
        ],
        "3a1171ff-50d3-4a8b-9ac9-4a89a5dade36": [
            "node_156"
        ],
        "d791444e-fcdf-47f8-be2f-35f9d7460c48": [
            "node_156"
        ],
        "3d9a3db0-0ff7-49ce-95e3-d530baae2035": [
            "node_156"
        ],
        "83f0763f-a195-48df-8ec8-10ab336ce514": [
            "node_156"
        ],
        "fe280c0e-5107-48f4-a0cf-4b6abf870f7f": [
            "node_156"
        ],
        "930ce2ef-4d29-42eb-9bc6-3ec11a64e742": [
            "node_553"
        ],
        "fd5e0920-c0d7-48db-8e10-6cc51d448dd5": [
            "node_553"
        ],
        "e22d6a10-60f4-4c34-a414-d7071a509e7a": [
            "node_553"
        ],
        "044cd3a5-d585-4b6e-b52d-c036cec7ade0": [
            "node_553"
        ],
        "edb9edee-0469-472d-b3c5-5525f9f23cfd": [
            "node_553"
        ],
        "a6127e59-5424-41af-9486-fb7552290781": [
            "node_1150"
        ],
        "d68faf66-528f-47dc-a207-4d6401a942b6": [
            "node_1150"
        ],
        "22fb0f92-3558-4637-b656-35da356852de": [
            "node_1150"
        ],
        "d35227f9-cffa-4b8c-85bd-ae7d55a97dc4": [
            "node_1150"
        ],
        "d441c08f-61b8-4b11-8978-3cb5cee1df29": [
            "node_1150"
        ],
        "8713f79c-abd2-4f3b-9193-ec10e5e6402e": [
            "node_1150"
        ],
        "a7d490bf-762f-4958-b616-81ece9dfd18f": [
            "node_1150"
        ],
        "0aaa49de-6bf4-472e-959b-f50b104a980d": [
            "node_690"
        ],
        "2d4fbe81-8da4-4386-9c45-7078a5e0ca6b": [
            "node_690"
        ],
        "1aa8eab8-2f6a-48ad-bb57-7ba9eee2e72d": [
            "node_690"
        ],
        "fbe6c219-059e-441b-9c48-4885aabf84cb": [
            "node_690"
        ],
        "e7f24045-706b-4d1b-9e9c-d115d250e5d7": [
            "node_690"
        ],
        "6fd6487d-5763-4585-ad51-d69e904d1a43": [
            "node_690"
        ],
        "d97f7af6-4bd0-45a4-ae48-dca16768b162": [
            "node_690"
        ],
        "50e54c79-3f8c-4471-a36c-61be6caa443b": [
            "node_690"
        ],
        "9d172c09-91b2-4b21-bdde-6c4c0d25b11d": [
            "node_690"
        ],
        "7d97bbdb-a4d0-46e2-9e44-5512e0b8ea3c": [
            "node_690"
        ],
        "fe96928c-79f0-453d-acd5-282634c66401": [
            "node_256"
        ],
        "f17ece9f-9bd0-465d-bbff-9abfe827e729": [
            "node_256"
        ],
        "ae4d7765-3da6-42bc-aaa6-3df09976eb5d": [
            "node_256"
        ],
        "30a95646-0503-449a-ba66-7ad7b4eb1242": [
            "node_256"
        ],
        "535778d3-8d33-4fab-ac42-a91569335dfa": [
            "node_256"
        ],
        "7c885f7b-dbf1-46d8-9701-4bc392e56136": [
            "node_1186"
        ],
        "6016dbed-a95a-4167-a024-0150b14c352e": [
            "node_1186"
        ],
        "2545c666-890b-4443-a381-24551c75d4c4": [
            "node_1186"
        ],
        "bad03ef2-3180-456f-a62c-4ec2155b0120": [
            "node_793"
        ],
        "db646a67-86ff-407e-80db-b9081e127b04": [
            "node_793"
        ],
        "1be1743a-ad26-4639-9e52-be233a12bd36": [
            "node_793"
        ],
        "a7506f63-814c-4fde-b8cb-357a0340529d": [
            "node_793"
        ],
        "4662a78c-e9e7-4fb1-a54b-9b895b2cf974": [
            "node_793"
        ],
        "a07d3763-deef-4916-b979-9a0e3c9d9250": [
            "node_793"
        ],
        "6cefa38a-9905-4061-9f4e-0c35a9b8c3b6": [
            "node_793"
        ],
        "5976bf4a-bc2d-42b7-ae73-dbcf3ec17103": [
            "node_665"
        ],
        "be2e3140-19a0-44d6-9baa-8f565b8fec7b": [
            "node_665"
        ],
        "a4e21338-18c7-40f5-8a9e-e70a773e6d56": [
            "node_665"
        ],
        "d817e598-f943-4010-a270-8b0805310796": [
            "node_665"
        ],
        "d797d9a8-2be0-4816-b717-4cb72905bb94": [
            "node_665"
        ],
        "c658fc12-a347-4a52-8003-8ee56f05f371": [
            "node_665"
        ],
        "f3688416-be30-4ebf-8f70-106c7d64c8d8": [
            "node_665"
        ],
        "3fa2a676-adc7-48cf-b34e-29bcf3306a52": [
            "node_665"
        ],
        "c2032714-8dd8-4898-b60d-5e95cbffecaf": [
            "node_1245"
        ],
        "d6412bac-4f1d-4bb5-b4e2-cfa9effc2e6d": [
            "node_1245"
        ],
        "44099708-e8ce-475e-9e3a-b5e2a0d3c0fc": [
            "node_1245"
        ],
        "7d1c8d11-53f9-4d68-bd2e-1726b5d9e83a": [
            "node_1245"
        ],
        "3a342b7a-2b61-4a80-a74d-dc35bc9a04cd": [
            "node_1245"
        ],
        "1657b468-aae6-4cf0-95d1-07910883a257": [
            "node_624"
        ],
        "7c4ae66e-7aad-4311-b909-85379d300229": [
            "node_624"
        ],
        "99523279-8457-4bb9-9c4e-643cef3913dc": [
            "node_624"
        ],
        "4a625ecf-c738-409e-bdf7-207fdede60bf": [
            "node_624"
        ],
        "a7474215-6bda-4948-9116-38d60658c1b6": [
            "node_624"
        ],
        "0de2e458-39fa-465f-9295-29a771fc1949": [
            "node_34"
        ],
        "5fbf876b-3581-4727-ae07-976ebf01e6e2": [
            "node_34"
        ],
        "de7eefcd-1a9b-4a35-8891-c365ff3f0fd9": [
            "node_34"
        ],
        "948d83b1-9c7e-4fc9-b97d-c57a94cf5bae": [
            "node_34"
        ],
        "48b1ab24-2b11-49f3-8f16-013d3ea19b91": [
            "node_34"
        ],
        "44ff0a13-0efd-4040-90b1-3e52d7e8b532": [
            "node_34"
        ],
        "60779489-f813-4836-8f29-86a30ca69d9c": [
            "node_34"
        ],
        "9a4b9912-5d1e-4020-9504-0e29f931213f": [
            "node_631"
        ],
        "a854bd0d-e977-4cb5-ab2b-319c6f1db94a": [
            "node_631"
        ],
        "de6e4ca7-ba6a-4bf3-b0c7-4946b87bcb4e": [
            "node_631"
        ],
        "949393ef-53b8-49d7-926f-2012146c2439": [
            "node_631"
        ],
        "0f15c79c-1190-4cdc-930f-bc4536cf497e": [
            "node_631"
        ],
        "6a219116-f849-46f6-9ef5-0b68742de112": [
            "node_1108"
        ],
        "00e977a3-d852-4569-bd34-914b2a871e86": [
            "node_1108"
        ],
        "4d824d24-b523-46d7-a849-5119cc8ce7c1": [
            "node_1108"
        ],
        "928adc15-a512-47a3-9295-a852d25cfcd7": [
            "node_1108"
        ],
        "c6718e9b-35e8-4bc5-879a-01356422efdb": [
            "node_1108"
        ],
        "a1eea70a-124c-4fab-8857-afa100e73078": [
            "node_905"
        ],
        "7a12cc9c-0b26-4cfb-abf3-3382a058e697": [
            "node_905"
        ],
        "7a2a5c77-5308-45d4-9866-6e48aedb66e5": [
            "node_905"
        ],
        "a7b8c1cc-359d-4b6f-9549-b775fa531b7e": [
            "node_905"
        ],
        "29e5e45f-b168-4212-90bf-7bebe293ff69": [
            "node_905"
        ],
        "f0750cee-8ff8-41f2-8167-9fa87a976681": [
            "node_405"
        ],
        "5e20c0ce-d337-4e7c-a683-07866ba0c765": [
            "node_405"
        ],
        "0c84f2b2-8d5f-4a74-a354-2d65191e2632": [
            "node_405"
        ],
        "7e959a06-fe45-411d-8fe2-948171e5a228": [
            "node_405"
        ],
        "d0713dfc-6323-4a2a-a772-c143434eb879": [
            "node_405"
        ],
        "b75f3cd9-348c-4110-8bea-7c3ce4258b7a": [
            "node_891"
        ],
        "3a60c89e-00a1-467d-a3d6-5358337ab481": [
            "node_891"
        ],
        "7ecdbdc2-1b96-4d5b-aa7e-f245129a7fb2": [
            "node_891"
        ],
        "13f74c75-73ae-4961-bc31-58fab63e6458": [
            "node_891"
        ],
        "d889858d-3a33-4048-a7cd-03a68ac92b01": [
            "node_891"
        ],
        "89a46b34-fa23-4888-9a20-8d64075d5d98": [
            "node_135"
        ],
        "f70c7d6b-4abf-468c-9cd6-010ad14710a0": [
            "node_135"
        ],
        "71c9a143-803f-4326-895f-40cc5fe5bd14": [
            "node_135"
        ],
        "d0af72a0-0f52-42c0-aef8-469bc555007a": [
            "node_135"
        ],
        "f72359e1-82aa-4b49-bbbe-d0ab95bff926": [
            "node_135"
        ],
        "117836e5-13c6-4e4e-b79c-c9817c25084a": [
            "node_357"
        ],
        "9e735e2d-218d-46eb-ab98-1b2ea071a5d3": [
            "node_357"
        ],
        "5ffe3705-1423-4f3f-bb77-e696cf4522b7": [
            "node_357"
        ],
        "a8a1a3b9-3b09-4dad-a41b-e9fc4ca91c1a": [
            "node_357"
        ],
        "47b78597-1153-4dc0-b512-939c3a1b6622": [
            "node_357"
        ],
        "7bfc4c09-9bd7-4c7f-9f39-68a1bb63b7e4": [
            "node_1158"
        ],
        "73e336c4-ae8a-47ef-a93f-5093aac0bec9": [
            "node_1158"
        ],
        "e51b5749-9b09-492a-b9c7-8c3bc31aca6c": [
            "node_1158"
        ],
        "d03dfd3c-28a9-47b9-aaf3-4d8ceeadc424": [
            "node_1158"
        ],
        "c2c61740-8530-4ca7-9439-1735322c5c89": [
            "node_1158"
        ],
        "fcabceb1-b971-4976-a43b-6c966a278185": [
            "node_101"
        ],
        "45af3936-3524-4790-831d-d61d62a1ef4e": [
            "node_101"
        ],
        "11208efc-d417-405f-85f9-00b5d486b687": [
            "node_101"
        ],
        "88002e89-c497-4f29-b995-2707cc5e1a7d": [
            "node_101"
        ],
        "2510d2cd-40de-4752-9c90-a42ebfe44142": [
            "node_101"
        ],
        "fa490ced-0d58-442d-96d4-ab5bcad2764b": [
            "node_298"
        ],
        "263fa17a-80b6-48bc-9a5f-6ad9cb362b70": [
            "node_298"
        ],
        "6c0f1e60-01e5-493d-ad89-9959b0e0b17f": [
            "node_298"
        ],
        "8487c4c0-e3e1-4164-b7c9-ace963147fb5": [
            "node_298"
        ],
        "aca1c5d4-6cb1-4561-aa20-10280b8c8f81": [
            "node_298"
        ],
        "3368044c-d085-4f96-84ec-ed1754c75702": [
            "node_1114"
        ],
        "d7b4bced-eb20-4aea-9666-cee453de0fa2": [
            "node_1114"
        ],
        "77d81e30-9cbc-4abe-b50e-4c9eddfbee48": [
            "node_1114"
        ],
        "ae44d192-dbfb-43e6-8f67-c3fb65205ce7": [
            "node_1114"
        ],
        "673bf1c3-86a3-4886-92d4-a165dee988f9": [
            "node_1114"
        ],
        "17d62603-089e-4fba-b5e5-0d945129177f": [
            "node_1114"
        ],
        "5dd98063-506a-4eb8-9f3d-ca44ea0d6597": [
            "node_1114"
        ],
        "872e3635-0b7d-4118-b3e6-4b28d2f60abb": [
            "node_1114"
        ],
        "4c8b49b4-e727-4695-98ac-3555ac76c1d9": [
            "node_35"
        ],
        "6a08e6f0-c51b-4e5b-b612-f8502bb09847": [
            "node_35"
        ],
        "c31065cc-094d-42a9-b8f5-d9c57ec9e79e": [
            "node_35"
        ],
        "b235414d-ef95-4c9f-845d-4a3306d85ad9": [
            "node_35"
        ],
        "a4c9291e-3ffa-47e8-8541-f45e8e332dfb": [
            "node_35"
        ],
        "d706a530-48e4-48a0-8b78-b373db10b292": [
            "node_1293"
        ],
        "1545e2e5-4e16-423f-b285-4d31f550e98c": [
            "node_1293"
        ],
        "33166945-acaf-46db-be80-d24048e7195d": [
            "node_1293"
        ],
        "3bb90531-4d3c-4ddb-a1cd-e8da42f8e466": [
            "node_1293"
        ],
        "d285574d-5cb6-4dc5-ad57-d774f1e82ad8": [
            "node_1293"
        ],
        "6f793f22-3678-4869-bae1-eb79e2ebfe00": [
            "node_1119"
        ],
        "f56dfac7-5533-45f7-a8c2-d04c761f03b4": [
            "node_1119"
        ],
        "19f06acb-eb89-468a-8622-331e44cfdb60": [
            "node_1119"
        ],
        "2aadb1b3-1ac9-4272-8105-63d21335148a": [
            "node_1119"
        ],
        "9badf5fa-61c7-4323-9e21-f2d8eef37c31": [
            "node_1119"
        ],
        "043b64ba-5bfd-4b80-8827-a240a6cf18e6": [
            "node_270"
        ],
        "679420eb-c3e1-4678-8a97-0afceabf4119": [
            "node_270"
        ],
        "386e3cf2-1580-405c-ae25-3053472136d5": [
            "node_270"
        ],
        "15edfe5e-4a3d-4041-a385-d8c6e3756431": [
            "node_270"
        ],
        "9dbca9e2-8eed-48f0-b256-c27c549c4e6b": [
            "node_270"
        ],
        "19b91dc9-133d-48ba-9b6b-e9852c3eae68": [
            "node_270"
        ],
        "e90af592-7eb1-48fe-bc7d-ea902a1ded3f": [
            "node_270"
        ],
        "8d64c02c-76ae-45f0-b81f-630d4614dc85": [
            "node_270"
        ],
        "6dfa30b8-6228-46e7-925a-120233a4fe41": [
            "node_600"
        ],
        "92427aeb-90b8-4544-86f6-8950a6e85f70": [
            "node_600"
        ],
        "057a9214-e8ed-475d-856c-3792857cc593": [
            "node_600"
        ],
        "34b45db1-0a15-4ded-95b7-54cf077a0a70": [
            "node_600"
        ],
        "6f93bb61-8c4d-4402-b6b3-a0994cd2c3c3": [
            "node_600"
        ],
        "ab8ea251-e94b-41b5-9503-805e66050e2c": [
            "node_227"
        ],
        "e32c1b1c-12c1-4496-add7-0661ec3ca890": [
            "node_227"
        ],
        "62706362-d128-4a54-8e4f-0dff7411bdde": [
            "node_227"
        ],
        "25d64099-0005-4255-ae04-1d5ea166a4c6": [
            "node_227"
        ],
        "442f109e-ad1b-4c3e-82da-a712637d3e08": [
            "node_227"
        ],
        "a6f4ee85-fc8b-46a8-a33f-afa9475cac16": [
            "node_708"
        ],
        "63156551-9347-4e56-a8c5-1aab2d48ffe4": [
            "node_708"
        ],
        "ce83a617-5243-44d8-ba11-b34abbcb7edf": [
            "node_708"
        ],
        "f9256a57-6617-4855-9091-a1c043b17115": [
            "node_708"
        ],
        "6b79077c-f035-46c7-b39d-5df477e252cc": [
            "node_708"
        ],
        "4ff9d4b8-35c7-4b53-9e3f-301ccf1d7b1d": [
            "node_708"
        ],
        "2968152f-4a7f-4d44-83c0-6bb55d6b0d41": [
            "node_708"
        ],
        "8dddfceb-2a0d-46fc-acba-5c6b3dda8eef": [
            "node_297"
        ],
        "6c8b1f84-52ff-4634-9250-23914229a6cc": [
            "node_915"
        ],
        "d6fd5491-e4c1-49fb-b013-fee4215f759b": [
            "node_915"
        ],
        "e0503c46-ac03-4c02-bd79-dbd6837caa3f": [
            "node_915"
        ],
        "56f15cb4-63ee-4ef1-91bf-d9bb5fe0a93c": [
            "node_915"
        ],
        "3bb2616a-9fc3-44f2-84e8-a04ad701b224": [
            "node_915"
        ],
        "b4d9b378-c087-4ae0-8f07-408488b611f5": [
            "node_169"
        ],
        "289b29de-254d-482a-a2d2-e2bb7f1d8a9e": [
            "node_169"
        ],
        "92cef9c7-48bc-4329-b4d5-22bff7c958d3": [
            "node_169"
        ],
        "f6fb3ba1-d15e-48f7-a5c1-96e60ab9cc91": [
            "node_169"
        ],
        "ed30451e-d2ff-4818-9bb5-8c0e13c2757e": [
            "node_169"
        ],
        "3dd68a7e-efba-4227-a7ed-a6070d026cb3": [
            "node_975"
        ],
        "0bc9d297-a7d5-4657-8c6f-980c4049e0f5": [
            "node_975"
        ],
        "b5d41443-5699-418d-b864-8b999f54ffb9": [
            "node_975"
        ],
        "30c4a548-f333-4af7-bb01-077c55f3de25": [
            "node_975"
        ],
        "bc3ab1a6-5273-4a63-a255-44d4ad4b3baf": [
            "node_586"
        ],
        "064ca626-672f-46fc-93ae-9958176f1d39": [
            "node_586"
        ],
        "e451cc32-d392-4960-970c-07be2b8eaa52": [
            "node_586"
        ],
        "dd8c29ce-0087-458e-973f-58cf08995343": [
            "node_586"
        ],
        "8fc674a1-b2e2-4629-ba8c-5733d3f2ef7b": [
            "node_586"
        ],
        "4158ccc9-48f8-4fce-bbcb-d783c319989e": [
            "node_775"
        ],
        "3c24d394-d246-41ac-9431-8f30c7364a9f": [
            "node_775"
        ],
        "64978e0e-f295-4274-9bcc-fc8aa9b28ba9": [
            "node_775"
        ],
        "c6e128a7-2338-48e0-a6dc-6478b10c5989": [
            "node_775"
        ],
        "3e20f6c8-cb25-42b0-b38d-4556482872f9": [
            "node_775"
        ],
        "3c3e4ce7-933c-421b-a632-a49ea6adb0cc": [
            "node_861"
        ],
        "f3c54998-6817-4b21-ae31-caf37a342abb": [
            "node_861"
        ],
        "b3b16557-7fb8-4033-8886-3d272cfd8841": [
            "node_861"
        ],
        "53714882-a4e4-454c-926a-1ecced3ce1a1": [
            "node_861"
        ],
        "53d3ec9e-5121-4a29-9f35-3ff86398e8a0": [
            "node_861"
        ],
        "c1368749-2066-4eac-b1bb-ab3aa9dd15d7": [
            "node_146"
        ],
        "ef4dcc80-0e7f-46c4-a2b5-c248c2bdb4c1": [
            "node_146"
        ],
        "d2b786f6-513c-4711-9b82-4697dae73a37": [
            "node_146"
        ],
        "2c45032c-cd7a-486a-80ac-a25c74f8fc88": [
            "node_146"
        ],
        "54800526-543e-4aa1-9133-1cecf5f63f1e": [
            "node_146"
        ],
        "0b14cbe3-9681-4859-b43e-89396546ca4b": [
            "node_146"
        ],
        "64265bde-1e4e-4836-8e98-24413ddf4cb2": [
            "node_146"
        ],
        "fce2823f-a62a-4c5f-8819-af5b70a70e83": [
            "node_146"
        ],
        "c2009fa0-d905-4ef8-a566-cc4f0b546b6d": [
            "node_146"
        ],
        "0ee4b410-bb3a-424f-9041-d224abc6000f": [
            "node_146"
        ],
        "ba5fef3c-62b7-45d8-a2dd-7a8991023c32": [
            "node_1078"
        ],
        "6dd8d241-6324-4868-9540-14f57eb30826": [
            "node_1078"
        ],
        "ee83c264-7317-40bc-a0e6-a323cfc3d7f3": [
            "node_1078"
        ],
        "cc56bd2c-cb12-4760-99f8-d35991e6229b": [
            "node_1078"
        ],
        "380c8fde-2100-4a78-98c9-1b1e42659053": [
            "node_1078"
        ],
        "59b3904c-cee4-4958-abf0-fd3db02b71ca": [
            "node_1292"
        ],
        "e840e7fa-0a16-4939-b2a9-45fa1e5ecfbf": [
            "node_1292"
        ],
        "032e6bd5-658e-4a4b-9cd2-dd261e529762": [
            "node_1292"
        ],
        "052d5fb0-bf32-41e1-a336-10dbb8999efc": [
            "node_1292"
        ],
        "d763305a-da8c-4121-96a7-5ceaefe8f508": [
            "node_1292"
        ],
        "179441b4-0707-4756-82b1-e7af8cf48e1e": [
            "node_1091"
        ],
        "b8efca98-ff55-4b93-a6a1-4d13d4574fc5": [
            "node_1091"
        ],
        "751b80db-0713-470b-9dc5-de7d7be688ab": [
            "node_1091"
        ],
        "3e518faf-692e-44b5-82f4-e248b186190a": [
            "node_1091"
        ],
        "869cc6ee-e7b2-4ac5-80b6-be8f5e663a0b": [
            "node_1091"
        ],
        "fde17296-b6d1-4212-b45f-0273e0a6aa16": [
            "node_218"
        ],
        "dbababcf-5814-4c31-b4b1-236bb288ea6b": [
            "node_218"
        ],
        "25d175a4-8f10-4632-9cfd-aff1c5b60f83": [
            "node_218"
        ],
        "2d4bfdc6-0737-4bd5-be6b-1f1aa3782cbe": [
            "node_218"
        ],
        "c1953bd0-2119-4e96-9c75-fc7a04c3933e": [
            "node_218"
        ]
    },
    "mode": "text"
}